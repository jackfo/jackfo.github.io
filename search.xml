<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[IO流相关问题]]></title>
    <url>%2F2018%2F01%2F22%2Fjava%2F2018-01-22-1%2F</url>
    <content type="text"><![CDATA[Q1GC能关闭IO资源？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;垃圾回收主要回收的是内存资源，而io开辟的资源是磁盘资源，所以不能被回收，需要手动释放。 Q2java7之后怎么样可以不写流close()代码而实现流的自动关闭 jdk为我们做了什么 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java7增强了try语句的功能，它允许在try关键字后紧跟一对圆括号，圆括号可以声明、初始化一个或多个资源（此处的资源是指那些必须在程序结束时显式关闭的资源，比如数据库连接，网络连接等），try-with-resources 是一个定义了一个或多个资源的try 声明，try语句在该语句结束时自动关闭这些资源。try-with-resources确保每一个资源在处理完成后都会被关闭。这些资源必须实现AutoCloseable或者Closeable接口，实现这两个接口就必须实现close() 方法。 Q3 有一个很大的文件，超过24字节大小，里面有中英文掺杂，现在用一个24字节的数组不断读取，会有什么问题吗？ 编码不一致 Q4推回输入流 http://blog.longjiazuo.com/archives/4462 Q5随机访问流，也就是RandomAccessFile流 http://blog.longjiazuo.com/archives/4576 Q6流中的命令模式 http://blog.longjiazuo.com/archives/4488]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java的流设计模型-节点流/处理流]]></title>
    <url>%2F2018%2F01%2F22%2Fjava%2F2018-01-22%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在字节流和字符流中同时讲述了输出流和输入流，现在就简单的对节点流和处理流进行分析 节点流Vs处理流 节点流:程序用于直接操作目标设备所对应的类叫节点流。 处理流:程序通过一个间接流类去调用节点流类，以达到更加灵活方便地读写各种类型的数据，这个间接流类就是处理流。 节点流节点流的类型 （1）File 文件流。对文件进行读、写操作 ：FileReader、FileWriter、FileInputStream、FileOutputStream。、 （2）Memory1）从/向内存数组读写数据: CharArrayReader与 CharArrayWriter、ByteArrayInputStream与ByteArrayOutputStream。2）从/向内存字符串读写数据 StringReader、StringWriter、StringBufferInputStream。 （3）Pipe管道流。 实现管道的输入和输出（进程间通信）: PipedReader与PipedWriter、PipedInputStream与PipedOutputStream。 节点流执行的图示 处理流处理流的类型 （1）Buffering缓冲流：在读入或写出时，对数据进行缓存，以减少I/O的次数：BufferedReader与BufferedWriter、BufferedInputStream与BufferedOutputStream。 （2）Filtering 滤流：在数据进行读或写时进行过滤：FilterReader与FilterWriter、FilterInputStream与FilterOutputStream。 （3）Converting between Bytes and Characters 转换流：按照一定的编码/解码标准将字节流转换为字符流，或进行反向转换（Stream到Reader）：InputStreamReader、OutputStreamWriter。 （4）Object Serialization 对象流 ：ObjectInputStream、ObjectOutputStream。 （5）DataConversion数据流： 按基本数据类型读、写（处理的数据是Java的基本类型（如布尔型，字节，整数和浮点数））：DataInputStream、DataOutputStream 。 （6）Counting计数流： 在读入数据时对行记数 ：LineNumberReader、LineNumberInputStream。 （7）Peeking Ahead预读流： 通过缓存机制，进行预读 ：PushbackReader、PushbackInputStream。 （8）Printing打印流： 包含方便的打印方法 ：PrintWriter、PrintStream。 处理流的图示: 参考链接:JAVA——IO流 之 节点流与处理流（2）http://blog.csdn.net/jingzi123456789/article/details/72123937]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java的流设计模型-字节流/字符流]]></title>
    <url>%2F2018%2F01%2F21%2Fjava%2F2018-01-21%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;java的流按照处理数据单位不同可以分为：字节流和字符流。按照实现功能不同可以分为：节点流和处理流。从程序的角度分为输入流和输出流。 字节流VS字符流 字节流:处理的最基本单位为单个字节，它通常用来处理二进制数据 字符流:处理的最基本的单元是Unicode码元（大小2字节），它通常用来处理文本数据 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从这张图可以看出IO流共有四个接口InputStream、OutPutStream、Reader、Writer四个接口，具体描述如下： InputStream:字节流输入流接口OutPutStream:字节流输出流接口Reader:字符流输入流接口Writer:字符流输出流接口 字符流与字节流的区别 字节流操作的基本单元为字节；字符流操作的基本单元为Unicode码元。 字节流默认不使用缓冲区；字符流使用缓冲区。 字节流通常用于处理二进制数据，实际上它可以处理任意类型的数据，但它不支持直接写入或读取Unicode码元；字符流通常处理文本数据，它支持写入及读取Unicode码元。 字节流与字符流的存储过程字节流的输入过程(读取)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所有的字节流都实现了InputStream接口,所以首先应该看这个接口定义的方法。 1 、int read() 功能：读取一个字节的数据，并且返回读到得数据，如果返回-1，则表示读到输入流的末尾。 2、int read(byte[] b) 功能：从输入流中读取一定量的字节，并将其存储在字节数组b中，返回实际读取的字节数，如果返回-1，则表示读到输入流的末尾。 3、int read(byte[] b, int off, int len) 功能：将数据读入一个字节数组，同时返回读取的实际字节数，如果返回-1，则表示读到输入流的末尾。off指定在数组b中存放数据的起始偏移位置，len指定读取的最大字节数。 4、available() 功能：返回此输入流下一个方法调用可以不受阻塞地从此输入流读取或跳过的估计字节数。 5、close() 功能：关闭输入流，释放这个流的相关资源。 由FileInputStream可以看出其都是调用本地方法，进行数据的传输. 1234567891011121314151617 private native void open0(String name) throws FileNotFoundException;private void open(String name) throws FileNotFoundException &#123; open0(name); &#125;public int read() throws IOException &#123; return read0(); &#125;private native int read0() throws IOException; private native int readBytes(byte b[], int off, int len) throws IOException;public int read(byte b[]) throws IOException &#123; return readBytes(b, 0, b.length);&#125; 字节流的输出过程&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所有的字节流都实现了OutputStream接口，所以应先看这个接口定义的方法. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1 、int write(int b) 功能：将b的最低的一个字节写入此输入流，其他三个字节丢弃。 2、int write(byte[] b) 功能：将指定的字节数组b写入此输入流。 3、int write(byte[] b, int off, int len) 功能：将指定byte数组中从偏移量off开始的len个字节写入输入流。 4、flush() 功能：刷新此输入流并强制写出所有缓冲的输出字节数。 5、close() 功能：关闭输出流，释放这个流的相关资源。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102private native void open0(String name, boolean append) throws FileNotFoundException; // wrap native call to allow instrumentation /** * Opens a file, with the specified name, for overwriting or appending. * @param name name of file to be opened * @param append whether the file is to be opened in append mode */ private void open(String name, boolean append) throws FileNotFoundException &#123; open0(name, append); &#125; /** * Writes the specified byte to this file output stream. * * @param b the byte to be written. * @param append &#123;@code true&#125; if the write operation first * advances the position to the end of file */ private native void write(int b, boolean append) throws IOException; /** * Writes the specified byte to this file output stream. Implements * the &lt;code&gt;write&lt;/code&gt; method of &lt;code&gt;OutputStream&lt;/code&gt;. * * @param b the byte to be written. * @exception IOException if an I/O error occurs. */ public void write(int b) throws IOException &#123; write(b, append); &#125; /** * Writes a sub array as a sequence of bytes. * @param b the data to be written * @param off the start offset in the data * @param len the number of bytes that are written * @param append &#123;@code true&#125; to first advance the position to the * end of file * @exception IOException If an I/O error has occurred. */ private native void writeBytes(byte b[], int off, int len, boolean append) throws IOException; /** * Writes &lt;code&gt;b.length&lt;/code&gt; bytes from the specified byte array * to this file output stream. * * @param b the data. * @exception IOException if an I/O error occurs. */ public void write(byte b[]) throws IOException &#123; writeBytes(b, 0, b.length, append); &#125; /** * Writes &lt;code&gt;len&lt;/code&gt; bytes from the specified byte array * starting at offset &lt;code&gt;off&lt;/code&gt; to this file output stream. * * @param b the data. * @param off the start offset in the data. * @param len the number of bytes to write. * @exception IOException if an I/O error occurs. */ public void write(byte b[], int off, int len) throws IOException &#123; writeBytes(b, off, len, append); &#125; /** * Closes this file output stream and releases any system resources * associated with this stream. This file output stream may no longer * be used for writing bytes. * * &lt;p&gt; If this stream has an associated channel then the channel is closed * as well. * * @exception IOException if an I/O error occurs. * * @revised 1.4 * @spec JSR-51 */ public void close() throws IOException &#123; synchronized (closeLock) &#123; if (closed) &#123; return; &#125; closed = true; &#125; if (channel != null) &#123; channel.close(); &#125; fd.closeAll(new Closeable() &#123; public void close() throws IOException &#123; close0(); &#125; &#125;); &#125; 字符流的输入过程123456789101112131415161718192021222324252627282930* @see BufferedReader* @see LineNumberReader* @see CharArrayReader* @see InputStreamReader* @see FileReader* @see FilterReader* @see PushbackReader* @see PipedReader* @see StringReader* @see Writerabstract void close() 关闭该流并释放与之关联的所有资源。 void mark(int readAheadLimit) 标记流中的当前位置。 boolean markSupported() 判断此流是否支持 mark() 操作。 int read() 读取单个字符。 int read(char[] cbuf) 将字符读入数组。 abstract int read(char[] cbuf, int off, int len) 将字符读入数组的某一部分。 int read(CharBuffer target) 试图将字符读入指定的字符缓冲区。 boolean ready() 判断是否准备读取此流。 void reset() 重置该流。 long skip(long n) 跳过字符。 现在以FileReader为例进行分析: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个过程中,实例化FileReader的过程中，依旧是用字节流打开文件，然后通过StreamDecoder将字节流进行解码，在读取的过程中主要是通过这个解码实例进行读取数据。下面我们看一看read的具体实现过程:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在StreamDecoder中,主要用的是四个方法，read0(), read(char cbuf[],int offset,int length) implRead(char[] cbuf, int off, int end),readBytes() 现在已read(char cbuf[],int offset,int length) 作为入口进行分析,先检查有没有遗留字符有的话直接进行读，如果剩余长度为1则调用read0方法（这是因为要保持每次读取读到两个字节），然后在read0之后看有遗留字符则直接读出来，没有新构造一个调用方法来调用read(cb,0,2),这个时候应该没有遗留字符，则调用implRead进行解码读取。由于这个代码是sun公司下，源码在IDE下一般很难直接看到，故展示如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379package sun.nio.cs;import java.io.*;import java.nio.*;import java.nio.channels.*;import java.nio.charset.*;public class StreamDecoder extends Reader&#123; private static final int MIN_BYTE_BUFFER_SIZE = 32; private static final int DEFAULT_BYTE_BUFFER_SIZE = 8192; private volatile boolean isOpen = true; //确保流文件是打开的 private void ensureOpen() throws IOException &#123; if (!isOpen) throw new IOException("Stream closed"); &#125; // In order to handle surrogates properly we must never try to produce // fewer than two characters at a time. If we're only asked to return one // character then the other is saved here to be returned later. //每次要求返回两个字符，如果只读取一个字符，另外一个字符保存在这里 private boolean haveLeftoverChar = false; private char leftoverChar; // Factories for java.io.InputStreamReader //InputStreamReader的工厂 public static StreamDecoder forInputStreamReader(InputStream in, Object lock, String charsetName) throws UnsupportedEncodingException &#123; String csn = charsetName; if (csn == null) //设置默认编码集 csn = Charset.defaultCharset().name(); try &#123; if (Charset.isSupported(csn)) return new StreamDecoder(in, lock, Charset.forName(csn)); &#125; catch (IllegalCharsetNameException x) &#123; &#125; throw new UnsupportedEncodingException (csn); &#125; public static StreamDecoder forInputStreamReader(InputStream in, Object lock, Charset cs) &#123; return new StreamDecoder(in, lock, cs); &#125; public static StreamDecoder forInputStreamReader(InputStream in, Object lock, CharsetDecoder dec) &#123; return new StreamDecoder(in, lock, dec); &#125; // Factory for java.nio.channels.Channels.newReader public static StreamDecoder forDecoder(ReadableByteChannel ch, CharsetDecoder dec, int minBufferCap) &#123; return new StreamDecoder(ch, dec, minBufferCap); &#125; // -- Public methods corresponding to those in InputStreamReader -- //响应InputStreamReader的共有方法 // All synchronization and state/argument checking is done in these public // methods; the concrete stream-decoder subclasses defined below need not // do any such checking. //所有同步和状态参数检查在这些公共完成所以子类不需要检查 public String getEncoding() &#123; if (isOpen()) return encodingName(); return null; &#125; public int read() throws IOException &#123; return read0(); &#125; private int read0() throws IOException &#123; synchronized (lock) &#123; // Return the leftover char, if there is one //如果有遗留字符直接返回,即上次读取了两个字符之后剩下的 if (haveLeftoverChar) &#123; haveLeftoverChar = false; return leftoverChar; &#125; // Convert more bytes //转化更多的字节 char cb[] = new char[2]; //读取两个字符放入cb int n = read(cb, 0, 2); switch (n) &#123; case -1: //如果一个没有读到返回-1 return -1; case 2: //如果读取到两个字符保留第二个字符由于没有break所以在case1中返回读取的第一个字符 leftoverChar = cb[1]; haveLeftoverChar = true; // FALL THROUGH case 1: //如果读取到一个字符,直接进行返回 return cb[0]; default: assert false : n; return -1; &#125; &#125; &#125; public int read(char cbuf[], int offset, int length) throws IOException &#123; //设置读取偏移量 int off = offset; //设置读取长度 int len = length; synchronized (lock) &#123; //确保流被打开 ensureOpen(); //检查偏移量和长度 if ((off &lt; 0) || (off &gt; cbuf.length) || (len &lt; 0) || ((off + len) &gt; cbuf.length) || ((off + len) &lt; 0)) &#123; throw new IndexOutOfBoundsException(); &#125; if (len == 0) return 0; int n = 0; //如果具有遗留字符直接返回，将其读取，此时读取长度为0，或者implReady为false则直接返回读取长度1 if (haveLeftoverChar) &#123; // Copy the leftover char into the buffer cbuf[off] = leftoverChar; off++; len--; haveLeftoverChar = false; n = 1; if ((len == 0) || !implReady()) // Return now if this is all we can produce w/o blocking return n; &#125; //如果剩余读取长度为1，调用read0里面会在调用这个方法进行读取 if (len == 1) &#123; // Treat single-character array reads just like read() int c = read0(); if (c == -1) return (n == 0) ? -1 : n; cbuf[off] = (char)c; return n + 1; &#125; // return n + implRead(cbuf, off, off + len); &#125; &#125; public boolean ready() throws IOException &#123; synchronized (lock) &#123; ensureOpen(); return haveLeftoverChar || implReady(); &#125; &#125; public void close() throws IOException &#123; synchronized (lock) &#123; if (!isOpen) return; implClose(); isOpen = false; &#125; &#125; private boolean isOpen() &#123; return isOpen; &#125; // -- Charset-based stream decoder impl -- // In the early stages of the build we haven't yet built the NIO native // code, so guard against that by catching the first UnsatisfiedLinkError // and setting this flag so that later attempts fail quickly. // private static volatile boolean channelsAvailable = true; private static FileChannel getChannel(FileInputStream in) &#123; if (!channelsAvailable) return null; try &#123; return in.getChannel(); &#125; catch (UnsatisfiedLinkError x) &#123; channelsAvailable = false; return null; &#125; &#125; private Charset cs; private CharsetDecoder decoder; private ByteBuffer bb; // Exactly one of these is non-null private InputStream in; private ReadableByteChannel ch; StreamDecoder(InputStream in, Object lock, Charset cs) &#123; this(in, lock, cs.newDecoder() .onMalformedInput(CodingErrorAction.REPLACE) .onUnmappableCharacter(CodingErrorAction.REPLACE)); &#125; StreamDecoder(InputStream in, Object lock, CharsetDecoder dec) &#123; super(lock); this.cs = dec.charset(); this.decoder = dec; // This path disabled until direct buffers are faster if (false &amp;&amp; in instanceof FileInputStream) &#123; ch = getChannel((FileInputStream)in); if (ch != null) bb = ByteBuffer.allocateDirect(DEFAULT_BYTE_BUFFER_SIZE); &#125; if (ch == null) &#123; this.in = in; this.ch = null; bb = ByteBuffer.allocate(DEFAULT_BYTE_BUFFER_SIZE); &#125; bb.flip(); // So that bb is initially empty &#125; StreamDecoder(ReadableByteChannel ch, CharsetDecoder dec, int mbc) &#123; this.in = null; this.ch = ch; this.decoder = dec; this.cs = dec.charset(); this.bb = ByteBuffer.allocate(mbc &lt; 0 ? DEFAULT_BYTE_BUFFER_SIZE : (mbc &lt; MIN_BYTE_BUFFER_SIZE ? MIN_BYTE_BUFFER_SIZE : mbc)); bb.flip(); &#125; private int readBytes() throws IOException &#123; //将缓冲区的有效数据全部移到缓冲区的首部，而position指向下一个可写位置。 bb.compact(); try &#123; //ch表示通道流 bb表示缓冲字节数组 if (ch != null) &#123; //从通道中读取数据 int n = ch.read(bb); if (n &lt; 0) return n; &#125; else &#123; //从输入流中读取数据 int lim = bb.limit(); int pos = bb.position(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); assert rem &gt; 0; int n = in.read(bb.array(), bb.arrayOffset() + pos, rem); if (n &lt; 0) return n; if (n == 0) throw new IOException("Underlying input stream returned zero bytes"); assert (n &lt;= rem) : "n = " + n + ", rem = " + rem; bb.position(pos + n); &#125; &#125; finally &#123; // Flip even when an IOException is thrown, // otherwise the stream will stutter bb.flip(); &#125; int rem = bb.remaining(); assert (rem != 0) : rem; return rem; &#125; int implRead(char[] cbuf, int off, int end) throws IOException &#123; // In order to handle surrogate pairs, this method requires that // the invoker attempt to read at least two characters. Saving the // extra character, if any, at a higher level is easier than trying // to deal with it here. assert (end - off &gt; 1); //构造一个CharBuffer实例,默认是堆缓存 CharBuffer cb = CharBuffer.wrap(cbuf, off, end - off); if (cb.position() != 0) // Ensure that cb[0] == cbuf[off] //创建新的字符缓冲区，其内容为此缓冲区内容的共享子序列 cb = cb.slice(); boolean eof = false; for (;;) &#123; //从给定的输入缓冲区中解码尽可能多的字节，把结果写入给定的输出缓冲区 CoderResult cr = decoder.decode(bb, cb, eof); //如果出现下溢情况,指示已解码尽可能多的输入缓冲区。如果没有进一步的输入，则调用者可以进行到解码操作的下一个步骤 if (cr.isUnderflow()) &#123; if (eof) break; if (!cb.hasRemaining()) break; if ((cb.position() &gt; 0) &amp;&amp; !inReady()) break; // Block at most once int n = readBytes(); if (n &lt; 0) &#123; eof = true; if ((cb.position() == 0) &amp;&amp; (!bb.hasRemaining())) break; decoder.reset(); &#125; continue; &#125; //如果出现溢出现象，指示该输出缓冲区中没有足够空间来解码任何更多字节 if (cr.isOverflow()) &#123; assert cb.position() &gt; 0; break; &#125; cr.throwException(); &#125; if (eof) &#123; // 重置此解码器，清除所有内部状态 decoder.reset(); &#125; if (cb.position() == 0) &#123; if (eof) return -1; assert false; &#125; return cb.position(); &#125; String encodingName() &#123; return ((cs instanceof HistoricallyNamedCharset) ? ((HistoricallyNamedCharset)cs).historicalName() : cs.name()); &#125; private boolean inReady() &#123; try &#123; return (((in != null) &amp;&amp; (in.available() &gt; 0)) || (ch instanceof FileChannel)); // ## RBC.available()? &#125; catch (IOException x) &#123; return false; &#125; &#125; boolean implReady() &#123; return bb.hasRemaining() || inReady(); &#125; void implClose() throws IOException &#123; if (ch != null) ch.close(); else in.close(); &#125;&#125; 字符流的输出过程1234567891011121314151617181920Writer append(char c) 将指定字符添加到此 writer。 Writer append(CharSequence csq) 将指定字符序列添加到此 writer。 Writer append(CharSequence csq, int start, int end) 将指定字符序列的子序列添加到此 writer.Appendable。 abstract void close() 关闭此流，但要先刷新它。 abstract void flush() 刷新该流的缓冲。 void write(char[] cbuf) 写入字符数组。 abstract void write(char[] cbuf, int off, int len) 写入字符数组的某一部分。 void write(int c) 写入单个字符。 void write(String str) 写入字符串。 void write(String str, int off, int len) 写入字符串的某一部分。 现在以FIleWriter进行分析 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个过程中,实例化FileWrite的过程中，打开文件流，然后通过StreamEncoder将字符编码为字节写入相应的流，在写入的过程中主要是通过这个StreamEncoder实例进行写入数据。下面我们看一看read的具体实现过程:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在StreamDecoder中,主要用的是四个方法，write(char cbuf[], int off, int len), implWrite(char cbuf[], int off, int len),flushLeftoverChar(CharBuffer cb, boolean endOfInput),writeBytes四个方法，现在以write(char cbuf[],int offset,int length) 作为入口进行分析,构建相应的字符缓冲区，将数据给写存入，然后在将数据通过编码的形式写入字节缓冲区，最终将数据写入流中. char –&gt;CharBuffer –&gt; ByteBuffer –&gt;输出流 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316package sun.nio.cs;import java.io.*;import java.nio.*;import java.nio.channels.*;import java.nio.charset.*;public class StreamEncoder extends Writer&#123; private static final int DEFAULT_BYTE_BUFFER_SIZE = 8192; private volatile boolean isOpen = true; private void ensureOpen() throws IOException &#123; if (!isOpen) throw new IOException("Stream closed"); &#125; // Factories for java.io.OutputStreamWriter public static StreamEncoder forOutputStreamWriter(OutputStream out, Object lock, String charsetName) throws UnsupportedEncodingException &#123; String csn = charsetName; if (csn == null) csn = Charset.defaultCharset().name(); try &#123; if (Charset.isSupported(csn)) return new StreamEncoder(out, lock, Charset.forName(csn)); &#125; catch (IllegalCharsetNameException x) &#123; &#125; throw new UnsupportedEncodingException (csn); &#125; public static StreamEncoder forOutputStreamWriter(OutputStream out, Object lock, Charset cs) &#123; return new StreamEncoder(out, lock, cs); &#125; public static StreamEncoder forOutputStreamWriter(OutputStream out, Object lock, CharsetEncoder enc) &#123; return new StreamEncoder(out, lock, enc); &#125; // Factory for java.nio.channels.Channels.newWriter public static StreamEncoder forEncoder(WritableByteChannel ch, CharsetEncoder enc, int minBufferCap) &#123; return new StreamEncoder(ch, enc, minBufferCap); &#125; // -- Public methods corresponding to those in OutputStreamWriter -- // All synchronization and state/argument checking is done in these public // methods; the concrete stream-encoder subclasses defined below need not // do any such checking. public String getEncoding() &#123; if (isOpen()) return encodingName(); return null; &#125; public void flushBuffer() throws IOException &#123; synchronized (lock) &#123; if (isOpen()) implFlushBuffer(); else throw new IOException("Stream closed"); &#125; &#125; public void write(int c) throws IOException &#123; char cbuf[] = new char[1]; cbuf[0] = (char) c; write(cbuf, 0, 1); &#125; public void write(char cbuf[], int off, int len) throws IOException &#123; synchronized (lock) &#123; //确保打开 ensureOpen(); if ((off &lt; 0) || (off &gt; cbuf.length) || (len &lt; 0) || ((off + len) &gt; cbuf.length) || ((off + len) &lt; 0)) &#123; throw new IndexOutOfBoundsException(); &#125; else if (len == 0) &#123; return; &#125; implWrite(cbuf, off, len); &#125; &#125; public void write(String str, int off, int len) throws IOException &#123; /* Check the len before creating a char buffer */ if (len &lt; 0) throw new IndexOutOfBoundsException(); char cbuf[] = new char[len]; str.getChars(off, off + len, cbuf, 0); write(cbuf, 0, len); &#125; public void flush() throws IOException &#123; synchronized (lock) &#123; ensureOpen(); implFlush(); &#125; &#125; public void close() throws IOException &#123; synchronized (lock) &#123; if (!isOpen) return; implClose(); isOpen = false; &#125; &#125; private boolean isOpen() &#123; return isOpen; &#125; // -- Charset-based stream encoder impl -- private Charset cs; private CharsetEncoder encoder; private ByteBuffer bb; // Exactly one of these is non-null private final OutputStream out; private WritableByteChannel ch; // Leftover first char in a surrogate pair private boolean haveLeftoverChar = false; private char leftoverChar; private CharBuffer lcb = null; private StreamEncoder(OutputStream out, Object lock, Charset cs) &#123; this(out, lock, cs.newEncoder() .onMalformedInput(CodingErrorAction.REPLACE) .onUnmappableCharacter(CodingErrorAction.REPLACE)); &#125; private StreamEncoder(OutputStream out, Object lock, CharsetEncoder enc) &#123; super(lock); this.out = out; this.ch = null; this.cs = enc.charset(); this.encoder = enc; // This path disabled until direct buffers are faster if (false &amp;&amp; out instanceof FileOutputStream) &#123; ch = ((FileOutputStream)out).getChannel(); if (ch != null) bb = ByteBuffer.allocateDirect(DEFAULT_BYTE_BUFFER_SIZE); &#125; if (ch == null) &#123; bb = ByteBuffer.allocate(DEFAULT_BYTE_BUFFER_SIZE); &#125; &#125; private StreamEncoder(WritableByteChannel ch, CharsetEncoder enc, int mbc) &#123; this.out = null; this.ch = ch; this.cs = enc.charset(); this.encoder = enc; this.bb = ByteBuffer.allocate(mbc &lt; 0 ? DEFAULT_BYTE_BUFFER_SIZE : mbc); &#125; private void writeBytes() throws IOException &#123; bb.flip(); int lim = bb.limit(); int pos = bb.position(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); if (rem &gt; 0) &#123; if (ch != null) &#123; if (ch.write(bb) != rem) assert false : rem; &#125; else &#123; out.write(bb.array(), bb.arrayOffset() + pos, rem); &#125; &#125; bb.clear(); &#125; private void flushLeftoverChar(CharBuffer cb, boolean endOfInput) throws IOException &#123; //如果不是遗留字符 直接返回 if (!haveLeftoverChar &amp;&amp; !endOfInput) return; if (lcb == null) //分配容量为2的字符缓冲区 lcb = CharBuffer.allocate(2); else lcb.clear(); //如果是遗留字符则将其put进去 if (haveLeftoverChar) lcb.put(leftoverChar); if ((cb != null) &amp;&amp; cb.hasRemaining()) //添加传入的字符缓冲区数据 lcb.put(cb.get()); //切换为读取状态 lcb.flip(); while (lcb.hasRemaining() || endOfInput) &#123; //将字符编码为相应的字节并存入到字节缓冲区 CoderResult cr = encoder.encode(lcb, bb, endOfInput); if (cr.isUnderflow()) &#123; if (lcb.hasRemaining()) &#123; leftoverChar = lcb.get(); if (cb != null &amp;&amp; cb.hasRemaining()) flushLeftoverChar(cb, endOfInput); return; &#125; break; &#125; if (cr.isOverflow()) &#123; assert bb.position() &gt; 0; writeBytes(); continue; &#125; cr.throwException(); &#125; haveLeftoverChar = false; &#125; void implWrite(char cbuf[], int off, int len) throws IOException &#123; //将字符数组包装到缓冲区中。 CharBuffer cb = CharBuffer.wrap(cbuf, off, len); //如果有遗留字符，flushLeftoverChar方式先将遗留字符添加进去再添加字符缓冲区的数据 if (haveLeftoverChar) flushLeftoverChar(cb, false); //如果字符缓冲区有数据，通过编码的方式将其添加到字节缓冲区 while (cb.hasRemaining()) &#123; CoderResult cr = encoder.encode(cb, bb, false); if (cr.isUnderflow()) &#123; assert (cb.remaining() &lt;= 1) : cb.remaining(); //如果字符缓冲区中只剩下一个数据先将其保存作为遗留字符，下次读取再写入，防止这个字需要两个字符 if (cb.remaining() == 1) &#123; haveLeftoverChar = true; leftoverChar = cb.get(); &#125; break; &#125; if (cr.isOverflow()) &#123; assert bb.position() &gt; 0; //将字节缓冲区数据写入到具体的流中 writeBytes(); continue; &#125; cr.throwException(); &#125; &#125; void implFlushBuffer() throws IOException &#123; if (bb.position() &gt; 0) writeBytes(); &#125; void implFlush() throws IOException &#123; implFlushBuffer(); if (out != null) out.flush(); &#125; void implClose() throws IOException &#123; flushLeftoverChar(null, true); try &#123; for (;;) &#123; CoderResult cr = encoder.flush(bb); if (cr.isUnderflow()) break; if (cr.isOverflow()) &#123; assert bb.position() &gt; 0; writeBytes(); continue; &#125; cr.throwException(); &#125; if (bb.position() &gt; 0) writeBytes(); if (ch != null) ch.close(); else out.close(); &#125; catch (IOException x) &#123; encoder.reset(); throw x; &#125; &#125; String encodingName() &#123; return ((cs instanceof HistoricallyNamedCharset) ? ((HistoricallyNamedCharset)cs).historicalName() : cs.name()); &#125;&#125; 参考链接Java之IO流—字节流http://blog.csdn.net/qq_28261343/article/details/52678681 Java之IO流—字符流http://blog.csdn.net/qq_28261343/article/details/52684071]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper选举机制]]></title>
    <url>%2F2018%2F01%2F18%2Fzookeeper%2F2018-01-11%2F</url>
    <content type="text"><![CDATA[znode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;zookeeper集群自身维护了一套数据结构。这个存储结构是一个树形结构，其上的每一个节点，我们称之为“znode” lookForLeader方法:]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLite简介]]></title>
    <url>%2F2018%2F01%2F13%2Fsqlite%2F2018-01-13%2F</url>
    <content type="text"><![CDATA[SQLite的组成 parser tokenize virtual machine SQLite的数据结构 Connections和Statements&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Connection和statement是执行SQL命令涉及的两个主要数据结构，几乎所有通过API进行的操作都要用到它们。一个连接(Connection)代表在一个独立的事务环境下的一个连接A (connection represents a single connection to a database as well as a single transaction context)。每一个statement都和一个connection关联，它通常表示一个编译过的SQL语句，在内部，它以VDBE字节码表示。Statement包括执行一个命令所需要一切，包括保存VDBE程序执行状态所需的资源，指向硬盘记录的B-树游标，以及参数等等 B-tree和pager&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个connection可以有多个database对象—一个主要的数据库以及附加的数据库，每一个数据库对象有一个B-tree对象，一个B-tree有一个pager对象(这里的对象不是面向对象的“对象”，只是为了说清楚问题)。 Statement最终都是通过connection的B-tree和pager从数据库读或者写数据，通过B-tree的游标(cursor)遍历存储在页面(page)中的记录。游标在访问页面之前要把数所从disk加载到内存，而这就是pager的任务。任何时候，如果B-tree需要页面，它都会请求pager从disk读取数据，然后把页面(page)加载到页面缓冲区(page cache)，之后，B-tree和与之关联的游标就可以访问位于page中的记录了。 如果cursor改变了page，为了防止事务回滚，pager必须采取特殊的方式保存原来的page。总的来说，pager负责读写数据库，管理内存缓存和页面（page），以及管理事务，锁和崩溃恢复(这些在事务一节会详细介绍)。 总之，关于connection和transaction，你必须知道两件事： (1)对数据库的任何操作，一个连接存在于一个事务下。 (2)一个连接决不会同时存在多个事务下。]]></content>
      <categories>
        <category>SQLite</category>
      </categories>
      <tags>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLite源码解析-操作数据库]]></title>
    <url>%2F2018%2F01%2F13%2Fsqlite%2F2018-01-14%2F</url>
    <content type="text"><![CDATA[SQLite基本操作方式 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SQLite的基本操作方式同大多数关系型数据库是一样的执行sqlite3_open打开数据库,若返回结果是SQLITE_OK即0则表示打开成功,利用sqlite3_exec执行相应的sql语句,返回函数同样是执行状态,SQLITE_OK表示执行成功,最终利用sqlite3_close关闭数据库 SQLite打开数据库&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SQLite打开数据库可以通过三种方式sqlite3_open、sqlite3_open_v2、sqlite3_open16他们的具体实现都是调用openDatabase,只有具体的参数有所不同，openDatabase的具体过程中进行了初始化和创建校对规则，以及加载相应的数据驱动。 123456789101112131415SQLITE_API int sqlite3_open(const char *zFilename, sqlite3 **ppDb )&#123; return openDatabase(zFilename, ppDb, SQLITE_OPEN_READWRITE | SQLITE_OPEN_CREATE, 0);&#125;SQLITE_API int sqlite3_open_v2( const char *filename, /* Database filename (UTF-8) */ sqlite3 **ppDb, /* OUT: SQLite db handle 返回一个数据库连接对象*/ int flags, /* Flags */ const char *zVfs /* Name of VFS module to use 数据库连接应该使用的操作系统接口的sqlite3_vfs对象的名称*/)&#123; return openDatabase(filename, ppDb, (unsigned int)flags, zVfs);&#125;SQLITE_API int sqlite3_open16(const void *zFilename, sqlite3 **ppDb) SQLite执行sql语句 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sqlite3exec()函数一次可以执行多条SQL命令。执行完成后返回一个SQLITE success/failure代码，还会将错误信息写到*pzErrMsg中。首先进行安全检查以及检查sql语句是为空，在获取线程锁，调用sqlite3Error将errCode赋值为SQLITE_OK之后调用sqlte3_prepare_v2编译一条语句，通过sqlite3_step进行具体执行，如果SQL是查询，查询结果中的每一行都会调用xCallback()函数。pArg为传递给xCallback()的第一个参数。如果xCallback==NULL，即使对查询命令也没有回叫调用。 sqlte3_prepare_v2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;它调用sqlite3GetToken对SQL语句zSql进行分词，然后调用sqlite3Parser进行语法分析。而sqlite3Parser在语法规则发生规约时调用相应的opcode生成子例程，生成opcode。 SQLite关闭数据库]]></content>
      <categories>
        <category>SQLite</category>
      </categories>
      <tags>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLite网址大全]]></title>
    <url>%2F2018%2F01%2F13%2Fsqlite%2F2018-01-14-1%2F</url>
    <content type="text"><![CDATA[SQLite API手册http://www.yfvb.com/help/sqlite3/ SQLite源码分析http://huili.github.io/sqlite/sqliteintro.html]]></content>
      <categories>
        <category>SQLite</category>
      </categories>
      <tags>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 源码分析一 zookeeper启动]]></title>
    <url>%2F2018%2F01%2F11%2Fzookeeper%2F2018-01-04%2F</url>
    <content type="text"><![CDATA[zookeeper启动类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; zookeeper的启动方式是调用目录下的zkServer.sh start 由此我们应该到这个文件下找相应的启动入口，最终我找到的org.apache.zookeeper.server.quorum.QuorumPeerMain #z ookeeper的启动流程 zookeeper的启动通过调用zkServer.sh start启动，这个过程实际上是以QuorumPeerMain的main方法为函数入口,具体步骤如下: 1调用初始化方法 1.1初始化过程中实例化QuorumPeerConfig解析配置文件 1.2创建文件清理器DatadirCleanupManager并启动 1.3判断启动方式，验证条件如果是有参数或者解析配置文件过程中给config的Server句柄具有相应的集群服务则通过运行配置文件启动，否则就是一个伪分布式直接通过ZooKeeperServerMain主函数启动服务 2.正常退出程序 runFromConfig利用配置文件启动过程位置: QuorumPeerMain.java runFromConfig &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 运行配置文件的过程中，主要将quorumPeer启动。具体步骤如下:1.注册JMX,作用是可以通过jconsole或者浏览器来管理各个对象2.创建ServerCnxnFactory这个server工厂,默认是NIOServerCnxnFactory,可以在配置文件中进行配置, 属性名是zookeeper.serverCnxnFactory, 在zookeeper中还提供另一种工程NettyServerCnxnFactory3.根据传入的地址通过configure方法打开socket通道，绑定ip地址,并注册相应的选择键4.实例化QuorumPeer并启动-待补录 启动QuorumPeerQuorumPeerMain.java&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.加载基础数据&nbsp;&nbsp; 2.创建相应的服务工厂&nbsp;&nbsp; 3.startLeaderElection开始选举&nbsp;&nbsp; 4.调用start启动当前线程即本实例方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.1 利用JMX注册MbeanServer jmxQuorumBean和LocalPeerBean，RemotePeerBean 这里是根据myId来进行注册，myId是在加载属性实例化QuorumPeer的时候注入。id是QuorumServer的属性，其在解析属性的过程中解析server.0=SY-001:2888:3888 这个0就是解析的id所以如果myid 和这个id相等则采用LocalPeerBean, myid和这个id定义不同则是RemotePeerBean， 可以看出其实定义的主zookeeper节点&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2在循环的过程中有四种 LOOKING, FOLLOWING, LEADING, OBSERVING针对当前状态执行相应的指令 1234LOOKING，竞选状态。这里是进行选举算法，将票投给谁setCurrentVote(makeLEStrategy().lookForLeader());FOLLOWING，随从状态，同步leader状态，参与投票。OBSERVING，观察状态,同步leader状态，不参与投票。LEADING，领导者状态。 quorumPeer.joinQuorumPeerMain.java 主要目的是为了让quorumPeer启动完毕,才继续向下执行。]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成5--搭建maven私服(nexus)]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-4%2F</url>
    <content type="text"><![CDATA[安装nexus]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成4--tomcat部署svnadmin]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-3%2F</url>
    <content type="text"><![CDATA[安装tomcat部署svnadmin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将svnadmin.war包部署到tomcat的服务器上解压,编辑配置文件 vim /usr/local/svn-tomcat/webapps/svnadmin/WEB-INF/jdbc.properties #tail -f -n 500 /usr/local/dubbo-tomcat/logs/catalina.out]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成3--安装jsvnadmin管理平台]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-2%2F</url>
    <content type="text"><![CDATA[安装mysql1yum install mysql-server mysql mysql-devel 启动1service mysqld start 查看1chkconfig --list | grep mysqld 设置开机启动1chkconfig mysqld on 设置mysql密码1mysqladmin -u root password root 进行远程访问赋权1Sql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION; Sql&gt; FLUSH PRIVILEGES;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成2--linux下安装svn]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-1%2F</url>
    <content type="text"><![CDATA[下载1yum install mod_dav_svn subversion 重启Apache服务&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里重启的是持续集成1中的httpd服务 123重启命令: service httpd restart查看命令: ls /etc/httpd/modules/ | grep svn查看版本: svn --version 创建svn库创建文件夹命令: 12mkdir /svn/``` 编辑subversion.conf文件 vim /etc/httpd/conf.d/subversion.conf DAV svnSVNListParentPath on SVNParentPath /svnAuthType BasicAuthName “Subversion repositories” AuthUserFile /svn/passwd.http AuthzSVNAccessFile /svn/authz Require valid-userRedirectMatch ^(/svn)$ $1/12# 创建/svn/passwd.http 和 /svn/authz 文件 touch /svn/passwd.httptouch /svn/authzservice httpd restart 重启apache服务```]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成1--linux下安装httpd]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04%2F</url>
    <content type="text"><![CDATA[下载 1yum install httpd httpd-devel 启动 1service httpd start 修改端口： 12vim /etc/httpd/conf/httpd.confServerName localhost:80 然后就可以根据ip进行访问]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 架构介绍]]></title>
    <url>%2F2018%2F01%2F04%2Fzookeeper%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[zookeeper介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。其具体功能如下: 文件系统 通知机制 ZooKeeper典型的应用场景&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zookeeper 从设计模式角度来看，是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper 就将负责通知已经在 Zookeeper 上注册的那些观察者做出相应的反应，从而实现集群中类似 Master/Slave 管理模式 统一命名服务（Name Service）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式应用中，通常需要有一套完整的命名规则，既能够产生唯一的名称又便于人识别和记住,而Name Service已经是 Zookeeper 内置的功能，所以你只要调用Zookeeper的 API就能实现。如调用create接口就可以很容易创建一个目录节点。 配置管理（Configuration Management）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;配置的管理在分布式应用环境中很常见，例如同一个应用系统需要多台 PC Server 运行，但是它们运行的应用系统的某些配置项是相同的，如果要修改这些相同的配置项，那么就必须同时修改每台运行这个应用系统的 PC Server，这样非常麻烦而且容易出错。像这样的配置信息完全可以交给 Zookeeper 来管理，将配置信息保存在 Zookeeper 的某个目录节点中，然后将所有需要修改的应用机器监控配置信息的状态，一旦配置信息发生变化，每台应用机器就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中。 集群管理（Group Membership）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zookeeper 能够很容易的实现集群管理的功能，如有多台 Server 组成一个服务集群，那么必须要一个“总管”知道当前集群中每台机器的服务状态，一旦有机器不能提供服务，集群中其它集群必须知道，从而做出调整重新分配服务策略。同样当增加集群的服务能力时，就会增加一台或多台Server，同样也必须让“总管”知道。Zookeeper 不仅能够帮你维护当前的集群中机器的服务状态，而且能够帮你选出一个“总管”，让这个总管来管理集群，这就是 Zookeeper 的另一个功能 Leader Election &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;它们的实现方式都是在 Zookeeper 上创建一个 EPHEMERAL 类型的目录节点，然后每个 Server 在它们创建目录节点的父目录节点上调用getChildren(String path,boolean watch) 方法并设置 watch 为 true，由于是 EPHEMERAL 目录节点，当创建它的 Server 死去，这个目录节点也随之被删除，所以 Children 将会变化，这时 getChildren上的 Watch 将会被调用，所以其它 Server 就知道已经有某台 Server 死去了。新增 Server 也是同样的原理。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zookeeper 如何实现 Leader Election，也就是选出一个 Master Server。和前面的一样每台 Server 创建一个 EPHEMERAL 目录节点，不同的是它还是一个 SEQUENTIAL 目录节点，所以它是个 EPHEMERAL_SEQUENTIAL 目录节点。之所以它是 EPHEMERAL_SEQUENTIAL 目录节点，是因为我们可以给每台 Server 编号，我们可以选择当前是最小编号的 Server 为 Master，假如这个最小编号的 Server 死去，由于是 EPHEMERAL 节点，死去的 Server 对应的节点也被删除，所以当前的节点列表中又出现一个最小编号的节点，我们就选择这个节点为当前 Master。这样就实现了动态选择 Master，避免了传统意义上单 Master 容易出现单点故障的问题 12345678910111213141516protected InetSocketAddress findLeader() &#123; InetSocketAddress addr = null; // Find the leader by id Vote current = self.getCurrentVote(); for (QuorumServer s : self.getView().values()) &#123; if (s.id == current.getId()) &#123; addr = s.addr; break; &#125; &#125; if (addr == null) &#123; LOG.warn("Couldn't find the leader with id = " + current.getId()); &#125; return addr; &#125; 共享锁（Locks）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;共享锁在同一个进程中很容易实现，但是在跨进程或者在不同 Server 之间就不好实现了。Zookeeper 却很容易实现这个功能，实现方式也是需要获得锁的 Server 创建一个 EPHEMERAL_SEQUENTIAL 目录节点，然后调用 getChildren方法获取当前的目录节点列表中最小的目录节点是不是就是自己创建的目录节点，如果正是自己创建的，那么它就获得了这个锁，如果不是那么它就调用 exists(String path, boolean watch) 方法并监控 Zookeeper 上目录节点列表的变化，一直到自己创建的节点是列表中最小编号的目录节点，从而获得锁，释放锁很简单，只要删除前面它自己所创建的目录节点就行了。 队列管理参考链接: ZooKeeper学习第一期—Zookeeper简单介绍https://www.cnblogs.com/wuxl360/p/5817471.html Zookeeper的功能以及工作原理https://www.cnblogs.com/felixzh/p/5869212.html 分布式服务框架Zookeeper(IBM)https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql一些常用sql语句]]></title>
    <url>%2F2018%2F01%2F03%2Fmysql%2F2018-01-03%2F</url>
    <content type="text"><![CDATA[E1获取当前时间select now&amp;#40; &amp;#4 #E2获取当前时间戳 123SELECT UNIX_TIMESTAMPSELECT UNIX_TIMESTAMP*1000 毫秒级SELECT UNIX_TIMESTAMP*1000*1000 微秒级]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 环境安装]]></title>
    <url>%2F2018%2F01%2F01%2Fzookeeper%2F2017-12-30%2F</url>
    <content type="text"><![CDATA[解压tar -zvxf zookeeper-3.4.5.tar.gz -C /usr/local #配置环境变量vim /etc/profile 12export ZOOKEEPER_HOME =/usr/local/zookeeper-3.4.5export PATH=$ZOOKEEPER_HOME/bin:$PATH source /etc/profile #修改配置文件 相对路径:/ZOOKEEPER_HOME/conf/zoo.cfg 修改 1.datadir=/ZOOKEEPER_HOME/data 2.server0=ip地址。。。。。。 ZOOKEEPER_HOME下面创建data文件并创建脚本文件myid #启动 1zkServer.sh start]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux修改ip为静态ip]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-01-3%2F</url>
    <content type="text"><![CDATA[#修改网卡信息 vi /etc/sysconfig/network-scripts/ifcfg-eth0 123456BOOTPROTO=&quot;static&quot; #注意：原值为dhcpHWADDR=&quot;00:0c:29:ba:18:25&quot;IPV6INIT=&quot;yes&quot;NM_CONTROLLED=&quot;yes&quot;ONBOOT=&quot;yes&quot;TYPE=&quot;Ethernet&quot; 以下是修改为静态时需要加IPADDR=192.168.1.200GATEWAY=192.168.1.1NETMASK=255.255.255.0 重启网卡service network restart #设置DNS vim /ect/resolv.conf 12nameserver 8.8.8.8nameserver 114.114.114.114]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机vm-tools安装]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-01-1%2F</url>
    <content type="text"><![CDATA[虚拟机vm-tools安装##centos下 ###点击vm fusion下安装VMware Tools ###解压 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在点击上面安装之后会出现一个CD文件，里面存在VmwareTools-10* 的包 这是一个tar.gz的压缩包，现在我们通过tar -zxvf 文件名tar.gz来进行解压（可以自行存放位置） ###安装 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;转到上面解压文件的目录vmware-tools-distrib 下，运行./vmware-install.pl 在安装的过程中不断点击enter 直到安装完成，之后调用reboot重新启动就完成了]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware Fusion实现虚拟机拷贝]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-01-2%2F</url>
    <content type="text"><![CDATA[参考链接:http://www.linuxidc.com/Linux/2017-06/144720.htm #拷贝&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;点击需要拷贝的文件,然后进行复制-粘贴,如下: #打开&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;打开相应的虚拟机&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;点击已拷贝 #修改hostname vi /etc/sysconfig/network 将”HOSTNAME=”后的内容改成机器名，比如centos.04，保存退出 vi /etc/hosts 在最后添加一行 127.0.0.1 centos.04，保存退出 如果要马上生效，可再输入hostname centos.04，否则要重启才能生效 shutdown -h now关机 注意最好执行这个命令，下面生成mac地址需要关机 #给新虚拟机的网卡，生成一个新mac地址在设置里面点击网络适配器生成一个新的mac地址 #修改网卡信息 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vi /etc/udev/rules.d/70-persistent-net.rules&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;编辑这个文件，它记录了当前机器上的所有网卡信息根据刚才新生成的mac地址，找到对应的行，把网卡名称改成 eth0，其它的全删除 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vi /etc/sysconfig/network-scripts/ifcfg-eth0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;把uuid随便改一个数字，保证它跟原来的系统不同即可，然后把HWADDR改成新生成的mac地址，保存退出]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux卸载openJDK安装sun下jdk]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[卸载openJDK查看相应openJDK的信息rpm -qa | grep java 123tzdata-java-2014g-1.el6.noarchjava-1.6.0-openjdk-1.6.0.0-11.1.13.4.el6.x86_64java-1.7.0-openjdk-1.7.0.65-2.5.1.2.el6_5.x86_64 删除相应的文件123rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-11.1.13.4.el6.x86_64rpm -e --nodeps java-1.7.0-openjdk-1.7.0.65-2.5.1.2.el6_5.x86_64rpm -e --nodeps tzdata-java-2014g-1.el6.noarch 安装JDK找到相应的jdk资源，将其解压到指定目录 配置环境打开环境变量存储文件vi /etc/profile 12345JAVA_HOME=/usr/java/jdk1.7JRE_HOME=/usr/java/jdk1.7/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH CLASSPATH 编译环境变量存储文件source /etc/profile]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Working principle of the Netty]]></title>
    <url>%2F2017%2F12%2F20%2Fnetty%2Fnetty3%2F</url>
    <content type="text"></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EightQueen]]></title>
    <url>%2F2017%2F12%2F17%2Farithmetic%2F2017-12-18%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The N queens puzzle is the problem of placing N chess queens on an N×N chessboard so that no two queens threaten each other. Thus, a solution requires that no two queens share the same row, column, or diagonal.For example, below is one of the solution for famous 8 Queen problem. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Backtracking Algorithm for N-Queen is already discussed here. In backtracking solution we backtrack when we hit a dead end. In Branch and Bound solution, after building a partial solution, we figure out that there is no point going any deeper as we are going to hit a dead end. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Let’s begin by describing backtracking solution. “The idea is to place queens one by one in different columns, starting from the leftmost column. When we place a queen in a column, we check for clashes with already placed queens. In the current column, if we find a row for which there is no clash, we mark this row and column as part of the solution. If we do not find such a row due to clashes, then we backtrack and return false.” &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.For the 1st Queen, there are total 8 possibilities as we can place 1st Queen in any row of first column. Let’s place Queen 1 on row 3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.After placing 1st Queen, there are 7 possibilities left for the 2nd Queen. But wait, we don’t really have 7 possibilities. We cannot place Queen 2 on rows 2, 3 or 4 as those cells are under attack from Queen 1. So, Queen 2 has only 8 – 3 = 5 valid positions left.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.After picking a position for Queen 2, Queen 3 has even fewer options as most of the cells in its column are under attack from the first 2 Queens. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We need to figure out an efficient way of keeping track of which cells are under attack. In previous solution we kept an 8­-by­-8 Boolean matrix and update it each time we placed a queen, but that required linear time to update as we need to check for safe cells. Basically, we have to ensure 4 things: No two queens share a column. No two queens share a row. No two queens share a top-right to left-bottom diagonal. No two queens share a top-left to bottom-right diagonal &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Number 1 is automatic because of the way we store the solution. For number 2, 3 and 4, we can perform updates in O(1) time. The idea is to keep three Boolean arrays that tell us which rows and which diagonals are occupied. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Lets do some pre-processing first. Let’s create two N x N matrix one for / diagonal and other one for \ diagonal. Let’s call them slashCode and backslashCode respectively. The trick is to fill them in such a way that two queens sharing a same /­diagonal will have the same value in matrix slashCode, and if they share same \­diagonal, they will have the same value in backslashCode matrix. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; For an N x N matrix, fill slashCode and backslashCode matrix using below formula – cols[N] != cols[N-1] cols[N] != cols[N-1]-1 cols[N]!=cols[N-1]+1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class Queen8 &#123; public static int num = 0; //累计方案总数 public static final int MAXQUEEN = 8;//皇后个数，同时也是棋盘行列总数 public static int[] cols = new int[MAXQUEEN]; //定义cols数组，表示8列棋子摆放情况 public Queen8() &#123; //核心函数 getArrangement(0); System.out.print("/n"); System.out.println(MAXQUEEN+"皇后问题有"+num+"种摆放方法。"); &#125; public void getArrangement(int n)&#123; //遍历该列所有不合法的行，并用rows数组记录，不合法即rows[i]=true boolean[] rows = new boolean[MAXQUEEN]; for(int i=0;i&lt;n;i++)&#123; rows[cols[i]]=true; int d = n-i; if(cols[i]-d &gt;= 0)rows[cols[i]-d]=true; if(cols[i]+d &lt;= MAXQUEEN-1)rows[cols[i]+d]=true; &#125; for(int i=0;i&lt;MAXQUEEN;i++)&#123; //判断该行是否合法 if(rows[i])continue; //设置当前列合法棋子所在行数 cols[n] = i; //当前列不为最后一列时 if(n&lt;MAXQUEEN-1)&#123; getArrangement(n+1); &#125;else&#123; //累计方案个数 num++; //打印棋盘信息 printChessBoard(); &#125; &#125; &#125; public void printChessBoard()&#123; System.out.print("第"+num+"种走法 /n"); for(int i=0;i&lt;MAXQUEEN;i++)&#123; for(int j=0;j&lt;MAXQUEEN;j++)&#123; if(i==cols[j])&#123; System.out.print("0 "); &#125;else System.out.print("+ "); &#125; System.out.print("/n"); &#125; &#125; public static void main(String args[])&#123; Queen8 queen = new Queen8(); &#125; &#125; output: 12345678910111213141516171819第1种走法 0 + + + + + + + + + + + + + 0 + + + + + 0 + + + + + + + + + + 0 + 0 + + + + + + + + + 0 + + + + + + + + + 0 + + + + 0 + + + + + 第2种走法 0 + + + + + + + + + + + + + 0 + + + + 0 + + + + + + + + + 0 + + + + + + + + + 0 + 0 + + + + + + + + + + 0 + + + + + 0 + + + + + .......]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Huffman Coding Greedy Algorithm]]></title>
    <url>%2F2017%2F12%2F17%2Farithmetic%2Fhuffmancoding%2F</url>
    <content type="text"><![CDATA[What is Huffman Coding&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Huffman coding is Data Compression Algorithm,Based on lengths of assigned codes based on frequencies, Variable Length Codes are known as Prefix Codes The GoalTry to reduce the total number of bits used without losing any information The process of Huffman coding Scan text to be compressed and tally occurrence of all characters. Sort or prioritize characters based on number of occurrences in text. Build Huffman code tree based on prioritized list. Perform a traversal of tree to determine all code words. Scan text again and create new file using the Huffman codes. The Schematic diagram Code process #The code of Huffman&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Now, we specific display Huffman code. By code, we analysis of its process step by step. ##The structure of Node&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In its structure, We define the frequency to statistic the number of occurrences of the characters. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Node implements Comparable&lt;Node&gt; &#123; private String chars = ""; private int frequence = 0; private Node parent; private Node leftNode; private Node rightNode; @Override public int compareTo(Node node) &#123; return frequence - node.frequence; &#125; public String getChars() &#123; return chars; &#125; public void setChars(String chars) &#123; this.chars = chars; &#125; public int getFrequence() &#123; return frequence; &#125; public void setFrequence(int frequence) &#123; this.frequence = frequence; &#125; public Node getParent() &#123; return parent; &#125; public void setParent(Node parent) &#123; this.parent = parent; &#125; public Node getLeftNode() &#123; return leftNode; &#125; public void setLeftNode(Node leftNode) &#123; this.leftNode = leftNode; &#125; public Node getRightNode() &#123; return rightNode; &#125; public void setRightNode(Node rightNode) &#123; this.rightNode = rightNode; &#125;&#125; statistic frequency of every character&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this part, Our main purpose is to statistic frequency of every character. so we structure a HashMap to store data, when we get data from the HashMap by key, we add one to the number of it and store into The value of the current mapping as new value 12345678910111213public static Map&lt;Character, Integer&gt; statistics(char[] charArray) &#123; Map&lt;Character, Integer&gt; map = new HashMap&lt;Character, Integer&gt;(); for (char c : charArray) &#123; Character character = new Character(c); if (map.containsKey(character)) &#123; map.put(character, map.get(character) + 1); &#125; else &#123; map.put(character, 1); &#125; &#125; return map; &#125; build a tree&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PriorityQueue will Retrieves and removes the head of this queue, or returns null if this queue is empty. PriorityQueue maintain a heap what you can poll the smallest element every time actually. so we will obtain the two minimum elements and build Node, By this way, we will get a complete binary tree.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The idea of algorithm: transfer statistical information to Node and stored in a priority queue. each time it pop-up two minimum frequency nodes the queue to build a new parent node. The frequency of characters is the sum of two pop-up Node.he first pop-up as the left child node, the back one as the right child node, and the newly built parent node inside the queue. Repeat the above action N-1 times. 1234567891011121314151617181920212223242526272829303132333435private static Tree buildTree(Map&lt;Character, Integer&gt; statistics, List&lt;Node&gt; leafs) &#123; Character[] keys = statistics.keySet().toArray(new Character[0]); PriorityQueue&lt;Node&gt; priorityQueue = new PriorityQueue&lt;Node&gt;(); for (Character character : keys) &#123; Node node = new Node(); node.setChars(character.toString()); node.setFrequence(statistics.get(character)); priorityQueue.add(node); leafs.add(node); &#125; int size = priorityQueue.size(); for (int i = 1; i &lt;= size - 1; i++) &#123; Node node1 = priorityQueue.poll(); Node node2 = priorityQueue.poll(); Node sumNode = new Node(); sumNode.setChars(node1.getChars()+node2.getChars()); sumNode.setFrequence(node1.getFrequence()+node2.getFrequence()); sumNode.setLeftNode(node1); sumNode.setRightNode(node2); node1.setParent(sumNode); node2.setParent(sumNode); priorityQueue.add(sumNode); &#125; Tree tree = new Tree(); tree.setRoot(priorityQueue.poll()); return tree; &#125; encode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this part, we will invoke buildTree to let the Node produce associated. searching up from the leaf node of current character, if the character is the parent node of the left node, add 0 before the coded character , otherwise if it is right node, add 1, until the root node. 12345678910111213141516171819public static String encode(String originalStr, Map&lt;Character, Integer&gt; statistics) &#123; if (originalStr == null || originalStr.equals("")) &#123; return ""; &#125; char[] charArray = originalStr.toCharArray(); List&lt;Node&gt; leafNodes = new ArrayList&lt;Node&gt;(); buildTree(statistics, leafNodes); Map&lt;Character, String&gt; encodInfo = buildEncodingInfo(leafNodes); StringBuffer buffer = new StringBuffer(); for (char c : charArray) &#123; Character character = new Character(c); buffer.append(encodInfo.get(character)); &#125; return buffer.toString(); &#125; decode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Huffman coding algorithm can ensure any binary code is not going to be another code prefix, decoding is simple, each in turn to take out the binary, search down from the root, 1 to the right, 0 to the left, to the leaf node (hit), return a root node continue to repeat the action 12345678910111213141516171819202122232425262728293031323334public static String decode(String binaryStr, Map&lt;Character, Integer&gt; statistics) &#123; if (binaryStr == null || binaryStr.equals("")) &#123; return ""; &#125; char[] binaryCharArray = binaryStr.toCharArray(); LinkedList&lt;Character&gt; binaryList = new LinkedList&lt;Character&gt;(); int size = binaryCharArray.length; for (int i = 0; i &lt; size; i++) &#123; binaryList.addLast(new Character(binaryCharArray[i])); &#125; List&lt;Node&gt; leafNodes = new ArrayList&lt;Node&gt;(); Tree tree = buildTree(statistics, leafNodes); StringBuffer buffer = new StringBuffer(); while (binaryList.size() &gt; 0) &#123; Node node = tree.getRoot(); do &#123; Character c = binaryList.removeFirst(); if (c.charValue() == '0') &#123; node = node.getLeftNode(); &#125; else &#123; node = node.getRightNode(); &#125; &#125; while (!node.isLeaf()); buffer.append(node.getChars()); &#125; return buffer.toString();&#125; The Test Result123456789101112public static void main(String[] args) &#123; String oriStr = "Huffman codes compress data very effectively"; Map&lt;Character, Integer&gt; statistics = statistics(oriStr.toCharArray()); String encodedBinariStr = encode(oriStr, statistics); String decodedStr = decode(encodedBinariStr, statistics); System.out.println("Original sstring: " + oriStr+"\n"); System.out.println("Huffman encoed binary string: " + encodedBinariStr+"\n"); System.out.println("decoded string from binariy string: " + decodedStr); &#125; result: 12345Original sstring: Huffman codes compress data very effectivelyHuffman encoed binary string: 11111011010101001011100100011011001111000010111011011001011110000101110011011100111011001100101111101100000011000011111101010011000001110101001010111000001111111111101011101000000decoded string from binariy string: Huffman codes compress data very effectively]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A example of Netty]]></title>
    <url>%2F2017%2F12%2F12%2Fnetty%2Fnetty1%2F</url>
    <content type="text"><![CDATA[The introduce of Netty&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; we often use an HTTP client library to retrieve information from a web server and to invoke a remote procedure call via web services. Netty is an NIO client server framework which enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server development. A example of NettyThe Main class&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this part, we introduce a simple process for a netty service. At first, we create multithreaded event loop that handles I/O operation and add them into corresponding server and add corresponding channel to transmit message. In this channel, we will create corresponding handle to receive the message, In this process, some handle can encode or decode the message. In the end, it will wait the message from client. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class DiscardServer &#123; private int port; public DiscardServer(int port) &#123; this.port = port; &#125; public void run() throws Exception &#123; //bossGroup will accept an incoming connection EventLoopGroup bossGroup = new NioEventLoopGroup(); //workerGroup handles the traffic of the accepted connection once the bossGroup accepts the connection //and registers the accepted the connection to the worker EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; //ServerBootstrap is a helper class that sets up a server. you can set up the server using channel ServerBootstrap serverBootstrap = new ServerBootstrap(); //we specify to use the NioServerSocketChannel class which is used to a new channel to accept incoming connection serverBootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) //the handler specified here will always be evaluated by a newly channel //The ChannelInitializer's purpose is to help user configure a new channel and add some handler which can implement network application .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new DiscardServerHandler()); &#125; &#125;) //you can set some socket option by this way //option() is for the NioServerSocketChannel that accepts incoming connections. //childOption() is for the Channels accepted by the parent ServerChannel, which is NioServerSocketChannel in this case. .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); // Bind and start to accept incoming connections. ChannelFuture f = serverBootstrap.bind(port).sync(); System.out.println("before closeFuture.."); // Wait until the server socket is closed. // In this example, this does not happen, but you can do that to gracefully // shut down your server. f.channel().closeFuture().sync(); System.out.println("after closeFuture.."); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; int port; if (args.length &gt; 0) &#123; port = Integer.parseInt(args[0]); &#125; else &#123; port = 8080; &#125; new DiscardServer(port).run(); &#125;&#125;``` ## The corresponding handle &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; In this handle, we override the channelRead method from the interface of ChannelInboundHandler to receive the message and do some operation. ```java/*** * * ChannelInboundHandlerAdapter is a implementation for ChannelHandlerAdapter (abstract class) and ChannelInboundHandler(interface) * ChannelInboundHandler provides various event handler methods that you can override * For now, it is just enough to extend ChannelInboundHandlerAdapter rather than to implement the handler interface by yourself. * */public class DiscardServerHandler extends ChannelInboundHandlerAdapter &#123; /** * we override the channelRead method from the interface of ChannelInboundHandler * Invoked when the current channel has read a message from the peer. * * @param ctx this variable provide various operations that enable you to trigger various I/O operations and event * @param msg receive the message from channel * */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf in = (ByteBuf) msg; char temp ; try &#123; ctx.write("you message:"); while (in.isReadable()) &#123; temp = (char)in.readByte(); System.out.print(temp); ctx.write(temp); System.out.flush(); &#125; ctx.flush(); &#125; finally &#123; ReferenceCountUtil.release(msg); &#125; &#125; /** * The exceptionCaught() event handler method s called with a Throwable * when an exception was raised by Netty due to an I/O error or by a handler implementation due to the exception thrown while processing events * */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // Close the connection when an exception is raised. System.out.println("channelRead..."); cause.printStackTrace(); ctx.close(); &#125;&#125; ##The result of this example]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PriorityQueue]]></title>
    <url>%2F2017%2F12%2F12%2FJdk%2FPriorityQueue%2F</url>
    <content type="text"><![CDATA[The introduce of PriorityQueue&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; An unbounded priority queue based on a priority heap. The elements of the priority queue are ordered according to their natural ordering, or by a Comparator provided at queue construction time, depending on which constructor is used. A priority queue does not permit null elements. A priority queue relying on natural ordering also does not permit insertion of non-comparable objects #The family of PriorityQueue #The structure of PriorityQueue #The method of PriorityQueue]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java NIO Selector]]></title>
    <url>%2F2017%2F12%2F11%2FNIO%2Fnio4%2F</url>
    <content type="text"><![CDATA[#The Selector, SelectableChannel, and SelectionKey Classes Selector&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The Selector class manages information about a set of registered channel and their readies state. Channels are registered with selectors, and a selector can be asked to update readies state of channels. When doing so, the invoking thread can optionally indicate that it would prefer to be suspended until one of the registered channel is ready. ##]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QuickSort]]></title>
    <url>%2F2017%2F12%2F11%2Farithmetic%2FquickSort%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Like Merge Sort, QuickSort is a Divide and Conquer algorithm. It picks an element as pivot and partitions the given array around the picked pivot. There are many different versions of quickSort that pick pivot in different ways. 1.Always pick first element as pivot.2.Always pick last element as pivot (implemented below)3.Pick a random element as pivot.4.Pick median as pivot. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The key process in quickSort is partition(). Target of partitions is, given an array and an element x of array as pivot, put x at its correct position in sorted array and put all smaller elements (smaller than x) before x, and put all greater elements (greater than x) after x. All this should be done in linear time. Pseudo Code for recursive QuickSort function :12345678910111213/* low --&gt; Starting index, high --&gt; Ending index */quickSort(arr[], low, high)&#123; if (low &lt; high) &#123; /* pi is partitioning index, arr[p] is now at right place */ pi = partition(arr, low, high); quickSort(arr, low, pi - 1); // Before pi quickSort(arr, pi + 1, high); // After pi &#125;&#125; Partition Algorithm&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There can be many ways to do partition, following pseudo code adopts the method given in CLRS book. The logic is simple, we start from the leftmost element and keep track of index of smaller (or equal to) elements as i. While traversing, if we find a smaller element, we swap current element with arr[i]. Otherwise we ignore current element. 12345678910111213/* low --&gt; Starting index, high --&gt; Ending index */quickSort(arr[], low, high)&#123; if (low &lt; high) &#123; /* pi is partitioning index, arr[p] is now at right place */ pi = partition(arr, low, high); quickSort(arr, low, pi - 1); // Before pi quickSort(arr, pi + 1, high); // After pi &#125;&#125; Pseudo code for partition()12345678910111213141516171819202122232425/* This function takes last element as pivot, places the pivot element at its correct position in sorted array, and places all smaller (smaller than pivot) to left of pivot and all greater elements to right of pivot */partition (arr[], low, high)&#123; // pivot (Element to be placed at right position) pivot = arr[high]; i = (low - 1) // Index of smaller element for (j = low; j &lt;= high- 1; j++) &#123; // If current element is smaller than or // equal to pivot if (arr[j] &lt;= pivot) &#123; i++; // increment index of smaller element swap arr[i] and arr[j] &#125; &#125; swap arr[i + 1] and arr[high]) return (i + 1)&#125; Illustration of partition()12345678910111213141516171819202122232425262728293031323334353637arr[] = &#123;10, 80, 30, 90, 40, 50, 70&#125;Indexes: 0 1 2 3 4 5 6 low = 0, high = 6, pivot = arr[h] = 70Initialize index of smaller element, i = -1Traverse elements from j = low to high-1j = 0 : Since arr[j] &lt;= pivot, do i++ and swap(arr[i], arr[j])i = 0 arr[] = &#123;10, 80, 30, 90, 40, 50, 70&#125; // No change as i and j // are samej = 1 : Since arr[j] &gt; pivot, do nothing// No change in i and arr[]j = 2 : Since arr[j] &lt;= pivot, do i++ and swap(arr[i], arr[j])i = 1arr[] = &#123;10, 30, 80, 90, 40, 50, 70&#125; // We swap 80 and 30 j = 3 : Since arr[j] &gt; pivot, do nothing// No change in i and arr[]j = 4 : Since arr[j] &lt;= pivot, do i++ and swap(arr[i], arr[j])i = 2arr[] = &#123;10, 30, 40, 90, 80, 50, 70&#125; // 80 and 40 Swappedj = 5 : Since arr[j] &lt;= pivot, do i++ and swap arr[i] with arr[j] i = 3 arr[] = &#123;10, 30, 40, 50, 80, 90, 70&#125; // 90 and 50 Swapped We come out of loop because j is now equal to high-1.Finally we place pivot at correct position by swappingarr[i+1] and arr[high] (or pivot) arr[] = &#123;10, 30, 40, 50, 70, 90, 80&#125; // 80 and 70 Swapped Now 70 is at its correct place. All elements smaller than70 are before it and all elements greater than 70 are afterit. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// Java program for implementation of QuickSortclass QuickSort&#123; /* This function takes last element as pivot, places the pivot element at its correct position in sorted array, and places all smaller (smaller than pivot) to left of pivot and all greater elements to right of pivot */ int partition(int arr[], int low, int high) &#123; int pivot = arr[high]; int i = (low-1); // index of smaller element for (int j=low; j&lt;high; j++) &#123; // If current element is smaller than or // equal to pivot if (arr[j] &lt;= pivot) &#123; i++; // swap arr[i] and arr[j] int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; &#125; // swap arr[i+1] and arr[high] (or pivot) int temp = arr[i+1]; arr[i+1] = arr[high]; arr[high] = temp; return i+1; &#125; /* The main function that implements QuickSort() arr[] --&gt; Array to be sorted, low --&gt; Starting index, high --&gt; Ending index */ void sort(int arr[], int low, int high) &#123; if (low &lt; high) &#123; /* pi is partitioning index, arr[pi] is now at right place */ int pi = partition(arr, low, high); // Recursively sort elements before // partition and after partition sort(arr, low, pi-1); sort(arr, pi+1, high); &#125; &#125; /* A utility function to print array of size n */ static void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i]+" "); System.out.println(); &#125; // Driver program public static void main(String args[]) &#123; int arr[] = &#123;10, 7, 8, 9, 1, 5&#125;; int n = arr.length; QuickSort ob = new QuickSort(); ob.sort(arr, 0, n-1); System.out.println("sorted array"); printArray(arr); &#125;&#125; output: 12Sorted array:1 5 7 8 9 10]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基本指令]]></title>
    <url>%2F2017%2F12%2F11%2Flinux%2F2018-01-01%2F</url>
    <content type="text"><![CDATA[解压1tar -zxvf 文件名 移动文件移动命令mv 命令格式：mv [-fiv] source destination 参数说明： -f:force，强制直接移动而不询问 -i:若目标文件(destination)已经存在，就会询问是否覆盖 -u:若目标文件已经存在，且源文件比较新，才会更新 如将/test1目录下的file1复制到/test3 目录，并将文件名改为file2,可输入以下命令： mv /test1/file1 /test3/file2 重命名关机poweroff 立刻关机shutdown -h now 立刻关机shutdown -h 10 10分钟后自动关机 关闭防火墙关闭命令： service iptables stop永久关闭防火墙：chkconfig iptables off永久关闭需要两条语句都运行 关闭端口1lsof -i:]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java NIO channel]]></title>
    <url>%2F2017%2F12%2F11%2FNIO%2Fnio3%2F</url>
    <content type="text"><![CDATA[java NIO channel&emsp;&emsp; When it comes to NIO, the first New concept we approach is channel, we operate data by using it instead of stream in traditional IO. The introduce of channelWhat is channel?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Channels is the second invocation of java NIO, they used to transmit data to the corresponding entity in both sides of the channel. Channels are gateways through which the native I/O services of the operating system can be accessed with a minimum of overhead, and buffers are the internal endpoints used by channels to send and receive data. The feature of channel 1.channel both can read data also can write data2.channel can read or write data from asynchronous3.channel must have a buffer to transmit data The family of channeljava.nio.channels.Channel 接口： |--FileChannel |--SocketChannel |--ServerSocketChannel |--DatagramChannel The use of channel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In the above, we know about what is channel roughly. Now, we tell channel by using it. Copy file by channel1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public void copyFile()&#123; FileInputStream fis = null; FileOutputStream fos = null; //Getting channel FileChannel inChannel = null; FileChannel outChannel = null; try &#123; fis = new FileInputStream("1.txt"); fos = new FileOutputStream("2.txt"); inChannel = fis.getChannel(); outChannel = fos.getChannel(); //allocate specified size buffer ByteBuffer buf = ByteBuffer.allocate(1024); //Getting data from channel, and storage it in buffer while(inChannel.read(buf) != -1)&#123; buf.flip(); //Flips this buffer //write the data in the buffer into the channel outChannel.write(buf); //clear buffer, The position is set to zero, the limit is set to the capacity buf.clear(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; //handle corresponding exception &#125; &#125;``` &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; above the code, we get corresponding stream from File stream, then we write data to FileOutputStream. Now, we detail some of these method. `FileChannelImpl.open` will create corresponding instance.# A set of method of channel## getChannel()&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; `getChannel`method will Returns the unique FileChannel object associated with this file input stream.```java /** * * &lt;p&gt; The initial &#123;@link java.nio.channels.FileChannel#position() * position&#125; of the returned channel will be equal to the * number of bytes read from the file so far. Reading bytes from this * stream will increment the channel's position. Changing the channel's * position, either explicitly or by reading, will change this stream's * file position. * * @return the file channel associated with this file input stream * * @since 1.4 * @spec JSR-51 */ public FileChannel getChannel() &#123; synchronized (this) &#123; if (channel == null) &#123; channel = FileChannelImpl.open(fd, path, true, false, this); &#125; return channel; &#125; &#125; read(ByteBuffer dst)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; read is abstract method, it will read a sequence of bytes from this channel into the given buffer. Bytes are read starting at this channel’s current file position, and then file position is updated with the number of bytes actually read. 1234567891011121314151617181920212223public int read(ByteBuffer dst) throws IOException &#123; ensureOpen(); if (!readable) throw new NonReadableChannelException(); synchronized (positionLock) &#123; int n = 0; int ti = -1; try &#123; begin(); ti = threads.add(); if (!isOpen()) return 0; do &#123; n = IOUtil.read(fd, dst, -1, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); end(n &gt; 0); assert IOStatus.check(n); &#125; &#125; &#125; write(ByteBuffer src)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Writes a sequence of bytes to this channel from given buffer. 1234567891011121314151617181920212223public int write(ByteBuffer src) throws IOException &#123; ensureOpen(); if (!writable) throw new NonWritableChannelException(); synchronized (positionLock) &#123; int n = 0; int ti = -1; try &#123; begin(); ti = threads.add(); if (!isOpen()) return 0; do &#123; n = IOUtil.write(fd, src, -1, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); end(n &gt; 0); assert IOStatus.check(n); &#125; &#125; &#125;]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java NIO buffer]]></title>
    <url>%2F2017%2F12%2F10%2FNIO%2Fnio2%2F</url>
    <content type="text"><![CDATA[java NIO buffer&emsp;&emsp; A buffer Object is a container of a fixed amount of data, it acts as a block or staging area, where data can be stored and later retrieved.Buffers work hand in glove with channels, Channels are portals through which i/o transfers take place, and buffers are the sources or targets of those data transfers. The family of buffer in java nio &emsp;&emsp; From the system diagram, we can find each of the basic data types has their own corresponding buffer class. as follows: ByteBuffershortBufferCharBufferIntBufferLongBufferFloatBufferDoubleBufferMappedByteBuffer Attributes&emsp;&emsp; Buffer is mainly has four attributes Capacity: The maximum number of data elements the buffer can hold. The capacity is set when the buffer is created and can never be changed. Limit: The first element of the buffer that should not be read or written. In other words, the count of live elements in the buffer. Position:The index of next element to be read or written. The position is updated automatically by get() and put() methods. Mark: A remembered position,Mark() and reset() are used together. when we use Mark(), we will record the position so that calling reset() sets position = mark The following relationship between these four attributes always holds: 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity Buffer interface The Usage of Buffer&emsp;&emsp; Now, i show how to use it and explain the source code through it’s the implementation class — ByteBuffer The constructor of it12345678910ByteBuffer(int mark, int pos, int lim, int cap, byte[] hb, int offset) &#123; super(mark, pos, lim, cap); this.hb = hb; this.offset = offset; &#125; // Creates a new buffer with the given mark, position, limit, and capacity ByteBuffer(int mark, int pos, int lim, int cap) &#123; this(mark, pos, lim, cap, null, 0); &#125; &emsp;&emsp;&emsp; we can find the core of it invoke the superclass, at first we see the parent class constructor. it easy to find the superclass is Buffer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657Buffer(int mark, int pos, int lim, int cap) &#123; if (cap &lt; 0) throw new IllegalArgumentException("Negative capacity: " + cap); this.capacity = cap; limit(lim); position(pos); if (mark &gt;= 0) &#123; if (mark &gt; pos) throw new IllegalArgumentException("mark &gt; position: (" + mark + " &gt; " + pos + ")"); this.mark = mark; &#125; &#125; /** * Sets this buffer's limit. If the position is larger than the new limit * then it is set to the new limit. If the mark is defined and larger than * the new limit then it is discarded. * * @param newLimit * The new limit value; must be non-negative * and no larger than this buffer's capacity * * @return This buffer * * @throws IllegalArgumentException * If the preconditions on &lt;tt&gt;newLimit&lt;/tt&gt; do not hold */ public final Buffer limit(int newLimit) &#123; if ((newLimit &gt; capacity) || (newLimit &lt; 0)) throw new IllegalArgumentException(); limit = newLimit; if (position &gt; limit) position = limit; if (mark &gt; limit) mark = -1; return this; &#125; /** * Sets this buffer's position. If the mark is defined and larger than the * new position then it is discarded. * * @param newPosition * The new position value; must be non-negative * and no larger than the current limit * * @return This buffer * * @throws IllegalArgumentException * If the preconditions on &lt;tt&gt;newPosition&lt;/tt&gt; do not hold */ public final Buffer position(int newPosition) &#123; if ((newPosition &gt; limit) || (newPosition &lt; 0)) throw new IllegalArgumentException(); position = newPosition; if (mark &gt; position) mark = -1; return this; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this constructor, Main purpose is to give the corresponding handle to set the appropriate attribute values through the way of refs, these attributes was introduced in the above. Each method of them has corresponding judgment whether the property value whether meet the conditions. if not, it will throws corresponding exception. allocate a specify memory space12345//allocate a specify memory spaceByteBuffer buf = ByteBuffer.allocate(1024);System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); 1234result:010241024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In the beginning of allocate a memory space to buffer, we can find the property value of position is 0, property values of limit and capacity is the value of the incoming. Buffer after five put( )s123456String str = "Hello"; //put data in the bufferbuf.put(str.getBytes());System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); 1234result:510241024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Follow the above code, I convert a string into a byte array and store it the buf instance. From the result, we can find the position has some change, limit and capacity don’t have any change. The model is shown. Switch to Read data mode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Continuing to follow the above code, we begin to read the data which we put in the above. At first we switch to read data mode by calling the flip() method. 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; 1234buf.flip();System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); result: 123051024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Flips this buffer. The limit is set to the current position and then the position is set to zero. If the mark is defined then it is discarded.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; After invoking the flip(), we begin to read the data in the buffer. Read data from buffer123456byte[] dst = new byte[buf.limit()];buf.get(dst);System.out.println(new String(dst, 0, dst.length));System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); result: 1234hello551024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; From the code, we can find we build a byte array to read data from buffer. after reading it, The property value of position changed. The principle of it is after we invoke the get() method It can read the Reads the byte at this buffer’s current position, and then increments the position. The process of get() method is in its implementation class. Rewinds this buffer12345public final Buffer rewind() &#123; position = 0; mark = -1; return this; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The position is set to zero and the mark is discarded. Invoking this method before a sequence of channel-write or get operations, assuming that the limit has already been set appropriately. Clears this buffer&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The position is set to zero, the limit is set to the capacity, and the mark is discarded.This method does not actually erase the data in the buffer, but it is named as if it did because it will most often be used in situations in which that might as well be the case. 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; hasRemaining()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Tells whether there are any elements between the current position and the limit. if true, there is at least one element remaining in this buffer 123public final boolean hasRemaining() &#123; return position &lt; limit; &#125; The Compare BuffersDirect byte buffers&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Direct byte buffers are usually the best choice for I/O operations. By design, they support the most efficient I/O mechanism available to the JVM.Direct buffers are optimal for I/O, but they may be more expensive to create than non direct byte buffers. The memory used by direct buffers is allocated by calling through to native, operating system-specific code, by passing the standard JVM heap. Setting up and tearing down direct buffers could be significantly more expensive than heap-resident buffers, depending on the host operating system and JVM implementation. The memory-storage areas of direct buffers are not subject to garbage collection because they are outside the standard JVM heap. —reference O’reilly java NIO The Method of creationstatic ByteBuffer allocateDirect(int capacity) 12345678910111213141516171819/** * Allocates a new direct byte buffer. * * &lt;p&gt; The new buffer's position will be zero, its limit will be its * capacity, its mark will be undefined, and each of its elements will be * initialized to zero. Whether or not it has a * &#123;@link #hasArray backing array&#125; is unspecified. * * @param capacity * The new buffer's capacity, in bytes * * @return The new byte buffer * * @throws IllegalArgumentException * If the &lt;tt&gt;capacity&lt;/tt&gt; is a negative integer */public static ByteBuffer allocateDirect(int capacity) &#123; return new DirectByteBuffer(capacity);&#125; 12345678910111213141516171819202122232425262728DirectByteBuffer(int cap) &#123; // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; base = unsafe.allocateMemory(size); &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null;&#125; Non direct byte buffers&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Non direct byte buffers can be passed to channels, but doing so may incur a performance penalty. It’s usually not possible for a non direct buffer to be the target of a native I/O operation. If you pass a non direct ByteBuffer object to a channel for write, the channel may implicitly do the following on each call: Create a temporary direct ByteBuffer object. Copy the content of the non direct buffer to the temporary buffer. Perform the low-level I/O operation using the temporary buffer. The temporary buffer object goes out of scope and is eventually garbage collected. —reference O‘reilly java NIO The Method of creation123456789101112131415161718192021/** * Allocates a new byte buffer. * * &lt;p&gt; The new buffer's position will be zero, its limit will be its * capacity, its mark will be undefined, and each of its elements will be * initialized to zero. It will have a &#123;@link #array backing array&#125;, * and its &#123;@link #arrayOffset array offset&#125; will be zero. * * @param capacity * The new buffer's capacity, in bytes * * @return The new byte buffer * * @throws IllegalArgumentException * If the &lt;tt&gt;capacity&lt;/tt&gt; is a negative integer */ public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity); &#125; 12345678910111213141516171819HeapByteBuffer(int cap, int lim) &#123; super(-1, 0, lim, cap, new byte[cap], 0); &#125;HeapByteBuffer(byte[] buf, int off, int len) &#123; super(-1, off, off + len, buf.length, buf, 0);&#125;protected HeapByteBuffer(byte[] buf, int mark, int pos, int lim, int cap, int off) &#123; super(mark, pos, lim, cap, buf, off); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We can see it invoke superclass’s constructor, so its data will store in the Heap.]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The introduce of NIO]]></title>
    <url>%2F2017%2F12%2F09%2FNIO%2Fnio1%2F</url>
    <content type="text"><![CDATA[The introduce of NIOWhat is NIO？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; java.nio (non-blocking I/O) is a collection of Java programming language APIs that offer features for intensive I/O operations. It was introduced with the J2SE 1.4 release of Java by Sun Microsystems to complement an existing standard I/O —reference wiki The compare between NIO and IO IO NIO Stream Oriented Buffer Oriented Blocking IO Non Blocking IO Selectors The function of NIO&emsp;&emsp; When it comes to NIO, we should what is IO. In the traditional IO, we read or store data in the form of stream, so it is easy to cause obstruction that we difficult calls in multiple threads.But in NIO,The problem has a good way to solve it, the way is that we convey information by channel. in the channel, we can construct the corresponding buffer to transfer data. so we can say it is base on Buffer Oriented.]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat源码解读一 Digester的解析方式]]></title>
    <url>%2F2017%2F11%2F12%2Ftomcat%2F2018-01-23-6%2F</url>
    <content type="text"><![CDATA[# Digester Digester在tomcat中的作用是对conf下的server.xml文件进行实例化，其是从Catalian这个组件开始，创建Digester实例，再添加对应的规则，然后将其实例化，通过setServer方法，将其实例话的对象作为当前Catalian实例的句柄。这样就实现了对象句柄之间的关联引用，从而实现整个平台的递进启动。 UML类图 UML时序图 规则添加解析 添加对应解析规则 规则的添加实在Catalia.java的load（）方法之中。规则主要是根据各个标签创建对应对象的规则,以及解析对象的通过何种方法设为相应句柄属性。其主要实现过程是创建Digester实例，设置规则]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat请求处理分析(六)servlet的处理过程]]></title>
    <url>%2F2017%2F08%2F20%2Ftomcat%2F2018-01-23-5%2F</url>
    <content type="text"><![CDATA[servlet的解析过程 servlet的解析分为两步实现，第一个是匹配到对应的Wrapper,第二个是加载对应的servlet并进行数据，这些数据是怎么到界面的，response.getWrite()获取对应的流，然后写入这个流中，这个流中就有上文的outputBuffer。 匹配到对应Wrapper 在上文中我们曾经走到过了doRun方法，现在就直接从这里开始 执行顺序如下： NioEndpoint（run）==&gt;下步调用doRun NioEndpoint（doRun）==&gt;下步调用state = &lt;em style=&quot;color:red&quot;&gt;handler&lt;/em&gt;.process(ka,status); handler实例对象Http11ConnectionHandler其继承AbstractConnectionHandler AbstractConnectionHandler（process） ==》下步调用 state = &lt;em style=&quot;color:red&quot;&gt;processor&lt;/em&gt;.process(wrapper); processor实例对象Http11NioProcessor 其继承AbstractHttp11Processor AbstractHttp11Processor（process） ==》下步调用getAdapter().service(request, response); &lt;em style=&quot;color:red&quot;&gt;CoyoteAdapter&lt;/em&gt;.service(request,response)这个方法就已经接近核心处理了，代码如下： 在第一处标红的地方，对请求进行了解析，并且匹配到对应的主机和context和wrapper 在第二处标红的地方是加载servlet并进行调用处理 在第三处标红的地方是刷新流，响应到界面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119@SuppressWarnings("deprecation")@Overridepublicvoid service(org.apache.coyote.Request req, org.apache.coyote.Responseres) throws Exception &#123; Request request = (Request)req.getNote(ADAPTER_NOTES); Response response =(Response) res.getNote(ADAPTER_NOTES); if (request == null) &#123; //创建一个request对象 request = connector.createRequest(); request.setCoyoteRequest(req); response = connector.createResponse(); response.setCoyoteResponse(res); // Link objects request.setResponse(response); response.setRequest(request); // Set as notes req.setNote(ADAPTER_NOTES,request); res.setNote(ADAPTER_NOTES,response); // Set query string encoding req.getParameters().setQueryStringEncoding (connector.getURIEncoding()); &#125; if (connector.getXpoweredBy())&#123; response.addHeader("X-Powered-By",POWERED_BY); &#125; boolean comet =false; boolean async = false; boolean postParseSuccess = false; try &#123; //设置执行线程线程名 req.getRequestProcessor().setWorkerThreadName(THREAD_NAME.get()); //对uri进行解码，主要是解析报文，如果不合法返回响应码400 postParseSuccess = postParseRequest(req,request, res, response); if (postParseSuccess) &#123; //设置是否支持异步 request.setAsyncSupported(connector.getService().getContainer().getPipeline().isAsyncSupported()); //不断调用管道加载对应的servlet进行调用,其中传递了response参数，所以可以放入流数据 connector.getService().getContainer().getPipeline().getFirst().invoke(request,response); if (request.isComet()) &#123; if (!response.isClosed()&amp;&amp; !response.isError()) &#123; comet = true; res.action(ActionCode.COMET_BEGIN, null); if (request.getAvailable()|| (request.getContentLength() &gt;0 &amp;&amp;(!request.isParametersParsed()))) &#123; event(req, res,SocketStatus.OPEN_READ); &#125; &#125; else &#123; request.setFilterChain(null); &#125; &#125; &#125; //如果是异步请求 if (request.isAsync())&#123; async = true; ReadListener readListener= req.getReadListener(); if (readListener != null&amp;&amp;request.isFinished()) &#123; ClassLoader oldCL =null; try &#123; oldCL =request.getContext().bind(false, null); if (req.sendAllDataReadEvent())&#123; req.getReadListener().onAllDataRead(); &#125; &#125; finally &#123; request.getContext().unbind(false,oldCL); &#125; &#125; Throwable throwable = (Throwable)request.getAttribute(RequestDispatcher.ERROR_EXCEPTION); if (!request.isAsyncCompleting()&amp;&amp; throwable !=null) &#123; request.getAsyncContextInternal().setErrorState(throwable, true); &#125; &#125; else if (!comet) &#123; //如果为同步请求，Flush并关闭输入输出流 request.finishRequest(); response.finishResponse(); &#125; &#125; catch (IOExceptione) &#123; // Ignore &#125; finally&#123; AtomicBoolean error = new AtomicBoolean(false); res.action(ActionCode.IS_ERROR,error); if (request.isAsyncCompleting()&amp;&amp; error.get()) &#123; res.action(ActionCode.ASYNC_POST_PROCESS, null); async = false; &#125; if (!async&amp;&amp; !comet) &#123; if (postParseSuccess)&#123; request.getMappingData().context.logAccess( request, response, System.currentTimeMillis()- req.getStartTime(), false); &#125; &#125; req.getRequestProcessor().setWorkerThreadName(null); if (!comet &amp;&amp;!async) &#123; request.recycle(); response.recycle(); &#125; else&#123; request.clearEncoders(); response.clearEncoders(); &#125; &#125;&#125; 构造对应request的MappingData属性 12345678postParseRequest:CoyoteAdapter(org.apache.catalina.connector)connector.getService().getMapper().map(serverName,decodedURI,version, request.getMappingData()); 下面是request部分构造代码protected final MappingDatamappingData =new MappingData();public MappingDatagetMappingData() &#123; return mappingData;&#125; 根据调用方法，我们可以知道其传入的参数有request实例成员对象mappingData的引用类型，所以下面的匹配的Context以及Wrapper所到的mappingData都是当前request的属性 ============================================ map: Mapper (org.apache.catalina.mapper) internalMap(host.getCharChunk(),uri.getCharChunk(), version, mappingData); internalMap:758,Mapper (org.apache.catalina.mapper) 在这里面匹配到了对应的虚拟主机，存放到了mappingData中去，以及Context主要采用了二分查找获取游标进行匹配然后其调用internalMapWrapper(contextVersion,uri, mappingData);匹配到了Wrapper存放到mappingData，其匹配规则如下 123456789101112131415161718192021222324252627282930313233/** * a: 对全新的路径进行精准匹配 * b: 对全新的路径进行通配符匹配 * c: 根据全新的路径，进行查找是否存在相应的文件，如果存在相应的文件，则需要将该文件返回。在回前我们需要进一步确认，这个文件是不是讲文件内容源码返回，还是像jsp文件一样，进行一定的处理然后再返回，所以又要确认下文件的扩展名是怎样的 * c1: 尝试寻找能够处理该文件扩展名的servlet，即进行扩展名匹配,如果找到，则使用对应的servlet * c2: 如果没找到，则默认使用defaultWrapper，即DefaultServlet（它只会将文件内容源码返回，不做任何处理） * d: 对全新的路径进行扩展名匹配（与c的目的不同，c的主要目的是想返回一个文件的内容，在返回内容前涉及到扩展名匹配，所以4c的前提是存在对应路径的文件） * 案例1： a.html，a、b没有匹配到，到c的时候，找到了该文件，然后又尝试扩展名匹配，来决定是走c1还是c2，由于.html还没有对应的servlet来处理，就使用了默认的DefaultServlet * 案例2： a.jsp，同上，在走到c的时候，找到了处理.jsp对应的servlet，所以走了c1 * 案例3： a.action,如果根目录下有a.action文件，则走到c1的时候，进行扩展名匹配，匹配到了SecondServlet，即走了c1，使用SecondServlet来处理请求；如果根目录下没有a.action文件，则走到了d，进行扩展名匹配，同样匹配到了SecondServlet，即走了d，同样使用SecondServlet来处理请求 * 案例4： first/abc，执行b的时候，就匹配到了FirstServlet，所以使用FirstServlet来处理请求 * */private final void internalMapWrapper(ContextVersioncontextVersion, CharChunkpath, MappingDatamappingData)throws IOException &#123; 。。。。。。。 if (found) &#123; mappingData.wrapperPath.setString(wrappers[pos].name); if (path.getLength() &gt;length) &#123; mappingData.pathInfo.setChars (path.getBuffer(), path.getOffset()+ length, path.getLength()- length); &#125; mappingData.requestPath.setChars (path.getBuffer(), path.getOffset(),path.getLength()); mappingData.wrapper=wrappers[pos].object; mappingData.jspWildCard=wrappers[pos].jspWildCard; &#125; &#125;&#125; 加载servlet并调用 一起执行顺序来看一下一个servlet如何进行加载 invoke:98,StandardEngineValve (org.apache.catalina.core) 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 基于请求的服务名选择合适的虚拟主机进行请求处理 * * 如果不能匹配到对应主机，返回对应的http错误 * * @param request 执行请求 * @param response Response tobe produced * */@Overridepublicfinal void invoke(Request request,Response response) throws IOException,ServletException&#123; //根据请求找到对应的host Host host =request.getHost(); if (host == null) &#123; response.sendError (HttpServletResponse.SC_BAD_REQUEST, sm.getString("standardEngine.noHost", request.getServerName())); return; &#125; //设置当前请求是否支持异步 if (request.isAsyncSupported())&#123; request.setAsyncSupported(host.getPipeline().isAsyncSupported()); &#125; //org.apache.catalina.valves.AccessLogValve[localhost] //org.apache.catalina.valves.ErrorReportValve[localhost] //org.apache.catalina.core.StandardHostValve[localhost] /** * 调用host的第一个valve * * 其执行原理是获取根据管道获取第一个阀门AccessLogValve调用其invoke方法 * * AccessLogValve的invoke第一行调用getNext().invoke()调用了ErrorReportValve * * 同理调用了StandardHostValve的invoke方法所以实际调用的最先的是invoke方法 * */ host.getPipeline().getFirst().invoke(request,response);&#125; invoke:143,StandardHostValve (org.apache.catalina.core) 下步调用context.getPipeline().getFirst().invoke(request,response); invoke:504,AuthenticatorBase(org.apache.catalina.authenticator) 下步调用getNext().invoke(request, response); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * * 基于URI的request获取对应的Wrapper如果没有匹配到返回一个HTTP错误 * * 在这个方法中做的事情主要是获取wrapper然后进行对应管道的阀门进行调用 * @param request Request tobe processed * @param response Response tobe produced * * @exception IOException if aninput/output error occurred * @exception ServletException ifa servlet error occurred */@Overridepublicfinal void invoke(Request request,Response response) throws IOException,ServletException&#123; // Disallow any directaccess to resources under WEB-INF or META-INF MessageBytesrequestPathMB = request.getRequestPathMB(); if ((requestPathMB.startsWithIgnoreCase("/META-INF/",0)) ||(requestPathMB.equalsIgnoreCase("/META-INF")) ||(requestPathMB.startsWithIgnoreCase("/WEB-INF/",0)) ||(requestPathMB.equalsIgnoreCase("/WEB-INF"))) &#123; response.sendError(HttpServletResponse.SC_NOT_FOUND); return; &#125; //获取当前request利用的wrapper Wrapper wrapper =request.getWrapper(); if (wrapper == null||wrapper.isUnavailable()) &#123; response.sendError(HttpServletResponse.SC_NOT_FOUND); return; &#125; // Acknowledge the request try &#123; response.sendAcknowledgement(); &#125; catch(IOExceptionioe) &#123; container.getLogger().error(sm.getString( "standardContextValve.acknowledgeException"),ioe); request.setAttribute(RequestDispatcher.ERROR_EXCEPTION,ioe); response.sendError(HttpServletResponse.SC_INTERNAL_SERVER_ERROR); return; &#125; if (request.isAsyncSupported())&#123; request.setAsyncSupported(wrapper.getPipeline().isAsyncSupported()); &#125; wrapper.getPipeline().getFirst().invoke(request,response);&#125; invoke:98,StandardWrapperValve (org.apache.catalina.core) 其主要操作如下：获取到对应的StandardWrapper，然后分配一个servlet,具体在loadServlet中进行实例话，再分配由于是成员变量，只有第一次调用的时候才会进行分配，之后直接返回第一次的实例化对一下对象，具体看allocate方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public final void invoke(Request request,Responseresponse) throws IOException,ServletException&#123; //获取到对应的StandardWrapper StandardWrapper wrapper= (StandardWrapper) getContainer(); //每个请求开始servlet都是为空 Servlet servlet = null; Context context =(Context) wrapper.getParent(); try &#123; if (!unavailable)&#123; servlet = wrapper.allocate(); &#125; &#125; MessageBytes requestPathMB =request.getRequestPathMB(); DispatcherTypedispatcherType = DispatcherType.REQUEST; if (request.getDispatcherType()==DispatcherType.ASYNC)dispatcherType = DispatcherType.ASYNC; request.setAttribute(Globals.DISPATCHER_TYPE_ATTR,dispatcherType); request.setAttribute(Globals.DISPATCHER_REQUEST_PATH_ATTR, requestPathMB); // 创建过滤器实例 ApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request,wrapper, servlet); if ((servlet !=null) &amp;&amp;(filterChain !=null)) &#123; if (context.getSwallowOutput()) &#123; try &#123; SystemLogHandler.startCapture(); if (request.isAsyncDispatching())&#123; request.getAsyncContextInternal().doInternalDispatch(); &#125; else if(comet) &#123; filterChain.doFilterEvent(request.getEvent()); &#125; else&#123; filterChain.doFilter(request.getRequest(), response.getResponse()); &#125; &#125; finally &#123; String log =SystemLogHandler.stopCapture(); if (log != null&amp;&amp;log.length() &gt; 0) &#123; context.getLogger().info(log); &#125; &#125; &#125; else &#123; if (request.isAsyncDispatching())&#123; request.getAsyncContextInternal().doInternalDispatch(); &#125; else if(comet) &#123; filterChain.doFilterEvent(request.getEvent()); &#125; else&#123; filterChain.doFilter (request.getRequest(), response.getResponse()); &#125; &#125; &#125; &#125; //释放过滤器 if (filterChain!=null) &#123; if (request.isComet())&#123; // If this is a Cometrequest, then the same chain will be used for the // processing of allsubsequent events. filterChain.reuse(); &#125; else&#123; filterChain.release(); &#125; &#125; // Deallocate theallocated servlet instance try &#123; if (servlet !=null) &#123; wrapper.deallocate(servlet); &#125; &#125; catch (Throwablee) &#123; ExceptionUtils.handleThrowable(e); container.getLogger().error(sm.getString("standardWrapper.deallocateException", wrapper.getName()),e); if (throwable == null) &#123; throwable = e; exception(request,response, e); &#125; &#125; try &#123; if ((servlet !=null) &amp;&amp; (wrapper.getAvailable() ==Long.MAX_VALUE)) &#123; wrapper.unload(); &#125; &#125; catch (Throwablee) &#123; ExceptionUtils.handleThrowable(e); container.getLogger().error(sm.getString("standardWrapper.unloadException", wrapper.getName()),e); if (throwable == null) &#123; throwable = e; exception(request,response, e); &#125; &#125; long t2=System.currentTimeMillis(); long time=t2-t1; processingTime += time; if( time &gt; maxTime)maxTime=time; if( time &lt; minTime)minTime=time;&#125; servlet的调用 按照这个顺序执行完所有过滤器就会执行对应的servlet,这是因为在创建过滤器 ApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request,wrapper, servlet); 的时候，将servlet给注入进去了，当过滤器执行完了，会执行调用servlet的service, 由于自己写的servlet是会继承HttpServlet的，所以将调用其service方法 调用如下： internalDoFilter:,ApplicationFilterChain 方法如下：下面展示了两个service ,同在HttpServlet只是方法的参数有所不同，加载过程先调用一个，然后第一个再调用第二个，根据请求方法调用自己对应的Servlet中的doGet等一些列方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172protected void service(HttpServletRequest req,HttpServletResponseresp) throws ServletException,IOException&#123; //获取对应的方法 String method = req.getMethod(); /** * 根据请求method调用对应方法 * GET ==&gt;doGet(req, resp) * head ==&gt; doHead(req, resp) * post ==&gt;doPost(req,resp) * * */ if (method.equals(METHOD_GET)) &#123; long lastModified= getLastModified(req); if (lastModified == -1) &#123; // servlet doesn't supportif-modified-since, no reason // to go through furtherexpensive logic doGet(req,resp); &#125; else&#123; long ifModifiedSince; try &#123; ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); &#125; catch(IllegalArgumentExceptioniae) &#123; // Invalid date header -proceed as if none was set ifModifiedSince = -1; &#125; if (ifModifiedSince&lt; (lastModified /1000 * 1000)) &#123; // If the servlet mod timeis later, call doGet() // Round down to thenearest second for a proper compare // A ifModifiedSince of-1 will always be less maybeSetLastModified(resp,lastModified); doGet(req,resp); &#125; else&#123; resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123; long lastModified =getLastModified(req); maybeSetLastModified(resp,lastModified); doHead(req,resp); &#125; else if(method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if(method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if(method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if(method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if(method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; // // Note that this means NOservlet supports whatever // method was requested, anywhereon this server. // String errMsg = lStrings.getString("http.method_not_implemented"); Object[] errArgs = newObject[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg,errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED,errMsg); &#125;&#125; 上面已经讲述了一个servlet调用的过程，他的信息是如何返回掉流中，我们的看一下response,getWrite方法可以看出这个流最终将outputBuffer给封装，其write方法所以是写到上文封装的流中，最后一并解析到页面，可以参照请求到响应流。]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat请求处理分析(五) 请求到响应流]]></title>
    <url>%2F2017%2F08%2F20%2Ftomcat%2F2018-01-23-4%2F</url>
    <content type="text"><![CDATA[请求到响应界面流&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;请求处理的过程主要是将所有的东西解析成流，转化成对应的http报文，所以在这里我先不关注servlet因为它最终也就是解析成流里面的数据processKey里面最终执行的是processSocket，它是线从缓存中获取对应的线程池，没有的话就创建一个，然后进行执行 123456789101112131415161718192021222324252627protected boolean processSocket(KeyAttachmentattachment, SocketStatus status, boolean dispatch) &#123; try &#123; if (attachment== null) &#123; return false; &#125; SocketProcessor sc = processorCache.pop(); if ( sc == null ) sc = new SocketProcessor(attachment, status); else sc.reset(attachment, status); Executor executor =getExecutor(); if (dispatch &amp;&amp;executor != null) &#123; executor.execute(sc); &#125; else &#123; sc.run(); &#125; &#125; catch (RejectedExecutionExceptionree) &#123; log.warn(sm.getString("endpoint.executor.fail", attachment.getSocket()), ree); return false; &#125; catch (Throwablet) &#123; ExceptionUtils.handleThrowable(t); // This means we got anOOM or similar creating a thread, or that // the pool and its queue arefull log.error(sm.getString("endpoint.process.fail"), t); return false; &#125; return true;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在上面描述的线程中，响应到页面主要是先构建对应的缓冲流，然后将缓冲流中的数据写入到sockt通道，这样就实现到了页面，具体操作逻辑如下：（自下向上执行） 下面我将与流相关的几步，进行一下讲述： process:,AbstractProtocol$AbstractConnectionHandler (org.apache.coyote) 12345678910111213141516if (processor == null) &#123; processor = createProcessor();&#125;protected Http11Processor createProcessor() &#123; Http11Processor processor = new Http11Processor( proto.getMaxHttpHeaderSize(), (JIoEndpoint)proto.endpoint, proto.getMaxTrailerSize(), proto.getAllowedTrailerHeadersAsSet(), proto.getMaxExtensionSize(), proto.getMaxSwallowSize()); proto.configureProcessor(processor); // BIO specificconfiguration processor.setDisableKeepAlivePercentage(proto.getDisableKeepAlivePercentage()); register(processor); return processor;&#125; 1234567891011121314public Http11Processor(int headerBufferSize, JIoEndpointendpoint, int maxTrailerSize, Set&lt;String&gt;allowedTrailerHeaders, int maxExtensionSize, int maxSwallowSize)&#123; super(endpoint); inputBuffer = new InternalInputBuffer(request, headerBufferSize); request.setInputBuffer(inputBuffer); outputBuffer = new InternalOutputBuffer(response, headerBufferSize); response.setOutputBuffer(outputBuffer); initializeFilters(maxTrailerSize, allowedTrailerHeaders, maxExtensionSize, maxSwallowSize);&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里不难看出构建了的outputBuffer这InternalOutputBuffer实例并与response进行关联，所以后面通过response进行一些相关属性操作就可以直接到缓冲流 process:,AbstractHttp11Processor(org.apache.coyote.http11) 12345678910111213141516getOutputBuffer().init(socketWrapper, endpoint);/** * 给当前实例 outputBuffer即response封装的对象 * * 给其成员变量NioChannel socket 以及pool进行赋值 * * */@Overridepublicvoid init(SocketWrapper&lt;NioChannel&gt; socketWrapper, AbstractEndpoint&lt;NioChannel&gt;endpoint) throws IOException &#123; socket =socketWrapper.getSocket(); pool =((NioEndpoint)endpoint).getSelectorPool();&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这一步进行的操作主要是将outputBuffer这个实例关联对应的socket通道，为最后将缓冲流的数据放入到sockt做铺垫 123456789101112131415161718public void close() throws IOException&#123; if (closed) &#123; return; &#125; if (suspended) &#123; return; &#125; //将缓冲去的字符刷新给页面 if (cb.getLength()&gt; 0) &#123; cb.flushBuffer(); &#125; 。。。。。。&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最终是将cb给刷新到了然后将数据返回到页面，看一下cb是怎么来的,由下不难看出将OutputBuffer给注入其通道 1234567891011public OutputBuffer(int size) &#123; bb = new ByteChunk(size); bb.setLimit(size); bb.setByteOutputChannel(this); cb = new CharChunk(size); cb.setLimit(size); cb.setOptimizedWrite(false); cb.setCharOutputChannel(this);&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样做最后怎么获取数据呢？由下面可以看出其一层一层不断的拆解最后还是到InternalOutputBuffer缓冲实例，所以解析的流数据最终还是经过这个进行处理 addToBB:,InternalNioOutputBuffer(org.apache.coyote.http11) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那最终它又是怎么到流中去，得看一下addToBB方法,由两步比较和核心，第一步就是将buf即InternalNioOutputBuffer实例中的数据拷贝到niochannel总去，第二步将niochannel通道中的数据写入到socket通道 123456789101112131415161718192021222324252627282930313233private synchronized void addToBB(byte[] buf, int offset, int length) throws IOException&#123; if (length == 0) return; //首先尝试先将数据发送出去 boolean dataLeft = flushBuffer(isBlocking()); //这里只有在缓冲区里面已经没有数据了才继续发送 while (!dataLeft&amp;&amp; length &gt; 0) &#123; //首先将要发送的数据copy到niochanel的发送buffer里面去 int thisTime =transfer(buf,offset,length,socket.getBufHandler().getWriteBuffer()); //计算还剩下多少字节没有写到niochannel的buffer里面，其实这里也就当做将数据转移到了niochannel的buffer就算是写出去了 length = length -thisTime; //这里用于调整偏移量 offset = offset +thisTime; //调用writeToSocket方法将niochannel的buffer的里面的数据通过socket写出去 int written =writeToSocket(socket.getBufHandler().getWriteBuffer(), isBlocking(), true); //如果在tomcat的response里面有writelistener的话，可以异步的写 if (written == 0) &#123; dataLeft = true; &#125; else &#123; dataLeft =flushBuffer(isBlocking()); &#125; &#125; NioEndpoint.KeyAttachment ka =(NioEndpoint.KeyAttachment)socket.getAttachment(); if (ka != null)ka.access();//prevent timeouts for just doing client writes if (!isBlocking()&amp;&amp; length &gt; 0) &#123; //在非阻塞的发送中，如果实在发送不出去，需要保存在额外的buffer里面 addToBuffers(buf, offset, length); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面在看一下具体怎么写到通道里面去 1234567891011121314151617181920212223242526272829private synchronized int writeToSocket(ByteBufferbytebuffer, boolean block, boolean flip) throws IOException&#123; if ( flip ) &#123; bytebuffer.flip(); flipped = true; &#125; int written = 0; NioEndpoint.KeyAttachmentatt = (NioEndpoint.KeyAttachment)socket.getAttachment(); if ( att == null ) throw new IOException("Keymust be cancelled"); long writeTimeout =att.getWriteTimeout(); Selector selector = null; try &#123; selector = pool.get(); &#125; catch (IOException x ) &#123; &#125; try &#123; written = pool.write(bytebuffer, socket,selector, writeTimeout, block); do &#123; if (socket.flush(true,selector,writeTimeout))break; &#125;while ( true ); &#125; finally &#123; if ( selector!= null)pool.put(selector); &#125; if ( block ||bytebuffer.remaining()==0) &#123; bytebuffer.clear(); flipped = false; &#125; return written;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pool实例，即NioBlockingSelector，可以看出其有阻塞和非组合两种写入方式，但最后都是通过socket.write(buf)写入socket通道就返回到页面，至于为什么写入到socket通道就能响应到页面可以看一下基于NIO的httpserver实现，主要SocketChannelImpl这个类,这里又一个简易的httpserver的实现，参考链接： http://www.cnblogs.com/a294098789/p/5676566.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public int write(ByteBuffer buf, NioChannelsocket, Selector selector, long writeTimeout, boolean block) throws IOException&#123; if ( SHARED &amp;&amp;block ) &#123; return blockingSelector.write(buf,socket,writeTimeout); &#125; SelectionKey key = null; int written = 0; boolean timedout = false; int keycount = 1; //assume we canwrite long time =System.currentTimeMillis(); //start the timeout timer try &#123; while ((!timedout) &amp;&amp; buf.hasRemaining() ) &#123; int cnt = 0; if ( keycount &gt; 0 ) &#123; //only write ifwe were registered for a write cnt = socket.write(buf);//write thedata if (cnt == -1) throw new EOFException(); written += cnt; if (cnt &gt; 0) &#123; time = System.currentTimeMillis(); //reset ourtimeout timer continue; //wesuccessfully wrote, try again without a selector &#125; if (cnt==0 &amp;&amp;(!block)) break; //don't block &#125; if ( selector!= null)&#123; //register OP_WRITE to theselector if (key==null) key =socket.getIOChannel().register(selector, SelectionKey.OP_WRITE); else key.interestOps(SelectionKey.OP_WRITE); if (writeTimeout==0) &#123; timedout =buf.hasRemaining(); &#125; else if (writeTimeout&lt;0) &#123; keycount =selector.select(); &#125; else &#123; keycount =selector.select(writeTimeout); &#125; &#125; if (writeTimeout&gt; 0 &amp;&amp; (selector == null || keycount== 0) ) timedout= (System.currentTimeMillis()-time)&gt;=writeTimeout; &#125;//while if ( timedout )thrownew SocketTimeoutException(); &#125; finally &#123; if (key != null) &#123; key.cancel(); if (selector != null)selector.selectNow();//removes the key from this selector &#125; &#125; return written;&#125;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat请求处理分析(四) 监听请求轮询处理]]></title>
    <url>%2F2017%2F08%2F18%2Ftomcat%2F2018-01-23-3%2F</url>
    <content type="text"><![CDATA[startInternal方法 这个方法是核心的启动方法，目前理解主要做了两件事情，第一件是创建轮询线程,即具体的读取线程,它是进行具体的处理，第二个是创建创建监听请求线程，它是等待请求，然后交给轮训进行处理。 1234567891011121314151617181920212223242526272829303132333435public void startInternal() throws Exception &#123; if (!running) &#123; running = true; paused = false; //一种带锁的栈，processorCache processorCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getProcessorCache()); //事件缓存 eventCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getEventCache()); //nio管道 nioChannels = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getBufferPool()); // Create workercollection if (getExecutor() == null ) &#123; createExecutor(); //实例化当前对象的成员变量executor，构建了一个线程池 &#125; initializeConnectionLatch(); //Poller的数量控制如果不设置的话最大就是2 pollers = new Poller[getPollerThreadCount()]; for (int i=0; i&lt;pollers.length; i++) &#123; pollers[i] = new Poller(); Thread pollerThread = new Thread(pollers[i], getName() + "-ClientPoller-"+i); pollerThread.setPriority(threadPriority);//用来设置进程、进程组和用户的进程执行优先权 pollerThread.setDaemon(true);//设置为守护线程 pollerThread.start(); &#125; startAcceptorThreads(); &#125;&#125; Poller启动 它是被设计成了守护线程,并且进行启动，其run方法如下，采用选择器的非阻塞方式，如果没有获取到注册事件返回空，下面迭代为空所以就什么都没有执行，如果返回不为空则会执行processKey方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public void run() &#123; //这是一个线程,所以进行死循环 while (true) &#123; try &#123; //如果是暂停并且未关闭则睡10s while (paused &amp;&amp;(!close) ) &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedExceptione) &#123; &#125; &#125; boolean hasEvents = false; //如果关闭之后,执行完毕时间后，关闭选择器 if (close) &#123; events(); timeout(0, false); try &#123; selector.close(); &#125; catch (IOExceptionioe) &#123; log.error(sm.getString( "endpoint.nio.selectorCloseFail"), ioe); &#125; break; &#125; else &#123; hasEvents = events(); &#125; /** * 如果endpoint是正常工作状态，处理已有的数据。 * 通过events方法来处理当前Poller中已有的事件（数据）。 * 同时使用selector.select或者selectNow来获取这个Poller上 * */ try &#123; if ( !close ) &#123; if (wakeupCounter.getAndSet(-1) &gt; 0) &#123; //if we are here, means we have other stuff to do //do a nonblocking select keyCount =selector.selectNow(); &#125; else &#123; keyCount =selector.select(selectorTimeout); &#125; wakeupCounter.set(0); &#125; if (close) &#123; events(); timeout(0, false); try &#123; selector.close(); &#125; catch (IOExceptionioe) &#123; log.error(sm.getString( "endpoint.nio.selectorCloseFail"), ioe); &#125; break; &#125; &#125; catch (Throwablex) &#123; ExceptionUtils.handleThrowable(x); log.error("",x); continue; &#125; //either we timed out orwe woke up, process events first if ( keyCount == 0 ) hasEvents= (hasEvents | events()); //正常状态下的数据处理，通过processKey来实现。获取对应的渠道的key，然后调用processKey方法 Iterator&lt;SelectionKey&gt;iterator = keyCount &gt; 0 ? selector.selectedKeys().iterator(): null; // Walk through thecollection of ready keys and dispatch // any active event. while (iterator !=null&amp;&amp;iterator.hasNext()) &#123; SelectionKey sk =iterator.next(); KeyAttachmentattachment = (KeyAttachment)sk.attachment(); if (attachment== null) &#123; iterator.remove(); &#125; else &#123; attachment.access(); iterator.remove(); //processKey的主要工作是调用NioEndpoint的processSocket来实现socket的读写。 processKey(sk, attachment); &#125; &#125;//while timeout(keyCount,hasEvents); if ( oomParachute&gt;0&amp;&amp;oomParachuteData==null)checkParachute(); &#125; stopLatch.countDown();&#125; Acceptor 这是一个接受请求的线程，调用的是startAcceptorThreads方法，方法代码如下： 1234567891011121314151617181920protected final void startAcceptorThreads() &#123; int count =getAcceptorThreadCount(); acceptors = new Acceptor[count]; for (int i = 0; i &lt; count; i++) &#123; acceptors[i] = createAcceptor(); String threadName =getName() + "-Acceptor-" + i; acceptors[i].setThreadName(threadName); Thread t = new Thread(acceptors[i], threadName); t.setPriority(getAcceptorThreadPriority()); t.setDaemon(getDaemon()); t.start(); &#125;&#125; protectedAbstractEndpoint.AcceptorcreateAcceptor() &#123; return new Acceptor();&#125; 所以启动的事Acceptor的线程，主要调用的是其run方法，它做的事情是等待客户端请求，由于在bind方法中ServerSocketChannel这个设置阻塞方式，所以socket = serverSock.accept();在接受请求之后才会进行处理，具体的处理过程在setSocketOptions方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * Acceptor负责用来管理连接到tomcat服务器的数量 * socket连接建立成功之后,读写是交由Poller机制去完成。 * */protected class Acceptor extends AbstractEndpoint.Acceptor&#123; @Override public void run() &#123; int errorDelay =0; while (running) &#123; while (paused &amp;&amp; running) &#123; state =AcceptorState.PAUSED; try &#123; Thread.sleep(50); &#125; catch (InterruptedExceptione) &#123; &#125; &#125; if (!running) &#123; break; &#125; state =AcceptorState.RUNNING; try &#123; countUpOrAwaitConnection(); //计数+1，达到最大值则等待 SocketChannel socket = null; try &#123; //ServerSocketChannel 一个阻塞监听等待请求 socket = serverSock.accept(); &#125; catch (IOExceptionioe) &#123; //we didn't geta socket countDownConnection(); // Introducedelay if necessary errorDelay =handleExceptionWithDelay(errorDelay); // re-throw throw ioe; &#125; // Successful accept,reset the error delay errorDelay = 0; // setSocketOptions() willadd channel to the poller // if successful if (running &amp;&amp; !paused) &#123; //将请求连接放入队列等待处理 if (!setSocketOptions(socket)) &#123; countDownConnection(); closeSocket(socket); &#125; &#125; else &#123; countDownConnection(); //计数-1 closeSocket(socket); //关闭当前socket套接字 &#125; &#125; catch (SocketTimeoutExceptionsx) &#123; // Ignore: Normalcondition &#125; catch (IOExceptionx) &#123; if (running) &#123; log.error(sm.getString("endpoint.accept.fail"), x); &#125; &#125; catch (OutOfMemoryErroroom) &#123; try &#123; oomParachuteData=null; releaseCaches(); log.error("", oom); &#125;catch ( Throwableoomt ) &#123; try &#123; try &#123; System.err.println(oomParachuteMsg); oomt.printStackTrace(); &#125;catch (ThrowableletsHopeWeDontGetHere)&#123; ExceptionUtils.handleThrowable(letsHopeWeDontGetHere); &#125; &#125;catch (ThrowableletsHopeWeDontGetHere)&#123; ExceptionUtils.handleThrowable(letsHopeWeDontGetHere); &#125; &#125; &#125; catch (Throwablet) &#123; ExceptionUtils.handleThrowable(t); log.error(sm.getString("endpoint.accept.fail"), t); &#125; &#125; state =AcceptorState.ENDED; &#125;&#125; acceptor线程转交到poller进行处理 setSocketOptions方法通过通道获取真实的socket注入一些属性,然后构造NioChannel，将socket通道注入到对应的NioChannel实例，利用getPoller0用的循环的方式来返回Poller然后将NioChannel实例注册 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859protected boolean setSocketOptions(SocketChannel socket)&#123; // Process the connection try &#123; //设置为非阻塞 socket.configureBlocking(false); //获取socket Socket sock = socket.socket();//实际socket //配置socket信息 socketProperties.setProperties(sock); //创建一个NioChannel 他封装了SocketChannel NioChannel channel = nioChannels.pop(); if ( channel == null ) &#123; //如果为null 创建一个NioChannel 这里使用系统内存 //使用系统内存可以省去一步从系统内存拷贝到堆内存的动作、性能上会有很大的提升，nioChannels初始化默认为128个 //当socket 关闭的重新清理NioChannel而不是销毁这个对象可以达到对象复用的效果、因为申请系统内存的开销比申请堆内存的开销要大很多 if (sslContext != null) &#123; SSLEngine engine =createSSLEngine(); int appbufsize =engine.getSession().getApplicationBufferSize(); //NioBufferHandler里分别分配了读缓冲区和写缓冲区 NioBufferHandler bufhandler= newNioBufferHandler(Math.max(appbufsize,socketProperties.getAppReadBufSize()), Math.max(appbufsize,socketProperties.getAppWriteBufSize()), socketProperties.getDirectBuffer()); channel = new SecureNioChannel(socket, engine, bufhandler, selectorPool); &#125; else &#123; // normal tcp setup NioBufferHandlerbufhandler = new NioBufferHandler(socketProperties.getAppReadBufSize(), socketProperties.getAppWriteBufSize(), socketProperties.getDirectBuffer()); channel = new NioChannel(socket, bufhandler); &#125; &#125; else &#123; //如果存在通道，则直接将当前socket注入 channel.setIOChannel(socket); if ( channel instanceof SecureNioChannel) &#123; SSLEngine engine =createSSLEngine(); ((SecureNioChannel)channel).reset(engine); &#125; else &#123; channel.reset(); &#125; &#125; // 这里就是将SocketChannel注册到Poller了。 // getPoller0用的循环的方式来返回Poller，即Poller 1, 2,3... n 然后再回到1, 2, 3.. getPoller0().register(channel); &#125; catch (Throwablet) &#123; ExceptionUtils.handleThrowable(t); try &#123; log.error("",t); &#125; catch (Throwablett) &#123; ExceptionUtils.handleThrowable(tt); &#125; // Tell to close thesocket return false; &#125; return true;&#125; 上文注册还不是选择器的注入方式，而是在NioEndpoint内部类Poller类的register方法，其代码如下：在前面设置了一些基本属性，然后调用addEvent唤醒对应的选择器，这个selector实例是Poller对象的一个成员变量，对应的非阻塞过程在run方法，所以监听请求世实际还是在Poller的run方法中selectNow后面进行处理 123456789101112131415161718192021222324252627public void register(final NioChannelsocket) &#123; //给当前socket设置为这个Poller实例 socket.setPoller(this); //构造KeyAttachment实例，其继承SocketWrapper KeyAttachment ka = new KeyAttachment(socket); //设置其轮询实例 ka.setPoller(this); ka.setTimeout(getSocketProperties().getSoTimeout()); ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests()); ka.setSecure(isSSLEnabled()); // 从Poller的事件对象缓存中取出一个PollerEvent，并用socket初始化事件对象 PollerEvent r = eventCache.pop(); // 设置读操作为感兴趣的操作 ka.interestOps(SelectionKey.OP_READ); if ( r==null) r = new PollerEvent(socket,ka,OP_REGISTER); else r.reset(socket,ka,OP_REGISTER); // 加入到Poller对象里的事件队列 addEvent(r);&#125; private void addEvent(PollerEvent event) &#123; events.offer(event); if ( wakeupCounter.incrementAndGet()== 0)selector.wakeup();&#125; 具体执行的接受到通道注册的时间之后，往下执行，就能够产生相应的选择键，这样会执行processKey这个方法，然后将请求进行处理，并解析成相关的流，返回到界面。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public void run() &#123; …… /** * 如果endpoint是正常工作状态，处理已有的数据。 * 通过events方法来处理当前Poller中已有的事件（数据）。 * 同时使用selector.select或者selectNow来获取这个Poller上 * */ try &#123; if ( !close ) &#123; if (wakeupCounter.getAndSet(-1) &gt; 0) &#123; keyCount = selector.selectNow(); &#125; else &#123; keyCount = selector.select(selectorTimeout); &#125; wakeupCounter.set(0); &#125; if (close) &#123; events(); timeout(0, false); try &#123; selector.close(); &#125; catch (IOExceptionioe) &#123; log.error(sm.getString( "endpoint.nio.selectorCloseFail"), ioe); &#125; break; &#125; &#125; catch (Throwablex) &#123; ExceptionUtils.handleThrowable(x); log.error("",x); continue; &#125; if ( keyCount == 0 ) hasEvents= (hasEvents | events()); //正常状态下的数据处理，通过processKey来实现。获取对应的渠道的key，然后调用processKey方法 Iterator&lt;SelectionKey&gt;iterator = keyCount &gt; 0 ? selector.selectedKeys().iterator(): null; // Walk through thecollection of ready keys and dispatch // any active event. while (iterator !=null&amp;&amp;iterator.hasNext()) &#123; SelectionKey sk =iterator.next(); KeyAttachmentattachment = (KeyAttachment)sk.attachment(); // Attachment may be nullif another thread has called // cancelledKey() if (attachment== null) &#123; iterator.remove(); &#125; else &#123; attachment.access(); iterator.remove(); //processKey的主要工作是调用NioEndpoint的processSocket来实现socket的读写。 processKey(sk, attachment); &#125; &#125;//while //process timeouts timeout(keyCount,hasEvents); if ( oomParachute&gt;0&amp;&amp;oomParachuteData==null)checkParachute(); &#125; catch (OutOfMemoryErroroom) &#123; try &#123; oomParachuteData = null; releaseCaches(); log.error("", oom); &#125;catch ( Throwableoomt ) &#123; try &#123; System.err.println(oomParachuteMsg); oomt.printStackTrace(); &#125;catch (ThrowableletsHopeWeDontGetHere)&#123; ExceptionUtils.handleThrowable(letsHopeWeDontGetHere); &#125; &#125; &#125; &#125;//while stopLatch.countDown();&#125;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat请求处理分析(三) 绑定本地端口监听请求]]></title>
    <url>%2F2017%2F08%2F18%2Ftomcat%2F2018-01-23-2%2F</url>
    <content type="text"><![CDATA[bind方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意：这个bind可能在load的过程就已经加载，这里只是验证 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NioEndpoint就是使用Java中的NIO技术，来实行对Socket的处理。它主要包含两个部业务处理部分：Poller线程组和Acceptor线程组。 解析过程&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先我们应该知道其bind方法做了一些什么操作,代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142public void bind() throws Exception &#123; // 打开监听信道 serverSock =ServerSocketChannel.open(); socketProperties.setProperties(serverSock.socket()); InetSocketAddress addr= (getAddress()!=null?new InetSocketAddress(getAddress(),getPort()):new InetSocketAddress(getPort())); serverSock.socket().bind(addr,getBacklog()); serverSock.configureBlocking(true); //mimic APRbehavior serverSock.socket().setSoTimeout(getSocketProperties().getSoTimeout()); if (acceptorThreadCount==0) &#123; // FIXME:Doesn't seem to work that well with multiple accept threads acceptorThreadCount = 1; &#125; if (pollerThreadCount&lt;=0) &#123; //minimum one pollerthread pollerThreadCount = 1; &#125; stopLatch = new CountDownLatch(pollerThreadCount); // Initialize SSL ifneeded if (isSSLEnabled())&#123; SSLUtil sslUtil = handler.getSslImplementation().getSSLUtil(this); sslContext =sslUtil.createSSLContext(); sslContext.init(wrap(sslUtil.getKeyManagers()), sslUtil.getTrustManagers(), null); SSLSessionContextsessionContext = sslContext.getServerSessionContext(); if (sessionContext != null) &#123; sslUtil.configureSessionContext(sessionContext); &#125; // Determine which ciphersuites and protocols to enable enabledCiphers =sslUtil.getEnableableCiphers(sslContext); enabledProtocols =sslUtil.getEnableableProtocols(sslContext); &#125; if (oomParachute&gt;0)reclaimParachute(true); selectorPool.open();&#125; 实例化ServerSocketChannelImpl serverSock =ServerSocketChannel.open(); 其方法具体实现： 123public static ServerSocketChannel open() throws IOException&#123; return SelectorProvider.provider().openServerSocketChannel();&#125; 在这个方法中进行了两步操作，第一步调用SelectorProvider的provider方法 1234567891011121314151617181920public static SelectorProvider provider() &#123; synchronized (lock) &#123; if (provider != null) return provider; //在与当前线程相同访问控制权限的环境中，加载SelectorProvider实例 return AccessController.doPrivileged( new PrivilegedAction&lt;SelectorProvider&gt;() &#123; public SelectorProvider run() &#123; if (loadProviderFromProperty()) return provider; //获取系统配置的SelectorProvider if (loadProviderAsService()) return provider; //获取类加载路径下的SelectorProvider //加载默认的SelectorProvider provider = sun.nio.ch.DefaultSelectorProvider.create(); return provider; &#125; &#125;); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;判断provider在当前进程是否已经被实例化过了，如果已经被实例化过了，那么就直接返回当前provider，不再执行后面的代码；否者就执行后面的代码实例化provider,AccessController.doPrivileged()在与当前线程相同访问控制权限的环境中，加载SelectorProvider实例 loadProviderFromProperty()这个函数判断如果系统属性java.nio.channels.spi.SelectorProvider 已经被定义了，则该属性名看作具体提供者类的完全限定名。加载并实例化该类；如果此进程失败，则抛出未指定的错误。 loadProviderAsService()这个函数判断：如果在对系统类加载器可见的 jar 文件中安装了提供者类，并且该 jar 文件包含资源目录 META-INF/services 中名为java.nio.channels.spi.SelectorProvider 的提供者配置文件，则采用在该文件中指定的第一个类名称。加载并实例化该类；如果此进程失败，则抛出未指定的错误。最后，如果未通过上述的方式制定任何provider，则实例化系统默认的provider并返回该结果(一般情况下，都是这种情况。)这个地方需要注意的是：这里系统默认的provider在不同系统上是不一样的，下面用一个表格来表示： 系统 provider macOSX KQueueSelectorProvider Linux KQueueSelectorProvider Windows WindowsSelectorProvider &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进入sun.nio.ch.DefaultSelectorProvider.create(); 这里系统会根据不同的操作系统返回不同的provider；具体信息在上面的表格 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总结：该方法的作用完成建立Pipe，并把pipe的读写文件描述符放入pollArray中,这个pollArray是Selector的枢纽 ====================方法分界线======================= &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述是调用provider方法的具体过程，下面讲解一下调用其之后继续调用openServerSocketChannel的过程 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以osx系统为例其返回了KQueueSelectorProvider，所以调用的方法是KQueueSelectorProvider.openServerSocketChannel 注意：其实这个方法不在KQueueSelectorProvider这个类中，而在其父类SelectorProviderImpl中,方法如下： 1234publicServerSocketChannelopenServerSocketChannel() throws IOException &#123; return new ServerSocketChannelImpl(this);&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;即ServerSocketChannel.open()方法实际上是产生了一个子类ServerSocketChannelImpl的对象实例。其构造器如下： 123456ServerSocketChannelImpl(SelectorProvider var1) throws IOException &#123; super(sp); this.fd = Net.serverSocket(true); //获取ServerSocket的文件描述符 this.fdVal = IOUtil.fdVal(this.fd); //获取文件描述的id this.state = ST_INUSE; //类变量 private static final int ST_INUSE = 0;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以在这里，serverSock = ServerSocketChannel.open();这个方法的作用是实例化ServerSocketChannelImpl,其成员变量具体实现代码如下： //获取ServerSocket的文件描述符 123456789101112131415161718192021222324252627282930class Net&#123; private static volatile boolean checkedIPv6 = false; private static volatile boolean isIPv6Available; public static final int SHUT_RD = 0;//关闭读操作 public static final int SHUT_WR = 1;//关闭写操作 public static final int SHUT_RDWR = 2;//关闭读写操作 static &#123; //加载nio和net资源库 Util.load(); initIDs(); &#125; private static native void initIDs(); //默认协议 static final ProtocolFamily UNSPEC = new ProtocolFamily() &#123; public String name() &#123; return "UNSPEC"; &#125; &#125;; //获取ServerSocket文件描述 static FileDescriptor serverSocket(boolean flag) &#123; return IOUtil.newFD(socket0(isIPv6Available(), flag, true)); &#125; private static native int socket0(boolean flag, boolean flag1, boolean flag2);&#125; ============================================================= 12345678910111213141516class IOUtil&#123; static final int IOV_MAX = iovMax(); static final boolean $assertionsDisabled = !sun/nio/ch/IOUtil.desiredAssertionStatus(); static &#123; Util.load(); &#125; 创建文件描述符 static FileDescriptor newFD(int i) &#123; FileDescriptor filedescriptor = new FileDescriptor(); setfdVal(filedescriptor, i); return filedescriptor; &#125;&#125; //获取文件描述的id 12345static native int fdVal(FileDescriptor filedescriptor);``` ### 构建socket并设置相关属性 socketProperties.setProperties(serverSock.socket());1234567891011121314151617181920 serverSock.socket()的具体实现```javapublicServerSocket socket() &#123; synchronized(stateLock) &#123; // stateLock是一个new Object() 加载进行 if(socket == null) socket =ServerSocketAdaptor.create(this); returnsocket; &#125;&#125; ============================create方法============================== 12345678910111213publicstatic ServerSocket create(ServerSocketChannelImpl ssc) &#123; try &#123; return new ServerSocketAdaptor(ssc); &#125; catch (IOException x) &#123; throw new Error(x); &#125; &#125; ==============================构造器============================= 123456789private(ServerSocketChannelImpl ssc) throws IOException &#123; this.ssc = ssc;&#125; ====================ServerSocketChannelImpl类属性=============== 123private final ServerSocketChannelImpl ssc;private volatile int timeout = 0; =============================================================== &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;此方法返回的是一个ServerSocket对象，其中利用同步保证了socket是一个单例到了这里socketProperties.setProperties(serverSock.socket());这个方法就等价于socketProperties.setProperties(ServerSocket),其代码如下： 1234567891011121314public void setProperties(ServerSocket socket) throws SocketException&#123; if (rxBufSize != null) socket.setReceiveBufferSize(rxBufSize.intValue()); //设置输入流缓冲大小 if (performanceConnectionTime!=null&amp;&amp;performanceLatency!=null&amp;&amp; performanceBandwidth != null) socket.setPerformancePreferences(//设置网络传输指标相对重要性 performanceConnectionTime.intValue(), performanceLatency.intValue(), performanceBandwidth.intValue()); if (soReuseAddress!=null) socket.setReuseAddress(soReuseAddress.booleanValue()); if (soTimeout != null &amp;&amp; soTimeout.intValue()&gt;= 0) socket.setSoTimeout(soTimeout.intValue());&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总结：这段代码的作用是创建socket实例并给当前socket设置一些属性，包括输入流缓冲区、网络传输三项指标的相对重要性、端口是否可复用、设置读取超时时间，其实在启动过程中这些都是null,所以并没有进行什么设置 123public int getReceiveBufferSize() throws SocketExceptionpublic void setReceiveBufferSize(int size) throwsSocketException &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在默认情况下，输入流的接收缓冲区是8096个字节（8K）。这个值是Java所建议的输入缓冲区的大小。如果这个默认值不能满足要求，可以用setReceiveBufferSize方法来重新设置缓冲区的大小。但最好不要将输入缓冲区设得太小，否则会导致传输数据过于频繁，从而降低网络传输的效率。如果底层的Socket实现不支持SO_RCVBUF选项，这两个方法将会抛出SocketException例外。必须将size设为正整数，否则setReceiveBufferSize方法将抛出IllegalArgumentException例外 =================================================================== 1public void setPerformancePreferences(int connectionTime,intlatency,int bandwidth) 以上方法的三个参数表示网络传输数据的三项指标： 参数connectionTime：表示用最少时间建立连接。 参数latency：表示最小延迟。 参数bandwidth：表示最高带宽。 setPerformancePreferences()方法用来设定这三项指标之间的相对重要性。可以为这些参数赋予任意的整数，这些整数之间的相对大小就决定了相应参数的相对重要性。例如，如果参数connectionTime为2，参数latency为1，而参数bandwidth为3，就表示最高带宽最重要，其次是最少连接时间，最后是最小延迟。 123public boolean getReuseAddress() throws SocketException public void setReuseAddress(boolean on) throws SocketException 错误的说法： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过这个选项，可以使多个Socket对象绑定在同一个端口上。 正确的说明是： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果端口忙，但TCP状态位于 TIME_WAIT ，可以重用端口。如果端口忙，而TCP状态位于其他状态，重用端口时依旧得到一个错误信息，抛出“Addressalready in use： JVM_Bind”。如果你的服务程序停止后想立即重启，不等60秒，而新套接字依旧使用同一端口，此时SO_REUSEADDR 选项非常有用。必须意识到，此时任何非期望数据到达，都可能导致服务程序反应混乱，不过这只是一种可能，事实上很不可能。这个参数在Windows平台与Linux平台表现的特点不一样。在Windows平台表现的特点是不正确的，在Linux平台表现的特点是正确的。在Windows平台，多个Socket新建立对象可以绑定在同一个端口上，这些新连接是非TIME_WAIT状态的。这样做并没有多大意义。在Linux平台，只有TCP状态位于 TIME_WAIT ，才可以重用端口。这才是正确的行为。 使用SO_REUSEADDR选项时有两点需要注意： 1. 必须在调用bind方法之前使用setReuseAddress方法来打开SO_REUSEADDR选项。因此，要想使用SO_REUSEADDR选项，就不能通过Socket类的构造方法来绑定端口。 2. 必须将绑定同一个端口的所有的Socket对象的SO_REUSEADDR选项都打开才能起作用。如在例程4-12中，socket1和socket2都使用了setReuseAddress方法打开了各自的SO_REUSEADDR选项。 在Windows操作系统上运行上面的代码的运行结果如下： 这种结果是不正确的。 socket1.getReuseAddress():true socket2.getReuseAddress():true 在Linux操作系统上运行上面的代码的运行结果如下： 这种结果是正确的。因为第一个连接不是TIME_WAIT状态的，第二个连接就不能使用8899端口； 只有第一个连接是TIME_WAIT状态的，第二个连接就才能使用8899端口； public int getSoTimeout() throws SocketException public void setSoTimeout(int timeout) throws SocketException 这个Socket选项在前面已经讨论过。可以通过这个选项来设置读取数据超时。当输入流的read方法被阻塞时，如果设置timeout（timeout的单位是毫秒），那么系统在等待了timeout毫秒后会抛出一个InterruptedIOException例外。在抛出例外后，输入流并未关闭，你可以继续通过read方法读取数据。如果将timeout设为0，就意味着read将会无限等待下去，直到服务端程序关闭这个Socket.这也是timeout的默认值。如下面的语句将读取数据超时设为30秒： 创建套接字地址1InetSocketAddress addr = (getAddress()!=null?new InetSocketAddress(getAddress(),getPort()):new InetSocketAddress(getPort())); 创建套接字地址，并设置其端口 绑定地址和端口serverSock.socket().bind(addr,getBacklog());socket()是一个单例模式创建其实例，所以在这里还是上面的ServerSocketChannelImpl实例，然后调用其bind方法，方法代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public ServerSocketChannel bind(SocketAddress socketaddress, int i) throws IOException &#123; synchronized(lock) &#123; if(!isOpen()) //如果socket关闭，则抛出ClosedChannelException throw new ClosedChannelException(); if(isBound()) //如果已绑定，则抛出AlreadyBoundException throw new AlreadyBoundException(); //确定inetsocketaddress InetSocketAddress inetsocketaddress = socketaddress != null ? Net.checkAddress(socketaddress) : new InetSocketAddress(0); SecurityManager securitymanager = System.getSecurityManager(); if(securitymanager != null) //检查地址端口监听权限 securitymanager.checkListen(inetsocketaddress.getPort()); //绑定前工作 NetHooks.beforeTcpBind(fd, inetsocketaddress.getAddress(), inetsocketaddress.getPort()); //实际地址绑定 Net.bind(fd, inetsocketaddress.getAddress(), inetsocketaddress.getPort()); //开启监听，如果参数i小于1，默认接受50个连接 Net.listen(fd, i &gt;= 1 ? i : 50); synchronized(stateLock) &#123; //更新ocalAddress localAddress = Net.localAddress(fd); &#125; &#125; return this; &#125;``` &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;从上面可以看出，bind首先检查ServerSocket是否关闭，是否绑定地址，如果既没有绑定也没关闭，则检查绑定的socketaddress是否正确或合法；然后通过Net工具类的bind（native）和listen（native），完成实际的ServerSocket地址绑定和开启监听，如果绑定是开启的参数小于1，则默认接受50个连接。 ### serverSock设置成阻塞IOserverSock.configureBlocking(true);代码如下：```javapublic finalSelectableChannelconfigureBlocking(boolean block) throws IOException&#123; synchronized (regLock) &#123; if (!isOpen()) throw new ClosedChannelException(); if (blocking == block) return this; if (block &amp;&amp; haveValidKeys()) throw new IllegalBlockingModeException(); implConfigureBlocking(block); blocking = block; &#125; return this;&#125;``` 1.1.1.1.1.6 设置读取超时时间```javaserverSock.socket().setSoTimeout(getSocketProperties().getSoTimeout()); 初始化线程数123456789//初始化acceptor和poller线程数if (acceptorThreadCount == 0) &#123; // FIXME: Doesn't seem to work that well with multiple accept threads acceptorThreadCount = 1;&#125;if (pollerThreadCount &lt;= 0) &#123; //minimum one poller thread pollerThreadCount = 1;&#125; 实例化线程同步辅助类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ountDownLatch类是一个同步计数器,构造时传入int参数,该参数就是计数器的初始值，每调用一次countDown()方法，计数器减1,计数器大于0 时，await()方法会阻塞程序继续执行stopLatch = new CountDownLatch(pollerThreadCount);参考链接：http://www.cnblogs.com/yezhenhan/archive/2012/01/07/2315652.html &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个属性的作用是为了在关闭的时候确定所有的pollers关闭才继续向后执行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void stopInternal() &#123; releaseConnectionLatch(); if (!paused) &#123; pause(); &#125; if (running) &#123; running = false; unlockAccept(); for (int i=0; pollers!=null &amp;&amp;i&lt;pollers.length; i++) &#123; if (pollers[i]==null) continue; pollers[i].destroy(); pollers[i] = null; &#125; try &#123; stopLatch.await(selectorTimeout+100, TimeUnit.MILLISECONDS); &#125; catch (InterruptedExceptionignore) &#123; &#125; shutdownExecutor(); eventCache.clear(); nioChannels.clear(); processorCache.clear(); &#125;&#125;``` ### NioSelectorPool实例设置属性selectorPool.open();其中selectorPool是成员变量 private NioSelectorPool selectorPool = new NioSelectorPool(); 在分析selectorPool.open();这段代码之前，我们必须了解Selector open()这个方法是干嘛，这个方法也在NioSelectorPool中代码如下：```javapublic staticSelector open() throws IOException &#123; returnSelectorProvider.provider().openSelector();&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过调用系统默认的SelectorProvider(这里不同的系统会有不同的SelectorProvider实现类)的openSelector()方法来创建新的selector SelectorProvider.provider()这个方法我们已经在上文分析过，这里获取的就是同一个KQueueSelectorProvider实例后面调用的也就是KQueueSelectorProvider.openSelector();源码如下： 12345public AbstractSelector openSelector()throws IOException &#123; returnnew KQueueSelectorImpl(this);&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据代码可以看出其实例化了一个KQueueSelectorImpl,这是一个选择器，看一下选择器的作用，Selector选择器类管理着一个被注册的通道集合的信息和它们的就绪状态。通道是和选择器一起被注册的，并且使用选择器来更新通道的就绪状态。当这么做的时候，可以选择将被激发的线程挂起，直到有就绪的的通道。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以下面代码的则用是构建blockingSelector实例，并将KQueueSelectorImpl给注入sharedSelector，这两个变量都是NioSelectorPool的属性 123456789101112131415161718192021222324252627282930public void open() throws IOException&#123; enabled = true; getSharedSelector(); if (SHARED) &#123; blockingSelector = new NioBlockingSelector(); blockingSelector.open(getSharedSelector()); &#125;&#125; protected Selector getSharedSelector() throws IOException&#123; if (SHARED &amp;&amp; SHARED_SELECTOR==null) &#123; synchronized ( NioSelectorPool.class ) &#123; if ( SHARED_SELECTOR==null) &#123; synchronized (Selector.class) &#123; SHARED_SELECTOR=Selector.open(); &#125; log.info("Usinga shared selector for servlet write/read"); &#125; &#125; &#125; return SHARED_SELECTOR;&#125; public static Selector open() throws IOException&#123; return SelectorProvider.provider().openSelector();&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面这个方法是创建一个轮询线程，然后将选择器赋值给这个公司，并设置起为守护线程 12345678public void open(Selector selector) &#123; sharedSelector = selector; poller = new BlockPoller(); poller.selector = sharedSelector; poller.setDaemon(true); poller.setName("NioBlockingSelector.BlockPoller-"+(++threadCounter)); poller.start();&#125;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat请求处理分析(二) 启动mapperListener]]></title>
    <url>%2F2017%2F08%2F18%2Ftomcat%2F2018-01-23-1%2F</url>
    <content type="text"><![CDATA[启动mapperListener 这个方法的核心就是注册Host的 123456789101112131415161718192021222324public void startInternal() throws LifecycleException&#123; setState(LifecycleState.STARTING); //获取当前service的container，其实也就是engine @SuppressWarnings("deprecation") Engine engine = (Engine) service.getContainer(); if (engine == null) &#123; return; &#125; findDefaultHost();//获取当前engine默认的host addListeners(engine);//给当前Mapper添加监听时间 //找到当前engine下所有host主机 Container[] conHosts =engine.findChildren(); for (Container conHost :conHosts) &#123; Host host = (Host) conHost; if (!LifecycleState.NEW.equals(host.getState()))&#123; // 登记host会注册context和 wrappers registerHost(host); &#125; &#125;&#125; 注册Host 注册Host主要进行了两步操作，第一步是添加Host 第二步是registerContext 123456789101112131415private void registerHost(Host host) &#123; String[] aliases = host.findAliases(); mapper.addHost(host.getName(), aliases, host); for (Container container :host.findChildren()) &#123; if (container.getState().isAvailable())&#123; registerContext((Context)container); &#125; &#125; if(log.isDebugEnabled())&#123; log.debug(sm.getString("mapperListener.registerHost", host.getName(), domain, service)); &#125;&#125; 添加Host 123456789101112131415161718192021222324252627282930313233343536public synchronizedvoid addHost(String name, String[]aliases, Host host) &#123; //StandardEngine[Catalina].StandardHost[localhost] //创建MappedHost对象的数组，这里长度需要加1 MappedHost[]newHosts = new MappedHost[hosts.length + 1]; //创建一个MappedHost对象，用于保存host的map信息 MappedHostnewHost = new MappedHost(name, host); //insertMap将hosts这个数组迁移到newHosts并将newHost按name添加到指定位置 if (insertMap(hosts, newHosts, newHost)) &#123; hosts= newHosts; //指向新的数组 if (log.isDebugEnabled()) &#123; log.debug(sm.getString("mapper.addHost.success", name)); &#125; &#125; else&#123; //不能插入这说明有相同名字的,有两种情况，第一种是在先前通过addContextVersion加入让那个newHost指向，另一种名字相同则直接返回 MappedHostduplicate = hosts[find(hosts, name)]; if (duplicate.object == host) &#123; if(log.isDebugEnabled()) &#123; log.debug(sm.getString("mapper.addHost.sameHost", name)); &#125; newHost = duplicate; &#125;else &#123; log.error(sm.getString("mapper.duplicateHost", name, duplicate.getRealHostName())); return; &#125; &#125; List&lt;MappedHost&gt; newAliases = new ArrayList&lt;&gt;(aliases.length); for (Stringalias : aliases) &#123; MappedHost newAlias = new MappedHost(alias, newHost); if (addHostAliasImpl(newAlias)) &#123; newAliases.add(newAlias); &#125; &#125; newHost.addAliases(newAliases);&#125; 这个方法的作用将新的host插入到已有的集合，如果存在，直接返回，不存在则按字母排序有序插入，其中实现有序插入主要是调用了find这个二分查找，找到跟当前name最近的一个，然后进行插入，数组迁移 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private static final &lt;T&gt; boolean insertMap (MapElement&lt;T&gt;[]oldMap, MapElement&lt;T&gt;[] newMap, MapElement&lt;T&gt;newElement) &#123; int pos = find(oldMap, newElement.name);//在old里面，最近接新的元素的name的位置，这里返回的pos要么name相当，要么最左侧 if ((pos != -1) &amp;&amp;(newElement.name.equals(oldMap[pos].name))) &#123; //这里表示有名字相同的，那么失败 return false; &#125; //分段拷贝，这样拷贝完了之后也是排好序的 System.arraycopy(oldMap, 0, newMap, 0, pos + 1); //对数组拷贝，这里相当于先拷贝小的 newMap[pos + 1] =newElement; System.arraycopy (oldMap, pos + 1, newMap, pos + 2, oldMap.length - pos - 1); return true;&#125;``` 二分查找方法如下:```javaprivate static final &lt;T&gt; int find(MapElement&lt;T&gt;[] map, String name)&#123; int a = 0; int b = map.length - 1; // Special cases: -1 and 0 if (b == -1) &#123; return -1; &#125; if (name.compareTo(map[0].name) &lt; 0) &#123; return -1; &#125; if (b == 0) &#123; return 0; &#125; int i = 0; while (true) &#123; i = (b + a) / 2; int result =name.compareTo(map[i].name); if (result &gt; 0) &#123; a = i; &#125; else if (result == 0) &#123; return i; &#125; else &#123; b = i; &#125; if ((b - a) == 1) &#123; int result2 =name.compareTo(map[b].name); if (result2 &lt; 0) &#123; return a; &#125; else &#123; return b; &#125; &#125; &#125;&#125; 注册web应用 在这里注册路由，经过http请求能够找到对应的web 应用，一个context对应一个web应用 123456789101112131415161718192021222324252627282930313233private void registerContext(Context context) &#123; String contextPath =context.getPath(); //获取context的路径 if ("/".equals(contextPath))&#123; contextPath = ""; &#125; Host host = (Host)context.getParent(); //获取的其host WebResourceRootresources = context.getResources(); //获取root String[] welcomeFiles =context.findWelcomeFiles(); //获取欢迎页 // 准备context 下的所有 wrapper 信息 List&lt;WrapperMappingInfo&gt;wrappers = new ArrayList&lt;&gt;(); for (Container container :context.findChildren()) &#123; prepareWrapperMappingInfo(context, (Wrapper)container, wrappers); if(log.isDebugEnabled())&#123; log.debug(sm.getString("mapperListener.registerWrapper", container.getName(), contextPath, service)); &#125; &#125; // 添加 contextVersion，在这里面会将该context下的所有wrapper映射信息也构建 mapper.addContextVersion(host.getName(), host, contextPath, context.getWebappVersion(), context, welcomeFiles, resources, wrappers); if(log.isDebugEnabled())&#123; log.debug(sm.getString("mapperListener.registerContext", contextPath, service)); &#125;&#125;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(九) 多租户]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz9%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819/** * @author 郑小康 * 设置完整的delegator 其可能形式有 default 或者defalut#tenantDelegatorName * 针对于第一种情况 delegatorBaseName =="default" delegatorTenantId=null * 针对第二种情况 delegatorBaseName =="default" delegatorTenantId="tenantDelegatorName" * 为什么存在第二种情况，是因为在多租户中要实现数据独立，所以获取基础delagtor 和租户delegator,注意这时并未创建实例更没有建立数据库连接 * 其再获取了默认的delegator中的信息之后，如果存在delegatorBaseName 则将 uri username password进行覆盖 * */ protected void setDelegatorNames(String delegatorFullName) &#123; this.delegatorFullName = delegatorFullName; int hashSymbolIndex = delegatorFullName.indexOf('#'); if (hashSymbolIndex == -1) &#123; this.delegatorBaseName = delegatorFullName; &#125; else &#123; this.delegatorBaseName = delegatorFullName.substring(0, hashSymbolIndex); this.delegatorTenantId = delegatorFullName.substring(hashSymbolIndex + 1); &#125; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//多租户 根据默认baseDelegator获取域名对应TenantId 拼接DelegatorName获取其实例if (useMultitenant) &#123; // get tenant delegator by domain name，获取服务名 String serverName = httpRequest.getServerName(); try &#123; // if tenant was specified, replace delegator with the new per-tenant delegator and set tenantId to session attribute Delegator delegator = getDelegator(config.getServletContext()); //Use base delegator for fetching data from entity of entityGroup com.hanlin.fadp.tenant Delegator baseDelegator = DelegatorFactory.getDelegator(delegator.getDelegatorBaseName()); GenericValue tenantDomainName = EntityQuery.use(baseDelegator).from("TenantDomainName").where("domainName", serverName).queryOne(); String tenantId = null; if(UtilValidate.isNotEmpty(tenantDomainName)) &#123; tenantId = tenantDomainName.getString("tenantId"); &#125; if(UtilValidate.isEmpty(tenantId)) &#123; tenantId = (String) httpRequest.getAttribute("userTenantId"); &#125; if(UtilValidate.isEmpty(tenantId)) &#123; tenantId = (String) httpRequest.getParameter("userTenantId"); &#125; if (UtilValidate.isNotEmpty(tenantId)) &#123; // if the request path is a root mount then redirect to the initial path if (UtilValidate.isNotEmpty(requestPath) &amp;&amp; requestPath.equals(contextUri)) &#123; GenericValue tenant = EntityQuery.use(baseDelegator).from("Tenant").where("tenantId", tenantId).queryOne(); String initialPath = tenant.getString("initialPath"); if (UtilValidate.isNotEmpty(initialPath) &amp;&amp; !"/".equals(initialPath)) &#123; ((HttpServletResponse)response).sendRedirect(initialPath); return; &#125; &#125; // make that tenant active, setup a new delegator and a new dispatcher String tenantDelegatorName = delegator.getDelegatorBaseName() + "#" + tenantId; httpRequest.getSession().setAttribute("delegatorName", tenantDelegatorName); // after this line the delegator is replaced with the new per-tenant delegator delegator = DelegatorFactory.getDelegator(tenantDelegatorName); config.getServletContext().setAttribute("delegator", delegator); // clear web context objects config.getServletContext().setAttribute("security", null); config.getServletContext().setAttribute("dispatcher", null); /** * 初始化security，根据delegatorName先从缓存中获取，如果缓存中不存在对应的security，则实例化一个 * 由于该过滤器是每次请求都会经过，所以根据域名不同，获取的security就有所不同，这样就可以实现共用一套用户表在不同租户中权限不同 */ Security security = getSecurity(); // initialize the services dispatcher LocalDispatcher dispatcher = getDispatcher(config.getServletContext()); // set web context objects request.setAttribute("dispatcher", dispatcher); request.setAttribute("security", security); request.setAttribute("userTenantId", tenantId); &#125; // NOTE DEJ20101130: do NOT always put the delegator name in the user's session because the user may // have logged in and specified a tenant, and even if no Tenant record with a matching domainName field // is found this will change the user's delegator back to the base one instead of the one for the // tenant specified on login // httpRequest.getSession().setAttribute("delegatorName", delegator.getDelegatorName()); &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, "Unable to get Tenant没有获取这个租户", module); &#125; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(八) 创建表]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz8%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158/** * @author 郑小康 * * 1.检验实体是否为空 * * 2.检验视图实体是否为空 * * 3.获取数据库连接 * * 4.根据对应的ModelEntity来创建表 其中modelEntities是关系表的集合 * * */public String createTable(ModelEntity entity, Map&lt;String, ModelEntity&gt; modelEntities, boolean addFks) &#123; if (entity == null) &#123; return "ModelEntity was null and is required to create a table ModelEntity是空，不能创建表"; &#125; if (entity instanceof ModelViewEntity) &#123; return "ERROR: Cannot create table for a view entity 不能为视图实体创建表"; &#125; Connection connection = null; Statement stmt = null; try &#123; connection = getConnection(); &#125; catch (SQLException e) &#123; String errMsg = "在建表过程中Unable to establish a connection with the database for helperName [" + this.helperInfo.getHelperFullName() + "]... Error was: " + e.toString(); Debug.logError(e, errMsg, module); return errMsg; &#125; catch (GenericEntityException e) &#123; String errMsg = "在建表过程中 Unable to establish a connection with the database for helperName [" + this.helperInfo.getHelperFullName() + "]... Error was: " + e.toString(); Debug.logError(e, errMsg, module); return errMsg; &#125; StringBuilder sqlBuf = new StringBuilder("CREATE TABLE "); sqlBuf.append(entity.getTableName(this.datasourceInfo)); sqlBuf.append(" ("); Iterator&lt;ModelField&gt; fieldIter = entity.getFieldsIterator(); while (fieldIter.hasNext()) &#123; ModelField field = fieldIter.next(); ModelFieldType type = modelFieldTypeReader.getModelFieldType(field.getType()); if (type == null) &#123; return "Field type [" + type + "] not found for field [" + field.getName() + "] of entity [" + entity.getEntityName() + "], not creating table."; &#125; sqlBuf.append(field.getColName()); sqlBuf.append(" "); sqlBuf.append(type.getSqlType()); if ("String".equals(type.getJavaType()) || "java.lang.String".equals(type.getJavaType())) &#123; // if there is a characterSet, add the CHARACTER SET arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCharacterSet())) &#123; sqlBuf.append(" CHARACTER SET "); sqlBuf.append(this.datasourceInfo.getCharacterSet()); &#125; // if there is a collate, add the COLLATE arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCollate())) &#123; sqlBuf.append(" COLLATE "); sqlBuf.append(this.datasourceInfo.getCollate()); &#125; &#125; if (field.getIsNotNull() || field.getIsPk()) &#123; if (this.datasourceInfo.getAlwaysUseConstraintKeyword()) &#123; sqlBuf.append(" CONSTRAINT NOT NULL, "); &#125; else &#123; sqlBuf.append(" NOT NULL, "); &#125; &#125; else &#123; sqlBuf.append(", "); &#125; &#125; String pkName = makePkConstraintName(entity, this.datasourceInfo.getConstraintNameClipLength()); if (this.datasourceInfo.getUsePkConstraintNames()) &#123; sqlBuf.append("CONSTRAINT "); sqlBuf.append(pkName); &#125; sqlBuf.append(" PRIMARY KEY ("); entity.colNameString(entity.getPkFieldsUnmodifiable(), sqlBuf, ""); sqlBuf.append(")"); if (addFks) &#123; // NOTE: This is kind of a bad idea anyway since ordering table creations is crazy, if not impossible // go through the relationships to see if any foreign keys need to be added Iterator&lt;ModelRelation&gt; relationsIter = entity.getRelationsIterator(); while (relationsIter.hasNext()) &#123; ModelRelation modelRelation = relationsIter.next(); if ("one".equals(modelRelation.getType())) &#123; ModelEntity relModelEntity = modelEntities.get(modelRelation.getRelEntityName()); if (relModelEntity == null) &#123; Debug.logError("Error adding foreign key: ModelEntity was null for related entity name " + modelRelation.getRelEntityName(), module); continue; &#125; if (relModelEntity instanceof ModelViewEntity) &#123; Debug.logError("Error adding foreign key: related entity is a view entity for related entity name " + modelRelation.getRelEntityName(), module); continue; &#125; String fkConstraintClause = makeFkConstraintClause(entity, modelRelation, relModelEntity, this.datasourceInfo.getConstraintNameClipLength(), this.datasourceInfo.getFkStyle(), this.datasourceInfo.getUseFkInitiallyDeferred()); if (UtilValidate.isNotEmpty(fkConstraintClause)) &#123; sqlBuf.append(", "); sqlBuf.append(fkConstraintClause); &#125; else &#123; continue; &#125; &#125; &#125; &#125; sqlBuf.append(")"); // if there is a tableType, add the TYPE arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getTableType())) &#123; // jaz:20101229 - This appears to be only used by mysql and now mysql has // deprecated (and in 5.5.x removed) the use of the TYPE keyword. This is // changed to ENGINE which is supported starting at 4.1 sqlBuf.append(" ENGINE "); //sqlBuf.append(" TYPE "); sqlBuf.append(this.datasourceInfo.getTableType()); &#125; // if there is a characterSet, add the CHARACTER SET arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCharacterSet())) &#123; sqlBuf.append(" CHARACTER SET "); sqlBuf.append(this.datasourceInfo.getCharacterSet()); &#125; // if there is a collate, add the COLLATE arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCollate())) &#123; sqlBuf.append(" COLLATE "); sqlBuf.append(this.datasourceInfo.getCollate()); &#125; if (Debug.verboseOn()) Debug.logVerbose("[createTable] sql=" + sqlBuf.toString(), module); try &#123; stmt = connection.createStatement(); stmt.executeUpdate(sqlBuf.toString()); &#125; catch (SQLException e) &#123; return "SQL Exception while executing the following:\n" + sqlBuf.toString() + "\nError was: " + e.toString(); &#125; finally &#123; try &#123; if (stmt != null) stmt.close(); &#125; catch (SQLException e) &#123; Debug.logError(e, module); &#125; try &#123; if (connection != null) &#123; connection.close(); &#125; &#125; catch (SQLException e) &#123; Debug.logError(e, module); &#125; &#125; return null;&#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(七) 检查数据源]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz7%2F</url>
    <content type="text"><![CDATA[123456789101112/** * Check the datasource to make sure the entity definitions are correct, optionally adding missing entities or fields on the server *@param modelEntities Map of entityName names and ModelEntity values *@param messages List to put any result messages in *@param addMissing Flag indicating whether or not to add missing entities and fields on the server * * 检查数据源确保实体正确定义,选择性添加没有的实体和字段 */ public void checkDataSource(Map&lt;String, ModelEntity&gt; modelEntities, List&lt;String&gt; messages, boolean addMissing) throws GenericEntityException &#123; genericDAO.checkDb(modelEntities, messages, addMissing); &#125;&#125; 值得一提helper的实例化的是GenericHelperDAO 所以checkDb调用的是GenericHeleper中的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * @author 郑小康 * * 1.从缓存中获取helperFullName的GenericHelper * * 2.如果为空根据helperBaseName(localmysql)获取Datasource标签实例 * * 3.根据Datasource标签的helperClass,创造构造器,构建对应实例 * * 4.以HelperFullName为k 实例为v存入到缓存 * * 5.返回当前实例化的GenericHelper * * */ public static GenericHelper getHelper(GenericHelperInfo helperInfo) &#123; GenericHelper helper = helperCache.get(helperInfo.getHelperFullName()); if (helper == null) &#123; // don't want to block here synchronized (GenericHelperFactory.class) &#123; // must check if null again as one of the blocked threads can still enter helper = helperCache.get(helperInfo.getHelperFullName()); if (helper == null) &#123; try &#123; Datasource datasourceInfo = EntityConfig.getDatasource(helperInfo.getHelperBaseName()); if (datasourceInfo == null) &#123; throw new IllegalStateException("Could not find datasource definition with name " + helperInfo.getHelperBaseName()); &#125; String helperClassName = datasourceInfo.getHelperClass(); Class&lt;?&gt; helperClass = null; if (UtilValidate.isNotEmpty(helperClassName)) &#123; try &#123; ClassLoader loader = Thread.currentThread().getContextClassLoader(); helperClass = loader.loadClass(helperClassName); &#125; catch (ClassNotFoundException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; &#125; Class&lt;?&gt;[] paramTypes = new Class&lt;?&gt;[] &#123;GenericHelperInfo.class&#125;; Object[] params = new Object[] &#123;helperInfo&#125;; java.lang.reflect.Constructor&lt;?&gt; helperConstructor = null; if (helperClass != null) &#123; try &#123; helperConstructor = helperClass.getConstructor(paramTypes); &#125; catch (NoSuchMethodException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; &#125; try &#123; helper = (GenericHelper) helperConstructor.newInstance(params); &#125; catch (IllegalAccessException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; catch (InstantiationException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; catch (java.lang.reflect.InvocationTargetException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; if (helper != null) helperCache.put(helperInfo.getHelperFullName(), helper); &#125; catch (SecurityException e) &#123; Debug.logError(e, module); throw new IllegalStateException("Error loading GenericHelper class: " + e.toString()); &#125; &#125; &#125; &#125; return helper; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(六) GenericHelper的初始化创建]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz6%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * @author 郑小康 * * 1.根据groupName获取GenericHelperInfo * * 2.获取GenericHelperInfo的helperBaseName * * 3.如果HelperFullName不为空,则进行下面的操作 HelperFullName可能是default,也可能是default#tenantId * * 4.根据helperBaseName(localmysql),获取对应的ModelFieldTypeReader 字段类型阅读器,这个是为了在建表的时候的创建对应字段类型 * * 5.根据helperInfo通过GenericHelperFactory工厂获取GenericHelper,实际是GenericHelperDAO * * 6.根据helperBaseName获取对应的Datasource标签实例 * * 7.根据GenericHelper所构建的实例,调用其checkDataSource检查数据源,向其中添加未添加的表和字段 * * */ private void initializeOneGenericHelper(String groupName) &#123; //根据groupName获取GenericHelperInfo GenericHelperInfo helperInfo = this.getGroupHelperInfo(groupName); if (helperInfo == null) &#123; if (Debug.infoOn()) &#123; Debug.logInfo("Delegator \"" + delegatorFullName + "\" NOT initializing helper for entity group \"" + groupName + "\" because the group is not associated to this delegator.", module); &#125; return; &#125; String helperBaseName = helperInfo.getHelperBaseName(); if (Debug.infoOn()) &#123; Debug.logInfo("Delegator \"" + delegatorFullName + "\" initializing helper \"" + helperBaseName + "\" for entity group \"" + groupName + "\".", module); &#125; if (UtilValidate.isNotEmpty(helperInfo.getHelperFullName())) &#123; // pre-load field type defs, the return value is ignored ModelFieldTypeReader.getModelFieldTypeReader(helperBaseName); // get the helper and if configured, do the datasource check GenericHelper helper = GenericHelperFactory.getHelper(helperInfo); try &#123; Datasource datasource = EntityConfig.getDatasource(helperBaseName); if (datasource.getCheckOnStart()) &#123; if (Debug.infoOn()) &#123; Debug.logInfo("Doing database check as requested in entityengine.xml with addMissing=" + datasource.getAddMissingOnStart(), module); &#125; helper.checkDataSource(this.getModelEntityMapByGroup(groupName), null, datasource.getAddMissingOnStart()); &#125; &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, e.getMessage(), module); &#125; &#125; &#125; protected Callable&lt;Void&gt; createHelperCallable(final String groupName) &#123; return new Callable&lt;Void&gt;() &#123; @Override public Void call() &#123; initializeOneGenericHelper(groupName); return null; &#125; &#125;; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(五) ModelGroupReader]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz5%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246public class ModelGroupReader implements Serializable &#123; public static final String module = ModelGroupReader.class.getName(); //缓存所有ModelGroupReader,其k是entity-group-reader属性值 private static final UtilCache&lt;String, ModelGroupReader&gt; readers = UtilCache.createUtilCache("entity.ModelGroupReader", 0, 0); private Map&lt;String, String&gt; groupCache = null;//以entityName为k groupName为v private Set&lt;String&gt; groupNames = null;//delegator所有的组名 public String modelName;//entity-group-reader属性值 public List&lt;ResourceHandler&gt; entityGroupResourceHandlers = new LinkedList&lt;ResourceHandler&gt;();//存放像entity-resource这样标签实例 /** * @author 郑小康 * 1.获取当前delegatorName的delegator标签的DelegatorElement实例 * * 2.获取delegator的entity-group-reader属性值 * * 3.根据属性值获取ModelGroupReader * * 4.如果没有获取到根据delegatorName和entity-group-reader属性值构造一个ModelGroupReader实例,具体过程就在本类中 * * */ public static ModelGroupReader getModelGroupReader(String delegatorName) throws GenericEntityConfException &#123; DelegatorElement delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorName); if (delegatorInfo == null) &#123; throw new GenericEntityConfException("不能发现叫做" + delegatorName+"的delegator"); &#125; String tempModelName = delegatorInfo.getEntityGroupReader(); ModelGroupReader reader = readers.get(tempModelName); if (reader == null) &#123; reader = readers.putIfAbsentAndGet(tempModelName, new ModelGroupReader(delegatorName, tempModelName)); &#125; return reader; &#125; /** * @author 郑小康 * 1. 赋值entity-group-reader的属性值 * * 2. 根据entity-group-reader的属性值获取其对应的EntityGroupReader实例,如果为空就抛出异常 * 原因:其获取的是EntityConfig实例的中的属性,EntityGroupReader是在EntityConfig实例化是加载的属性标签的对象,所以没有是肯定有问题的 * * 3. 添加entityngine.xml中的句柄属性标签MainResourceHandler实例 * * 4. 获取component.xml文件中entity-resource标签类型为group,根据与entity-group-reader的属性值对应reader-name构建ComponentResourceHandler实例添加到entityGroupResourceHandlers这个集合 * 作用是通过这个属性在对应文件中entityName所在的组,后续将其放入到对应的组中，与具体的数据源关联 * * 5. 获取delegator中与entity-group-reader的属性值对应的entity-resource中reader-name相同的标签实例 * 根据entity-resource的路径获取文件下所有entity-group实例,将其以entityName为k,groupNam为v存入到具体的groupCache中 * */ public ModelGroupReader(String delegatorName, String modelName) throws GenericEntityConfException &#123; this.modelName = modelName; EntityGroupReader entityGroupReaderInfo = EntityConfig.getInstance().getEntityGroupReader(modelName); if (entityGroupReaderInfo == null) &#123; throw new GenericEntityConfException("Cound not find an entity-group-reader with the name " + modelName); &#125; for (Resource resourceElement: entityGroupReaderInfo.getResourceList()) &#123; this.entityGroupResourceHandlers.add(new MainResourceHandler(EntityConfig.ENTITY_ENGINE_XML_FILENAME, resourceElement.getLoader(), resourceElement.getLocation())); &#125; // get all of the component resource group stuff, ie specified in each fadp-component.xml file for (ComponentConfig.EntityResourceInfo componentResourceInfo: ComponentConfig.getAllEntityResourceInfos("group")) &#123; if (modelName.equals(componentResourceInfo.readerName)) &#123; this.entityGroupResourceHandlers.add(componentResourceInfo.createResourceHandler()); &#125; &#125; // preload caches... getGroupCache(delegatorName); &#125; /** * @author 郑小康 * 如果groupCache为空则将当前delegator下,如果不为空才进行下面的操作 * * 1.构建对应的groupCache和groupNames * * 2.加载所有资源句柄文件 * 即根据与当前entity-group-reader的属性值相同的entity-resource中reader-name的entity-resource标签 * 根据entity-resource的路径获取文件下所有entity-group实例,将其以entityName为k,groupNam为v存入到具体的groupCache中 * 以entityName为k groupName为v 这样做的作用就是像getEntityGroupName等方法可以根据实体名获取对应的组名 * */ public Map&lt;String, String&gt; getGroupCache(String delegatorName) &#123; if (this.groupCache == null) &#123; // don't want to block here synchronized (ModelGroupReader.class) &#123; //再次检查groupCache是否为空,避免其它线程创建 if (this.groupCache == null) &#123; //构造groupCache这个hashMap 和groupNames这个TreeSet this.groupCache = new HashMap&lt;String, String&gt;(); this.groupNames = new TreeSet&lt;String&gt;(); //做一些时间的通知 UtilTimer utilTimer = new UtilTimer(); utilTimer.timerString("[ModelGroupReader.getGroupCache] Before getDocument"); int i = 0; //遍历所有entity-resource标签对应ComponentResourceHandler实例 for (ResourceHandler entityGroupResourceHandler: this.entityGroupResourceHandlers) &#123; Document document = null; try &#123; //解析为文档元素 document = entityGroupResourceHandler.getDocument(); &#125; catch (GenericConfigException e) &#123; Debug.logError(e, "Error loading entity group model", module); &#125; //如果document为空,缓存置为空,并且返回 if (document == null) &#123; this.groupCache = null; return null; &#125; // utilTimer.timerString("[ModelGroupReader.getGroupCache] Before getDocumentElement"); Element docElement = document.getDocumentElement(); if (docElement == null) &#123; continue; &#125; //移除空的文本节点 docElement.normalize(); //以获取首个节点,而后进行遍历,处理所有entity-group节点将其组名加到groupNames这个集合,并以entityName为k,groupName为v存到对应groupCache中 //注意有一个检查,检查是否具有entityengine.xml对应的group-map的实例,如果没有加载就没有任何意义 Node curChild = docElement.getFirstChild(); if (curChild != null) &#123; utilTimer.timerString("[ModelGroupReader.getGroupCache] Before start of entity loop"); do &#123; if (curChild.getNodeType() == Node.ELEMENT_NODE &amp;&amp; "entity-group".equals(curChild.getNodeName())) &#123; Element curEntity = (Element) curChild; String entityName = UtilXml.checkEmpty(curEntity.getAttribute("entity")).intern(); String groupName = UtilXml.checkEmpty(curEntity.getAttribute("group")).intern(); if (groupName == null || entityName == null) continue; try &#123; if (null == EntityConfig.getInstance().getDelegator(delegatorName).getGroupDataSource(groupName)) &#123; Debug.logError("The declared group name " + groupName + " has no corresponding group-map in entityengine.xml: ", module); &#125; &#125; catch (GenericEntityConfException e) &#123; Debug.logWarning(e, "Exception thrown while getting group name: ", module); &#125; this.groupNames.add(groupName); this.groupCache.put(entityName, groupName); i++; &#125; &#125; while ((curChild = curChild.getNextSibling()) != null); &#125; else &#123; Debug.logWarning("[ModelGroupReader.getGroupCache] No child nodes found.", module); &#125; &#125; utilTimer.timerString("[ModelGroupReader.getGroupCache] FINISHED - Total Entity-Groups: " + i + " FINISHED"); &#125; &#125; &#125; return this.groupCache; &#125; /** * @author 郑小康 * 方法作用:根据entityName和delegatorBaseName获取其对应的组名 * * 1.根据方法获取groupCache * * 2.根据entityName获取组名 * * 3.如果组名为空,获取delegator标签实体，获取其默认组名 * * 4.返回组名 * */ public String getEntityGroupName(String entityName, String delegatorBaseName) &#123; Map&lt;String, String&gt; gc = getGroupCache(delegatorBaseName); if (gc != null) &#123; String groupName = gc.get(entityName); if (groupName == null) &#123; DelegatorElement delegatorInfo = null; try &#123; delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorBaseName); &#125; catch (GenericEntityConfException e) &#123; Debug.logWarning(e, "Exception thrown while getting delegator config: ", module); &#125; if (delegatorInfo == null) &#123; throw new RuntimeException("Could not find DelegatorInfo for delegatorBaseName [" + delegatorBaseName + "]"); &#125; groupName = delegatorInfo.getDefaultGroupName(); &#125; return groupName; &#125; else &#123; return null; &#125; &#125; /** * @author 郑小康 * * 1.确保delegatorName是默认的delegatorName * * 2.调用getGroupCache方法的作用确保将对应的groupCache给加载到类属性 * * 3.根据delegator的default-group-name获取所有其下面默认group-name标签实例的name,将其添加到一个HashSet集合 * * 4.向该集合中添加已经通过getGroupCache方法加载的存放过entityName的groupNames集合 * */ public Set&lt;String&gt; getGroupNames(String delegatorBaseName) &#123; if (delegatorBaseName.indexOf('#') &gt;= 0) &#123; delegatorBaseName = delegatorBaseName.substring(0, delegatorBaseName.indexOf('#')); &#125; getGroupCache(delegatorBaseName); if (this.groupNames == null) return null; Set&lt;String&gt; newSet = new HashSet&lt;String&gt;(); try &#123; newSet.add(EntityConfig.getInstance().getDelegator(delegatorBaseName).getDefaultGroupName()); &#125; catch (GenericEntityConfException e) &#123; Debug.logWarning(e, "Exception thrown while getting delegator config: ", module); &#125; newSet.addAll(this.groupNames); return newSet; &#125; /** * * @author 郑小康 * * 1.构造一个Set根据delegatorBaseName和groupName,向该set注入该组里面所有的实体名 * * 2.遍历groupCache,将组名相同的entityName添加到enames这个HashSet * * 3.返回对应的enames */ public Set&lt;String&gt; getEntityNamesByGroup(String delegatorBaseName, String groupName) &#123; Map&lt;String, String&gt; gc = getGroupCache(delegatorBaseName); Set&lt;String&gt; enames = new HashSet&lt;String&gt;(); if (groupName == null || groupName.length() &lt;= 0) return enames; if (UtilValidate.isEmpty(gc)) return enames; for (Map.Entry&lt;String, String&gt; entry: gc.entrySet()) &#123; if (groupName.equals(entry.getValue())) enames.add(entry.getKey()); &#125; return enames; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(四) ModelReader的作用]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz4%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668public class ModelReader implements Serializable &#123; public static final String module = ModelReader.class.getName(); private static final UtilCache&lt;String, ModelReader&gt; readers = UtilCache.createUtilCache("entity.ModelReader", 0, 0); protected Map&lt;String, ModelEntity&gt; entityCache = null; protected int numEntities = 0; protected int numViewEntities = 0; protected int numFields = 0; protected int numRelations = 0; protected int numAutoRelations = 0; protected String modelName; /**实体资源句柄文件集合*/ protected Collection&lt;ResourceHandler&gt; entityResourceHandlers; /**实体资源句柄文件为key,其下面entityName的集合为v*/ protected Map&lt;ResourceHandler, Collection&lt;String&gt;&gt; resourceHandlerEntities; /**entityName为k 实体资源句柄文件 为v*/ protected Map&lt;String, ResourceHandler&gt; entityResourceHandlerMap; /** * @author 郑小康 * * 1.根据delegatorName获取对应DelegatorElement标签实例 * * 2.获取Delegator的entity-model-reader属性值 * * 3.根据entity-model-reader属性值获取ModelReader实例 * * 4.如果ModelReader实例为空,则创建其对应的ModelReader,并获取所有实体缓存 * * 5.以entity-model-reader属性值为k ModelReader实例为v存放到readers这个UtilCache中去 * * 6.返回当前ModelReader实例 * */ public static ModelReader getModelReader(String delegatorName) throws GenericEntityException &#123; DelegatorElement delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorName); if (delegatorInfo == null) &#123; throw new GenericEntityConfException("Could not find a delegator with the name " + delegatorName); &#125; String tempModelName = delegatorInfo.getEntityModelReader(); ModelReader reader = readers.get(tempModelName); if (reader == null) &#123; reader = new ModelReader(tempModelName); // preload caches... reader.getEntityCache(); reader = readers.putIfAbsentAndGet(tempModelName, reader); &#125; return reader; &#125; /** * @author 郑小康 * * 1.赋值entity-model-reader的属性 * * 2.根据entity-model-reader的属性值获取其对应的EntityModelReader实例,如果为空就抛出异常 * 原因:其获取的是EntityConfig实例的中的属性,EntityModelReader是在EntityConfig实例化是加载的属性标签的对象,所以没有是肯定有问题的 * * 3.添加entityngine.xml中的句柄属性标签MainResourceHandler实例 * * 4.获取*****-component.xml文件中entity-resource标签类型为model,根据与entity-model-reader的属性值对应reader-name构建ComponentResourceHandler实例添加到entityModelResourceHandlers这个集合 * * 注意:这个构造器主要是给entityResourceHandlers这个集合中添加了当前EntityModelReader 对应entity-resource对应的实例 * 它是一个私有构造器,通过getModelReader方法来创建对应实例,后续操作在getModelReader这个静态方法中 * */ private ModelReader(String modelName) throws GenericEntityException &#123; this.modelName = modelName; entityResourceHandlers = new LinkedList&lt;ResourceHandler&gt;(); resourceHandlerEntities = new HashMap&lt;ResourceHandler, Collection&lt;String&gt;&gt;(); entityResourceHandlerMap = new HashMap&lt;String, ResourceHandler&gt;(); EntityModelReader entityModelReaderInfo = EntityConfig.getInstance().getEntityModelReader(modelName); if (entityModelReaderInfo == null) &#123; throw new GenericEntityConfException("Cound not find an entity-model-reader with the name " + modelName); &#125; // get all of the main resource model stuff, ie specified in the entityengine.xml file for (Resource resourceElement : entityModelReaderInfo.getResourceList()) &#123; ResourceHandler handler = new MainResourceHandler(EntityConfig.ENTITY_ENGINE_XML_FILENAME, resourceElement.getLoader(), resourceElement.getLocation()); entityResourceHandlers.add(handler); &#125; // get all of the component resource model stuff, ie specified in each fadp-component.xml file for (ComponentConfig.EntityResourceInfo componentResourceInfo: ComponentConfig.getAllEntityResourceInfos("model")) &#123; if (modelName.equals(componentResourceInfo.readerName)) &#123; entityResourceHandlers.add(componentResourceInfo.createResourceHandler()); &#125; &#125; &#125; /** * @author 郑小康 * 1.判断节点元素是否是entity * * 2.获取entity-name的值 * * 3.获取entity的redefinition属性,这个属性的作用是说明这个实体不能被覆盖,即entity节点元素不能定义两遍 * 但这仅仅是一个警告,定义了后面的就会覆盖钱买呢 * * 4.获取当前资源句柄文件的实体名集合,为空则实例化一个LinkedList集合 * 将当前实体名添加到集合 * * 5.以entityName为k entityResourceHandler为v存放在entityResourceHandlerMap,这样做的好处是根据entityName获取其资源句柄文件 * * 6.实体不为空,构造对应的modelEntity或者ModelViewEntity * * 7.将实体的资源句柄文件路径添加到当前modelEntity * * 8.返回当前modelEntity * * 注意:这里只是构造modelEntity,并没有在数据库建表 * */ private ModelEntity buildEntity(ResourceHandler entityResourceHandler, Element curEntityElement, int i, ModelInfo def) throws GenericEntityException &#123; boolean isEntity = "entity".equals(curEntityElement.getNodeName()); String entityName = UtilXml.checkEmpty(curEntityElement.getAttribute("entity-name")).intern(); //获取entity的redefinition属性,这个属性的作用是 boolean redefinedEntity = "true".equals(curEntityElement.getAttribute("redefinition")); //获取当前entityResourceHandler的resourceHandlerEntityNames,里面存放的是这个句柄文件中存在entity,在这里获取的目的是将当前构建的entity的entityName添加进去 Collection&lt;String&gt; resourceHandlerEntityNames = resourceHandlerEntities.get(entityResourceHandler); if (resourceHandlerEntityNames == null) &#123; resourceHandlerEntityNames = new LinkedList&lt;String&gt;(); resourceHandlerEntities.put(entityResourceHandler, resourceHandlerEntityNames); &#125; resourceHandlerEntityNames.add(entityName); //检查缓存中是包含 如果缓存中包含,且它不允许重定义(entity属性中默认是false) 这样就会报一些井盖 if (entityCache.containsKey(entityName) &amp;&amp; !redefinedEntity) &#123; Debug.logWarning("实体 " + entityName + " 被再次定义,其将覆盖原有的", module); Debug.logWarning("Entity " + entityName + " 被发现在资源句柄文件 " + entityResourceHandler + ", 但是已经被定义在 " + entityResourceHandlerMap.get(entityName).toString(), module); &#125; //以entityName为k entityResourceHandler为v存放在entityResourceHandlerMap,这样做的好处是根据entityName获取其资源句柄文件 entityResourceHandlerMap.put(entityName, entityResourceHandler); //构造对应的modelEntity或者ModelViewEntity ModelEntity modelEntity = null; if (isEntity) &#123; modelEntity = createModelEntity(curEntityElement, null, def); &#125; else &#123; modelEntity = createModelViewEntity(curEntityElement, null, def); &#125; //获取句柄资源文件的路径 String resourceLocation = entityResourceHandler.getLocation(); try &#123; resourceLocation = entityResourceHandler.getURL().toExternalForm(); &#125; catch (GenericConfigException e) &#123; Debug.logError(e, "Could not get resource URL", module); &#125; //如果modelEntity不为空,将实体的路径注入到modelEntity if (modelEntity != null) &#123; modelEntity.setLocation(resourceLocation); // utilTimer.timerString(" After entityCache.put -- " + i + " --"); if (isEntity) &#123; if (Debug.verboseOn()) Debug.logVerbose("-- [Entity]: #" + i + ": " + entityName, module); &#125; else &#123; if (Debug.verboseOn()) Debug.logVerbose("-- [ViewEntity]: #" + i + ": " + entityName, module); &#125; &#125; else &#123; Debug.logWarning("-- -- ENTITYGEN ERROR:getModelEntity: Could not create " + "entity for entityName: " + entityName, module); &#125; return modelEntity; &#125; /** * @author 郑小康 * 1.检查entityCache是否为空,如果不为空直接返回当前缓存,如果为空才向下执行 * * 2.再次检查,避免其他线程在这个过程创建entityCache * * 3.对类属性进行初始化 numEntities:实体数量 numViewEntities:视图实体数量 numFields:字段数量 * numRelations: numAutoRelations numAutoRelations: * * 4.创建tempViewEntityList&lt;ModelViewEntity&gt;:临时视图模型实体集合 tempExtendEntityElementList&lt;Element&gt; 扩展实体元素 * * 5.遍历所有资源句柄文件,包括entity-model-reader中孩子标签Resource 和对应的组件下entity-resource * * 6.根据entityResourceHandler的路径,获取其对应的文档的Document实例 * * 7.从首个节点开始,首先构造ModelInfo,获取当前entity的属性 * * 8.节点有三种 entity view-entity extend-entity * 如果是实体或者视图实体,调用buildEntity,构造对应的ModelEntity * 视图实体:构造后,添加到tempViewEntityList集合 * 实体:构造后以entityName为k modelEntity为v放入到entityCache * * 如果是extend-entity,直接将节点元素添加到对应的tempExtendEntityElementList集合 * * 9.从缓存中获取extend-entity的name相同的ModelEntity,然后对这个ModelEntity进行扩展字段,并且其会覆盖原有entity的属性 * * 10.将视图实体添加到对应的成员ModelEntity,这样就可以通过ModelEntity获取其下面所有ModelViewEntity * 并将视图以entityName为k ModelViewEntity为v存放到缓存 * * 11.检查出某些视图存在有些成员实体不存在，列举出来,这些ModelViewEntity并没有加到entitycache中 * * 12构建关系,主要是给当前实体添加其存在的关系集合,关系的实体中也添加这个ModelRelation到CopyOnWriteArrayList&lt;ModelRelation&gt; relations * CopyOnWrite容器即写时复制的容器。 * 读取的时候拷贝一个副本,进行读取 * 写入的需要加锁,对副本进行写入之后,再将原容器的引用指向新的容器 * 这样的好处是可以进行并发的读 * * */ public Map&lt;String, ModelEntity&gt; getEntityCache() throws GenericEntityException &#123; if (entityCache == null) &#123; // don't want to block here synchronized (ModelReader.class) &#123; // must check if null again as one of the blocked threads can still enter if (entityCache == null) &#123; // now it's safe numEntities = 0; numViewEntities = 0; numFields = 0; numRelations = 0; numAutoRelations = 0; entityCache = new HashMap&lt;String, ModelEntity&gt;(); List&lt;ModelViewEntity&gt; tempViewEntityList = new LinkedList&lt;ModelViewEntity&gt;(); List&lt;Element&gt; tempExtendEntityElementList = new LinkedList&lt;Element&gt;(); UtilTimer utilTimer = new UtilTimer(); for (ResourceHandler entityResourceHandler: entityResourceHandlers) &#123; // utilTimer.timerString("Before getDocument in file " + entityFileName); Document document = null; try &#123; document = entityResourceHandler.getDocument(); &#125; catch (GenericConfigException e) &#123; throw new GenericEntityConfException("Error getting document from resource handler 获取entitymodel.xml文件失败", e); &#125; if (document == null) &#123; throw new GenericEntityConfException("Could not get document for " + entityResourceHandler.toString()); &#125; // utilTimer.timerString("Before getDocumentElement in " + entityResourceHandler.toString()); Element docElement = document.getDocumentElement(); if (docElement == null) &#123; return null; &#125; docElement.normalize(); Node curChild = docElement.getFirstChild(); ModelInfo def = ModelInfo.createFromElements(ModelInfo.DEFAULT, docElement); int i = 0; if (curChild != null) &#123; utilTimer.timerString("Before start of entity loop in " + entityResourceHandler.toString()); do &#123; boolean isEntity = "entity".equals(curChild.getNodeName()); boolean isViewEntity = "view-entity".equals(curChild.getNodeName()); boolean isExtendEntity = "extend-entity".equals(curChild.getNodeName()); if ((isEntity || isViewEntity) &amp;&amp; curChild.getNodeType() == Node.ELEMENT_NODE) &#123; i++; ModelEntity modelEntity = buildEntity(entityResourceHandler, (Element) curChild, i, def); // put the view entity in a list to get ready for the second pass to populate fields... if (isViewEntity) &#123; tempViewEntityList.add((ModelViewEntity) modelEntity); &#125; else &#123; entityCache.put(modelEntity.getEntityName(), modelEntity); &#125; &#125; else if (isExtendEntity &amp;&amp; curChild.getNodeType() == Node.ELEMENT_NODE) &#123; tempExtendEntityElementList.add((Element) curChild); &#125; &#125; while ((curChild = curChild.getNextSibling()) != null); &#125; else &#123; Debug.logWarning("No child nodes found.", module); &#125; utilTimer.timerString("Finished " + entityResourceHandler.toString() + " - Total Entities: " + i + " FINISHED"); &#125; //从缓存中获取extend-entity的name相同的ModelEntity,然后对这个ModelEntity进行扩展字段,并且其会覆盖原有entity的属性 for (Element extendEntityElement: tempExtendEntityElementList) &#123; String entityName = UtilXml.checkEmpty(extendEntityElement.getAttribute("entity-name")); ModelEntity modelEntity = entityCache.get(entityName); if (modelEntity == null) throw new GenericEntityConfException("Entity to extend does not exist: " + entityName); modelEntity.addExtendEntity(this, extendEntityElement); &#125; //如果视图不为空,获取视图的大小 while (!tempViewEntityList.isEmpty()) &#123; int startSize = tempViewEntityList.size(); //对视图进行迭代 Iterator&lt;ModelViewEntity&gt; mveIt = tempViewEntityList.iterator();TEMP_VIEW_LOOP: while (mveIt.hasNext()) &#123; ModelViewEntity curViewEntity = mveIt.next(); //遍历当前视图的所有ModelMemberEntity(member-entity)成员,如果在缓存中不存在就不执行,存在则继续执行 for (ModelViewEntity.ModelMemberEntity mve: curViewEntity.getAllModelMemberEntities()) &#123; if (!entityCache.containsKey(mve.getEntityName())) &#123; continue TEMP_VIEW_LOOP; &#125; &#125; mveIt.remove(); //注入视图实体所有字段 curViewEntity.populateFields(this); //加视图实体添加到其下面所有成员实体ModelEntity下,以为这可以根据ModelEntity查询其所有视图实体 for (ModelViewEntity.ModelMemberEntity mve: curViewEntity.getAllModelMemberEntities()) &#123; ModelEntity me = entityCache.get(mve.getEntityName()); me.addViewEntity(curViewEntity); &#125; entityCache.put(curViewEntity.getEntityName(), curViewEntity); &#125; //这段代码的作用是标识tempViewEntityList集合中的成员是都存在不包含在entityCache if (tempViewEntityList.size() == startSize) &#123; // Oops, the remaining views reference other entities // that can't be found, or they reference other views // that have some reference problem. break; &#125; &#125; //这段代码的作用是在上面遍历tempViewEntityList,有些MemberEntity在缓存中不存在 //检查不存在的memberEntity添加到perViewMissingEntities这个SET集合,并将其给输出 if (!tempViewEntityList.isEmpty()) &#123; StringBuilder sb = new StringBuilder("View entities reference non-existant members:\n"); Set&lt;String&gt; allViews = new HashSet&lt;String&gt;(); for (ModelViewEntity curViewEntity: tempViewEntityList) &#123; allViews.add(curViewEntity.getEntityName()); &#125; for (ModelViewEntity curViewEntity: tempViewEntityList) &#123; Set&lt;String&gt; perViewMissingEntities = new HashSet&lt;String&gt;(); Iterator&lt;ModelViewEntity.ModelMemberEntity&gt; mmeIt = curViewEntity.getAllModelMemberEntities().iterator(); while (mmeIt.hasNext()) &#123; ModelViewEntity.ModelMemberEntity mme = mmeIt.next(); String memberEntityName = mme.getEntityName(); if (!entityCache.containsKey(memberEntityName)) &#123; // this member is not a real entity // check to see if it is a view if (!allViews.contains(memberEntityName)) &#123; // not a view, it's a real missing entity perViewMissingEntities.add(memberEntityName); &#125; &#125; &#125; for (String perViewMissingEntity: perViewMissingEntities) &#123; sb.append("\t[").append(curViewEntity.getEntityName()).append("] missing member entity [").append(perViewMissingEntity).append("]\n"); &#125; &#125; throw new GenericEntityConfException(sb.toString()); &#125; /** * @author 郑小康 * 1.遍历当前ModelReader下所有实体名 * 2.获取对应ModelEntity * 3.将其关系进行迭代处理 * 4.如果类型是one 或者one-nofk(不是AutoRelation) 获取其关系ModelEntity * 5.将所有key-map的name添加到curEntityKeyFields集合 * 6.实例化ModelRelation * 7.如果是自关联,将ModelRealation添加到当前实体 * 如果不是在相关实体加入ModelRealation * */ TreeSet&lt;String&gt; orderedMessages = new TreeSet&lt;String&gt;(); for (String curEntityName: new TreeSet&lt;String&gt;(this.getEntityNames())) &#123; ModelEntity curModelEntity = this.getModelEntity(curEntityName); if (curModelEntity instanceof ModelViewEntity) &#123; // for view-entities auto-create relationships for all member-entity relationships that have all corresponding fields in the view-entity &#125; else &#123; // for entities auto-create many relationships for all type one relationships // just in case we add a new relation to the same entity, keep in a separate list and add them at the end List&lt;ModelRelation&gt; newSameEntityRelations = new LinkedList&lt;ModelRelation&gt;(); Iterator&lt;ModelRelation&gt; relationsIter = curModelEntity.getRelationsIterator(); while (relationsIter.hasNext()) &#123; ModelRelation modelRelation = relationsIter.next(); if (("one".equals(modelRelation.getType()) || "one-nofk".equals(modelRelation.getType())) &amp;&amp; !modelRelation.isAutoRelation()) &#123; ModelEntity relatedEnt = null; try &#123; /** 得到参考的 RelEntityName. */ relatedEnt = this.getModelEntity(modelRelation.getRelEntityName()); &#125; catch (GenericModelException e) &#123;// com.hanlin.fadp.petrescence.datasource.FindMissedEntity.addMissed(modelRelation.getRelEntityName()); throw new GenericModelException("Error getting related entity [" + modelRelation.getRelEntityName() + "] definition from entity [" + curEntityName + "]", e); &#125; if (relatedEnt != null) &#123; // create the new relationship even if one exists so we can show what we are looking for in the info message // don't do relationship to the same entity, unless title is "Parent", then do a "Child" automatically String title = modelRelation.getTitle(); if (curModelEntity.getEntityName().equals(relatedEnt.getEntityName()) &amp;&amp; "Parent".equals(title)) &#123; title = "Child"; &#125; String description = ""; String type = ""; String relEntityName = curModelEntity.getEntityName(); String fkName = ""; ArrayList&lt;ModelKeyMap&gt; keyMaps = new ArrayList&lt;ModelKeyMap&gt;(); boolean isAutoRelation = true; Set&lt;String&gt; curEntityKeyFields = new HashSet&lt;String&gt;(); for (ModelKeyMap curkm : modelRelation.getKeyMaps()) &#123; keyMaps.add(new ModelKeyMap(curkm.getRelFieldName(), curkm.getFieldName())); curEntityKeyFields.add(curkm.getFieldName()); &#125; keyMaps.trimToSize(); // decide whether it should be one or many by seeing if the key map represents the complete pk of the relEntity if (curModelEntity.containsAllPkFieldNames(curEntityKeyFields)) &#123; // always use one-nofk, we don't want auto-fks getting in for these automatic ones type = "one-nofk"; // to keep it clean, remove any additional keys that aren't part of the PK List&lt;String&gt; curPkFieldNames = curModelEntity.getPkFieldNames(); Iterator&lt;ModelKeyMap&gt; nrkmIter = keyMaps.iterator(); while (nrkmIter.hasNext()) &#123; ModelKeyMap nrkm =nrkmIter.next(); String checkField = nrkm.getRelFieldName(); if (!curPkFieldNames.contains(checkField)) &#123; nrkmIter.remove(); &#125; &#125; &#125; else &#123; type= "many"; &#125; ModelRelation newRel = ModelRelation.create(relatedEnt, description, type, title, relEntityName, fkName, keyMaps, isAutoRelation); ModelRelation existingRelation = relatedEnt.getRelation(title + curModelEntity.getEntityName()); if (existingRelation == null) &#123; numAutoRelations++; if (curModelEntity.getEntityName().equals(relatedEnt.getEntityName())) &#123; newSameEntityRelations.add(newRel); &#125; else &#123; relatedEnt.addRelation(newRel); &#125; &#125; else &#123; if (newRel.equals(existingRelation)) &#123; // don't warn if the target title+entity = current title+entity if (Debug.infoOn() &amp;&amp; !(title + curModelEntity.getEntityName()).equals(modelRelation.getTitle() + modelRelation.getRelEntityName())) &#123; //String errorMsg = "Relation already exists to entity [] with title [" + targetTitle + "],from entity []"; String message = "Entity [" + relatedEnt.getPackageName() + ":" + relatedEnt.getEntityName() + "] already has identical relationship to entity [" + curModelEntity.getEntityName() + "] title [" + title + "]; would auto-create: type [" + newRel.getType() + "] and fields [" + newRel.keyMapString(",", "") + "]"; orderedMessages.add(message); &#125; &#125; else &#123; String message = "Existing relationship with the same name, but different specs found from what would be auto-created for Entity [" + relatedEnt.getEntityName() + "] and relationship to entity [" + curModelEntity.getEntityName() + "] title [" + title + "]; would auto-create: type [" + newRel.getType() + "] and fields [" + newRel.keyMapString(",", "") + "]"; Debug.logVerbose(message, module); &#125; &#125; &#125; else &#123; String errorMsg = "Could not find related entity [" + modelRelation.getRelEntityName() + "], no reverse relation added."; Debug.logWarning(errorMsg, module); &#125; &#125; &#125; if (newSameEntityRelations.size() &gt; 0) &#123; for (ModelRelation newRel: newSameEntityRelations) &#123; curModelEntity.addRelation(newRel); &#125; &#125; &#125; &#125; if (Debug.infoOn()) &#123; for (String message : orderedMessages) &#123; Debug.logInfo(message, module); &#125; Debug.logInfo("Finished loading entities; #Entities=" + numEntities + " #ViewEntities=" + numViewEntities + " #Fields=" + numFields + " #Relationships=" + numRelations + " #AutoRelationships=" + numAutoRelations, module); &#125; &#125; &#125; &#125; return entityCache; &#125; /** * rebuilds the resourceHandlerEntities Map of Collections based on the current * entityResourceHandlerMap Map, must be done whenever a manual change is made to the * entityResourceHandlerMap Map after the initial load to make them consistent again. * * Map&lt;ResourceHandler, Collection&lt;String&gt;&gt; resourceHandlerEntities * Map&lt;String, ResourceHandler&gt; entityResourceHandlerMap * 依据entityResourceHandlerMap来更新resourceHandlerEntities * FIXME:暂时不理解为什么会出现这种情况 */ public void rebuildResourceHandlerEntities() &#123; resourceHandlerEntities = new HashMap&lt;ResourceHandler, Collection&lt;String&gt;&gt;(); Iterator&lt;Map.Entry&lt;String, ResourceHandler&gt;&gt; entityResourceIter = entityResourceHandlerMap.entrySet().iterator(); while (entityResourceIter.hasNext()) &#123; Map.Entry&lt;String, ResourceHandler&gt; entry = entityResourceIter.next(); // add entityName to appropriate resourceHandlerEntities collection Collection&lt;String&gt; resourceHandlerEntityNames = resourceHandlerEntities.get(entry.getValue()); if (resourceHandlerEntityNames == null) &#123; resourceHandlerEntityNames = new LinkedList&lt;String&gt;(); resourceHandlerEntities.put(entry.getValue(), resourceHandlerEntityNames); &#125; resourceHandlerEntityNames.add(entry.getKey()); &#125; &#125; /**获取当前模型阅读器的resourceHandler迭代器*/ public Iterator&lt;ResourceHandler&gt; getResourceHandlerEntitiesKeyIterator() &#123; if (resourceHandlerEntities == null) return null; return resourceHandlerEntities.keySet().iterator(); &#125; public Collection&lt;String&gt; getResourceHandlerEntities(ResourceHandler resourceHandler) &#123; if (resourceHandlerEntities == null) return null; return resourceHandlerEntities.get(resourceHandler); &#125; public void addEntityToResourceHandler(String entityName, String loaderName, String location) &#123; entityResourceHandlerMap.put(entityName, new MainResourceHandler(EntityConfig.ENTITY_ENGINE_XML_FILENAME, loaderName, location)); &#125; public ResourceHandler getEntityResourceHandler(String entityName) &#123; return entityResourceHandlerMap.get(entityName); &#125; /** Gets an Entity object based on a definition from the specified XML Entity descriptor file. * @param entityName The entityName of the Entity definition to use. * @return An Entity object describing the specified entity of the specified descriptor file. */ public ModelEntity getModelEntity(String entityName) throws GenericEntityException &#123; if (entityName == null) &#123; throw new IllegalArgumentException("Tried to find entity definition for a null entityName"); &#125; Map&lt;String, ModelEntity&gt; ec = getEntityCache(); if (ec == null) &#123; throw new GenericEntityConfException("ERROR: Unable to load Entity Cache"); &#125; ModelEntity modelEntity = ec.get(entityName); if (modelEntity == null) &#123; String errMsg = "Could not find definition for entity name " + entityName; // Debug.logError(new Exception("Placeholder"), errMsg, module);// com.hanlin.fadp.petrescence.datasource.FindMissedEntity.addMissed(entityName); throw new GenericModelException(errMsg); &#125; return modelEntity; &#125; public ModelEntity getModelEntityNoCheck(String entityName) &#123; Map&lt;String, ModelEntity&gt; ec = null; try &#123; ec = getEntityCache(); &#125; catch (GenericEntityException e) &#123; Debug.logError(e, "Error getting entity cache", module); &#125; if (ec == null) &#123; return null; &#125; ModelEntity modelEntity = ec.get(entityName); return modelEntity; &#125; /** Creates a Iterator with the entityName of each Entity defined in the specified XML Entity Descriptor file. * @return A Iterator of entityName Strings */ public Iterator&lt;String&gt; getEntityNamesIterator() throws GenericEntityException &#123; Collection&lt;String&gt; collection = getEntityNames(); if (collection != null) &#123; return collection.iterator(); &#125; else &#123; return null; &#125; &#125; /** Creates a Set with the entityName of each Entity defined in the specified XML Entity Descriptor file. * @return A Set of entityName Strings */ public Set&lt;String&gt; getEntityNames() throws GenericEntityException &#123; Map&lt;String, ModelEntity&gt; ec = getEntityCache(); if (ec == null) &#123; throw new GenericEntityConfException("ERROR: Unable to load Entity Cache"); &#125; return ec.keySet(); &#125; /** Get all entities, organized by package */ public Map&lt;String, TreeSet&lt;String&gt;&gt; getEntitiesByPackage(Set&lt;String&gt; packageFilterSet, Set&lt;String&gt; entityFilterSet) throws GenericEntityException &#123; Map&lt;String, TreeSet&lt;String&gt;&gt; entitiesByPackage = new HashMap&lt;String, TreeSet&lt;String&gt;&gt;(); //put the entityNames TreeSets in a HashMap by packageName Iterator&lt;String&gt; ecIter = this.getEntityNames().iterator(); while (ecIter.hasNext()) &#123; String entityName = ecIter.next(); ModelEntity entity = this.getModelEntity(entityName); String packageName = entity.getPackageName(); if (UtilValidate.isNotEmpty(packageFilterSet)) &#123; // does it match any of these? boolean foundMatch = false; for (String packageFilter: packageFilterSet) &#123; if (packageName.contains(packageFilter)) &#123; foundMatch = true; &#125; &#125; if (!foundMatch) &#123; //Debug.logInfo("Not including entity " + entityName + " becuase it is not in the package set: " + packageFilterSet, module); continue; &#125; &#125; if (UtilValidate.isNotEmpty(entityFilterSet) &amp;&amp; !entityFilterSet.contains(entityName)) &#123; //Debug.logInfo("Not including entity " + entityName + " because it is not in the entity set: " + entityFilterSet, module); continue; &#125; TreeSet&lt;String&gt; entities = entitiesByPackage.get(entity.getPackageName()); if (entities == null) &#123; entities = new TreeSet&lt;String&gt;(); entitiesByPackage.put(entity.getPackageName(), entities); &#125; entities.add(entityName); &#125; return entitiesByPackage; &#125; /** Util method to validate an entity name; if no entity is found with the name, * characters are stripped from the beginning of the name until a valid entity name is found. * It is intended to be used to determine the entity name from a relation name. * @return A valid entityName or null */ public String validateEntityName(String entityName) throws GenericEntityException &#123; if (entityName == null) &#123; return null; &#125; Set&lt;String&gt; allEntities = this.getEntityNames(); while (!allEntities.contains(entityName) &amp;&amp; entityName.length() &gt; 0) &#123; entityName = entityName.substring(1); &#125; return (entityName.length() &gt; 0? entityName: null); &#125; ModelEntity createModelEntity(Element entityElement, UtilTimer utilTimer, ModelInfo def) &#123; if (entityElement == null) return null; this.numEntities++; ModelEntity entity = new ModelEntity(this, entityElement, utilTimer, def); return entity; &#125; ModelEntity createModelViewEntity(Element entityElement, UtilTimer utilTimer, ModelInfo def) &#123; if (entityElement == null) return null; this.numViewEntities++; ModelViewEntity entity = new ModelViewEntity(this, entityElement, utilTimer, def); return entity; &#125; public ModelRelation createRelation(ModelEntity entity, Element relationElement) &#123; this.numRelations++; ModelRelation relation = ModelRelation.create(entity, relationElement, false); return relation; &#125; /**增加当前ModelReader字段个数*/ public void incrementFieldCount(int amount) &#123; this.numFields += amount; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(三) GenericDelegator实例化的具体过程]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz3%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * @author 郑小康 * 1.设置delegatorFullName 基本delegatorName+"#"+tenantId 如果tenantId为空 则就是默认的delegatorName * * 2.获取EntityConfig实例,并获取基本delegatorBaseName的delegator标签,并解析为对应的DelegatorElement实例 * &lt;delegator name="default" entity-model-reader="main" entity-group-reader="main"&gt;&lt;/delegator&gt; * * 3.判断delegatorTenantId是否为空,这是租户id * 第一种情况租户id不为空:获取默认的Delegator,用delegator查询Tenant表中当前tenantId的对应GenericValue * :获取对应租户的kekText FIXME:暂时未应用 网上搜索说对数据库连接密码进行解密的操作 * 第二种情况租户id为空 :获取delegator标签实例的key-encrypting-key * * 4.获取ModelReader 检查了实体缓存之类的操作,获取所有ModelEntity * * 5.获取所有ModelGroupReader * 该类的主要操作是构造对应groupCache缓存,将entity-name为k,groupName为v这样存放,并提供一些获取方法,如获取所有组名,根据实体名获取组名 * * 6.缓存当前delegatorFullName * * 7.对实体进行检查 有检查组里面是否有对应实体 实体名是否是保留字 建立视图一个字段是否被引用多次 * * 8.获取组名集合 * * 9.遍历delegaot组,通过ThreadPoolExecutor线程池提交Future中任务,对每个组的实体创建到其组对应数据源的数据库 * 调用Future的原因是,是因为建表很耗时间,所以采用异步执行 * * */ protected GenericDelegator(String delegatorFullName) throws GenericEntityException &#123; this.setDelegatorNames(delegatorFullName); //获取基本的delegator中的信息 this.delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorBaseName); String kekText; // before continuing, if there is a tenantId use the base delegator to see if it is valid if (UtilValidate.isNotEmpty(this.delegatorTenantId)) &#123; Delegator baseDelegator = DelegatorFactory.getDelegator(this.delegatorBaseName); GenericValue tenant = EntityQuery.use(baseDelegator).from("Tenant").where("tenantId", this.delegatorTenantId).cache(true).queryOne(); if (tenant == null) &#123; throw new GenericEntityException("No Tenant record found for delegator [" + this.delegatorFullName + "] with tenantId [" + this.delegatorTenantId + "]"); &#125; else if ("Y".equals(tenant.getString("disabled"))) &#123; throw new GenericEntityException("No Tenant record found for delegator [" + this.delegatorFullName + "] with tenantId [" + this.delegatorTenantId + "]"); &#125; GenericValue kekValue = EntityQuery.use(baseDelegator).from("TenantKeyEncryptingKey").where("tenantId", getDelegatorTenantId()).cache(true).queryOne(); if (kekValue != null) &#123; kekText = kekValue.getString("kekText"); &#125; else &#123; kekText = this.delegatorInfo.getKeyEncryptingKey(); &#125; &#125; else &#123; kekText = this.delegatorInfo.getKeyEncryptingKey(); &#125; this.modelReader = ModelReader.getModelReader(delegatorBaseName); this.modelGroupReader = ModelGroupReader.getModelGroupReader(delegatorBaseName); cache = new Cache(delegatorFullName); //对实体进行检查 有检查组里面是否有对应实体 实体名是否是保留字 建立视图一个字段是否被引用多次 List&lt;String&gt; warningList = new LinkedList&lt;String&gt;(); Debug.logInfo("Doing entity definition check...", module); ModelEntityChecker.checkEntities(this, warningList); if (warningList.size() &gt; 0) &#123; Debug.logWarning("=-=-=-=-= Found " + warningList.size() + " warnings when checking the entity definitions:", module); for (String warning: warningList) &#123; Debug.logWarning(warning, module); &#125; &#125; //获取当前delegator中的groupNames集合,遍历创建对应的GenericHelper,同时在数据库中创建未创建的表和字段 Set&lt;String&gt; groupNames = getModelGroupReader().getGroupNames(delegatorBaseName); List&lt;Future&lt;Void&gt;&gt; futures = new LinkedList&lt;Future&lt;Void&gt;&gt;(); for (String groupName: groupNames) &#123; futures.add(ExecutionPool.GLOBAL_BATCH.submit(createHelperCallable(groupName))); &#125; ExecutionPool.getAllFutures(futures); // NOTE: doing some things before the ECAs and such to make sure it is in place just in case it is used in a service engine startup thing or something // setup the crypto class; this also after the delegator is in the cache otherwise we get infinite recursion this.crypto = new EntityCrypto(this, kekText); &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(二) delegator实例化具体方式]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz2%2F</url>
    <content type="text"><![CDATA[123456789101112131415/** * @author 郑小康 * 采用spi创建对应实例DelegatorFactoryImpl * */ public static &lt;A, R&gt; R getObjectFromFactory(Class&lt;? extends Factory&lt;R, A&gt;&gt; factoryInterface, A obj) throws ClassNotFoundException &#123; Iterator&lt;? extends Factory&lt;R, A&gt;&gt; it = ServiceLoader.load(factoryInterface).iterator(); while (it.hasNext()) &#123; Factory&lt;R, A&gt; factory = it.next(); R instance = factory.getInstance(obj); if (instance != null) &#123; return instance; &#125; &#125; throw new ClassNotFoundException(factoryInterface.getClass().getName()); &#125; 注：上下代码不是在一个类 1234567891011121314151617181920 /** * @author 郑小康 * 根据delegatorName创建一个GenericDelegator * 所以实际delegator引用的是一个GenericDelegator实例 * */public class DelegatorFactoryImpl extends DelegatorFactory &#123; public static final String module = DelegatorFactoryImpl.class.getName(); public Delegator getInstance(String delegatorName) &#123; if (Debug.infoOn()) Debug.logInfo("Creating new delegator [" + delegatorName + "] (" + Thread.currentThread().getName() + ")", module); //Debug.logInfo(new Exception(), "Showing stack where new delegator is being created...", module); try &#123; return new GenericDelegator(delegatorName); &#125; catch (GenericEntityException e) &#123; Debug.logError(e, "Error creating delegator", module); return null; &#125; &#125;&#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(一) 获取Delegator]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz1%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public abstract class DelegatorFactory implements Factory&lt;Delegator, String&gt; &#123; public static final String module = DelegatorFactoryImpl.class.getName(); private static final ConcurrentHashMap&lt;String, Future&lt;Delegator&gt;&gt; delegators = new ConcurrentHashMap&lt;String, Future&lt;Delegator&gt;&gt;(); private static final ThreadGroup DELEGATOR_THREAD_GROUP = new ThreadGroup("DelegatorFactory"); private static final ScheduledExecutorService executor = ExecutionPool.getScheduledExecutor(DELEGATOR_THREAD_GROUP, "delegator-startup", Runtime.getRuntime().availableProcessors(), 10, true); /** *@author 郑小康 * * 根据delegatorName调用getDelegatorFuture方法,获取当前delegator的 Future&lt;Delegator&gt; * * 而后调用get方法获取Delegator实例 * * */ public static Delegator getDelegator(String delegatorName) &#123; Future&lt;Delegator&gt; future = getDelegatorFuture(delegatorName); try &#123; return future.get(); &#125; catch (ExecutionException e) &#123; Debug.logError(e, module); return null; &#125; catch (InterruptedException e) &#123; Debug.logError(e, module); return null; &#125; &#125; /** * @author 郑小康 * * 根据delegatorName获取Future&lt;Delegator&gt; 如果为空,新创建一个FutureTask&lt;Delegator&gt;将其加入到缓存中去 * * 将这个futureTask给提交到线程池,futureTask中存放的是DelegatorConfigurable实例对象 * * * */ public static Future&lt;Delegator&gt; getDelegatorFuture(String delegatorName) &#123; if (delegatorName == null) &#123; delegatorName = "default"; //Debug.logWarning(new Exception("Location where getting delegator with null name"), "Got a getGenericDelegator call with a null delegatorName, assuming default for the name.", module); &#125; do &#123; Future&lt;Delegator&gt; future = delegators.get(delegatorName); if (future != null) &#123; //Debug.logInfo("got delegator(future(" + delegatorName + ")) from cache", module); return future; &#125; FutureTask&lt;Delegator&gt; futureTask = new FutureTask&lt;Delegator&gt;(new DelegatorConfigurable(delegatorName)); //Debug.logInfo("putting delegator(future(" + delegatorName + ")) into cache", module); if (delegators.putIfAbsent(delegatorName, futureTask) != null) &#123; continue; &#125; executor.submit(futureTask); &#125; while (true); &#125; public static final class DelegatorConfigurable implements Callable&lt;Delegator&gt; &#123; private final String delegatorName; public DelegatorConfigurable(String delegatorName) &#123; this.delegatorName = delegatorName; &#125; /** * 获取delegator的具体方法 * 并做了分布式缓存和ECA Handler FIXME:未研究 * */ public Delegator call() throws ClassNotFoundException &#123; try &#123; Delegator delegator = UtilObject.getObjectFromFactory(DelegatorFactory.class, delegatorName); // setup the Entity ECA Handler delegator.initEntityEcaHandler(); // setup the distributed CacheClear delegator.initDistributedCacheClear(); return delegator; &#125; catch (ClassNotFoundException e) &#123; Debug.logError(e, module); throw e; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz方法之FreeMarkerWorker的makeConfiguration]]></title>
    <url>%2F2017%2F06%2F26%2Fofbiz%2Fofbiz10%2F</url>
    <content type="text"><![CDATA[代码展示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133public static Configuration makeConfiguration(BeansWrapper wrapper) &#123; /** * freemarker.template.Configuration实例并调整其设置。 * 一个Configuration实例是存储FreeMarker应用程序级别设置的中心。 * 另外，它处理预先解析的模板（即 对象）的创建和 缓存Template * */ Configuration newConfig = new Configuration(version); /** * @author jack * * 对象包装器 * wrapper == &gt;freemarker.ext.beans.BeansWrapper * 这是一个最原始的对象包装器，主要用来映射java * 虽然原始，但是也有使用的时候，比如collection-s和map-s被允许修改模板时执行 * 参考资料 http://freemarker.org/docs/pgui_misc_beanwrapper.html * */ newConfig.setObjectWrapper(wrapper); /** * @author jack * * 从beanswrapper返回TemplateHashModel。 * getstaticmodels()可以用来访问静态方法和任意一类的字段创建哈希模型。 * */ TemplateHashModel staticModels = wrapper.getStaticModels(); /** * @author jack * 将TemplateHashModel通过Static注入 以后就可以直接通过Static进行访问 * Shared variables共享变量是为所有模板定义的变量 * 形式：statics["java.lang.System"].currentTimeMillis() 这是一种调用java方法的处理方式 ftl中的用法 * */ newConfig.setSharedVariable("Static", staticModels); /** * @author jack * * #assign ls = EntityQuery.use(delegator).from("DictType").() ftl中的用法 * 注入后就可以直接使用EntityQuery了 * */ try &#123; newConfig.setSharedVariable("EntityQuery", staticModels.get("com.hanlin.fadp.entity.util.EntityQuery")); &#125; catch (TemplateModelException e) &#123; Debug.logError(e, module); &#125; /** * @author jack * * 当一个模板包含另一个模板时，它试图加载以相同的本地化环境加载模板。 * 假定你的模板以本地化en_US来加载，那就意味着是U.S. English。当你包含另外一个模板：那么引擎实际上就会寻找一些模板，并按照这个顺序： * footer_en_US.ftl * footer_en.ftl * footer.ftl * 设置成为false就不会有这些问题 * */ newConfig.setLocalizedLookup(false); //创建StringUtil这个工具类共享变量 newConfig.setSharedVariable("StringUtil", new BeanModel(StringUtil.INSTANCE, wrapper)); /** * @author jack * * 如果在这些内建的模版加载器中没有一个符合你的要求， * 那么你可以自己定制一个模版加载器，只需要实现freemarker.cache.TemplateLoader 接口就可以了， * 然后通过方法setTemplateLoader(TemplateLoader loader)把其传递给Configuration对象。 * 主要业务处理不是很清楚 * */ newConfig.setTemplateLoader(new FlexibleTemplateLoader()); /** * @author jack * * 导入库也就是说，它创建一个新的空命名空间 然后执行path在该命名空间中使用参数给出的模板 * 导入法则： * #import "/lib/example.ftl" as e * &lt;@e.copyright date="1999-2002"/&gt; * 属性文件中的模板就是通过这种方式加载进去 * 所以在调用的时候需要加入命令空间 * */ newConfig.setAutoImports(UtilProperties.getProperties("freemarkerImports")); /** * @author jack * * 自定义类实现TemplateExceptionHandler * 当ftl渲染出现异常调用这个类的handleTemplateException * */ newConfig.setTemplateExceptionHandler(new FreeMarkerWorker.OFBizTemplateExceptionHandler()); try &#123; newConfig.setSetting("datetime_format", "yyyy-MM-dd HH:mm:ss.SSS"); newConfig.setSetting("number_format", "0.##########"); &#125; catch (TemplateException e) &#123; Debug.logError("Unable to set date/time and number formats in FreeMarker: " + e, module); &#125; // Transforms properties file set up as key=transform name, property=transform class name /** * @author jack * * 获取上下文加载器，当前加载器在webapp,随意加载其中config的freemarkerTransforms.properties所有值 * */ ClassLoader loader = Thread.currentThread().getContextClassLoader(); Enumeration&lt;URL&gt; resources; try &#123; resources = loader.getResources("freemarkerTransforms.properties"); &#125; catch (IOException e) &#123; Debug.logError(e, "Could not load list of freemarkerTransforms.properties", module); throw UtilMisc.initCause(new InternalError(e.getMessage()), e); &#125; /** * @author jack * * 创建其中资源文件值得实例并通过key用setSharedVariable设置进入共享变量 * */ while (resources.hasMoreElements()) &#123; URL propertyURL = resources.nextElement(); Debug.logInfo("loading properties: " + propertyURL, module); Properties props = UtilProperties.getProperties(propertyURL); if (UtilValidate.isEmpty(props)) &#123; Debug.logError("Unable to locate properties file " + propertyURL, module); &#125; else &#123; loadTransforms(loader, props, newConfig); &#125; &#125; return newConfig; &#125; 用例说明1&lt;#assign displayApps = Static[&quot;org.ofbiz.webapp.control.LoginWorker&quot;].getAppBarWebInfos(security, userLogin, ofbizServerName, &quot;main&quot;)&gt; StringUtil1&lt;link rel=&quot;shortcut icon&quot; href=&quot;&lt;@ofbizContentUrl&gt;$&#123;StringUtil.wrapString(shortcutIcon)&#125;&lt;/@ofbizContentUrl&gt;&quot; /&gt;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz方法之条件查询createConditionList]]></title>
    <url>%2F2017%2F06%2F26%2Fofbiz%2Fofbiz11%2F</url>
    <content type="text"><![CDATA[方法代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110/** * Parses input parameters and returns an &lt;code&gt;EntityCondition&lt;/code&gt; list. * * @param parameters * @param fieldList * @param queryStringMap * @param delegator * @param context * @return returns an EntityCondition list * * @author jack * 第一步：获取所有字段信息 存入到Map&lt;String, ModelField&gt; fieldMap * 第二步：将上下文这个map进行遍历,这个map是传进来的参数 * 由于是根据参数，一个字段最多具有三个条件 _op _fld0_op _fld1_op * 第三步: 调用createSingleCondition创造条件，添加到集合 * * @param parameters 获取传入的参数 * @param fieldList 传入当前实体所有字段 * @param queryStringMap * @param delegator 操作数据库的实例 * @param context 获取上下文 */ public static List&lt;EntityCondition&gt; createConditionList(Map&lt;String, ? extends Object&gt; parameters, List&lt;ModelField&gt; fieldList, Map&lt;String, Object&gt; queryStringMap, Delegator delegator, Map&lt;String, ?&gt; context) &#123; Set&lt;String&gt; processed = new LinkedHashSet&lt;String&gt;(); Set&lt;String&gt; keys = new LinkedHashSet&lt;String&gt;(); Map&lt;String, ModelField&gt; fieldMap = new LinkedHashMap&lt;String, ModelField&gt;(); for (ModelField modelField : fieldList) &#123; fieldMap.put(modelField.getName(), modelField); &#125; List&lt;EntityCondition&gt; result = new LinkedList&lt;EntityCondition&gt;(); for (Map.Entry&lt;String, ? extends Object&gt; entry : parameters.entrySet()) &#123; String parameterName = entry.getKey(); //获取上下文中的键值 //如果已经有了这个键值在进程中就不在对它进行处理 if (processed.contains(parameterName)) &#123; continue; &#125; keys.clear(); String fieldName = parameterName; Object fieldValue = null; String operation = null; boolean ignoreCase = false; /** * 将参数名截断对应实体中的字段名，这样做的方式是先获取字段名 * (如果包含fld0 fld1下面则需要再截断）， * 下面进行连接，针对几种不同的情况进行处理 */ if (parameterName.endsWith("_ic") || parameterName.endsWith("_op")) &#123; fieldName = parameterName.substring(0, parameterName.length() - 3); &#125; else if (parameterName.endsWith("_value")) &#123; fieldName = parameterName.substring(0, parameterName.length() - 6); &#125; //_ic连接 是判断条件查找是否忽略大小写 String key = fieldName.concat("_ic"); if (parameters.containsKey(key)) &#123; keys.add(key); ignoreCase = "Y".equals(parameters.get(key)); &#125; //获取字段要进行的操作 key = fieldName.concat("_op"); if (parameters.containsKey(key)) &#123; keys.add(key); operation = (String) parameters.get(key); &#125; //获取字段的值,如果具有_fld0 这些可能获取不到，后面会进一步截断获取 key = fieldName.concat("_value"); if (parameters.containsKey(key)) &#123; keys.add(key); fieldValue = parameters.get(key); &#125; //主要是对时间进行处理，一个条件大于多少 小于多少 if (fieldName.endsWith("_fld0") || fieldName.endsWith("_fld1")) &#123; if (parameters.containsKey(fieldName)) &#123; keys.add(fieldName); &#125; fieldName = fieldName.substring(0, fieldName.length() - 5); &#125; //将字段名，之所以这样不断截断是为了获取对应与实体中的真实字段名 if (parameters.containsKey(fieldName)) &#123; keys.add(fieldName); &#125; processed.addAll(keys); ModelField modelField = fieldMap.get(fieldName); if (modelField == null) &#123; continue; &#125; //获取字段值 if (fieldValue == null) &#123; fieldValue = parameters.get(fieldName); &#125; //如果值为空，则不进行任何操作 if (ObjectType.isEmpty(fieldValue) &amp;&amp; !"empty".equals(operation)) &#123; continue; &#125; //将创建的条件加入list集合 即AND关系 result.add(createSingleCondition(modelField, operation, fieldValue, ignoreCase, delegator, context)); for (String mapKey : keys) &#123; queryStringMap.put(mapKey, parameters.get(mapKey)); &#125; &#125; return result; &#125; 方法使用1234567&lt;select name=&quot;visitId_op&quot; class=&quot;selectBox&quot;&gt; &lt;option value=&quot;equals&quot;&gt;等于&lt;/option&gt; &lt;option value=&quot;like&quot;&gt;开头字符&lt;/option&gt; &lt;option value=&quot;contains&quot; selected=&quot;selected&quot;&gt;包含&lt;/option&gt; &lt;option value=&quot;empty&quot;&gt;为空&lt;/option&gt; &lt;option value=&quot;notEqual&quot;&gt;不等于&lt;/option&gt;&lt;/select&gt;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz view渲染处理机制]]></title>
    <url>%2F2017%2F06%2F16%2Fofbiz%2Fofbiz12%2F</url>
    <content type="text"><![CDATA[初始化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ControlServlet.java 这是一个servlet,其配置文件在web.xml里 1234567891011&lt;servlet&gt; &lt;servlet-name&gt;ControlServlet&lt;/servlet-name&gt; &lt;display-name&gt;ControlServlet&lt;/display-name&gt; &lt;description&gt;MainControl Servlet&lt;/description&gt; &lt;servlet-class&gt;org.apache.ofbiz.webapp.control.ControlServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;ControlServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/control/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这也是为什么大多数请求都是组件名/control/* 首先在第一次请求时经过Servlet的init方法，该Servlet方法如下： 123456789101112131415public void init(ServletConfig config) throws ServletException &#123; super.init(config); if (Debug.infoOn()) &#123; ServletContext servletContext = config.getServletContext(); String webappName = servletContext.getContextPath().length() != 0 ?servletContext.getContextPath().substring(1) : ""; Debug.logInfo("Loading webapp [" + webappName + "],located at " + servletContext.getRealPath("/"), module);&#125; //配置默认脚本引擎，默认有beanshell和平台自定义的minilang脚本，可扩展其它脚本 configureBsf(); // 初始化request处理句柄，实质就是加载controller.xml中handler节点中class属性值对应类的实例化和初始化 getRequestHandler();&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 该方法中的getRequestHandler就是获取所有的handler节点，加载方式如下 123456789/** * @Title: getRequestHandler * @Description: 获取request的处理句柄，request处理分两类，一类是view， * 另一类是event，对应controller.xml中handler节点的配置信息的获取 * @return: RequestHandler */ protected RequestHandler getRequestHandler() &#123; return RequestHandler.getRequestHandler(getServletContext());&#125; 12345678910111213141516/** * @Title: getRequestHandler * @Description: 在上下文中新建一个requesthandler，命名为_REQUEST_HANDLER_， * 构造方法为private，此方法共外界获取实例，为单例模式使用，requesthandler配置来至 * 处理controller.xml中handler节点的配置数据 * @param servletContext * @return: RequestHandler */ public static RequestHandler getRequestHandler(ServletContextservletContext) &#123; RequestHandler rh = (RequestHandler)servletContext.getAttribute("_REQUEST_HANDLER_"); if (rh == null) &#123; rh = newRequestHandler(servletContext); servletContext.setAttribute("_REQUEST_HANDLER_", rh); &#125; return rh;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 其中的RequestHandler方法如下 12345678910111213141516171819202122232425/** * @author jack * 第一步:将controller.xml的解析信息加入到缓存中 * */ private RequestHandler(ServletContext context) &#123; // init the ControllerConfig, but don't save it anywhere, just load itinto the cache this.controllerConfigURL = ConfigXMLReader.getControllerConfigURL(context); try &#123; //将controller.xml的解析信息加入到缓存中 ConfigXMLReader.getControllerConfig(this.controllerConfigURL); &#125; catch (WebAppConfigurationException e) &#123; // FIXME: controller.xml errors should throw an exception. Debug.logError(e, "Exception thrown while parsing controller.xmlfile: ", module); &#125; //加载ViewHandler实现类的实例，其为controller.xml中handler的类型为view this.viewFactory = new ViewFactory(context,this.controllerConfigURL); //加载EventHandler实现类的实例，其为controller.xml中handler的类型为非view的情况 this.eventFactory = new EventFactory(context, this.controllerConfigURL); this.forceHttpSession ="true".equalsIgnoreCase(context.getInitParameter("forceHttpSession")); this.trackServerHit =!"false".equalsIgnoreCase(context.getInitParameter("track-serverhit")); this.trackVisit =!"false".equalsIgnoreCase(context.getInitParameter("track-visit")); this.cookies = !"false".equalsIgnoreCase(context.getInitParameter("cookies")); this.charset = context.getInitParameter("charset");&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 其具体存储方式如下 12345678910111213141516171819202122232425262728293031/** * @author jack * 构建ViewHandler实现类的map，对handler节点的class属性值对应的类进行实例化和初始化， * 并设置key=default时，其value=com.hanlin.fadp.webapp.view.JspViewHandler的实例 * @param context * @param controllerConfigURL */ public ViewFactory(ServletContext context, URL controllerConfigURL) &#123; // load all the view handlers try &#123; Set&lt;Map.Entry&lt;String,String&gt;&gt; handlerEntries =ConfigXMLReader.getControllerConfig(controllerConfigURL).getViewHandlerMap().entrySet(); if (handlerEntries != null) &#123; for(Map.Entry&lt;String,String&gt; handlerEntry: handlerEntries) &#123; //将对应的handler给实例化 ViewHandlerhandler = (ViewHandler) ObjectType.getInstance(handlerEntry.getValue()); handler.setName(handlerEntry.getKey()); handler.init(context); this.handlers.put(handlerEntry.getKey(),handler); &#125; &#125; // load the "default" type if (!this.handlers.containsKey("default")) &#123; ViewHandler defaultHandler =(ViewHandler) ObjectType.getInstance("com.hanlin.fadp.webapp.view.JspViewHandler"); defaultHandler.init(context); this.handlers.put("default", defaultHandler); &#125; &#125; catch (Exception e) &#123; Debug.logError(e, module); throw new GeneralRuntimeException(e); &#125; &#125; 渲染处理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在经过多contoller文件的request 和response标签处理后，其中的response中对应type=“view”会到对应的view-map标签处理，最终处理如下： 123456789try &#123; if (Debug.verboseOn())Debug.logVerbose("Rendering view [" + nextPage + "] of type[" + viewMap.type + "]", module); ViewHandlervh = viewFactory.getViewHandler(viewMap.type); vh.render(view,nextPage, viewMap.info, contentType, charset, req, resp); &#125; catch (ViewHandlerException e) &#123; Throwable throwable = e.getNested()!= null ? e.getNested() : e; throw newRequestHandlerException(e.getNonNestedMessage(), throwable); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 标记的第一步是根据key获取上文初始化中的对应ViewHandler实例，这个key来自于view-map中的screen.具体操作如下 1234567891011public ViewHandlergetViewHandler(String type) throws ViewHandlerException &#123; if (UtilValidate.isEmpty(type)) &#123; type = "default"; &#125; // get the view handler by type fromthe contextHandlers ViewHandler handler =handlers.get(type); if (handler == null) &#123; throw newViewHandlerException("No handler found for type: " + type); &#125; return handler; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 标记的第二步是进行具体的渲染，针对于不同类型有不同实现类进行处理，在这里只是展示一下它的接口 1234567891011/** * Render the page. * * @param name The name of the view. * @param page The source of the view;could be a page, url, etc depending on the type of handler. * @param info An info string attached tothis view * @param request The HttpServletRequestobject used when requesting this page. * @param response The HttpServletResponseobject to be used to present the page. * @throws ViewHandlerException */ public void render(String name, Stringpage, String info, String contentType, String encoding, HttpServletRequestrequest, HttpServletResponse response) throws ViewHandlerException;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hashMap]]></title>
    <url>%2F2017%2F01%2F10%2FJdk%2F2018-01-10%2F</url>
    <content type="text"><![CDATA[hashMap的简介1.HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。2.HashMap 继承于AbstractMap，实现了Map、Cloneable、java.io.Serializable接口 hashMap的关系结构图 hashMap的构造器■ HashMap():构建一个初始容量为16,负载因子为0.75的HashMap。■ HashMap(int initialCapacity):构建一个初始容量为 initialCapacity，负栽因子为0.75的 HashMap.■ HashMap(int initialCapacity, float loadFactor):以指定初始容量、指定的负栽因子创建一 个 HashMap. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; init(); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */ public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */ public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR); &#125; /** * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the * specified &lt;tt&gt;Map&lt;/tt&gt;. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); inflateTable(threshold); putAllForCreate(m); &#125; 当创建一个HashMap时，系统会自动创建一个table数组来保存HashMap中的Entry。下 面是HashMap中一个构造器的代码 table = new Entry[capacity]; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; hashMap has four Constructs, at first we must know the public HashMap(int initialCapacity, float loadFactor)]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring doGetBean源码解读]]></title>
    <url>%2F2017%2F01%2F07%2Fspring%2F2018-01-07-2%2F</url>
    <content type="text"><![CDATA[AbstractBeanFactory 123456789101112/** * Return an instance, which may be shared or independent, of the specified bean. * @param name the name of the bean to retrieve * @param requiredType the required type of the bean to retrieve * @param args arguments to use when creating a bean instance using explicit arguments * (only applied when creating a new instance as opposed to retrieving an existing one) * @param typeCheckOnly whether the instance is obtained for a type check, * not for actual use * @return an instance of the bean * @throws BeansException if the bean could not be created */protected &lt;T&gt; T doGetBean(final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) 1.name转化为规范形式beanname2.根据beanname调用getSingleton获取相应的单例3.如果2中没有获取则根据beanname获取RootBeanDefinition而后通过匿名内部类的方式创建其单例]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring IOC源码分析]]></title>
    <url>%2F2017%2F01%2F07%2Fspring%2F2018-01-07%2F</url>
    <content type="text"><![CDATA[What is IOC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ioc—Inversion of Control，即“控制反转”，不是什么技术，而是一种设计思想&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 谁控制谁，控制什么：Ioc容器来控制对象的创建,控制了外部资源获取&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为何是反转，哪些方面反转了：因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转,依赖对象的获取被反转了 传统程序设计: IOC容器模型: IOC的作用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IoC是一个重要的面向对象编程的法则，它能指导我们如何设计出松耦合、更优良的程序。即由IoC容器帮对象找相应的依赖对象并注入，而不是由对象主动去找。 参考链接：http://jinnianshilongnian.iteye.com/category/206533]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring ClassPathXmlApplicationContext代码解读]]></title>
    <url>%2F2017%2F01%2F07%2Fspring%2F2018-01-07-1%2F</url>
    <content type="text"><![CDATA[实例化ClassPathXmlApplicationContext12ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext( new String[] &#123; "spring-context.xml" &#125;); 调用父级构造器123this(configLocations, refresh, null);。。。。。。super(parent); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在实例化的过程中不断调用父类构造器直到找到AbstractApplicationContext,调用this方法实例化PathMatchingResourcePatternResolver并注入作为句柄。并且该实例的resourceLoader句柄的值就是当前ClassPathXmlApplicationContext实例。这个时候ClassPathXmlApplicationContext中传入的父级上下文为空，所以父级上下文始终为空。 设置配置文件路径1setConfigLocations(configLocations); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个代码中,主要做的事情是设置配置文件的路径。如上文中的spring-context.xml，最终将其存入configLocations这个String数组中。 refresh方法123if (refresh) &#123; refresh();&#125; 具体代码过程如下: 12/** 这里会重新设置容器启动时间和启动标志字段*/ prepareRefresh(); 1234567891011121314151617181920ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();``` 通知子类刷新beanFactory，具体实现在AbstractRefreshableApplicationContext中， 注这里的默认实例&gt; 1.如果当前Context持有beanFactory，则先destoryBeans，再关闭beanFactory &gt; &gt; 2.createBeanFactory：用父容器创建一个DefaultListableBeanFactory，（这里如果父容器为ConfigurableApplicationContext， 则返回该context持有的beanFacotry，否则直接返回父BeanFactory。ps：这里可能就是context和beanFactory的区分点） &gt; &gt; 3.customizeBeanFactory：根据参数设置是否允许子类定制DefaultListableBeanFactory。 &gt; &gt; 4.loadBeanDefinitions：加载BeanDefinitions，具体实现在AbstractXmlApplicationContext中。（TODO：后面会详细扩展讲解） 并返回子类的beanFactory &gt; &gt; ```javaprepareBeanFactory(beanFactory); 1.设置ClassLoader 2.addPropertyEditorRegistrar，设置用户定义的propertyEditor注册器 3.addBeanPostProcessor，设置ApplicationContextAwareProcessor， 处理ApplicationContextAware实现接口的Bean。 4.ignoreDependencyInterface，设置不解析某些接口的依赖关系 5.registerResolvableDependency,设置特殊接口和bean的绑定关系 /* 提供接口给子类修改beanFactory。 / postProcessBeanFactory(beanFactory); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** 调用注册的BeanFactoryPostProcessor，按照实现的排序接口PriorityOrdered&gt;Ordered&gt;无接口 */ invokeBeanFactoryPostProcessors(beanFactory); /** 按照排序接口，依次注册BeanPostProcessor，后面会按照这个顺序调用 */ registerBeanPostProcessors(beanFactory); /** * 初始化messageSource,（MessageSource接口用于支持国际化）如果context中尤定义id为messageSource * 的MessageSource接口的bean（潜规则），则采用它来解析Message资源，否则采用父容器messageSource，这里会创建一个DelegatingMessageSource， * 避免为空的情况导致调用失败。 */ initMessageSource(); /** * 初始化并注册ApplicationEventMulticaster，容器事情广播器，同样采用MessageSource类似的潜规则， * 如果容器中有名为applicationEventMulticaster且实现了ApplicationEventMulticaster接口的bean，则注册它， * 否则创建SimpleApplicationEventMulticaster，将它当作默认的广播器。 */ initApplicationEventMulticaster(); /** 给子类保留的接口，通知子类刷新 */ onRefresh(); /** 获取容器中定义的所有ApplicationListener，容器事件监听器，并注册 */ registerListeners(); /** * 1.清除用于类型匹配的classLoader * 2.冻结bean definitions中设置，不能再修改bean的配置 * 3.实例化非延迟加载的单例bean，包括由FactoryBean实例化的bean（TODO：需要进一步深挖） */ finishBeanFactoryInitialization(beanFactory); /** 广播ContextRefreshedEvent容器刷新事件。 */ finishRefresh(); ``` # 调用ClassPathXmlApplicationContext的start方法```javapublic void start() &#123; getLifecycleProcessor().start(); publishEvent(new ContextStartedEvent(this));&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面展示它的具体实现方法.getLifecycleProcessor获取的默认的实例是，在其中会调用如下: 1234public void start() &#123; startBeans(false); this.running = true;&#125; 1234567891011121314151617181920212223private void startBeans(boolean autoStartupOnly) &#123; Map&lt;String, Lifecycle&gt; lifecycleBeans = getLifecycleBeans(); Map&lt;Integer, LifecycleGroup&gt; phases = new HashMap&lt;Integer, LifecycleGroup&gt;(); for (Map.Entry&lt;String, ? extends Lifecycle&gt; entry : lifecycleBeans.entrySet()) &#123; Lifecycle bean = entry.getValue(); if (!autoStartupOnly || (bean instanceof SmartLifecycle &amp;&amp; ((SmartLifecycle) bean).isAutoStartup())) &#123; int phase = getPhase(bean); LifecycleGroup group = phases.get(phase); if (group == null) &#123; group = new LifecycleGroup(phase, this.timeoutPerShutdownPhase, lifecycleBeans, autoStartupOnly); phases.put(phase, group); &#125; group.add(entry.getKey(), bean); &#125; &#125; if (phases.size() &gt; 0) &#123; List&lt;Integer&gt; keys = new ArrayList&lt;Integer&gt;(phases.keySet()); Collections.sort(keys); for (Integer key : keys) &#123; phases.get(key).start(); &#125; &#125;&#125; 12345678910public void publishEvent(ApplicationEvent event) &#123; Assert.notNull(event, "Event must not be null"); if (logger.isTraceEnabled()) &#123; logger.trace("Publishing event in " + getDisplayName() + ": " + event); &#125; getApplicationEventMulticaster().multicastEvent(event); if (this.parent != null) &#123; this.parent.publishEvent(event); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以第一句的作用是添加相应监听器，第二句的作用是通知监听器，然后执行相应的时间 loadBeanDefinitions&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个里面有个东西需要单独说明一下，即装载bean。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo环境搭建]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[#解压dubbo-admin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将dubbo-admin解压到tomcat的webapps下面 解压命令unzip dubbo-admin.war -d dubbp-admin #修改属性文件 1.将用户密码都改成root2.修改相应地址 截图如下: #启动tomcat&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;直接将tomcat启动，启动之后可以查看相应的日志，启动命令：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在相应的bin目录下执行startup.sh日志命令:tail -f -n 500 /usr/local/dubbo-tomcat/logs/catalina.out]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git基本指令]]></title>
    <url>%2F2017%2F01%2F02%2Fgit%2F2017-12-29%2F</url>
    <content type="text"><![CDATA[The knowledge of gitbase codegit init在当前目录生成的一个管理git仓库的文件夹，这里包含所有git操作所需要的东西 1 hooks:这个目录存放一些shell脚本，可以设置特定的git命令后触发相应的脚本；在搭建gitweb系统或其他git托管系统会经常用到hook script。 2 info:包含仓库的一些信息 3 logs:保存所有更新的引用记录 4 objects:该目录存放所有的Git对象，对象的SHA1哈希值的前两位是文件夹名称，后38位作为对象文件名。比如前面log里的HEAD文件里有个哈希值5426426e3ccc9ab4e3330640862a7b96e28828af 5 refs:具体的引用，Reference Specification，这个目录一般包括三个子文件夹，heads、remotes和tags，比如，heads中的master文件标识了项目中的master分支指向的当前commit，其他类似。 6 COMMIT_EDITMSG:保存最新的commit message，Git系统不会用到这个文件，只是给用户一个参考 7 config:这个是GIt仓库的配置文件 8 description:仓库的描述信息，主要给gitweb等git托管系统使用 9 index:这个文件就是我们前面提到的暂存区（stage），是一个二进制文件 10 HEAD:这个文件包含了一个分支（branch）的引用，通过这个文件Git可以得到下一次commit的parent，什么是引用呢，你可以理解为指针，哪儿都可以指，但是不能指向没有的东西哦。详细介绍请看这里： ###git add git add . ：他会监控工作区的状态树，使用它会把工作时的所有变化提交到暂存区，包括文件内容修改(modified)以及新文件(new)，但不包括被删除的文件。 git add -u ：他仅监控已经被add的文件（即tracked file），他会将被修改的文件提交到暂存区。add -u 不会提交新文件（untracked file）。（git add –update的缩写） git add -A ：是上面两个功能的合集（git add –all的缩写） git remotegit remote add:命令用于添加远程主机 1git remote add &lt;主机名&gt; &lt;网址&gt; src refspec master does not match any.]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo源码分析1-spring方式启动]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2F2018-01-07%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在一下的代码中主要是装载标签元素并进行解析，其中装载是根据namespaceUri找到对应的句柄，然后通过句柄来解析自己定义的元素. 123456789public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; String namespaceUri = getNamespaceURI(ele); NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error("Unable to locate Spring NamespaceHandler for XML schema namespace [" + namespaceUri + "]", ele); return null; &#125; return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));&#125; 装载标签元素Spring为了支持用户自定义类加载到Spring容器，提供了org.springframework.beans.factory.xml.NamespaceHandler接口org.springframework.beans.factory.xml.NamespaceHandlerSupport抽象类，NamespaceHandler#init方法会在对象的构造函数调用之后、属性初始化之前被DefaultNamespaceHandlerResolver调用。dubbo的DubboNamespaceHandler类正是继承了NamespaceHandlerSupport所以在spring加载过程中会执行这个类中的内容 1234567891011121314151617181920public class DubboNamespaceHandler extends NamespaceHandlerSupport &#123; static &#123; Version.checkDuplicate(DubboNamespaceHandler.class); &#125; public void init() &#123; registerBeanDefinitionParser("application", new DubboBeanDefinitionParser(ApplicationConfig.class, true)); registerBeanDefinitionParser("module", new DubboBeanDefinitionParser(ModuleConfig.class, true)); registerBeanDefinitionParser("registry", new DubboBeanDefinitionParser(RegistryConfig.class, true)); registerBeanDefinitionParser("monitor", new DubboBeanDefinitionParser(MonitorConfig.class, true)); registerBeanDefinitionParser("provider", new DubboBeanDefinitionParser(ProviderConfig.class, true)); registerBeanDefinitionParser("consumer", new DubboBeanDefinitionParser(ConsumerConfig.class, true)); registerBeanDefinitionParser("protocol", new DubboBeanDefinitionParser(ProtocolConfig.class, true)); registerBeanDefinitionParser("service", new DubboBeanDefinitionParser(ServiceBean.class, true)); registerBeanDefinitionParser("reference", new DubboBeanDefinitionParser(ReferenceBean.class, false)); registerBeanDefinitionParser("annotation", new DubboBeanDefinitionParser(AnnotationBean.class, true)); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过上面发现所有的标签元素都是通过registerBeanDefinitionParser注册，这个方法主要是将所有的标签对应的解析定义注入一个parsers这个Map 123protected final void registerBeanDefinitionParser(String elementName, BeanDefinitionParser parser) &#123; this.parsers.put(elementName, parser);&#125; #解析标签元素&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将所有dubbo的标签给装载之后，就是对具体的标签进行解析，首先展示一下解析逻辑,从这里可以看出来，它是根据具体的标签元素找到DubboBeanDefinitionParser这个实例,然后开始进行解析。 12345678910111213141516171819202122232425/** * Parse the elements at the root level in the document: * "import", "alias", "bean". * @param root the DOM root element of the document */protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; else &#123; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125;&#125; 123456789public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; String namespaceUri = getNamespaceURI(ele); NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error("Unable to locate Spring NamespaceHandler for XML schema namespace [" + namespaceUri + "]", ele); return null; &#125; return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));&#125; 1234@Overridepublic BeanDefinition parse(Element element, ParserContext parserContext) &#123; return findParserForElement(element, parserContext).parse(element, parserContext);&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意在这里将上面注册的beanClass给传入进去，所以在解析beanDefinition的时候就可以获取到这个标签的具体类实例 123public BeanDefinition parse(Element element, ParserContext parserContext) &#123; return parse(element, parserContext, beanClass, required);&#125;]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo源码分析2-远程接口暴露过程]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2FReferenceConfig%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在提供接口服务的过程，都是围绕着一行代码展开，如下:&lt;dubbo:reference interface=&quot;cfs.com.facade.SysUserFacade&quot; id=&quot;sysUserFacade&quot; /&gt; 获取相应ReferenceBean&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里我们先要获取的是相应的ReferenceFactoryBean具体过程在dubbo源码分析1-spring方式启动中,首先装载所有标签相应的 DubboNamespaceHandler.java 1registerBeanDefinitionParser("reference", new DubboBeanDefinitionParser(ReferenceBean.class, false)); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据DubboBeanDefinitionParser来解析，在loadBeanDefinitions中将所有的BeanDefinition解析出来生成形影的ReferenceBean DubboBeanDefinitionParser.java 1private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) &#123;&#125; 调用ReferenceBean的get方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于ReferenceBean继承ReferenceConfig，且自身没有覆盖get方法所以调用的是ReferenceConfig中. 123456789public synchronized T get() &#123; if (destroyed)&#123; throw new IllegalStateException("Already destroyed!"); &#125; if (ref == null) &#123; init(); &#125; return ref;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由上可以看出其核心方法是调用init 1.验证时候初始化，如果已经初始化直接返回2.保证接口名长度不为空或者03.配置消费者和提供者全局属性4.获取相应的接口全限定类名5.设置基础属性6.将属性添加到context_map这个静态map中去7.创建相应的代理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142 private void init() &#123; if (initialized) &#123; return; &#125; initialized = true; if (interfaceName == null || interfaceName.length() == 0) &#123; throw new IllegalStateException("&lt;dubbo:reference interface=\"\" /&gt; interface not allow null!"); &#125; // 获取消费者全局配置 checkDefault(); appendProperties(this); if (getGeneric() == null &amp;&amp; getConsumer() != null) &#123; setGeneric(getConsumer().getGeneric()); &#125; if (ProtocolUtils.isGeneric(getGeneric())) &#123; interfaceClass = GenericService.class; &#125; else &#123; try &#123; interfaceClass = Class.forName(interfaceName, true, Thread.currentThread() .getContextClassLoader());&#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e);&#125; checkInterfaceAndMethods(interfaceClass, methods); &#125; String resolve = System.getProperty(interfaceName); String resolveFile = null; if (resolve == null || resolve.length() == 0) &#123; resolveFile = System.getProperty("dubbo.resolve.file"); if (resolveFile == null || resolveFile.length() == 0) &#123; File userResolveFile = new File(new File(System.getProperty("user.home")), "dubbo-resolve.properties"); if (userResolveFile.exists()) &#123; resolveFile = userResolveFile.getAbsolutePath(); &#125; &#125; if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) &#123; Properties properties = new Properties(); FileInputStream fis = null; try &#123; fis = new FileInputStream(new File(resolveFile)); properties.load(fis); &#125; catch (IOException e) &#123; throw new IllegalStateException("Unload " + resolveFile + ", cause: " + e.getMessage(), e); &#125; finally &#123; try &#123; if(null != fis) fis.close(); &#125; catch (IOException e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; resolve = properties.getProperty(interfaceName); &#125; &#125; if (resolve != null &amp;&amp; resolve.length() &gt; 0) &#123; url = resolve; if (logger.isWarnEnabled()) &#123; if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) &#123; logger.warn("Using default dubbo resolve file " + resolveFile + " replace " + interfaceName + "" + resolve + " to p2p invoke remote service."); &#125; else &#123; logger.warn("Using -D" + interfaceName + "=" + resolve + " to p2p invoke remote service."); &#125; &#125; &#125; if (consumer != null) &#123; if (application == null) &#123; application = consumer.getApplication(); &#125; if (module == null) &#123; module = consumer.getModule(); &#125; if (registries == null) &#123; registries = consumer.getRegistries(); &#125; if (monitor == null) &#123; monitor = consumer.getMonitor(); &#125; &#125; if (module != null) &#123; if (registries == null) &#123; registries = module.getRegistries(); &#125; if (monitor == null) &#123; monitor = module.getMonitor(); &#125; &#125; if (application != null) &#123; if (registries == null) &#123; registries = application.getRegistries(); &#125; if (monitor == null) &#123; monitor = application.getMonitor(); &#125; &#125; checkApplication(); checkStubAndMock(interfaceClass); Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); Map&lt;Object, Object&gt; attributes = new HashMap&lt;Object, Object&gt;(); map.put(Constants.SIDE_KEY, Constants.CONSUMER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; if (! isGeneric()) &#123; String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put("revision", revision); &#125; String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if(methods.length == 0) &#123; logger.warn("NO method found in service interface " + interfaceClass.getName()); map.put("methods", Constants.ANY_VALUE); &#125; else &#123; map.put("methods", StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), ",")); &#125; &#125; map.put(Constants.INTERFACE_KEY, interfaceName); appendParameters(map, application); appendParameters(map, module); appendParameters(map, consumer, Constants.DEFAULT_KEY); appendParameters(map, this); String prifix = StringUtils.getServiceKey(map); if (methods != null &amp;&amp; methods.size() &gt; 0) &#123; for (MethodConfig method : methods) &#123; appendParameters(map, method, method.getName()); String retryKey = method.getName() + ".retry"; if (map.containsKey(retryKey)) &#123; String retryValue = map.remove(retryKey); if ("false".equals(retryValue)) &#123; map.put(method.getName() + ".retries", "0"); &#125; &#125; appendAttributes(attributes, method, prifix + "." + method.getName()); checkAndConvertImplicitConfig(method, map, attributes); &#125; &#125; //attributes通过系统context进行存储. StaticContext.getSystemContext().putAll(attributes); ref = createProxy(map); &#125; createProxy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个方式是init中的最后一步，创建相应的url 1.先判断是否是本地服务引用injvm 2.判断是否是点对点直连 3.判断是否是通过注册中心连接 4.然后是服务的引用]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo相关问题]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2F2017-12-29%2F</url>
    <content type="text"><![CDATA[The question of dubboQ1防火墙问题:关闭命令： service iptables stop永久关闭防火墙：chkconfig iptables off永久关闭需要两条语句都运行]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[druid分析]]></title>
    <url>%2F2017%2F01%2F02%2Fdruid%2F2017-12-30%2F</url>
    <content type="text"><![CDATA[The analysis of DruidInstancing DruidDataSourceDruidDataSource have two Constructor,and the one without any argument will invoke another by writing a argument, as follows At first, We find it will invoke super(fairLock),its default value is false by instancing the constructor without any argument , it wil call the superclass object and invoke the methods of configFromPropety to Set up relevant property values by getting System property values. Its superclass object constructor is shown below: In superclass object constructor,the instance create Creates an instance of ReentrantLock with the given unfairness policy. after that it will create Condition instance for use with this Lock instance. The returned Condition instance supports the same usages as do the Object monitor methods (wait, notify, and notifyAll) when used with the built-in monitor lock.]]></content>
      <categories>
        <category>druid</category>
      </categories>
      <tags>
        <tag>druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea上svn相关问题]]></title>
    <url>%2F2017%2F01%2F01%2Fother%2F2018-01-04%2F</url>
    <content type="text"><![CDATA[idea上不显示svn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IntelliJ IDEA打开带SVN信息的项目不显示SVN信息，项目右键SVN以及图标还有Changes都不显示解决方法在VCS菜单中有个开关，叫Enabled Version Control Integration，在打开的窗口的选项中选择Subversion即可 idea忽略某些文件更新]]></content>
      <categories>
        <category>idea</category>
      </categories>
      <tags>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven命令使用指南]]></title>
    <url>%2F2017%2F01%2F01%2Fmaven%2F2018-01-03%2F</url>
    <content type="text"><![CDATA[#基本命令 编译源代码: mvn compile编译测试代码：mvn test-compile运行测试：mvn test产生site：mvn site打包：mvn package -Dmaven.test.skip=true(跳过测试) #编译jar到本地仓库 mvn install:install-file -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4-1.7 -Dpackaging=jar -Dfile=dubbo-2.8.4.jar mvn install:install-file -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4-1.7 -Dpackaging=jar -Dfile=dubbo-2.8.4-sources.jar -Dclassifier=sources mvn install:install-file -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4-1.7 -Dpackaging=jar -Dfile=dubbo-2.8.4-javadoc.jar -Dclassifier=javadoc]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea相关问题]]></title>
    <url>%2F2017%2F01%2F01%2Fother%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[Q1源发行版 1.6 需要目标发行版 1.6 setting-&gt;Compiler-&gt;Java Compiler 设置相应Module的target byte code version的合适版本就行来（搜索首选项）]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven错误记录]]></title>
    <url>%2F2017%2F01%2F01%2Fmaven%2F2018-01-05%2F</url>
    <content type="text"><![CDATA[不能部署1Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.5: deploy (default-deploy) 这是在发布到私服的过程中，可能]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac切换jdk]]></title>
    <url>%2F2017%2F01%2F01%2Fother%2F2018-01-03%2F</url>
    <content type="text"><![CDATA[#切换jdk命令 切换版本： jenv use java 1.8设置缺少版本： jenv default java 1.8]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ofbiz模块加载机制即创建独立模块（脱离热部署)]]></title>
    <url>%2F2016%2F07%2F25%2Fofbiz%2Fofbiz13%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 一般我们在ofbiz下的hot-deploy下直接创建模块组件就可以进行访问，但是我觉得文件过多话，就不方便管理，所以我们可以分离出来单独建立一个文件模块，原理大家可以从启动类开始看，在这里我只说明一下操作步骤,因为好多东西我也没看懂呢。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一步：找到framework\base\config\component-load.xml这个文件，内容如下： 1234567891011121314151617&lt;component-loaderxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/component-loader.xsd&quot;&gt; &lt;load-components parent-directory=&quot;framework&quot;/&gt; &lt;load-components parent-directory=&quot;themes&quot;/&gt; &lt;load-components parent-directory=&quot;applications&quot;/&gt; &lt;load-components parent-directory=&quot;specialpurpose&quot;/&gt; &lt;load-components parent-directory=&quot;hot-deploy&quot;/&gt; &lt;load-components parent-directory=&quot;wuliys&quot;/&gt;&lt;/component-loader&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 很显然start类通过该文件属性，找到相应的子目录，如图所示： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当然这里的runtime和tools文件夹并没有加载进来，因为它们一个是运行，一个是工具存放的.而其它模块则加载进来了，文件夹是加载进来了，然后怎么进行具体操作.看第二步. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第二步:因为上面的除了最后一个都是系统存在的，所以我就拿自己创建的一个模块做例子讲述.，文件分级如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 我们先看看component-load.xml文件里面是什么(文件路径已经从同级开始往下哈哈)如下： 1234567891011&lt;?xmlversion=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;component-loaderxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/component-loader.xsd&quot;&gt; &lt;load-componentcomponent-location=&quot;mytest&quot;/&gt; &lt;load-componentcomponent-location=&quot;myparty&quot;/&gt; &lt;/component-loader&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 很显然就是通过load-component这一元素将mytest和myparty这两个文件加给加载进来。至于这两个模块就是我们能够写具体请求应用的模块。至于具体请求可以参考网上的热部署hello,world差不多]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz连接mysql并创建独立数据库]]></title>
    <url>%2F2016%2F07%2F24%2Fofbiz%2F2018-01-16%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ofbiz原生数据库是derby，而作为开发使用，其就不能满足我们需求，ofbiz支持多种数据库，我们就可以将数据移植到mysql. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第一步：找到framework\entity\config\entityengine.xml这个文件，找到之后进行下面相关操作 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1、添加或者修改datasource,因为该文件本身存在这些资料，只是被注释掉了. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171&lt;datasourcename=&quot;localmysql&quot; helper-class=&quot;org.ofbiz.entity.datasource.GenericHelperDAO&quot; field-type-name=&quot;mysql&quot; check-on-start=&quot;true&quot; add-missing-on-start=&quot;true&quot; check-pks-on-start=&quot;false&quot; use-foreign-keys=&quot;true&quot; join-style=&quot;ansi-no-parenthesis&quot; alias-view-columns=&quot;false&quot; drop-fk-use-foreign-key-keyword=&quot;true&quot; table-type=&quot;InnoDB&quot; character-set=&quot;utf8&quot; collate=&quot;utf8_general_ci&quot;&gt; &lt;read-data reader-name=&quot;tenant&quot;/&gt; &lt;read-data reader-name=&quot;seed&quot;/&gt; &lt;read-data reader-name=&quot;seed-initial&quot;/&gt; &lt;read-data reader-name=&quot;demo&quot;/&gt; &lt;read-data reader-name=&quot;ext&quot;/&gt; &lt;inline-jdbc jdbc-driver=&quot;com.mysql.jdbc.Driver&quot; jdbc-uri=&quot;jdbc:mysql://localhost:3306/ofbiz?autoReconnect=true&amp;characterEncoding=UTF-8&quot; jdbc-username=&quot;root&quot; jdbc-password=&quot;&quot; isolation-level=&quot;ReadCommitted&quot; pool-minsize=&quot;2&quot; pool-maxsize=&quot;250&quot; time-between-eviction-runs-millis=&quot;600000&quot;/&gt; &lt;/datasource&gt; &lt;datasource name=&quot;localmysqlolap&quot; helper-class=&quot;org.ofbiz.entity.datasource.GenericHelperDAO&quot; field-type-name=&quot;mysql&quot; check-on-start=&quot;true&quot; add-missing-on-start=&quot;true&quot; check-pks-on-start=&quot;false&quot; use-foreign-keys=&quot;true&quot; join-style=&quot;ansi-no-parenthesis&quot; alias-view-columns=&quot;false&quot; drop-fk-use-foreign-key-keyword=&quot;true&quot; table-type=&quot;InnoDB&quot; character-set=&quot;utf8&quot; collate=&quot;utf8_general_ci &quot;&gt; &lt;read-data reader-name=&quot;tenant&quot;/&gt; &lt;read-data reader-name=&quot;seed&quot;/&gt; &lt;read-data reader-name=&quot;seed-initial&quot;/&gt; &lt;read-data reader-name=&quot;demo&quot;/&gt; &lt;read-data reader-name=&quot;ext&quot;/&gt; &lt;inline-jdbc jdbc-driver=&quot;com.mysql.jdbc.Driver&quot; jdbc-uri=&quot;jdbc:mysql://localhost:3306/ofbizolap?autoReconnect=true&amp;characterEncoding=UTF-8&quot; jdbc-username=&quot;root&quot; jdbc-password=&quot;&quot; isolation-level=&quot;ReadCommitted&quot; pool-minsize=&quot;2&quot; pool-maxsize=&quot;250&quot; time-between-eviction-runs-millis=&quot;600000&quot;/&gt; &lt;/datasource&gt; &lt;datasource name=&quot;localmysqltenant&quot; helper-class=&quot;org.ofbiz.entity.datasource.GenericHelperDAO&quot; field-type-name=&quot;mysql&quot; check-on-start=&quot;true&quot; add-missing-on-start=&quot;true&quot; check-pks-on-start=&quot;false&quot; use-foreign-keys=&quot;true&quot; join-style=&quot;ansi-no-parenthesis&quot; alias-view-columns=&quot;false&quot; drop-fk-use-foreign-key-keyword=&quot;true&quot; table-type=&quot;InnoDB&quot; character-set=&quot;utf8&quot; collate=&quot;utf8_general_ci&quot;&gt; &lt;read-data reader-name=&quot;tenant&quot;/&gt; &lt;read-data reader-name=&quot;seed&quot;/&gt; &lt;read-data reader-name=&quot;seed-initial&quot;/&gt; &lt;read-data reader-name=&quot;demo&quot;/&gt; &lt;read-data reader-name=&quot;ext&quot;/&gt; &lt;inline-jdbc jdbc-driver=&quot;com.mysql.jdbc.Driver&quot; jdbc-uri=&quot;jdbc:mysql://localhost:3306/ofbiztenant?autoReconnect=true&amp;characterEncoding=UTF-8&quot; jdbc-username=&quot;root&quot; jdbc-password=&quot;&quot; isolation-level=&quot;ReadCommitted&quot; pool-minsize=&quot;2&quot; pool-maxsize=&quot;250&quot; time-between-eviction-runs-millis=&quot;600000&quot;/&gt; &lt;/datasource&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.还是在该文件添加一些内容，注意上面的datasource name=””与下面的datasource-name是对应的. 1234567891011121314151617181920212223242526272829303132333435&lt;delegator name=&quot;default&quot;entity-model-reader=&quot;main&quot; entity-group-reader=&quot;main&quot;entity-eca-reader=&quot;main&quot;distributed-cache-clear-enabled=&quot;false&quot;&gt; &lt;group-map group-name=&quot;org.ofbiz&quot;datasource-name=&quot;localmysql&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.olap&quot;datasource-name=&quot;localmysqlolap&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.tenant&quot; datasource-name=&quot;localmysqltenant&quot;/&gt; &lt;/delegator&gt; &lt;delegator name=&quot;default-no-eca&quot;entity-model-reader=&quot;main&quot; entity-group-reader=&quot;main&quot;entity-eca-reader=&quot;main&quot; entity-eca-enabled=&quot;false&quot;distributed-cache-clear-enabled=&quot;false&quot;&gt; &lt;group-mapgroup-name=&quot;org.ofbiz&quot; datasource-name=&quot;localmysql&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.olap&quot;datasource-name=&quot;localmysqlolap&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.tenant&quot;datasource-name=&quot;localmysqltenant&quot;/&gt; &lt;/delegator&gt; &lt;!-- be sure that your default delegator (or the one you use) usesthe same datasource for test. You must run &quot;ant load-demo&quot; beforerunning &quot;ant run-tests&quot; --&gt; &lt;delegator name=&quot;test&quot; entity-model-reader=&quot;main&quot;entity-group-reader=&quot;main&quot; entity-eca-reader=&quot;main&quot;&gt; &lt;group-mapgroup-name=&quot;org.ofbiz&quot; datasource-name=&quot;localmysql&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.olap&quot;datasource-name=&quot;localmysqlolap&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.tenant&quot; datasource-name=&quot;localmysqltenant&quot;/&gt;&lt;/delegator&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; datasource-name:就是配置1中对应的数据库名 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; group-name： :是用来进行分组辨识的，即可以将数据资料移植到不同的数据库 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 问题：可以一直为什么要创建三个数据库，一个不行？带着这个问题我们进行下面操作. 12345678910111213141516171819202122232425&lt;span style=&quot;font-size:14px;&quot;&gt;&lt;?xml version=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;entitygroup xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/entitygroup.xsd&quot;&gt; &lt;!-- ========================================================= --&gt; &lt;!-- org.ofbiz.entity.tenant --&gt; &lt;!-- ========================================================= --&gt; &lt;entity-group group=&quot;org.ofbiz.tenant&quot;entity=&quot;Tenant&quot;/&gt; &lt;entity-group group=&quot;org.ofbiz.tenant&quot;entity=&quot;TenantDataSource&quot;/&gt; &lt;entity-group group=&quot;org.ofbiz.tenant&quot;entity=&quot;Component&quot;/&gt; &lt;entity-group group=&quot;org.ofbiz.tenant&quot;entity=&quot;TenantComponent&quot;/&gt; &lt;entity-group group=&quot;org.ofbiz.tenant&quot;entity=&quot;TenantDomainName&quot;/&gt;&lt;/entitygroup&gt;&lt;/span&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 就是这个配置将Tenant等一些实体(数据库中的表，至于创建方式我就不在这里讲述了)分到org.ofbiz.tenant这个组名的数据库中即上面中第三个数据库，数据库名叫localmysqltenant.当然若没有这种配置，那么数据资料就会到默认数据库中，但是这里是项目自带，所以我们就需要这样一个数据库，同样的道理还有到另一个数据库中的资料，加上默认的，所以我们需要三个数据库. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 至于这些文件的加载在当前目下ofbiz-component.xml文件下，如下： 123&lt;entity-resource type=&quot;model&quot;reader-name=&quot;main&quot; loader=&quot;main&quot;location=&quot;entitydef/entitymodel.xml&quot;/&gt;&lt;entity-resourcetype=&quot;group&quot; reader-name=&quot;main&quot; loader=&quot;main&quot;location=&quot;entitydef/entitygroup.xml&quot;/&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 注意：framework/base/lib下需要导入mysql的包 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 上面就配置完成，然后我们在数据库创建对应的三个数据库名会跟上文中一一对应（注意编码一致），在启动的时候带参数load-data（如何代参运行，不知道的话，详情百度，嘻嘻） 下面我们独立创建一个数据库，来放我们自己的资料. 相应文件的位置： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第一步：在上文配置文件framework\entity\config\entityengine.xml下加入相应的配置，我的资料如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 &lt;datasourcename=&quot;test&quot; &lt;pre name=&quot;code&quot; class=&quot;html&quot;&gt; helper-class=&quot;org.ofbiz.entity.datasource.GenericHelperDAO&quot; field-type-name=&quot;mysql&quot; check-on-start=&quot;true&quot; add-missing-on-start=&quot;true&quot; check-pks-on-start=&quot;false&quot; use-foreign-keys=&quot;true&quot; join-style=&quot;ansi-no-parenthesis&quot; alias-view-columns=&quot;false&quot; drop-fk-use-foreign-key-keyword=&quot;true&quot; table-type=&quot;InnoDB&quot; character-set=&quot;utf8&quot; collate=&quot;utf8_general_ci&quot;&gt; &lt;read-data reader-name=&quot;tenant&quot;/&gt; &lt;read-data reader-name=&quot;seed&quot;/&gt; &lt;read-data reader-name=&quot;seed-initial&quot;/&gt; &lt;read-data reader-name=&quot;demo&quot;/&gt; &lt;read-data reader-name=&quot;ext&quot;/&gt; &lt;inline-jdbc jdbc-driver=&quot;com.mysql.jdbc.Driver&quot; jdbc-uri=&quot;jdbc:mysql://localhost:3306/wuliys?autoReconnect=true&amp;characterEncoding=UTF-8&quot; jdbc-username=&quot;root&quot; jdbc-password=&quot;&quot; isolation-level=&quot;ReadCommitted&quot; pool-minsize=&quot;2&quot; pool-maxsize=&quot;250&quot; time-between-eviction-runs-millis=&quot;600000&quot;/&gt; &lt;/datasource&gt; 1&lt;group-mapgroup-name=&quot;org.ofbiz.wuliys&quot; datasource-name=&quot;test&quot;/&gt; 至于这些资料所放位置与上文一一对应 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第二步:创建对应的数据库wuliys，并设置其编码为utf-8,字符集utf8_general_ci &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第三步:创建一个实体，文件路径\myparty\entitydef\entitymodel.xml，注意其可以是hot-deploy下的一个模块，也可以是你分离出来的一个模块.内容如下： 123456789101112131415161718192021&lt;entitymodelxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/entitymodel.xsd&quot;&gt; &lt;title&gt;Entity of anApache OFBiz Component&lt;/title&gt; &lt;description&gt;None&lt;/description&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;entityentity-name=&quot;Test&quot; package-name=&quot;wuliys&quot;&gt; &lt;field name=&quot;myId&quot; type=&quot;id-ne&quot;&gt;&lt;/field&gt; &lt;field name=&quot;myName&quot;type=&quot;id-ne&quot;&gt;&lt;/field&gt; &lt;prim-key field=&quot;myId&quot;/&gt; &lt;/entity&gt; &lt;/entitymodel&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第四步:将创建的实体引入到自己所想到的分组,文件路径: \myparty\entitydef\entitygroup.xml,内容如下： 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;entitygroupxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/entitygroup.xsd&quot;&gt;&lt;entity-group entity=&quot;Test&quot;group=&quot;org.ofbiz.wuliys&quot;/&gt;&lt;/entitygroup&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第五步:在该实体下创建一条数据，文件路径\myparty\data\testdata.xml，内容如下： 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;entity-engine-xml&gt; &lt;Test myName=&quot;jack&quot;&gt;&lt;/Test&gt; &lt;Test myName=&quot;zheng&quot;&gt;&lt;/Test&gt; &lt;/entity-engine-xml&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第六步:将这写配置文件在该模块的ofbiz-component.xml下加载，内容如下 12345678910111213141516171819202122232425&lt;?xmlversion=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;ofbiz-componentname=&quot;myparty&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/ofbiz-component.xsd&quot;&gt; &lt;resource-loader name=&quot;main&quot;type=&quot;component&quot;/&gt; &lt;entity-resource type=&quot;model&quot;reader-name=&quot;main&quot; loader=&quot;main&quot;location=&quot;entitydef/entitymodel.xml&quot;/&gt; &lt;entity-resource type=&quot;group&quot;reader-name=&quot;main&quot; loader=&quot;main&quot;location=&quot;entitydef/entitygroup.xml&quot;/&gt; &lt;entity-resourcetype=&quot;data&quot; reader-name=&quot;seed&quot; loader=&quot;main&quot;location=&quot;data/testdata.xml&quot;/&gt; &lt;webappname=&quot;myparty&quot; server=&quot;default-server&quot; location=&quot;webapp/myparty&quot; mount-point=&quot;/myparty&quot;&gt;&lt;/webapp&gt;&lt;/ofbiz-component&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 而后带参load-data启动一下，就在数据库相应位置创建好了自己的数据资料.]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
</search>
