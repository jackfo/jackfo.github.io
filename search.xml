<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ofbiz 任务调度处理策略]]></title>
    <url>%2F2018%2F02%2F17%2Fofbiz%2F2018-02-17%2F</url>
    <content type="text"><![CDATA[表相关设计 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; OFbiz中的任务调度是基于数据库实现的,共有四张表来实现,通过jobSandBox找到相关轮训信息以及运行数据： job_sandbox 计划任务作业沙盒recurrence_info 计划任务轮训信息recurrence_rule 计划任务轮训规则runtime_data 计划任务轮训依赖数据 状态活动图&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 上面展示的是活动切换图,每一个状态意义如下: SERVICE_PENDING 任务待执行,即生成的新任务 SERVICE_QUEUED 任务排队,这个是调用exec方法,将任务放入线程池执行前 SERVICE_RUNNING 任务正在执行,表示任务已放入线程池进行执行 SERVICE_PENDING 已经设置的任务取消 SERVICE_FINISHED 任务正常执行完毕的状态 SERVICE_FAILED 执行失败任务的状态 SERVICE_CRASHED 服务器出现意外重启时的状态,原先SERVICE_PENDING，SERVICE_QUEUED，SERVICE_RUNNING的任务都会设置为SERVICE_CRASHED,本会根据这些任务生成新的任务,状态都为SERVICE_CRASHED 类的关系图 源码解读JobManager实例化 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; JobManager顾名思义,任务管理器,其实例化过程在启动RMI容器中,实例化服务调度过程中,有一行代码this.jm = JobManager.getInstance(origDelegator, enableJM);首先会从registeredManagers这个映射中获取,在为空的状态下会NEW一个并通过registerJobManager方法将其注入JobPoller的jobManagers这个Map.注意在这个过程中,JobPoller中的类变量线程池句柄以及JobPoller会进行初始化。并且JobManager是以delegatorName为key存入到Map,这是考虑到多租户的情况,这也是为什么存在多个JobManager的原因,一个数据库Delegator维持一个任务调度管理器 线程池句柄初始化1234567891011121314private static final ThreadPoolExecutor executor = createThreadPoolExecutor(); private static ThreadPoolExecutor createThreadPoolExecutor() &#123; try &#123; //获取threadPool相关并创建线程池 ThreadPool threadPool = ServiceConfigUtil.getServiceEngine(ServiceConfigUtil.engine).getThreadPool(); return new ThreadPoolExecutor(threadPool.getMinThreads(), threadPool.getMaxThreads(), threadPool.getTtl(), TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(threadPool.getJobs()), new JobInvokerThreadFactory(), new ThreadPoolExecutor.AbortPolicy()); &#125; catch (GenericConfigException e) &#123; Debug.logError(e, "Exception thrown while getting &lt;thread-pool&gt; model, using default &lt;thread-pool&gt; values: ", module); return new ThreadPoolExecutor(ThreadPool.MIN_THREADS, ThreadPool.MAX_THREADS, ThreadPool.THREAD_TTL, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(ThreadPool.QUEUE_SIZE), new JobInvokerThreadFactory(), new ThreadPoolExecutor.AbortPolicy()); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 针对于在上面添加jobManager的时候,调用了JobPoller的静态方法,这时类变量就会进行初始化,创建线程池,在这个过程中会注入threadPool的基本属性(从serverengine.xml中thread=pool标签解析的参数),在这里要注意这个线程池的工厂是自实现JobInvokerThreadFactory,其中创建线程方式如下: 123public Thread newThread(Runnable runnable) &#123; return new Thread(runnable, "OFBiz-JobQueue-" + created.getAndIncrement());&#125; JobPoller句柄实例化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这个是比较关键的一步,它会实例化JobPoller,代码如下: 12345678910private JobPoller() &#123; if (pollEnabled()) &#123; jobManagerPollerThread = new Thread(new JobManagerPoller(), "OFBiz-JobPoller"); jobManagerPollerThread.setDaemon(false); jobManagerPollerThread.start(); &#125; else &#123; jobManagerPollerThread = null; &#125; ServiceConfigUtil.registerServiceConfigListener(this); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个过程中很容易发现其创建了JobManagerPoller线程并启动 JobManagerPoller线程run方法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先确保线程池队列容量大于0,然后遍历所有JobManager（一个数据库对应一个,首先调用reloadCrashedJobs方法,这个方法的作用是,服务器启动之后,首次才会执行,会找出数据库中以前未执行完且有效的任务。设置它们状态为SERVICE_CRASHED并取消,然后依据这些任务生成新的任务。之后将所有任务通过JobManager的poll方法扫描相应JobSandBox实体中需要执行的任务,添加到pollResults集合,然后迭代到queueCandidates集合,并通过queueNow来执行任务,代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private class JobManagerPoller implements Runnable &#123; @Override public void run() &#123; Debug.logInfo("JobPoller thread started.", module); try &#123; while (Start.getInstance().getCurrentState() != Start.ServerState.RUNNING) &#123; Thread.sleep(1000); &#125; //线程池没有关闭则一直进行循环 while (!executor.isShutdown()) &#123; //获取线程池中队列剩余容量 int remainingCapacity = executor.getQueue().remainingCapacity(); if (remainingCapacity &gt; 0) &#123; //获取所有JobManager Collection&lt;JobManager&gt; jmCollection = jobManagers.values(); List&lt;Iterator&lt;Job&gt;&gt; pollResults = new ArrayList&lt;Iterator&lt;Job&gt;&gt;(); for (JobManager jm : jmCollection) &#123; if (!jm.isAvailable()) &#123; if (Debug.infoOn())&#123; Debug.logInfo("The job manager is locked.", module); &#125; continue; &#125; //验证服务器是否刚启动,如果刚启动则需要查找出所有先前未执行完毕的任务,设置状态为SERVICE_CRASHED 并生成新执行的任务 jm.reloadCrashedJobs(); pollResults.add(jm.poll(remainingCapacity).iterator()); &#125; //将所有Job添加到queueCandidates List&lt;Job&gt; queueCandidates = new ArrayList&lt;Job&gt;(); boolean addingJobs = true; while (addingJobs) &#123; addingJobs = false; for (Iterator&lt;Job&gt; jobIterator : pollResults) &#123; if (jobIterator.hasNext()) &#123; queueCandidates.add(jobIterator.next()); addingJobs = true; &#125; &#125; &#125; /**将job方法线程池中进行执行*/ for (Job job : queueCandidates) &#123; try &#123; queueNow(job); &#125; catch (InvalidJobException e) &#123; Debug.logError(e, module); &#125; &#125; &#125; //睡眠线程池等待时间 Thread.sleep(pollWaitTime()); &#125; &#125; catch (InterruptedException e) &#123; // Happens when JobPoller shuts down - nothing to do. Thread.currentThread().interrupt(); &#125; Debug.logInfo("JobPoller thread stopped.", module); &#125; &#125; reloadCrashedJob方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public synchronized void reloadCrashedJobs() &#123; assertIsRunning(); if (crashedJobsReloaded) &#123; return; &#125; List&lt;GenericValue&gt; crashed = null; //查询条件 statusId == SERVICE_PENDING or statusId ==SERVICE_QUEUED or statusId==SERVICE_RUNNING List&lt;EntityExpr&gt; statusExprList = UtilMisc.toList(EntityCondition.makeCondition("statusId", EntityOperator.EQUALS, "SERVICE_PENDING"), EntityCondition.makeCondition("statusId", EntityOperator.EQUALS, "SERVICE_QUEUED"), EntityCondition.makeCondition("statusId", EntityOperator.EQUALS, "SERVICE_RUNNING")); EntityCondition statusCondition = EntityCondition.makeCondition(statusExprList, EntityOperator.OR); EntityCondition mainCondition = EntityCondition.makeCondition(UtilMisc.toList(EntityCondition.makeCondition("runByInstanceId", instanceId), statusCondition)); try &#123; crashed = EntityQuery.use(delegator).from("JobSandbox").where(mainCondition).orderBy("startDateTime").queryList(); &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, "Unable to load crashed jobs", module); &#125; if (UtilValidate.isNotEmpty(crashed)) &#123; int rescheduled = 0; //获取当前时间戳 Timestamp now = UtilDateTime.nowTimestamp(); for (GenericValue job : crashed) &#123; try &#123; if (Debug.infoOn()) &#123; Debug.logInfo("Scheduling Job : " + job, module); &#125; //获取父任务标识 如果为空则设置当前任务标识jobId为pJobId String pJobId = job.getString("parentJobId"); if (pJobId == null) &#123; pJobId = job.getString("jobId"); &#125; GenericValue newJob = GenericValue.create(job); //设置状态为待进行 newJob.set("statusId", "SERVICE_PENDING"); //设置运行时间为现在 newJob.set("runTime", now); //设置先前任务标识Id newJob.set("previousJobId", job.getString("jobId")); newJob.set("parentJobId", pJobId); newJob.set("startDateTime", null); newJob.set("runByInstanceId", null); //don't set a recurrent schedule on the new job, run it just one time newJob.set("tempExprId", null); newJob.set("recurrenceInfoId", null); //根据job创建一个新任务,新任务主要previousJobId为job的id parentJobId为job父id delegator.createSetNextSeqId(newJob); // set the cancel time on the old job to the same as the re-schedule time job.set("statusId", "SERVICE_CRASHED"); job.set("cancelDateTime", now); delegator.store(job); rescheduled++; &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, module); &#125; &#125; if (Debug.infoOn())&#123; Debug.logInfo("-- " + rescheduled + " jobs re-scheduled", module); &#125; &#125; else &#123; if (Debug.infoOn())&#123; Debug.logInfo("No crashed jobs to re-schedule", module); &#125; &#125; crashedJobsReloaded = true; &#125; jm.poll123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146/** * 扫描JobSandbox实体,并返回一个任务运行的列表。如果没有运行工作返回一个空列表。由JobPoller轮询线程调用此方法 * 。 * 主要查出的任务是runTime&lt;当前系统时间 startDateTime、cancelDateTime、runByInstanceId为空或者带当前服务器poolId或者pollId为空 * 最终生成PersistedServiceJob添加到poll * * 如果poll为空则finishDateTime不为空并且小于当前时间 或者cancelDateTime不为空并且小于当前时间的JobSandBox */ protected List&lt;Job&gt; poll(int limit) &#123; //检测是否还在运行 assertIsRunning(); //返回调度器上下文 DispatchContext dctx = getDispatcher().getDispatchContext(); if (dctx == null) &#123; Debug.logWarning("Unable to locate DispatchContext object; not running job!", module); return Collections.emptyList(); &#125; // 构造查询条件 runTime&lt;当前系统时间 startDateTime、cancelDateTime、runByInstanceId为空 List&lt;EntityExpr&gt; expressions = UtilMisc.toList(EntityCondition.makeCondition("runTime", EntityOperator.LESS_THAN_EQUAL_TO, UtilDateTime.nowTimestamp()), EntityCondition.makeCondition("startDateTime", EntityOperator.EQUALS, null), EntityCondition.makeCondition("cancelDateTime", EntityOperator.EQUALS, null), EntityCondition.makeCondition("runByInstanceId", EntityOperator.EQUALS, null)); // limit to just defined pools List&lt;String&gt; pools = null; try &#123; //获取配置文件中的thread-pool下runFromPools的name构成集合 pools = getRunPools(); &#125; catch (GenericConfigException e) &#123; Debug.logWarning(e, "Unable to get run pools - not running job: ", module); return Collections.emptyList(); &#125; //构造条件poolId为空或者是当前 List&lt;EntityExpr&gt; poolsExpr = UtilMisc.toList(EntityCondition.makeCondition("poolId", EntityOperator.EQUALS, null)); if (!pools.isEmpty()) &#123; for (String poolName : pools) &#123; poolsExpr.add(EntityCondition.makeCondition("poolId", EntityOperator.EQUALS, poolName)); &#125; &#125; List&lt;Job&gt; poll = new ArrayList&lt;Job&gt;(limit); // 生成条件 查询runTime小于当前时间的runByInstanceId为空或者poolId为当前服务器中runFromPools的name值得作业 EntityCondition baseCondition = EntityCondition.makeCondition(expressions); EntityCondition poolCondition = EntityCondition.makeCondition(poolsExpr, EntityOperator.OR); EntityCondition mainCondition = EntityCondition.makeCondition(UtilMisc.toList(baseCondition, poolCondition)); EntityListIterator jobsIterator = null; boolean beganTransaction = false; try &#123; beganTransaction = TransactionUtil.begin(); if (!beganTransaction) &#123; Debug.logWarning("Unable to poll JobSandbox for jobs; unable to begin transaction.", module); return poll; &#125; //查询JobSandbox中已经运行了的任务 jobsIterator = EntityQuery.use(delegator).from("JobSandbox").where(mainCondition).orderBy("runTime").queryIterator(); GenericValue jobValue = jobsIterator.next(); while (jobValue != null) &#123; //构造查询条件jobId = jobValue的标识 List&lt;EntityExpr&gt; updateExpression = UtilMisc.toList(EntityCondition.makeCondition("jobId", EntityOperator.EQUALS, jobValue.get("jobId")), EntityCondition.makeCondition("runByInstanceId", EntityOperator.EQUALS, null)); //修改runByInstanceId为当前实例instanceId 并添加PersistedServiceJob实例,这是因为存在任务开始并没有指定runByInstanceId int rowsUpdated = delegator.storeByCondition("JobSandbox", UtilMisc.toMap("runByInstanceId", instanceId), EntityCondition.makeCondition(updateExpression)); if (rowsUpdated == 1) &#123; poll.add(new PersistedServiceJob(dctx, jobValue, null)); //如果poll超过限制 跳出 if (poll.size() == limit) &#123; break; &#125; &#125; jobValue = jobsIterator.next(); &#125; TransactionUtil.commit(beganTransaction); &#125; catch (Throwable t) &#123; String errMsg = "Exception thrown while polling JobSandbox: "; try &#123; TransactionUtil.rollback(beganTransaction, errMsg, t); &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, "Exception thrown while rolling back transaction: ", module); &#125; Debug.logWarning(t, errMsg, module); return Collections.emptyList(); &#125; finally &#123; if (jobsIterator != null) &#123; try &#123; jobsIterator.close(); &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, module); &#125; &#125; &#125; if (poll.isEmpty()) &#123; //获取Calendar实例 Calendar cal = Calendar.getInstance(); try &#123; int daysToKeep = ServiceConfigUtil.getServiceEngine().getThreadPool().getPurgeJobDays(); cal.add(Calendar.DAY_OF_YEAR, -daysToKeep); &#125; catch (GenericConfigException e) &#123; Debug.logWarning(e, "Unable to get purge job days: ", module); return Collections.emptyList(); &#125; //构造条件finishDateTime不为空并且小于当前时间 或者cancelDateTime不为空并且小于当前时间 Timestamp purgeTime = new Timestamp(cal.getTimeInMillis()); List&lt;EntityExpr&gt; finExp = UtilMisc.toList(EntityCondition.makeCondition("finishDateTime", EntityOperator.NOT_EQUAL, null), EntityCondition.makeCondition("finishDateTime", EntityOperator.LESS_THAN, purgeTime)); List&lt;EntityExpr&gt; canExp = UtilMisc.toList(EntityCondition.makeCondition("cancelDateTime", EntityOperator.NOT_EQUAL, null), EntityCondition.makeCondition("cancelDateTime", EntityOperator.LESS_THAN, purgeTime)); EntityCondition doneCond = EntityCondition.makeCondition(UtilMisc.toList(EntityCondition.makeCondition(canExp), EntityCondition.makeCondition(finExp)), EntityOperator.OR); mainCondition = EntityCondition.makeCondition(UtilMisc.toList(EntityCondition.makeCondition("runByInstanceId", instanceId), doneCond)); beganTransaction = false; jobsIterator = null; try &#123; beganTransaction = TransactionUtil.begin(); if (!beganTransaction) &#123; Debug.logWarning("Unable to poll JobSandbox for jobs; unable to begin transaction.", module); return Collections.emptyList(); &#125; //查找已完成的JOB以及取消的任务 构建相应的PurgeJob jobsIterator = EntityQuery.use(delegator).from("JobSandbox").where(mainCondition).orderBy("jobId").queryIterator(); GenericValue jobValue = jobsIterator.next(); while (jobValue != null) &#123; poll.add(new PurgeJob(jobValue)); if (poll.size() == limit) &#123; break; &#125; jobValue = jobsIterator.next(); &#125; TransactionUtil.commit(beganTransaction); &#125; catch (Throwable t) &#123; String errMsg = "Exception thrown while polling JobSandbox: "; try &#123; TransactionUtil.rollback(beganTransaction, errMsg, t); &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, "Exception thrown while rolling back transaction: ", module); &#125; Debug.logWarning(t, errMsg, module); return Collections.emptyList(); &#125; finally &#123; if (jobsIterator != null) &#123; try &#123; jobsIterator.close(); &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, module); &#125; &#125; &#125; &#125; return poll; &#125; queueNow(job)12345678910public void queueNow(Job job) throws InvalidJobException &#123; //主要是修改数据库记录状态,设置任务状态为SERVICE_QUEUED标识正在进行 job.queue(); try &#123; executor.execute(job); &#125; catch (Exception e) &#123; //出现异常则设置状态为SERVICE_PENDING 并置空开始时间 job.deQueue(); &#125; &#125; PersistedServiceJob的执行 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PersistedServiceJob最终继承的是Runnable，在线程池中执行的过程中,最终调用AbstractJob的run方法来执行exec,这是一种模板方法,最终调用子类方法，在这个过程继续初始化生成下一次要执行的任务,然后执行当前任务,如果执行成功则设置完成状态,如果为执行成功,修改当前Job实体状态,供下一次执行。具体代码太长,就不做展示。 PurgeJob的执行123456789101112131415161718192021222324252627282930313233343536/** * 清除关于JobSandbox无用RecurrenceInfo和RuntimeData信息 * */ @Override public void exec() throws InvalidJobException &#123; if (currentState != State.QUEUED) &#123; throw new InvalidJobException("Illegal state change"); &#125; currentState = State.RUNNING; try &#123; // TODO: This might need to be in a transaction - to avoid the possibility of // leaving orphaned related values. jobValue.remove(); //根据JOB获取相关轮训信息 GenericValue relatedValue = jobValue.getRelatedOne("RecurrenceInfo", false); //获取该轮训信息下面所有的JOB 如果为空则移除这一轮训信息 if (relatedValue != null) &#123; List&lt;GenericValue&gt; valueList = relatedValue.getRelated("JobSandbox", null, null, false); if (valueList.isEmpty()) &#123; relatedValue.remove(); relatedValue.removeRelated("RecurrenceRule"); &#125; &#125; //获取相关的运行数据 relatedValue = jobValue.getRelatedOne("RuntimeData", false); if (relatedValue != null) &#123; List&lt;GenericValue&gt; valueList = relatedValue.getRelated("JobSandbox", null, null, false); if (valueList.isEmpty()) &#123; relatedValue.remove(); &#125; &#125; Debug.logInfo("Purged job " + getJobId(), module); &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, "Exception thrown while purging job: ", module); &#125; &#125; 任务调度的使用方法一:在webtools中进行调用,注意任务,一般调用的是服务 方法二: 12345678910111213141516171819202122232425/** * 在一个具体的开始时间运行异步调度服务 * @param poolName service pool的名字 * @param serviceName 调用服务名 * @param context 上下文 * @param startTime 服务开始时间 * @param frequency 服务执行频率 * @param interval 执行间隔 配合frequency 使用 ， frequency 为单位 ， interval 为数量 ，联合起来其 XX天/次（XX天执行一次） 、XX小时/次（XX小时执行一次） * @param count 执行次数 。 最大执行次数，当执行次数达到这个值时就不在执行了 。 如果设置-1 即不限次 * @param endTime 执行结束时间，一般用在count 为-1 的时候 * @param maxRetry 失败后重复执行次数 * @throws ServiceAuthException * @throws ServiceValidationException * @throws GenericServiceException */void schedule(String poolName, String serviceName, Map&lt;String, ? extends Object&gt; context, long startTime, int frequency, int interval, int count, long endTime, int maxRetry) throws GenericServiceException;void schedule(String poolName, String serviceName, long startTime, int frequency, int interval, int count, long endTime, int maxRetry, Object... context) throws GenericServiceException; void schedule(String serviceName, Map&lt;String, ? extends Object&gt; context, long startTime, int frequency, int interval, int count, long endTime) throws GenericServiceException;void schedule(String serviceName, long startTime, int frequency, int interval, int count, long endTime, Object... context) throws GenericServiceException;void schedule(String serviceName, Map&lt;String, ? extends Object&gt; context, long startTime, int frequency, int interval, int count) throws GenericServiceException;void schedule(String serviceName, long startTime, int frequency, int interval, int count, Object... context) throws GenericServiceException;void schedule(String serviceName, Map&lt;String, ? extends Object&gt; context, long startTime, int frequency, int interval, long endTime) throws GenericServiceException;void schedule(String serviceName, long startTime, int frequency, int interval, long endTime, Object... context) throws GenericServiceException;void schedule(String serviceName, Map&lt;String, ? extends Object&gt; context, long startTime) throws GenericServiceException;void schedule(String serviceName, long startTime, Object... context) throws GenericServiceException;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Future模式源码解读]]></title>
    <url>%2F2018%2F02%2F10%2FJdk%2F2018-02-10%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Future模式是将处理过程交给其它线程处理,主线程通过get()方法中返回。这样的好处时,在这个过程主线程可以做其它事情,从而提高效率,在框架启动过程中,加载数据库信息这块比较常用,将这个过程用其它线程启动,主线程继续加载框架其它部分信息,当我们需要操作数据库时只需要通过get()方法获取其他线程中数据库相应句柄就可以进行相关操作。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 现在我们对这部分的源码做一个大致解读,在解读之前首先需要了解线程池相关知识,这里在网上看到很好的关于线程池源码解读https://fangjian0423.github.io/2016/03/22/java-threadpool-analysis/ 如果对线程池已经有了解,那么我们开始吧。 类的关系图 Future模式的使用12345678910111213141516171819202122232425class Task implements Callable&lt;Integer&gt; &#123; private int a,b; public Task(int a, int b) &#123; this.a = a; this.b = b; &#125; @Override public Integer call() throws Exception &#123; Integer result = a + b; return result; &#125;&#125;public class FutureDemo &#123; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; ExecutorService executor = Executors.newSingleThreadExecutor(); //JDK目前为止返回的都是FutureTask的实例 Future&lt;Integer&gt; future = executor.submit(new Task(1, 2)); Integer result = future.get(); System.out.print("输出结果："+result); &#125;&#125; result: 1输出结果：3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在上面构建了一个Task,实现了Callable接口,这个接口和Runnable接口的主要区别是它具有返回结果,并且只能通过线程池的方式进行处理,Thread不能对它进行处理。现在我们将Task通过submit提交给线程池,这样就可以根据返回Future实例调用get方法获取相关处理结果,如果没有获取到处理结果就会进行阻塞。现在我们从submit开始进行分析 任务提交&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主要是对executor.submit(new Task(1, 2));代码如下: 123456789101112131415161718public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask; &#125; public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; /** * Sets this Future to the result of its computation * unless it has been cancelled. */ void run();&#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从代码可以看出,我们将Callable（对应任务）封装到RunnableFuture接口的实现类FutureTask,然后开始执行,返回的是ftask,RunnableFuture接口继承了Runnable所以可以看出在execute是调用的是ftask的run方法。现在看FutureTask具体run方法。 12345678910111213141516171819202122232425262728293031323334353637383940public void run() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); &#125; if (ran) set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125; protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state finishCompletion(); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; run方法就是在新开启的线程中执行,最终在这里获取封装的Callable并调用c.call,将结果赋值给result并调用 set(result);将结果注入outcome句柄并利用cas来修改状态。finishCompletion方法在获取结果的时候进行描述 获取结果123456789101112131415public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s); &#125; private V report(int s) throws ExecutionException &#123; Object x = outcome; if (s == NORMAL) return (V)x; if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;判断任务当前的state &lt;= COMPLETING是否成立。如果成立，表明任务还没有结束(这里的结束包括任务正常执行完毕，任务执行异常，任务被取消)，则会调用awaitDone()进行阻塞等待。如果不成立表明任务已经结束，调用report()返回结果。 123456789101112131415161718192021222324252627282930313233343536private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; LockSupport.parkNanos(this, nanos); &#125; else LockSupport.park(this); &#125; &#125; 1.判断调用get()的线程是否被其他线程中断，如果是的话则在等待队列中删除对应节点然后抛出InterruptedException异常。 2.获取任务当前状态，如果当前任务状态大于COMPLETING则表示任务执行完成，则把thread字段置null并返回结果。 3.如果任务处于COMPLETING状态，则表示任务已经处理完成(正常执行完成或者执行出现异常)，但是执行结果或者异常原因还没有保存到outcome字段中。这个时候调用线程让出执行权让其他线程优先执行。 4.如果等待节点为空，则构造一个等待节点WaitNode。WaitNode里面具有当前线程句柄,为了让后面可以进行唤醒。 5。如果第四步中新建的节点还没如队列，则CAS的把该节点加入waiters队列的首节点。 6.阻塞等待。 如果我们阻塞之后,我们该怎么处理呢，这就是finishCompletion方法的作用 123456789101112131415161718192021222324private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; done(); callable = null; // to reduce footprint &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;依次遍历waiters链表，唤醒节点中的线程，然后把callable置空。被唤醒的线程会各自从awaitDone()方法中的LockSupport.park*()阻塞中返回，然后会进行新一轮的循环。在新一轮的循环中会返回执行结果(或者更确切的说是返回任务的状态)。]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 锁的分析]]></title>
    <url>%2F2018%2F02%2F08%2FJdk%2F2018-02-08%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;锁存在的意义是,当一个线程获取资源对其它线程的相关控制,从系统角度分为独占锁和共享锁两种,从程序员角度分为悲观锁和乐观锁 独占锁:每次只能有一个线程能持有锁，ReentrantLock就是以独占方式实现的互斥锁 主要有synchronized ReentrantLock 共享锁:共享锁，则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock 在读的时候可以实现多个线程同时访问 悲观锁:悲观锁就是认为并发时一定会有冲突发生，采用加锁的方式,独占锁和共享锁 乐观锁:乐观锁是假设并发时不会有冲突发生，如果发生冲突，则操作失败，并不断重试。乐观锁的机制就是CAS(Compare and Swap) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以上对几种锁作了简单描述,在这里有一种处理方式没有归在上面,即信号量,它的目的可以设置一个初始值,当获取资源的线程数达到这个值之后才会进行阻塞。当然在这里我主要是对独占锁ReentrantLock来进行分析,对于这种处理方式理解了,对共享锁理解也很轻松。 ReentrantLock的类图 ReentrantLock的使用方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class LockDemo &#123; static class LockClass&#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void await() &#123; try &#123; lock.lock(); System.out.println("await时间为：" + System.currentTimeMillis()); condition.await(); System.out.println("await等待结束"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void signal() &#123; try &#123; lock.lock(); System.out.println("signal时间为：" + System.currentTimeMillis()); condition.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; LockClass lockClass = new LockClass(); Thread awaitThread = new Thread(new Runnable() &#123; @Override public void run() &#123; lockClass.await(); &#125; &#125;); Thread signalThread = new Thread(new Runnable() &#123; @Override public void run() &#123; lockClass.signal(); &#125; &#125;); awaitThread.start(); Thread.sleep(1000); signalThread.start(); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在活动图中展示了处理过程,在这个过程中阻塞的先决条件是获取锁,并且在调用await的时候会释放当前线程的锁,之后线程2才能够获取临界资源,然后在里面调用signAll之后唤醒等待队列里面的线程,在线程2释放锁之后,阻塞线程1才会继续执行。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在通过以下过程进行分析： 线程1获取锁-&gt;线程1等待-&gt;线程2获取锁-&gt;线程2唤醒-&gt;线程2释放锁&gt;-&gt;线程1解除等待状态 对象实例化 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;锁进行相关操作的先决条件是实例化Lock和Condition两个对象。在这里是实例方式先通过new ReentrantLock()获取互斥锁并且在里面根据传入参数若为true,则会在其内部实现公平锁,反之则为非公平锁(接下来过程主要以非公平锁进行实现)。之后就是获取condition,在这里通过lock.newConditionl来利用sync句柄创建ConditionObject实例。 线程1获取锁 &nbsp;&nbsp;&nbsp;&nbsp;加锁的就一行代码lock.lock();主要通过Sync句柄调用真实加锁方法,利用CAS操作方式比较state如果状态为0则写入1并将当前线程设置成锁持有的线程。如果state不为0,表示有的线程已经获取了,在这个过程中就需要尝试获取,下面针对于非公平锁的实现方法。 123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125; 1.获取当前线程，以及AQS的状态 2.如果当前AQS的状态为0的话，那么说明当前的锁没有被任何线程获取，则尝试做一次CAS操作，将当前的状态设置成acquires，如果设置成功了的话，那么则将当前线程设置成锁持有的线程，并且返回true，表示获取成功。 3.如果当前的状态不为0的话，说明已经有线程持有锁，则判断当前线程与持有锁的线程是否相同，如果相同的话，则将当前的状态加上acquires重新将状态设置，并且返回true，这也就是重入锁的原因。 4.如果当前线程没有获取到锁的话，那么就会返回false，表示获取锁失败 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里为真有两种情况： 1.锁没有被线程获取 2.锁被当前线程获取,这也是该锁为重入锁的原因,如在临界区获取其它方法的锁。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面代码是没有获取到锁之后的处理方式 123456789101112131415161718192021222324252627282930313233343536373839404142 public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125; final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addWaiter方法则会新建一个Node，然后将节点添加到队列中，让这个节点成为 tail。具体实现过程是如果该节点通过cas方式插入成功,则直接返回节点,否则调用enq（node）将当前节点添加到队列尾部。(第一次插入肯定会调用,因为初始化过程在里面) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在acquireQueued()中，当前线程会等待它在“CLH队列”中前面的所有线程执行并释放锁之后，才能获取锁并返回。如果“当前线程”在休眠等待过程中被中断过，则调用selfInterrupt()来自己产生一个中断。线程就是在这里不断尝试获取锁。 1.进入这个方法后，可以看到会进入一个死循环，这个死循环中，只有当p == head &amp;&amp; tryAcquire(arg)才会返回，这个条件代表的是，只有当当前节点的前驱是头节点，并且已经成功获取锁了，才会将当前的节点设置成头节点，并且前节点的next设置成空帮助GC回收，并且将failed标记成失败，并且返回当前线程是否被中断了。 2.如果当前节点的前驱不是头节点的话，那么则会判断当前线程在获取锁失败后， 是否需要阻塞，如果需要阻塞的话，就会调用parkAndCheckInterrupt方法进行当前线程的阻塞，并且在线程唤醒后，返回是否当前线程已经中断。这样处理的原因是因为在唤醒过程中是从首节点开始,如果前面还有节点处于signal,那么现在是不可能获取锁的,此时parkAndCheckInterrupt会把当前线程挂起，从而阻塞住线程的调用栈 线程1 await等待123456789101112131415161718public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; 1.await方法是及时响应中断的。它首先检查了一下中断标志。然后调用addConditionWaiter将当前线程放入Condition队列的尾，并顺手清理了一下队列里的无用节点 2.调用fullyRelease方法释放当前线程持有的锁,首先获取了state的值，这个值表示可锁被“重入”深度，并调用release释放全部的重入获取，如果成功，返回这个深度，如果失败，要将当前线程的waitStatus设置为CANCELLED。状态清除是首先获取状态，然后在通过release传入,之后再获取一次进行相减。 3.循环检测线程的状态，直到线程被signal或者中断唤醒且被放入Sync锁等待队列。如果中断发生的话，还需要调用checkInterruptWhileWaiting方法，根据中断发生的时机确定后去处理这次中断的方式，如果发生中断，退出while循环。 4.退出while循环后，我们调用acquireQueued方法来获取锁也就是这里说明等待线程被唤醒之后还要等待释放锁才行 线程2获取锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在线程1进入等待之后线程2就可以获取相关的锁,具体过程同线程1获取差不多 线程2唤醒&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;线程2唤醒指的是通过该操作唤醒其它阻塞线程,具体代码是condition.signal(); 1234567public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先验证是否是当前线程获取独占锁,如果是则调用doSignal来进行唤醒操作。 12345678private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将first节点从队列中摘下，然后调用transferForSignal去改变first节点的waitStatus（所谓唤醒线程），这个方法有可能失败，因为等待线程可能已经到时或者被中断，因此while循环这个操作直到成功唤醒或队列为空，如果if判断为真证明没有阻塞节点则跳出循环。 12345678910111213141516171819final boolean transferForSignal(Node node) &#123; /* * If cannot change waitStatus, the node has been cancelled. */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ Node p = enq(node); int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;方法首先调用CAS操作修改node的waitStatus，如果失败，表示线程已经放弃等待（到时或被中断），直接返回false。如果成功，调用enq方法将它放入Sync锁等待队列，返回值p是node在Sync队列中的前驱节点。紧接着检测一下前驱p的waitStatus，如果发现不为SIGNAL，需要将node持有的线程（注意不是当前线程）unpark，这里必须搞清楚，node线程是在哪里park的，显然，他还在await方法的那个while循环里。unpark之后，node线程将会从while循环中退出，然后去调用acquireQueued方法，这个方法是一个自旋，弄得线程会在自旋过程中清除已经为CANCELLED状态的前驱，然后注册前驱节点的waitStatus为SIGNAL。 #之后操作 线程2释放锁之后,线程1就会尝试获取锁然后继续进行下面相关操作]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于阿里凑单算法Graph Embedding思考]]></title>
    <url>%2F2018%2F02%2F02%2Fjava%2F2018-02-02%2F</url>
    <content type="text"><![CDATA[阿里凑单业务分析功能名称:商品推荐页 凑单的重要场景是当用户已经加购了商品A，还想找一个能一起打包买的商品B 处理方式:利用图的相关算法 设计表：订单表 订单-商品关系表 商品表 读取订单关系表中的数据针对商品构建邻接表(这个队列可以采用优先队列,重新实现compareTo方法即可)两个商品在订单条目上出现一次则权值+1,然后查找当前商品标识上的优先队列 获取靠前的元素]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ASM使用的相关DEMO]]></title>
    <url>%2F2018%2F02%2F01%2Fasm%2F2018-02-25%2F</url>
    <content type="text"><![CDATA[对字节码添加方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181public class Adapt extends ClassLoader &#123; @Override protected synchronized Class&lt;?&gt; loadClass(final String name, final boolean resolve) throws ClassNotFoundException &#123; if (name.startsWith("java.")) &#123; System.err.println("Adapt: loading class '" + name + "' without on the fly adaptation"); return super.loadClass(name, resolve); &#125; else &#123; System.err.println("Adapt: loading class '" + name + "' with on the fly adaptation"); &#125; // 获取class的文件流 String resource = name.replace('.', '/') + ".class"; InputStream is = getResourceAsStream(resource); byte[] b; // adapts the class on the fly try &#123; //字节码的读取与分析引擎 ClassReader cr = new ClassReader(is); //它实现了ClassVisitor接口，用于拼接字节码。 ClassWriter cw = new ClassWriter(0); //定义在读取Class字节码时会触发的事件，如类头解析完成、注解解析、字段解析、方法解析等。封装生成字节码文件的实例 ClassVisitor cv = new TraceFieldClassAdapter(cw); cr.accept(cv, 0); //将类转化为字节数组 b = cw.toByteArray(); &#125; catch (Exception e) &#123; throw new ClassNotFoundException(name, e); &#125; // optional: stores the adapted class on disk try &#123; //新建一个输出流 FileOutputStream fos = new FileOutputStream(resource + ".adapted"); fos.write(b); fos.close(); &#125; catch (IOException e) &#123; &#125; // returns the adapted class return defineClass(name, b, 0, b.length); &#125; public static void main(final String args[]) throws Exception &#123; // loads the application class (in args[0]) with an Adapt class loader String[] classArgs = new String[]&#123;"ArraySet"&#125;; //创建一个Adapt类加载实例,该类继承ClassLoader ClassLoader loader = new Adapt(); //装载相应的类 Class&lt;?&gt; c = loader.loadClass(classArgs[0]); // calls the 'main' static method of this class with the // application arguments (in args[1] ... args[n]) as parameter //将剩余的参数传入 Method m = c.getMethod("main", new Class&lt;?&gt;[] &#123; String[].class &#125;); String[] applicationArgs = new String[classArgs.length-1]; System.arraycopy(classArgs, 1, applicationArgs, 0, applicationArgs.length); m.invoke(null, new Object[] &#123; applicationArgs &#125;); &#125;&#125;class TraceFieldClassAdapter extends ClassVisitor implements Opcodes &#123; private String owner; public TraceFieldClassAdapter(final ClassVisitor cv) &#123; super(Opcodes.ASM5, cv); &#125; @Override public void visit(final int version, final int access, final String name, final String signature, final String superName, final String[] interfaces) &#123; owner = name; super.visit(version, access, name, signature, superName, interfaces); &#125; /** * 生成字段相应的setter和getter方法 * */ @Override public FieldVisitor visitField(final int access, final String name, final String desc, final String signature, final Object value) &#123; FieldVisitor fv = super .visitField(access, name, desc, signature, value); if ((access &amp; ACC_STATIC) == 0) &#123; //获取字段类型 Type t = Type.getType(desc); int size = t.getSize(); // generates getter method String gDesc = "()" + desc; //根据字段名返回一个新的方法实例 MethodVisitor gv = cv.visitMethod(ACC_PRIVATE, "_get" + name, gDesc, null, null); gv.visitFieldInsn(GETSTATIC, "java/lang/System", "err", "Ljava/io/PrintStream;"); gv.visitLdcInsn("_get" + name + " called"); //调用静态方法System.out.println gv.visitMethodInsn(INVOKEVIRTUAL, "java/io/PrintStream", "println", "(Ljava/lang/String;)V", false); //字段相关的指令操作 gv.visitVarInsn(ALOAD, 0); gv.visitFieldInsn(GETFIELD, owner, name, desc); //无操作数的指令操作 gv.visitInsn(t.getOpcode(IRETURN)); //设置操作数栈大小和局部变量表 这里生成的是get方法 只具有this 所以局部变量表长度设置为1 gv.visitMaxs(1 + size, 1); //方法生成结束 gv.visitEnd(); //自动生成getter方法 String sDesc = "(" + desc + ")V"; //设置权限访问符 方法名 描述符 MethodVisitor sv = cv.visitMethod(ACC_PRIVATE, "_set" + name, sDesc, null, null); //对类进行初始化工作 sv.visitFieldInsn(GETSTATIC, "java/lang/System", "err", "Ljava/io/PrintStream;"); //将常量加载到栈 sv.visitLdcInsn("_set" + name + " called"); //调用System.out.println方法 sv.visitMethodInsn(INVOKEVIRTUAL, "java/io/PrintStream", "println", "(Ljava/lang/String;)V", false); //aload_0 将引用类型this压入操作数栈 sv.visitVarInsn(ALOAD, 0); //iload_1 第二个本地变量推送至栈顶为int型 sv.visitVarInsn(t.getOpcode(ILOAD), 1); //putfield 从运行时的常量池中取一个指向成员变量的引用和值,将值赋给对象的相关字段 存对象 存值 取出值和对象并将值赋给对象相关字段 sv.visitFieldInsn(PUTFIELD, owner, name, desc); //返回 sv.visitInsn(RETURN); //设置操作数栈大小和局部变量表长度 sv.visitMaxs(1 + size, 1 + size); //方法生成结束 sv.visitEnd(); &#125; return fv; &#125; @Override public MethodVisitor visitMethod(final int access, final String name, final String desc, final String signature, final String[] exceptions) &#123; MethodVisitor mv = cv.visitMethod(access, name, desc, signature, exceptions); return mv == null ? null : new TraceFieldCodeAdapter(mv, owner); &#125;&#125;class TraceFieldCodeAdapter extends MethodVisitor implements Opcodes &#123; private String owner; public TraceFieldCodeAdapter(final MethodVisitor mv, final String owner) &#123; super(Opcodes.ASM5, mv); this.owner = owner; &#125; @Override public void visitFieldInsn(final int opcode, final String owner, final String name, final String desc) &#123; if (owner.equals(this.owner)) &#123; if (opcode == GETFIELD) &#123; // replaces GETFIELD f by INVOKESPECIAL _getf String gDesc = "()" + desc; //调用方法 visitMethodInsn(INVOKESPECIAL, owner, "_get" + name, gDesc, false); return; &#125; else if (opcode == PUTFIELD) &#123; // replaces PUTFIELD f by INVOKESPECIAL _setf String sDesc = "(" + desc + ")V"; visitMethodInsn(INVOKESPECIAL, owner, "_set" + name, sDesc, false); return; &#125; &#125; super.visitFieldInsn(opcode, owner, name, desc); &#125;&#125; 指令分析&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里需要注意一条对应一个栈帧,这是因为栈帧是在不断变化,每一个时刻有所不同 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129public class Analysis implements Opcodes &#123; public static void main(final String[] args) throws Exception &#123; //读取Analysis这个类 ClassReader cr = new ClassReader("Analysis"); ClassNode cn = new ClassNode(); cr.accept(cn, ClassReader.SKIP_DEBUG); //获取所有的方法节点 List&lt;MethodNode&gt; methods = cn.methods; //遍历所有方法 for (int i = 0; i &lt; methods.size(); ++i) &#123; MethodNode method = methods.get(i); if (method.instructions.size() &gt; 0) &#123; if (!analyze(cn, method)) &#123; Analyzer&lt;?&gt; a = new Analyzer&lt;BasicValue&gt;(new BasicVerifier()); try &#123; a.analyze(cn.name, method); &#125; catch (Exception ignored) &#123; &#125; //获取该方法所有栈帧 final Frame&lt;?&gt;[] frames = a.getFrames(); Textifier t = new Textifier(Opcodes.ASM5) &#123; @Override public void visitMaxs(final int maxStack, final int maxLocals) &#123; for (int i = 0; i &lt; text.size(); ++i) &#123; StringBuilder s = new StringBuilder( frames[i] == null ? "null" : frames[i].toString()); while (s.length() &lt; Math.max(20, maxStack + maxLocals + 1)) &#123; s.append(' '); &#125; System.err.print(Integer.toString(i + 1000) .substring(1) + " " + s + " : " + text.get(i)); &#125; System.err.println(); &#125; &#125;; //利用TraceMethodVisitor将Textifier给封装,在指令accept时候传入其句柄最终调用其相关方法 MethodVisitor mv = new TraceMethodVisitor(t); //遍历方法中的指令,将其添加到text这个ArrayList集合（注:这里是对已获取的指令进行输出） for (int j = 0; j &lt; method.instructions.size(); ++j) &#123; Object insn = method.instructions.get(j); ((AbstractInsnNode) insn).accept(mv); &#125; //调用visitMaxs 这个方法即该类覆盖方法 将指令信息给输出 mv.visitMaxs(0, 0); &#125; &#125; &#125; &#125; public static boolean analyze(final ClassNode c, final MethodNode m) throws Exception &#123; Analyzer&lt;SourceValue&gt; a = new Analyzer&lt;SourceValue&gt;(new SourceInterpreter()); /** * 根据传入的方法类名以及方法 返回 方法字节码指令执行顺序栈帧的符号 * 返回数组的大小等于指令的数量(和标签)的方法 * */ Frame&lt;SourceValue&gt;[] frames = a.analyze(c.name, m); // for each xLOAD instruction, we find the xSTORE instructions that can // produce the value loaded by this instruction, and we put them in // 'stores' /** * 遍历xLOAD指令 * */ Set&lt;AbstractInsnNode&gt; stores = new HashSet&lt;AbstractInsnNode&gt;(); int tempCount = 0; for (int i = 0; i &lt; m.instructions.size(); ++i) &#123; AbstractInsnNode insn = m.instructions.get(i); //获取操作指令 int opcode = insn.getOpcode(); if ((opcode &gt;= ILOAD &amp;&amp; opcode &lt;= ALOAD) || opcode == IINC) &#123; int var = opcode == IINC ? ((IincInsnNode) insn).var : ((VarInsnNode) insn).var; //获取当前指令时刻对应的栈帧 Frame&lt;SourceValue&gt; f = frames[i]; if (f != null) &#123; /** * 返回当前栈帧是指令节点集合 * 这是因为每一刻栈帧都具备一个操作栈,这里返回的是在当前指令时刻栈帧中操作数栈中的指令 * getLocal返回的是SourceValue * */ Set&lt;AbstractInsnNode&gt; s = f.getLocal(var).insns; Iterator&lt;AbstractInsnNode&gt; j = s.iterator(); while (j.hasNext()) &#123; insn = j.next(); if (insn instanceof VarInsnNode) &#123; stores.add(insn); &#125; &#125; &#125; &#125; &#125; // 遍历方法的指令且输出opcode &gt;= ISTORE &amp;&amp; opcode &lt;= ASTORE 指令 如果存在无用的指令则设置OK为false boolean ok = true; for (int i = 0; i &lt; m.instructions.size(); ++i) &#123; AbstractInsnNode insn = m.instructions.get(i); int opcode = insn.getOpcode(); if (opcode &gt;= ISTORE &amp;&amp; opcode &lt;= ASTORE) &#123; if (!stores.contains(insn)) &#123; ok = false; System.err.println("method " + m.name + ", instruction " + i + ": useless store instruction"); &#125; &#125; &#125; return ok; &#125;&#125; 添加属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116public class Attributes extends ClassLoader &#123; public static void main(final String args[]) throws Exception &#123; //ClassReader是ASM中最核心的实现，它用于读取并解析Class字节码 ClassReader cr = new ClassReader("CommentAttribute"); //它实现了ClassVisitor接口，用于拼接字节码。一遍封装进ClassVisitor 然后在其里面进行调用 ClassWriter cw = new ClassWriter(0); //字节码的读取与分析引擎。它采用类似SAX的事件读取机制，每当有事件发生时，调用注册的ClassVisitor ClassVisitor cv = new AddCommentClassAdapter(cw); // cr.accept(cv, new Attribute[] &#123; new CommentAttribute("") &#125;, 0); //转化为字节数组 byte[] b = cw.toByteArray(); // stores the adapted class on disk FileOutputStream fos = new FileOutputStream( "CommentAttribute.class.new"); try &#123; fos.write(b); &#125; finally &#123; fos.close(); &#125; // "disassembles" the adapted class cr = new ClassReader(b); cv = new TraceClassVisitor(new PrintWriter(System.out)); cr.accept(cv, new Attribute[] &#123; new CommentAttribute("") &#125;, 0); &#125;&#125;class AddCommentClassAdapter extends ClassVisitor implements Opcodes &#123; public AddCommentClassAdapter(final ClassVisitor cv) &#123; super(Opcodes.ASM5, cv); &#125; /** * * */ @Override public void visit(final int version, final int access, final String name, final String signature, final String superName, final String[] interfaces) &#123; super.visit(version, access, name, signature, superName, interfaces); visitAttribute(new CommentAttribute("this is a class comment")); &#125; @Override public FieldVisitor visitField(final int access, final String name, final String desc, final String signature, final Object value) &#123; //访问字段,并构造相应FieldWriter实例 FieldVisitor fv = super.visitField(access, name, desc, signature, value); //增加字段相关属性 FieldVisitor实际调用FieldWriter然后添加属性到FieldWriter句柄attrs首 fv.visitAttribute(new CommentAttribute("this is a field comment")); return fv; &#125; /** * 同覆盖的visitField方法一样 将返回MethodVisitor注入一个CommentAttribute属性到MethodWriter * */ @Override public MethodVisitor visitMethod(final int access, final String name, final String desc, final String signature, final String[] exceptions) &#123; MethodVisitor mv = cv.visitMethod(access, name, desc, signature, exceptions); if (mv != null) &#123; mv.visitAttribute(new CommentAttribute("this is a method comment")); &#125; return mv; &#125;&#125;class CommentAttribute extends Attribute implements Textifiable &#123; private String comment; public CommentAttribute(final String comment) &#123; super("Comment"); this.comment = comment; &#125; public String getComment() &#123; return comment; &#125; @Override public boolean isUnknown() &#123; return false; &#125; /** * 在读取字节码的过程中 在方法或者字段中返现当前属性则会触发这个方法 * */ @Override protected Attribute read(final ClassReader cr, final int off, final int len, final char[] buf, final int codeOff, final Label[] labels) &#123; return new CommentAttribute(cr.readUTF8(off, buf)); &#125; /** * 在转化字节数组的过程中,会获取相应访问器的属性集合 然后调用write写进字节码文件 * */ @Override protected ByteVector write(final ClassWriter cw, final byte[] code, final int len, final int maxStack, final int maxLocals) &#123; return new ByteVector().putShort(cw.newUTF8(comment)); &#125; /** * 在访问属性的时候会调用当前方法 * */ public void textify(StringBuffer buf, Map&lt;Label, String&gt; labelNames) &#123; buf.append(": " + comment + "\n"); &#125;&#125;]]></content>
      <categories>
        <category>ASM</category>
      </categories>
      <tags>
        <tag>ASM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz UtilCache缓存设计]]></title>
    <url>%2F2018%2F02%2F01%2Fofbiz%2F2018-01-31%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;OFBiz缓存的数据主要有业务数据和系统运行数据两种,在这里主要是为了展示一种缓存设计思路,所以就不对业务，数据的处理过程作相关描述(因为涉及分布式缓存,相对麻烦)所以在这里主要是针对系统数据缓存作相关描述。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;OFBiz缓存防止OOM主要做了两种处理: 设置终止时间+硬软引用设置最大容量 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;设置终止时间主要即对象存在的时间周期,如设置为3秒,则这个对象的存在时间之后3秒,之后获取就会得到控制。在这个过程中维护的map集合为ConcurrentHashMap。并且这种方式可以和硬软引用一起使用,强弱引用同java中的四大引用方式有所不同，主要是用在监听器上如果是软引用,删除后会及时清除引用,然后不能在监听器对这个对象操作;如果是硬引用不会及时清除引用,这样就可以在监听器时间中对该对象进行处理。当然硬软引用在主动移除缓存对象的过程中也是可以使用的。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;设置最大容量主要是采用ConcurrentLinkedHashMap,这个结构是在ConcurrentHashMap上有所增强,针对与所有节点在原有的基础上维持了一个双向链表,使得队列能够有序存在,但是现在主要使用的是基于这个结构上的LRU策略,即对象达到设置容量数目之后,会清除队首元素（每次添加会添加到队尾,并且读取某元素之后,这个元素的位置会移动到队尾）利用这种方式做缓存。我们可以定义它的容器大小,就可以保证较高的命中率了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先来一张类的关系图,对使用类有大概了解,下面基于各种方式进行描述。 设置终止时间+硬软引用硬引用 代码: 12345678TestCacheListener testCacheListener = new TestCacheListener();UtilCache&lt;String,Object&gt; softReferenceCache = UtilCache.createUtilCache("softReferenceCache");softReferenceCache.addListener(testCacheListener);softReferenceCache.put("2","as",2000);System.out.println(softReferenceCache.get("2"));Thread.sleep(3000);System.out.println("=============分界线===========");System.out.println(softReferenceCache.get("2")); result: 12345监听器TestCacheListener执行添加事件as监听器TestCacheListener执行删除事件::key-&gt;2::oldValue-&gt;as=============分界线===========null 软引用 代码： 1234567UtilCache&lt;String,Object&gt; hardReferenceCache = UtilCache.createUtilCache("hardReferenceCache",true);hardReferenceCache.addListener(testCacheListener);hardReferenceCache.put("2","as",2000);System.out.println(hardReferenceCache.get("2"));Thread.sleep(3000);System.out.println("=============分界线===========");System.out.println(hardReferenceCache.get("2")); result: 12345监听器TestCacheListener执行添加事件as监听器TestCacheListener执行删除事件::key-&gt;2::oldValue-&gt;null=============分界线===========null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从这个过程中,可以看出对象在过了终止时间之后就会被清空在硬引用过程,监听器中此时是可以获取对象值的.在软引用过程,监听器中此时是对象值为空其中监听器的处理方式是利用观察者模式,在进行相应数据操作过程中会唤醒当前缓存实例中所有监听器,并进行相应的事件操作。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里展示了整个缓存过程,现在分步骤来描述 创建缓存实例&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创建缓存实例具体过程如下： 获取缓存实例名字 创建缓存实例 利用storeCache将缓存实例添加到缓存表 获取缓存实例名字1String cacheName = "default" + getNextDefaultIndex("default"); 创建缓存实例&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个过程中会根据sizeLimit和maxInMemory属性来判断是生成ConcurrentHashMap还是ConcurrentLinkedHashMap,并且设置是使用硬引用还是软引用来构建缓存行,之后会根据是否采用文件存储来绝对是否使用JDBM缓存,在这里是使用jdbm的Htree结构进行检索存储。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private UtilCache(String cacheName, int sizeLimit, int maxInMemory, long expireTimeMillis, boolean useSoftReference, boolean useFileSystemStore, String propName, String... propNames) &#123; this.name = cacheName; this.sizeLimit = sizeLimit; this.maxInMemory = maxInMemory; this.expireTimeNanos = TimeUnit.NANOSECONDS.convert(expireTimeMillis, TimeUnit.MILLISECONDS); this.useSoftReference = useSoftReference; this.useFileSystemStore = useFileSystemStore; setPropertiesParams(propName); setPropertiesParams(propNames); int maxMemSize = this.maxInMemory; //缓存数目获取,先获取maxInMemorydaxiao 如果为0则再获取sizeLimit if (maxMemSize == 0)&#123; maxMemSize = sizeLimit; &#125; //最终maxMemSize为0则构建ConcurrentHashMap实例否则构建ConcurrentLinkedHashMap实例 if (maxMemSize == 0) &#123; memoryTable = new ConcurrentHashMap&lt;Object, CacheLine&lt;V&gt;&gt;(); &#125; else &#123; memoryTable = new Builder&lt;Object, CacheLine&lt;V&gt;&gt;() .maximumWeightedCapacity(maxMemSize) .listener(this) .build(); &#125; //是否使用文件存储 if (this.useFileSystemStore) &#123; // 创建一个JdbmRecordManager fileStore是文件路径 jdbmMgr = fileManagers.get(fileStore); if (jdbmMgr == null) &#123; Debug.logImportant("Creating file system cache store for cache with name: " + cacheName, module); try &#123; String ofbizHome = System.getProperty("ofbiz.home"); if (ofbizHome == null) &#123; Debug.logError("No ofbiz.home property set in environment", module); &#125; else &#123; jdbmMgr = new JdbmRecordManager(ofbizHome + "/" + fileStore); &#125; &#125; catch (IOException e) &#123; Debug.logError(e, "Error creating file system cache store for cache with name: " + cacheName, module); &#125; fileManagers.putIfAbsent(fileStore, jdbmMgr); &#125; jdbmMgr = fileManagers.get(fileStore); if (jdbmMgr != null) &#123; try &#123; //jdbm提供通过hash的方式索引kv this.fileTable = HTree.createInstance(jdbmMgr); jdbmMgr.setNamedObject(cacheName, this.fileTable.getRecid()); jdbmMgr.commit(); &#125; catch (IOException e) &#123; Debug.logError(e, module); &#125; &#125; &#125;&#125; 利用storeCache将缓存实例添加到缓存表1234567891011storeCache(new UtilCache&lt;K, V&gt;(String cacheName, int sizeLimit, int maxInMemory, long expireTimeMillis, boolean useSoftReference, boolean useFileSystemStore, String propName, String... propNames)); private static &lt;K, V&gt; UtilCache&lt;K, V&gt; storeCache(UtilCache&lt;K, V&gt; cache) &#123; utilCacheTable.put(cache.getName(), cache); return cache; &#125; /** 维持所有的缓存表 */private static final ConcurrentHashMap&lt;String, UtilCache&lt;?, ?&gt;&gt; utilCacheTable = new ConcurrentHashMap&lt;String, UtilCache&lt;?, ?&gt;&gt;(); 给缓存实例添加监听器&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个过程中,主要是给集合listeners添加相应的缓存监听器,然后再具体的调用过程中会调用相应方法。 12345TestCacheListener testCacheListener = new TestCacheListener();public void addListener(CacheListener&lt;K, V&gt; listener) &#123; listeners.add(listener);&#125; 向缓存实例中添加值 代码如下： 1234567891011121314151617181920212223242526V putInternal(K key, V value, long expireTimeNanos) &#123; //获取对象的k Object nulledKey = fromKey(key); //在memoryTable这个ConcurrentHashMap添加CacheLine CacheLine有强引用和弱引用两种 CacheLine&lt;V&gt; oldCacheLine = memoryTable.put(nulledKey, createCacheLine(key, value, expireTimeNanos)); V oldValue = oldCacheLine == null ? null : cancel(oldCacheLine); if (fileTable != null) &#123; try &#123; synchronized (this) &#123; if (oldValue == null) oldValue = fileTable.get(nulledKey); fileTable.put(nulledKey, value); jdbmMgr.commit(); &#125; &#125; catch (IOException e) &#123; Debug.logError(e, module); &#125; &#125; //如果旧值为空,则是添加元素,通过noteAddition调用监听器的添加时间,旧值不为空则调用更新事件 if (oldValue == null) &#123; noteAddition(key, value); return null; &#125; else &#123; noteUpdate(key, value, oldValue); return oldValue; &#125; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个方法是核心方法,也比较复杂,首先对key进行验证如果key不为空则返回相应的key,如果为空则返回构建的NullObject对象 12345678 Object nulledKey = fromKey(key); private Object fromKey(Object key) &#123; return key == null ? ObjectType.NULL : key; &#125; public static final Object NULL = new NullObject(); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然后向memoryTable中以nulledKey为键,创建的缓存行为v的映射关系，真实值封装在cacheLine相关实例中。在创建过程会根据useSoftReference属性创建对应的硬缓存行或者软缓存行。 1CacheLine&lt;V&gt; oldCacheLine = memoryTable.put(nulledKey, createCacheLine(key, value, expireTimeNanos)); 123456789private CacheLine&lt;V&gt; createCacheLine(K key, V value, long expireTimeNanos) &#123; //获取终止时间,如果&gt;0 则获取系统时间 long loadTimeNanos = expireTimeNanos &gt; 0 ? System.nanoTime() : 0; if (useSoftReference) &#123; return createSoftRefCacheLine(key, value, loadTimeNanos, expireTimeNanos); &#125; else &#123; return createHardRefCacheLine(key, value, loadTimeNanos, expireTimeNanos); &#125; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在其中主要是调用tryRegister方法将缓存行添加到相应的延迟队列。这里loadTimeNanos=0则这个对象并不会添加到延迟队列,所以通过这种方式就会一直存在。 12345678910 private CacheLine&lt;V&gt; tryRegister(long loadTimeNanos, CacheLine&lt;V&gt; line) &#123; if (loadTimeNanos &gt; 0) &#123; ExecutionPool.addPulse(line); &#125; return line; &#125;public static void addPulse(Pulse pulse) &#123; delayQueue.put(pulse); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意在 ExecutionPool类中具有一个静态代码块 123456789101112131415161718192021222324static &#123; //返回可用处理器的Java虚拟机的数量 int numberOfExecutionPoolPulseWorkers = Runtime.getRuntime().availableProcessors(); //向线程池中添加相应的线程数量 for (int i = 0; i &lt; numberOfExecutionPoolPulseWorkers; i++) &#123; pulseExecutionPool.execute(new ExecutionPoolPulseWorker()); &#125; &#125; private static final DelayQueue&lt;Pulse&gt; delayQueue = new DelayQueue&lt;Pulse&gt;(); public static class ExecutionPoolPulseWorker implements Runnable &#123; @Override public void run() &#123; try &#123; //循环从队列中去除元素 调用相应的方法 while (true) &#123; delayQueue.take().run(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很容易知道这个代码块是从构建线程池不断循环检测延迟队列是否具有到了终止时间的缓存行,具有的会取出并调用相关run方法, 先展示缓存行继承的抽象类来说明为什么会从延迟队列取出到了终止时间的缓存行,类结构如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public static abstract class Pulse implements Delayed, Runnable &#123; protected final long expireTimeNanos; protected final long loadTimeNanos; protected Pulse(long delayNanos) &#123; this(System.nanoTime(), delayNanos); &#125; protected Pulse(long loadTimeNanos, long delayNanos) &#123; this.loadTimeNanos = loadTimeNanos; expireTimeNanos = loadTimeNanos + delayNanos; &#125; public long getLoadTimeNanos() &#123; return loadTimeNanos; &#125; public long getExpireTimeNanos() &#123; return expireTimeNanos; &#125; //在从延迟队列中取出的时候,需要判断时候getDelay返回值为0才可以取出 @Override public final long getDelay(TimeUnit unit) &#123; //TimeUnit.NANOSECONDS 纳秒 return unit.convert(expireTimeNanos - System.nanoTime(), TimeUnit.NANOSECONDS); &#125; /** *优先队列里面优先级规则 *比较 1是放入队尾 -1是放入队头 *所以终止时间早的放入对头可以达到先出队列的效果 * */ @Override public final int compareTo(Delayed other) &#123; long r = (expireTimeNanos - ((Pulse) other).expireTimeNanos); if (r &lt; 0)&#123; return -1; &#125; if (r &gt; 0)&#123; return 1; &#125; return 0; &#125; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 我们在来看看run方法作了什么操作 1234567891011121314151617181920212223242526272829public abstract class CacheLine&lt;V&gt; extends ExecutionPool.Pulse &#123; protected CacheLine(long loadTimeNanos, long expireTimeNanos) &#123; //如果具有终止时间的的loadTimeNanos为创建的系统时间 super(loadTimeNanos, expireTimeNanos); // FIXME: this seems very odd to me (ARH) //if (loadTime &lt;= 0) &#123; // hasExpired = true; //&#125; &#125; abstract CacheLine&lt;V&gt; changeLine(boolean useSoftReference, long expireTimeNanos); abstract void remove(); boolean differentExpireTime(long expireTimeNanos) &#123; return this.expireTimeNanos - loadTimeNanos - expireTimeNanos != 0; &#125; public abstract V getValue(); void cancel() &#123; &#125; //调用remove @Override public void run() &#123; remove(); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由此可知调用了相关remove操作,最终实现如下,在这个过程中,都会从memoryTable中移除,不同点是调用cancel(existingCacheLine);的时候硬缓存行什么也不会做，软缓存行会清楚引用,所以在调用noteRemoval监听事件的时候软缓存行获取的是空值,硬缓存行传入的是相关对象,所以我们可以在监听事件对其进行处理。 1234567891011121314151617181920protected synchronized void removeInternal(Object key, CacheLine&lt;V&gt; existingCacheLine) &#123; Object nulledKey = fromKey(key); cancel(existingCacheLine); //从memoryTable表中进行清楚 if (!memoryTable.remove(nulledKey, existingCacheLine)) &#123; return; &#125; if (fileTable != null) &#123; try &#123; synchronized (this) &#123; fileTable.remove(nulledKey); jdbmMgr.commit(); &#125; &#125; catch (IOException e) &#123; Debug.logError(e, module); &#125; &#125; // noteRemoval(UtilGenerics.&lt;K&gt;cast(key), existingCacheLine.getValue());&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cancel方法如下，首先从延迟队列中移除,然后清除缓存行, 12345678910111213141516171819private V cancel(CacheLine&lt;V&gt; line) &#123; // FIXME: this is a race condition, the item could expire // between the time it is replaced, and it is cancelled V oldValue = line.getValue(); ExecutionPool.removePulse(line); line.cancel(); return oldValue; &#125; //软引用中 @Override void cancel() &#123; ref.clear(); &#125;//硬引用中void cancel() &#123; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这些操作之后继续完成添加操作,即jdbm处理以及监听事件处理，但是线程池启动了就会一直检查延迟队列并进行相关操作。 设置最大容量代码： 12345678910UtilCache&lt;String,Object&gt; maxInMemoryWithSoftReferenceCache = UtilCache.createUtilCache("maxInMemoryWithCache",3,0);maxInMemoryWithSoftReferenceCache.addListener(testCacheListener);maxInMemoryWithSoftReferenceCache.put("1","as");maxInMemoryWithSoftReferenceCache.put("2","as");maxInMemoryWithSoftReferenceCache.put("3","as");maxInMemoryWithSoftReferenceCache.put("4","as");System.out.println(maxInMemoryWithSoftReferenceCache.get("1"));System.out.println(maxInMemoryWithSoftReferenceCache.get("2"));System.out.println(maxInMemoryWithSoftReferenceCache.get("3"));System.out.println(maxInMemoryWithSoftReferenceCache.get("4")); result: 12345678添加监听器TestCacheListener添加监听器TestCacheListener添加监听器TestCacheListener添加监听器TestCacheListenernullasasas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个过程中其余处理逻辑和上面一样,只是构建Map集合为ConcurrentLinkedHashMap,当容量达到上限就会移除队首，具体过程上面有讲解，代码如下： 1234567891011121314151617if (maxMemSize == 0)&#123; maxMemSize = sizeLimit; &#125; //最终maxMemSize为0则构建ConcurrentHashMap实例否则构建ConcurrentLinkedHashMap实例 if (maxMemSize == 0) &#123; memoryTable = new ConcurrentHashMap&lt;Object, CacheLine&lt;V&gt;&gt;(); &#125; else &#123; memoryTable = new Builder&lt;Object, CacheLine&lt;V&gt;&gt;() .maximumWeightedCapacity(maxMemSize) .listener(this) .build(); &#125; public ConcurrentLinkedHashMap&lt;K, V&gt; build() &#123; this.maximumWeightedCapacity(this.maximumWeightedCapacity); return new ConcurrentLinkedHashMap(this); &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat源码解读八 tomcat的BIO、NIO和AIO模型]]></title>
    <url>%2F2018%2F01%2F29%2Ftomcat%2F2018-02-20%2F</url>
    <content type="text"></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat源码解读七 tomcat的BIO、NIO和AIO模型]]></title>
    <url>%2F2018%2F01%2F29%2Ftomcat%2F2018-01-29%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在前面已经整体对tomcat的启动过程分析过,现在就这三种模型做单独的分析，主要是为了进一步加深对I/O模型的理解。 tomcat的BIO模型类的关系图 类的时序图&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在以Acceptor为入口进行分析,在这里通过一个while循环+调用serverSocketFactory.acceptSocket(serverSocket);实际就是socket.accept();进行阻塞，等待接受客户端请求,当接受到客户端请求之后，将socket利用SocketWrapper进行包装加入到线程实例SocketProcessor里面，然后将相应线程实例添加到线程池中进行执行.这就是多线程阻塞IO的使用方式,通过一个线程接受请求,将请求交给具体的线程进行处理 tomcat的NIO模型类的关系图 类的时序图 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在NIO模型中,首先得提的是bind方法,创建了一个ServerSocketChannel并且设置为阻塞，所以在Acceptor接受请求的时候是阻塞处理的，因为在这个过程中没有必要用非阻塞，当接受到请求之后获取相应的socketChannel之后先设置其为非阻塞再调用setSocketOptions(socket)方法将构建相应NioChannel(在这里里面封装了实际socket套接字,以及NioBufferHandler),之后获取Poller实例register方法构建相应PollerEvent并将其添加到events数组(这里获取到那个Poller就是哪个Poller,变量都是实例变量,多个Poller之间唯一联系是选择器selector).&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Acceptor线程启动之前,Poller线程已经启动,放在这里描述是为了好理解,调用select阻塞1秒或者不阻塞取决于events里面是否具有元素,如果具有元素,调用不阻塞，反之阻塞1s,最终处理方式都是如果获取相应就绪通道，先出里就绪通道数据，最终调用proccessKey对套接字进行相关处理.如果没有，则执行events里面的PollerEvent,里面具体逻辑也是将NioChannel注册到就绪通道。 tomcat中的AIO模型类的关系图 类的时序图 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;异步的核心是基于内核,主要是内核获取相关套接字,然后通过利用回调方式进行处理,在Tomcat的AIO模型处理过程中,在serverSock.accept().get();这个获取异步套接字，然后进行相应的封装,最后socket.getSocket().read(byteBuffer, socket.getTimeout(), TimeUnit.MILLISECONDS, socket, awaitBytes);进行读取数据,在这个过程中当客户端往套接字发送数据时,内核从网卡接受数据后就会调用回调函数,回调函数在awaitBytes实例中,定义如下: 1234567891011121314151617private CompletionHandler&lt;Integer, SocketWrapper&lt;Nio2Channel&gt;&gt; awaitBytes = new CompletionHandler&lt;Integer, SocketWrapper&lt;Nio2Channel&gt;&gt;() &#123; @Override public synchronized void completed(Integer nBytes, SocketWrapper&lt;Nio2Channel&gt; attachment) &#123; if (nBytes.intValue() &lt; 0) &#123; failed(new ClosedChannelException(), attachment); return; &#125; processSocket0(attachment, SocketStatus.OPEN_READ, true); &#125; @Override public void failed(Throwable exc, SocketWrapper&lt;Nio2Channel&gt; attachment) &#123; processSocket0(attachment, SocketStatus.DISCONNECT, true); &#125; &#125;;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java IO模型]]></title>
    <url>%2F2018%2F01%2F28%2Fjava%2F2018-01-25%2F</url>
    <content type="text"><![CDATA[在java IO模型中通常以同步/异步 阻塞/非阻塞进行分析,比较常用的模型有： 同步阻塞IO（Blocking IO） 同步非阻塞IO（Non-blocking IO） IO多路复用（IO Multiplexing） 异步IO（Asynchronous IO 阻塞IO 针对于阻塞IO进行,当前线程需要获取IO资源时，会调用内核,然后内核准备相应数据返回,当线程应用获取到数据的时候才会继续向下执行,&lt;em style=&quot;color:red&quot;&gt;在获取数据时候,阻塞的是当前线程&lt;/em&gt;,所以在这种情况下,就出现了单线程会阻塞,程序就必须对待当前资源处理完毕,才能继续处理下去，如果在这个过程中我们需要同时对多个IO资源进行处理,就可以采用多线程方式来进行处理，这样就能解决单线并发能力低的缺点 在这个过程中我们提到过IO模型，现在总结描述一下它们的特点: 1:单线程阻塞I/O模型:整个运行过程中只有一个线程，只能同时处理一个IO资源,如果有多个IO资源的话必须排队处理,系统资源消耗较少,但并发能力较低。 2.多线程阻塞I/O模型:支持同时处理多个I/O资源,处理能力得到大幅度提高,有较大的并发量,但系统资源消耗较大，并且会产生很多线程切换成本. &lt;em style=&quot;color:red;margin-left:30px;&quot;&gt;注意：对文件IO资源进行处理的时候,可以针对一个文件同时打开多个文件流,如果需要实现数据同步,可以采用文件锁的方式进行处理&lt;/em&gt; 同步非阻塞IO 非阻塞IO一般是针对于服务器来说的,创建相应的ServerSocket通道，不管是否读取到客户端数据都会进行返回,这样做的好处是,&lt;em style=&quot;color:red;&quot;&gt;你可以在等待的过程中做一些其他的事情,只需要个一段时间看是否有新的套接字简历&lt;/em&gt; 在NIO模型中的非阻塞点有两个 ServerSocketChannel.accept() Selector 针对于第一个非阻塞点,设置为非阻塞代表获取到无论是否获取socket套接字都会为空 针对于第二个非阻塞点,几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道 int select() 阻塞到至少有一个通道在你注册的事件上就绪了。 int select(long timeout) 最长会阻塞timeout毫秒 int selectNow() 不会阻塞，不管什么通道就绪都立刻返回 I/O复用 在NIO中一个优势,线程可以进行复用,这种复用技术是利用Selector和socket通道进行配合,打开相应通道,注册该通道感兴趣的事件,如ServerSocketChannel注册一个接受通道事件到选择键之后,当获取到相应客户端请求,相应通道就会准备就绪，select机会返回相应的数量，此时我们可以获取SocketChannel,将其注册到选择器，在循环获取的过程就可以获取相应的读事件,之后进行相关的处理. 在windows系统是Selector.open()会自己和自己建立两条TCP链接,在Linux下，Selector.open()会自己和自己建两条管道,这样做的目的就是在获取相应连接的时候可以被唤醒。 异步非阻塞IO 异步描述的是执行IO操作的主体是谁，同步是由用户进程自己去执行最终的IO操作。异步是用户进程自己不关系实际IO操作的过程，只需要由内核在IO完成后通知它既可，由内核进程来执行最终的IO操作。 非阻塞异步IO指的是用户调用读写方法是不阻塞的，立刻返回，而且用户不需要关注读写，只需要提供回调操作，内核线程在完成读写后回调用户提供的callback。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java归并排序]]></title>
    <url>%2F2018%2F01%2F27%2Farithmetic%2F2018-01-27%2F</url>
    <content type="text"><![CDATA[归并排序的思想:利用递归与分治技术将数据不断半分然后逐步进行排序合并 核心实现方法有两个： 子数组排序： merge(int[] a, int low, int mid, int high) a表示数组，low标识左边一部分开始位置，mid表示右边部分位置 实现过程: 第一次循环:(i &lt;= mid &amp;&amp; j &lt;= high) 进行不断填充到一个临时数组 第二次循环:判断低位部分时候还有数据 第三次循环:判断高位部分是否还有数据 然后将原有这部分无序的用临时数组有序替换掉 mergeSort(int[] a, int low, int high) 如果low&lt;height 始终调用 mergeSort(a, low, mid); mergeSort(a, mid + 1, high); merge(a, low, mid, high); 这样就进行不断拆分到最小，然后合并排序]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO流相关问题]]></title>
    <url>%2F2018%2F01%2F22%2Fjava%2F2018-01-22-1%2F</url>
    <content type="text"><![CDATA[Q1GC能关闭IO资源？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;垃圾回收主要回收的是内存资源，而io开辟的资源是磁盘资源，所以不能被回收，需要手动释放。 Q2java7之后怎么样可以不写流close()代码而实现流的自动关闭 jdk为我们做了什么 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java7增强了try语句的功能，它允许在try关键字后紧跟一对圆括号，圆括号可以声明、初始化一个或多个资源（此处的资源是指那些必须在程序结束时显式关闭的资源，比如数据库连接，网络连接等），try-with-resources 是一个定义了一个或多个资源的try 声明，try语句在该语句结束时自动关闭这些资源。try-with-resources确保每一个资源在处理完成后都会被关闭。这些资源必须实现AutoCloseable或者Closeable接口，实现这两个接口就必须实现close() 方法。 Q3 有一个很大的文件，超过24字节大小，里面有中英文掺杂，现在用一个24字节的数组不断读取，会有什么问题吗？ 编码不一致 Q4推回输入流 http://blog.longjiazuo.com/archives/4462 Q5随机访问流，也就是RandomAccessFile流 http://blog.longjiazuo.com/archives/4576 Q6流中的命令模式 http://blog.longjiazuo.com/archives/4488]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java的IO流设计-节点流/处理流]]></title>
    <url>%2F2018%2F01%2F22%2Fjava%2F2018-01-22%2F</url>
    <content type="text"><![CDATA[在字节流和字符流中同时讲述了输出流和输入流，现在就简单的对节点流和处理流进行分析 节点流Vs处理流 节点流:程序用于直接操作目标设备所对应的类叫节点流。 处理流:程序通过一个间接流类去调用节点流类，以达到更加灵活方便地读写各种类型的数据，这个间接流类就是处理流。 节点流 节点流的类型 （1）File 文件流。对文件进行读、写操作 ：FileReader、FileWriter、FileInputStream、FileOutputStream。、 （2）Memory 1）从/向内存数组读写数据: CharArrayReader与 CharArrayWriter、ByteArrayInputStream与ByteArrayOutputStream。 2）从/向内存字符串读写数据 StringReader、StringWriter、StringBufferInputStream。 （3）Pipe管道流。 实现管道的输入和输出（进程间通信）: PipedReader与PipedWriter、PipedInputStream与PipedOutputStream。 节点流执行的图示 处理流 处理流的类型 （1）Buffering缓冲流：在读入或写出时，对数据进行缓存，以减少I/O的次数：BufferedReader与BufferedWriter、BufferedInputStream与BufferedOutputStream。 （2）Filtering 滤流：在数据进行读或写时进行过滤：FilterReader与FilterWriter、FilterInputStream与FilterOutputStream。 （3）Converting between Bytes and Characters 转换流：按照一定的编码/解码标准将字节流转换为字符流，或进行反向转换（Stream到Reader）：InputStreamReader、OutputStreamWriter。 （4）Object Serialization 对象流 ：ObjectInputStream、ObjectOutputStream。 （5）DataConversion数据流： 按基本数据类型读、写（处理的数据是Java的基本类型（如布尔型，字节，整数和浮点数））：DataInputStream、DataOutputStream 。 （6）Counting计数流： 在读入数据时对行记数 ：LineNumberReader、LineNumberInputStream。 （7）Peeking Ahead预读流： 通过缓存机制，进行预读 ：PushbackReader、PushbackInputStream。 （8）Printing打印流： 包含方便的打印方法 ：PrintWriter、PrintStream。 处理流的图示: 参考链接: JAVA——IO流 之 节点流与处理流（2） http://blog.csdn.net/jingzi123456789/article/details/72123937]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java的流设计模型-字节流/字符流]]></title>
    <url>%2F2018%2F01%2F21%2Fjava%2F2018-01-21%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;java的流按照处理数据单位不同可以分为：字节流和字符流。按照实现功能不同可以分为：节点流和处理流。从程序的角度分为输入流和输出流。 字节流VS字符流 字节流:处理的最基本单位为单个字节，它通常用来处理二进制数据 字符流:处理的最基本的单元是Unicode码元（大小2字节），它通常用来处理文本数据 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从这张图可以看出IO流共有四个接口InputStream、OutPutStream、Reader、Writer四个接口，具体描述如下： InputStream:字节流输入流接口OutPutStream:字节流输出流接口Reader:字符流输入流接口Writer:字符流输出流接口 字符流与字节流的区别 字节流操作的基本单元为字节；字符流操作的基本单元为Unicode码元。 字节流默认不使用缓冲区；字符流使用缓冲区。 字节流通常用于处理二进制数据，实际上它可以处理任意类型的数据，但它不支持直接写入或读取Unicode码元；字符流通常处理文本数据，它支持写入及读取Unicode码元。 字节流与字符流的存储过程字节流的输入过程(读取)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所有的字节流都实现了InputStream接口,所以首先应该看这个接口定义的方法。 1 、int read() 功能：读取一个字节的数据，并且返回读到得数据，如果返回-1，则表示读到输入流的末尾。 2、int read(byte[] b) 功能：从输入流中读取一定量的字节，并将其存储在字节数组b中，返回实际读取的字节数，如果返回-1，则表示读到输入流的末尾。 3、int read(byte[] b, int off, int len) 功能：将数据读入一个字节数组，同时返回读取的实际字节数，如果返回-1，则表示读到输入流的末尾。off指定在数组b中存放数据的起始偏移位置，len指定读取的最大字节数。 4、available() 功能：返回此输入流下一个方法调用可以不受阻塞地从此输入流读取或跳过的估计字节数。 5、close() 功能：关闭输入流，释放这个流的相关资源。 由FileInputStream可以看出其都是调用本地方法，进行数据的传输. 1234567891011121314151617 private native void open0(String name) throws FileNotFoundException;private void open(String name) throws FileNotFoundException &#123; open0(name); &#125;public int read() throws IOException &#123; return read0(); &#125;private native int read0() throws IOException; private native int readBytes(byte b[], int off, int len) throws IOException;public int read(byte b[]) throws IOException &#123; return readBytes(b, 0, b.length);&#125; 字节流的输出过程&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所有的字节流都实现了OutputStream接口，所以应先看这个接口定义的方法. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1 、int write(int b) 功能：将b的最低的一个字节写入此输入流，其他三个字节丢弃。 2、int write(byte[] b) 功能：将指定的字节数组b写入此输入流。 3、int write(byte[] b, int off, int len) 功能：将指定byte数组中从偏移量off开始的len个字节写入输入流。 4、flush() 功能：刷新此输入流并强制写出所有缓冲的输出字节数。 5、close() 功能：关闭输出流，释放这个流的相关资源。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102private native void open0(String name, boolean append) throws FileNotFoundException; // wrap native call to allow instrumentation /** * Opens a file, with the specified name, for overwriting or appending. * @param name name of file to be opened * @param append whether the file is to be opened in append mode */ private void open(String name, boolean append) throws FileNotFoundException &#123; open0(name, append); &#125; /** * Writes the specified byte to this file output stream. * * @param b the byte to be written. * @param append &#123;@code true&#125; if the write operation first * advances the position to the end of file */ private native void write(int b, boolean append) throws IOException; /** * Writes the specified byte to this file output stream. Implements * the &lt;code&gt;write&lt;/code&gt; method of &lt;code&gt;OutputStream&lt;/code&gt;. * * @param b the byte to be written. * @exception IOException if an I/O error occurs. */ public void write(int b) throws IOException &#123; write(b, append); &#125; /** * Writes a sub array as a sequence of bytes. * @param b the data to be written * @param off the start offset in the data * @param len the number of bytes that are written * @param append &#123;@code true&#125; to first advance the position to the * end of file * @exception IOException If an I/O error has occurred. */ private native void writeBytes(byte b[], int off, int len, boolean append) throws IOException; /** * Writes &lt;code&gt;b.length&lt;/code&gt; bytes from the specified byte array * to this file output stream. * * @param b the data. * @exception IOException if an I/O error occurs. */ public void write(byte b[]) throws IOException &#123; writeBytes(b, 0, b.length, append); &#125; /** * Writes &lt;code&gt;len&lt;/code&gt; bytes from the specified byte array * starting at offset &lt;code&gt;off&lt;/code&gt; to this file output stream. * * @param b the data. * @param off the start offset in the data. * @param len the number of bytes to write. * @exception IOException if an I/O error occurs. */ public void write(byte b[], int off, int len) throws IOException &#123; writeBytes(b, off, len, append); &#125; /** * Closes this file output stream and releases any system resources * associated with this stream. This file output stream may no longer * be used for writing bytes. * * &lt;p&gt; If this stream has an associated channel then the channel is closed * as well. * * @exception IOException if an I/O error occurs. * * @revised 1.4 * @spec JSR-51 */ public void close() throws IOException &#123; synchronized (closeLock) &#123; if (closed) &#123; return; &#125; closed = true; &#125; if (channel != null) &#123; channel.close(); &#125; fd.closeAll(new Closeable() &#123; public void close() throws IOException &#123; close0(); &#125; &#125;); &#125; 字符流的输入过程123456789101112131415161718192021222324252627282930* @see BufferedReader* @see LineNumberReader* @see CharArrayReader* @see InputStreamReader* @see FileReader* @see FilterReader* @see PushbackReader* @see PipedReader* @see StringReader* @see Writerabstract void close() 关闭该流并释放与之关联的所有资源。 void mark(int readAheadLimit) 标记流中的当前位置。 boolean markSupported() 判断此流是否支持 mark() 操作。 int read() 读取单个字符。 int read(char[] cbuf) 将字符读入数组。 abstract int read(char[] cbuf, int off, int len) 将字符读入数组的某一部分。 int read(CharBuffer target) 试图将字符读入指定的字符缓冲区。 boolean ready() 判断是否准备读取此流。 void reset() 重置该流。 long skip(long n) 跳过字符。 现在以FileReader为例进行分析: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个过程中,实例化FileReader的过程中，依旧是用字节流打开文件，然后通过StreamDecoder将字节流进行解码，在读取的过程中主要是通过这个解码实例进行读取数据。下面我们看一看read的具体实现过程:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在StreamDecoder中,主要用的是四个方法，read0(), read(char cbuf[],int offset,int length) implRead(char[] cbuf, int off, int end),readBytes() 现在已read(char cbuf[],int offset,int length) 作为入口进行分析,先检查有没有遗留字符有的话直接进行读，如果剩余长度为1则调用read0方法（这是因为要保持每次读取读到两个字节），然后在read0之后看有遗留字符则直接读出来，没有新构造一个调用方法来调用read(cb,0,2),这个时候应该没有遗留字符，则调用implRead进行解码读取。由于这个代码是sun公司下，源码在IDE下一般很难直接看到，故展示如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379package sun.nio.cs;import java.io.*;import java.nio.*;import java.nio.channels.*;import java.nio.charset.*;public class StreamDecoder extends Reader&#123; private static final int MIN_BYTE_BUFFER_SIZE = 32; private static final int DEFAULT_BYTE_BUFFER_SIZE = 8192; private volatile boolean isOpen = true; //确保流文件是打开的 private void ensureOpen() throws IOException &#123; if (!isOpen) throw new IOException("Stream closed"); &#125; // In order to handle surrogates properly we must never try to produce // fewer than two characters at a time. If we're only asked to return one // character then the other is saved here to be returned later. //每次要求返回两个字符，如果只读取一个字符，另外一个字符保存在这里 private boolean haveLeftoverChar = false; private char leftoverChar; // Factories for java.io.InputStreamReader //InputStreamReader的工厂 public static StreamDecoder forInputStreamReader(InputStream in, Object lock, String charsetName) throws UnsupportedEncodingException &#123; String csn = charsetName; if (csn == null) //设置默认编码集 csn = Charset.defaultCharset().name(); try &#123; if (Charset.isSupported(csn)) return new StreamDecoder(in, lock, Charset.forName(csn)); &#125; catch (IllegalCharsetNameException x) &#123; &#125; throw new UnsupportedEncodingException (csn); &#125; public static StreamDecoder forInputStreamReader(InputStream in, Object lock, Charset cs) &#123; return new StreamDecoder(in, lock, cs); &#125; public static StreamDecoder forInputStreamReader(InputStream in, Object lock, CharsetDecoder dec) &#123; return new StreamDecoder(in, lock, dec); &#125; // Factory for java.nio.channels.Channels.newReader public static StreamDecoder forDecoder(ReadableByteChannel ch, CharsetDecoder dec, int minBufferCap) &#123; return new StreamDecoder(ch, dec, minBufferCap); &#125; // -- Public methods corresponding to those in InputStreamReader -- //响应InputStreamReader的共有方法 // All synchronization and state/argument checking is done in these public // methods; the concrete stream-decoder subclasses defined below need not // do any such checking. //所有同步和状态参数检查在这些公共完成所以子类不需要检查 public String getEncoding() &#123; if (isOpen()) return encodingName(); return null; &#125; public int read() throws IOException &#123; return read0(); &#125; private int read0() throws IOException &#123; synchronized (lock) &#123; // Return the leftover char, if there is one //如果有遗留字符直接返回,即上次读取了两个字符之后剩下的 if (haveLeftoverChar) &#123; haveLeftoverChar = false; return leftoverChar; &#125; // Convert more bytes //转化更多的字节 char cb[] = new char[2]; //读取两个字符放入cb int n = read(cb, 0, 2); switch (n) &#123; case -1: //如果一个没有读到返回-1 return -1; case 2: //如果读取到两个字符保留第二个字符由于没有break所以在case1中返回读取的第一个字符 leftoverChar = cb[1]; haveLeftoverChar = true; // FALL THROUGH case 1: //如果读取到一个字符,直接进行返回 return cb[0]; default: assert false : n; return -1; &#125; &#125; &#125; public int read(char cbuf[], int offset, int length) throws IOException &#123; //设置读取偏移量 int off = offset; //设置读取长度 int len = length; synchronized (lock) &#123; //确保流被打开 ensureOpen(); //检查偏移量和长度 if ((off &lt; 0) || (off &gt; cbuf.length) || (len &lt; 0) || ((off + len) &gt; cbuf.length) || ((off + len) &lt; 0)) &#123; throw new IndexOutOfBoundsException(); &#125; if (len == 0) return 0; int n = 0; //如果具有遗留字符直接返回，将其读取，此时读取长度为0，或者implReady为false则直接返回读取长度1 if (haveLeftoverChar) &#123; // Copy the leftover char into the buffer cbuf[off] = leftoverChar; off++; len--; haveLeftoverChar = false; n = 1; if ((len == 0) || !implReady()) // Return now if this is all we can produce w/o blocking return n; &#125; //如果剩余读取长度为1，调用read0里面会在调用这个方法进行读取 if (len == 1) &#123; // Treat single-character array reads just like read() int c = read0(); if (c == -1) return (n == 0) ? -1 : n; cbuf[off] = (char)c; return n + 1; &#125; // return n + implRead(cbuf, off, off + len); &#125; &#125; public boolean ready() throws IOException &#123; synchronized (lock) &#123; ensureOpen(); return haveLeftoverChar || implReady(); &#125; &#125; public void close() throws IOException &#123; synchronized (lock) &#123; if (!isOpen) return; implClose(); isOpen = false; &#125; &#125; private boolean isOpen() &#123; return isOpen; &#125; // -- Charset-based stream decoder impl -- // In the early stages of the build we haven't yet built the NIO native // code, so guard against that by catching the first UnsatisfiedLinkError // and setting this flag so that later attempts fail quickly. // private static volatile boolean channelsAvailable = true; private static FileChannel getChannel(FileInputStream in) &#123; if (!channelsAvailable) return null; try &#123; return in.getChannel(); &#125; catch (UnsatisfiedLinkError x) &#123; channelsAvailable = false; return null; &#125; &#125; private Charset cs; private CharsetDecoder decoder; private ByteBuffer bb; // Exactly one of these is non-null private InputStream in; private ReadableByteChannel ch; StreamDecoder(InputStream in, Object lock, Charset cs) &#123; this(in, lock, cs.newDecoder() .onMalformedInput(CodingErrorAction.REPLACE) .onUnmappableCharacter(CodingErrorAction.REPLACE)); &#125; StreamDecoder(InputStream in, Object lock, CharsetDecoder dec) &#123; super(lock); this.cs = dec.charset(); this.decoder = dec; // This path disabled until direct buffers are faster if (false &amp;&amp; in instanceof FileInputStream) &#123; ch = getChannel((FileInputStream)in); if (ch != null) bb = ByteBuffer.allocateDirect(DEFAULT_BYTE_BUFFER_SIZE); &#125; if (ch == null) &#123; this.in = in; this.ch = null; bb = ByteBuffer.allocate(DEFAULT_BYTE_BUFFER_SIZE); &#125; bb.flip(); // So that bb is initially empty &#125; StreamDecoder(ReadableByteChannel ch, CharsetDecoder dec, int mbc) &#123; this.in = null; this.ch = ch; this.decoder = dec; this.cs = dec.charset(); this.bb = ByteBuffer.allocate(mbc &lt; 0 ? DEFAULT_BYTE_BUFFER_SIZE : (mbc &lt; MIN_BYTE_BUFFER_SIZE ? MIN_BYTE_BUFFER_SIZE : mbc)); bb.flip(); &#125; private int readBytes() throws IOException &#123; //将缓冲区的有效数据全部移到缓冲区的首部，而position指向下一个可写位置。 bb.compact(); try &#123; //ch表示通道流 bb表示缓冲字节数组 if (ch != null) &#123; //从通道中读取数据 int n = ch.read(bb); if (n &lt; 0) return n; &#125; else &#123; //从输入流中读取数据 int lim = bb.limit(); int pos = bb.position(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); assert rem &gt; 0; int n = in.read(bb.array(), bb.arrayOffset() + pos, rem); if (n &lt; 0) return n; if (n == 0) throw new IOException("Underlying input stream returned zero bytes"); assert (n &lt;= rem) : "n = " + n + ", rem = " + rem; bb.position(pos + n); &#125; &#125; finally &#123; // Flip even when an IOException is thrown, // otherwise the stream will stutter bb.flip(); &#125; int rem = bb.remaining(); assert (rem != 0) : rem; return rem; &#125; int implRead(char[] cbuf, int off, int end) throws IOException &#123; // In order to handle surrogate pairs, this method requires that // the invoker attempt to read at least two characters. Saving the // extra character, if any, at a higher level is easier than trying // to deal with it here. assert (end - off &gt; 1); //构造一个CharBuffer实例,默认是堆缓存 CharBuffer cb = CharBuffer.wrap(cbuf, off, end - off); if (cb.position() != 0) // Ensure that cb[0] == cbuf[off] //创建新的字符缓冲区，其内容为此缓冲区内容的共享子序列 cb = cb.slice(); boolean eof = false; for (;;) &#123; //从给定的输入缓冲区中解码尽可能多的字节，把结果写入给定的输出缓冲区 CoderResult cr = decoder.decode(bb, cb, eof); //如果出现下溢情况,指示已解码尽可能多的输入缓冲区。如果没有进一步的输入，则调用者可以进行到解码操作的下一个步骤 if (cr.isUnderflow()) &#123; if (eof) break; if (!cb.hasRemaining()) break; if ((cb.position() &gt; 0) &amp;&amp; !inReady()) break; // Block at most once int n = readBytes(); if (n &lt; 0) &#123; eof = true; if ((cb.position() == 0) &amp;&amp; (!bb.hasRemaining())) break; decoder.reset(); &#125; continue; &#125; //如果出现溢出现象，指示该输出缓冲区中没有足够空间来解码任何更多字节 if (cr.isOverflow()) &#123; assert cb.position() &gt; 0; break; &#125; cr.throwException(); &#125; if (eof) &#123; // 重置此解码器，清除所有内部状态 decoder.reset(); &#125; if (cb.position() == 0) &#123; if (eof) return -1; assert false; &#125; return cb.position(); &#125; String encodingName() &#123; return ((cs instanceof HistoricallyNamedCharset) ? ((HistoricallyNamedCharset)cs).historicalName() : cs.name()); &#125; private boolean inReady() &#123; try &#123; return (((in != null) &amp;&amp; (in.available() &gt; 0)) || (ch instanceof FileChannel)); // ## RBC.available()? &#125; catch (IOException x) &#123; return false; &#125; &#125; boolean implReady() &#123; return bb.hasRemaining() || inReady(); &#125; void implClose() throws IOException &#123; if (ch != null) ch.close(); else in.close(); &#125;&#125; 字符流的输出过程1234567891011121314151617181920Writer append(char c) 将指定字符添加到此 writer。 Writer append(CharSequence csq) 将指定字符序列添加到此 writer。 Writer append(CharSequence csq, int start, int end) 将指定字符序列的子序列添加到此 writer.Appendable。 abstract void close() 关闭此流，但要先刷新它。 abstract void flush() 刷新该流的缓冲。 void write(char[] cbuf) 写入字符数组。 abstract void write(char[] cbuf, int off, int len) 写入字符数组的某一部分。 void write(int c) 写入单个字符。 void write(String str) 写入字符串。 void write(String str, int off, int len) 写入字符串的某一部分。 现在以FIleWriter进行分析 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个过程中,实例化FileWrite的过程中，打开文件流，然后通过StreamEncoder将字符编码为字节写入相应的流，在写入的过程中主要是通过这个StreamEncoder实例进行写入数据。下面我们看一看read的具体实现过程:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在StreamDecoder中,主要用的是四个方法，write(char cbuf[], int off, int len), implWrite(char cbuf[], int off, int len),flushLeftoverChar(CharBuffer cb, boolean endOfInput),writeBytes四个方法，现在以write(char cbuf[],int offset,int length) 作为入口进行分析,构建相应的字符缓冲区，将数据给写存入，然后在将数据通过编码的形式写入字节缓冲区，最终将数据写入流中. char –&gt;CharBuffer –&gt; ByteBuffer –&gt;输出流 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316package sun.nio.cs;import java.io.*;import java.nio.*;import java.nio.channels.*;import java.nio.charset.*;public class StreamEncoder extends Writer&#123; private static final int DEFAULT_BYTE_BUFFER_SIZE = 8192; private volatile boolean isOpen = true; private void ensureOpen() throws IOException &#123; if (!isOpen) throw new IOException("Stream closed"); &#125; // Factories for java.io.OutputStreamWriter public static StreamEncoder forOutputStreamWriter(OutputStream out, Object lock, String charsetName) throws UnsupportedEncodingException &#123; String csn = charsetName; if (csn == null) csn = Charset.defaultCharset().name(); try &#123; if (Charset.isSupported(csn)) return new StreamEncoder(out, lock, Charset.forName(csn)); &#125; catch (IllegalCharsetNameException x) &#123; &#125; throw new UnsupportedEncodingException (csn); &#125; public static StreamEncoder forOutputStreamWriter(OutputStream out, Object lock, Charset cs) &#123; return new StreamEncoder(out, lock, cs); &#125; public static StreamEncoder forOutputStreamWriter(OutputStream out, Object lock, CharsetEncoder enc) &#123; return new StreamEncoder(out, lock, enc); &#125; // Factory for java.nio.channels.Channels.newWriter public static StreamEncoder forEncoder(WritableByteChannel ch, CharsetEncoder enc, int minBufferCap) &#123; return new StreamEncoder(ch, enc, minBufferCap); &#125; // -- Public methods corresponding to those in OutputStreamWriter -- // All synchronization and state/argument checking is done in these public // methods; the concrete stream-encoder subclasses defined below need not // do any such checking. public String getEncoding() &#123; if (isOpen()) return encodingName(); return null; &#125; public void flushBuffer() throws IOException &#123; synchronized (lock) &#123; if (isOpen()) implFlushBuffer(); else throw new IOException("Stream closed"); &#125; &#125; public void write(int c) throws IOException &#123; char cbuf[] = new char[1]; cbuf[0] = (char) c; write(cbuf, 0, 1); &#125; public void write(char cbuf[], int off, int len) throws IOException &#123; synchronized (lock) &#123; //确保打开 ensureOpen(); if ((off &lt; 0) || (off &gt; cbuf.length) || (len &lt; 0) || ((off + len) &gt; cbuf.length) || ((off + len) &lt; 0)) &#123; throw new IndexOutOfBoundsException(); &#125; else if (len == 0) &#123; return; &#125; implWrite(cbuf, off, len); &#125; &#125; public void write(String str, int off, int len) throws IOException &#123; /* Check the len before creating a char buffer */ if (len &lt; 0) throw new IndexOutOfBoundsException(); char cbuf[] = new char[len]; str.getChars(off, off + len, cbuf, 0); write(cbuf, 0, len); &#125; public void flush() throws IOException &#123; synchronized (lock) &#123; ensureOpen(); implFlush(); &#125; &#125; public void close() throws IOException &#123; synchronized (lock) &#123; if (!isOpen) return; implClose(); isOpen = false; &#125; &#125; private boolean isOpen() &#123; return isOpen; &#125; // -- Charset-based stream encoder impl -- private Charset cs; private CharsetEncoder encoder; private ByteBuffer bb; // Exactly one of these is non-null private final OutputStream out; private WritableByteChannel ch; // Leftover first char in a surrogate pair private boolean haveLeftoverChar = false; private char leftoverChar; private CharBuffer lcb = null; private StreamEncoder(OutputStream out, Object lock, Charset cs) &#123; this(out, lock, cs.newEncoder() .onMalformedInput(CodingErrorAction.REPLACE) .onUnmappableCharacter(CodingErrorAction.REPLACE)); &#125; private StreamEncoder(OutputStream out, Object lock, CharsetEncoder enc) &#123; super(lock); this.out = out; this.ch = null; this.cs = enc.charset(); this.encoder = enc; // This path disabled until direct buffers are faster if (false &amp;&amp; out instanceof FileOutputStream) &#123; ch = ((FileOutputStream)out).getChannel(); if (ch != null) bb = ByteBuffer.allocateDirect(DEFAULT_BYTE_BUFFER_SIZE); &#125; if (ch == null) &#123; bb = ByteBuffer.allocate(DEFAULT_BYTE_BUFFER_SIZE); &#125; &#125; private StreamEncoder(WritableByteChannel ch, CharsetEncoder enc, int mbc) &#123; this.out = null; this.ch = ch; this.cs = enc.charset(); this.encoder = enc; this.bb = ByteBuffer.allocate(mbc &lt; 0 ? DEFAULT_BYTE_BUFFER_SIZE : mbc); &#125; private void writeBytes() throws IOException &#123; bb.flip(); int lim = bb.limit(); int pos = bb.position(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); if (rem &gt; 0) &#123; if (ch != null) &#123; if (ch.write(bb) != rem) assert false : rem; &#125; else &#123; out.write(bb.array(), bb.arrayOffset() + pos, rem); &#125; &#125; bb.clear(); &#125; private void flushLeftoverChar(CharBuffer cb, boolean endOfInput) throws IOException &#123; //如果不是遗留字符 直接返回 if (!haveLeftoverChar &amp;&amp; !endOfInput) return; if (lcb == null) //分配容量为2的字符缓冲区 lcb = CharBuffer.allocate(2); else lcb.clear(); //如果是遗留字符则将其put进去 if (haveLeftoverChar) lcb.put(leftoverChar); if ((cb != null) &amp;&amp; cb.hasRemaining()) //添加传入的字符缓冲区数据 lcb.put(cb.get()); //切换为读取状态 lcb.flip(); while (lcb.hasRemaining() || endOfInput) &#123; //将字符编码为相应的字节并存入到字节缓冲区 CoderResult cr = encoder.encode(lcb, bb, endOfInput); if (cr.isUnderflow()) &#123; if (lcb.hasRemaining()) &#123; leftoverChar = lcb.get(); if (cb != null &amp;&amp; cb.hasRemaining()) flushLeftoverChar(cb, endOfInput); return; &#125; break; &#125; if (cr.isOverflow()) &#123; assert bb.position() &gt; 0; writeBytes(); continue; &#125; cr.throwException(); &#125; haveLeftoverChar = false; &#125; void implWrite(char cbuf[], int off, int len) throws IOException &#123; //将字符数组包装到缓冲区中。 CharBuffer cb = CharBuffer.wrap(cbuf, off, len); //如果有遗留字符，flushLeftoverChar方式先将遗留字符添加进去再添加字符缓冲区的数据 if (haveLeftoverChar) flushLeftoverChar(cb, false); //如果字符缓冲区有数据，通过编码的方式将其添加到字节缓冲区 while (cb.hasRemaining()) &#123; CoderResult cr = encoder.encode(cb, bb, false); if (cr.isUnderflow()) &#123; assert (cb.remaining() &lt;= 1) : cb.remaining(); //如果字符缓冲区中只剩下一个数据先将其保存作为遗留字符，下次读取再写入，防止这个字需要两个字符 if (cb.remaining() == 1) &#123; haveLeftoverChar = true; leftoverChar = cb.get(); &#125; break; &#125; if (cr.isOverflow()) &#123; assert bb.position() &gt; 0; //将字节缓冲区数据写入到具体的流中 writeBytes(); continue; &#125; cr.throwException(); &#125; &#125; void implFlushBuffer() throws IOException &#123; if (bb.position() &gt; 0) writeBytes(); &#125; void implFlush() throws IOException &#123; implFlushBuffer(); if (out != null) out.flush(); &#125; void implClose() throws IOException &#123; flushLeftoverChar(null, true); try &#123; for (;;) &#123; CoderResult cr = encoder.flush(bb); if (cr.isUnderflow()) break; if (cr.isOverflow()) &#123; assert bb.position() &gt; 0; writeBytes(); continue; &#125; cr.throwException(); &#125; if (bb.position() &gt; 0) writeBytes(); if (ch != null) ch.close(); else out.close(); &#125; catch (IOException x) &#123; encoder.reset(); throw x; &#125; &#125; String encodingName() &#123; return ((cs instanceof HistoricallyNamedCharset) ? ((HistoricallyNamedCharset)cs).historicalName() : cs.name()); &#125;&#125; 参考链接Java之IO流—字节流http://blog.csdn.net/qq_28261343/article/details/52678681 Java之IO流—字符流http://blog.csdn.net/qq_28261343/article/details/52684071]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper选举机制]]></title>
    <url>%2F2018%2F01%2F18%2Fzookeeper%2F2018-01-11%2F</url>
    <content type="text"><![CDATA[znode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;zookeeper集群自身维护了一套数据结构。这个存储结构是一个树形结构，其上的每一个节点，我们称之为“znode” lookForLeader方法:]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLite简介]]></title>
    <url>%2F2018%2F01%2F13%2Fsqlite%2F2018-01-13%2F</url>
    <content type="text"><![CDATA[SQLite的组成 parser tokenize virtual machine SQLite的数据结构 Connections和Statements&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Connection和statement是执行SQL命令涉及的两个主要数据结构，几乎所有通过API进行的操作都要用到它们。一个连接(Connection)代表在一个独立的事务环境下的一个连接A (connection represents a single connection to a database as well as a single transaction context)。每一个statement都和一个connection关联，它通常表示一个编译过的SQL语句，在内部，它以VDBE字节码表示。Statement包括执行一个命令所需要一切，包括保存VDBE程序执行状态所需的资源，指向硬盘记录的B-树游标，以及参数等等 B-tree和pager&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个connection可以有多个database对象—一个主要的数据库以及附加的数据库，每一个数据库对象有一个B-tree对象，一个B-tree有一个pager对象(这里的对象不是面向对象的“对象”，只是为了说清楚问题)。 Statement最终都是通过connection的B-tree和pager从数据库读或者写数据，通过B-tree的游标(cursor)遍历存储在页面(page)中的记录。游标在访问页面之前要把数所从disk加载到内存，而这就是pager的任务。任何时候，如果B-tree需要页面，它都会请求pager从disk读取数据，然后把页面(page)加载到页面缓冲区(page cache)，之后，B-tree和与之关联的游标就可以访问位于page中的记录了。 如果cursor改变了page，为了防止事务回滚，pager必须采取特殊的方式保存原来的page。总的来说，pager负责读写数据库，管理内存缓存和页面（page），以及管理事务，锁和崩溃恢复(这些在事务一节会详细介绍)。 总之，关于connection和transaction，你必须知道两件事： (1)对数据库的任何操作，一个连接存在于一个事务下。 (2)一个连接决不会同时存在多个事务下。]]></content>
      <categories>
        <category>SQLite</category>
      </categories>
      <tags>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLite源码解析-操作数据库]]></title>
    <url>%2F2018%2F01%2F13%2Fsqlite%2F2018-01-14%2F</url>
    <content type="text"><![CDATA[SQLite基本操作方式 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SQLite的基本操作方式同大多数关系型数据库是一样的执行sqlite3_open打开数据库,若返回结果是SQLITE_OK即0则表示打开成功,利用sqlite3_exec执行相应的sql语句,返回函数同样是执行状态,SQLITE_OK表示执行成功,最终利用sqlite3_close关闭数据库 SQLite打开数据库&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SQLite打开数据库可以通过三种方式sqlite3_open、sqlite3_open_v2、sqlite3_open16他们的具体实现都是调用openDatabase,只有具体的参数有所不同，openDatabase的具体过程中进行了初始化和创建校对规则，以及加载相应的数据驱动。 123456789101112131415SQLITE_API int sqlite3_open(const char *zFilename, sqlite3 **ppDb )&#123; return openDatabase(zFilename, ppDb, SQLITE_OPEN_READWRITE | SQLITE_OPEN_CREATE, 0);&#125;SQLITE_API int sqlite3_open_v2( const char *filename, /* Database filename (UTF-8) */ sqlite3 **ppDb, /* OUT: SQLite db handle 返回一个数据库连接对象*/ int flags, /* Flags */ const char *zVfs /* Name of VFS module to use 数据库连接应该使用的操作系统接口的sqlite3_vfs对象的名称*/)&#123; return openDatabase(filename, ppDb, (unsigned int)flags, zVfs);&#125;SQLITE_API int sqlite3_open16(const void *zFilename, sqlite3 **ppDb) SQLite执行sql语句 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sqlite3exec()函数一次可以执行多条SQL命令。执行完成后返回一个SQLITE success/failure代码，还会将错误信息写到*pzErrMsg中。首先进行安全检查以及检查sql语句是为空，在获取线程锁，调用sqlite3Error将errCode赋值为SQLITE_OK之后调用sqlte3_prepare_v2编译一条语句，通过sqlite3_step进行具体执行，如果SQL是查询，查询结果中的每一行都会调用xCallback()函数。pArg为传递给xCallback()的第一个参数。如果xCallback==NULL，即使对查询命令也没有回叫调用。 sqlte3_prepare_v2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;它调用sqlite3GetToken对SQL语句zSql进行分词，然后调用sqlite3Parser进行语法分析。而sqlite3Parser在语法规则发生规约时调用相应的opcode生成子例程，生成opcode。 SQLite关闭数据库]]></content>
      <categories>
        <category>SQLite</category>
      </categories>
      <tags>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLite网址大全]]></title>
    <url>%2F2018%2F01%2F13%2Fsqlite%2F2018-01-14-1%2F</url>
    <content type="text"><![CDATA[SQLite API手册http://www.yfvb.com/help/sqlite3/ SQLite源码分析http://huili.github.io/sqlite/sqliteintro.html]]></content>
      <categories>
        <category>SQLite</category>
      </categories>
      <tags>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 源码分析一 zookeeper启动]]></title>
    <url>%2F2018%2F01%2F11%2Fzookeeper%2F2018-01-04%2F</url>
    <content type="text"><![CDATA[zookeeper启动类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; zookeeper的启动方式是调用目录下的zkServer.sh start 由此我们应该到这个文件下找相应的启动入口，最终我找到的org.apache.zookeeper.server.quorum.QuorumPeerMain #z ookeeper的启动流程 zookeeper的启动通过调用zkServer.sh start启动，这个过程实际上是以QuorumPeerMain的main方法为函数入口,具体步骤如下: 1调用初始化方法 1.1初始化过程中实例化QuorumPeerConfig解析配置文件 1.2创建文件清理器DatadirCleanupManager并启动 1.3判断启动方式，验证条件如果是有参数或者解析配置文件过程中给config的Server句柄具有相应的集群服务则通过运行配置文件启动，否则就是一个伪分布式直接通过ZooKeeperServerMain主函数启动服务 2.正常退出程序 runFromConfig利用配置文件启动过程位置: QuorumPeerMain.java runFromConfig &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 运行配置文件的过程中，主要将quorumPeer启动。具体步骤如下:1.注册JMX,作用是可以通过jconsole或者浏览器来管理各个对象2.创建ServerCnxnFactory这个server工厂,默认是NIOServerCnxnFactory,可以在配置文件中进行配置, 属性名是zookeeper.serverCnxnFactory, 在zookeeper中还提供另一种工程NettyServerCnxnFactory3.根据传入的地址通过configure方法打开socket通道，绑定ip地址,并注册相应的选择键4.实例化QuorumPeer并启动-待补录 启动QuorumPeerQuorumPeerMain.java&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.加载基础数据&nbsp;&nbsp; 2.创建相应的服务工厂&nbsp;&nbsp; 3.startLeaderElection开始选举&nbsp;&nbsp; 4.调用start启动当前线程即本实例方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.1 利用JMX注册MbeanServer jmxQuorumBean和LocalPeerBean，RemotePeerBean 这里是根据myId来进行注册，myId是在加载属性实例化QuorumPeer的时候注入。id是QuorumServer的属性，其在解析属性的过程中解析server.0=SY-001:2888:3888 这个0就是解析的id所以如果myid 和这个id相等则采用LocalPeerBean, myid和这个id定义不同则是RemotePeerBean， 可以看出其实定义的主zookeeper节点&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2在循环的过程中有四种 LOOKING, FOLLOWING, LEADING, OBSERVING针对当前状态执行相应的指令 1234LOOKING，竞选状态。这里是进行选举算法，将票投给谁setCurrentVote(makeLEStrategy().lookForLeader());FOLLOWING，随从状态，同步leader状态，参与投票。OBSERVING，观察状态,同步leader状态，不参与投票。LEADING，领导者状态。 quorumPeer.joinQuorumPeerMain.java 主要目的是为了让quorumPeer启动完毕,才继续向下执行。]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成5--搭建maven私服(nexus)]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-4%2F</url>
    <content type="text"><![CDATA[安装nexus]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成4--tomcat部署svnadmin]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-3%2F</url>
    <content type="text"><![CDATA[安装tomcat部署svnadmin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将svnadmin.war包部署到tomcat的服务器上解压,编辑配置文件 vim /usr/local/svn-tomcat/webapps/svnadmin/WEB-INF/jdbc.properties #tail -f -n 500 /usr/local/dubbo-tomcat/logs/catalina.out]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成3--安装jsvnadmin管理平台]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-2%2F</url>
    <content type="text"><![CDATA[安装mysql1yum install mysql-server mysql mysql-devel 启动1service mysqld start 查看1chkconfig --list | grep mysqld 设置开机启动1chkconfig mysqld on 设置mysql密码1mysqladmin -u root password root 进行远程访问赋权1Sql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION; Sql&gt; FLUSH PRIVILEGES;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成2--linux下安装svn]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-1%2F</url>
    <content type="text"><![CDATA[下载1yum install mod_dav_svn subversion 重启Apache服务&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里重启的是持续集成1中的httpd服务 123重启命令: service httpd restart查看命令: ls /etc/httpd/modules/ | grep svn查看版本: svn --version 创建svn库创建文件夹命令: 12mkdir /svn/``` 编辑subversion.conf文件 vim /etc/httpd/conf.d/subversion.conf DAV svnSVNListParentPath on SVNParentPath /svnAuthType BasicAuthName “Subversion repositories” AuthUserFile /svn/passwd.http AuthzSVNAccessFile /svn/authz Require valid-userRedirectMatch ^(/svn)$ $1/12# 创建/svn/passwd.http 和 /svn/authz 文件 touch /svn/passwd.httptouch /svn/authzservice httpd restart 重启apache服务```]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成1--linux下安装httpd]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04%2F</url>
    <content type="text"><![CDATA[下载 1yum install httpd httpd-devel 启动 1service httpd start 修改端口： 12vim /etc/httpd/conf/httpd.confServerName localhost:80 然后就可以根据ip进行访问]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 架构介绍]]></title>
    <url>%2F2018%2F01%2F04%2Fzookeeper%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[zookeeper介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。其具体功能如下: 文件系统 通知机制 ZooKeeper典型的应用场景&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zookeeper 从设计模式角度来看，是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper 就将负责通知已经在 Zookeeper 上注册的那些观察者做出相应的反应，从而实现集群中类似 Master/Slave 管理模式 统一命名服务（Name Service）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式应用中，通常需要有一套完整的命名规则，既能够产生唯一的名称又便于人识别和记住,而Name Service已经是 Zookeeper 内置的功能，所以你只要调用Zookeeper的 API就能实现。如调用create接口就可以很容易创建一个目录节点。 配置管理（Configuration Management）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;配置的管理在分布式应用环境中很常见，例如同一个应用系统需要多台 PC Server 运行，但是它们运行的应用系统的某些配置项是相同的，如果要修改这些相同的配置项，那么就必须同时修改每台运行这个应用系统的 PC Server，这样非常麻烦而且容易出错。像这样的配置信息完全可以交给 Zookeeper 来管理，将配置信息保存在 Zookeeper 的某个目录节点中，然后将所有需要修改的应用机器监控配置信息的状态，一旦配置信息发生变化，每台应用机器就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中。 集群管理（Group Membership）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zookeeper 能够很容易的实现集群管理的功能，如有多台 Server 组成一个服务集群，那么必须要一个“总管”知道当前集群中每台机器的服务状态，一旦有机器不能提供服务，集群中其它集群必须知道，从而做出调整重新分配服务策略。同样当增加集群的服务能力时，就会增加一台或多台Server，同样也必须让“总管”知道。Zookeeper 不仅能够帮你维护当前的集群中机器的服务状态，而且能够帮你选出一个“总管”，让这个总管来管理集群，这就是 Zookeeper 的另一个功能 Leader Election &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;它们的实现方式都是在 Zookeeper 上创建一个 EPHEMERAL 类型的目录节点，然后每个 Server 在它们创建目录节点的父目录节点上调用getChildren(String path,boolean watch) 方法并设置 watch 为 true，由于是 EPHEMERAL 目录节点，当创建它的 Server 死去，这个目录节点也随之被删除，所以 Children 将会变化，这时 getChildren上的 Watch 将会被调用，所以其它 Server 就知道已经有某台 Server 死去了。新增 Server 也是同样的原理。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zookeeper 如何实现 Leader Election，也就是选出一个 Master Server。和前面的一样每台 Server 创建一个 EPHEMERAL 目录节点，不同的是它还是一个 SEQUENTIAL 目录节点，所以它是个 EPHEMERAL_SEQUENTIAL 目录节点。之所以它是 EPHEMERAL_SEQUENTIAL 目录节点，是因为我们可以给每台 Server 编号，我们可以选择当前是最小编号的 Server 为 Master，假如这个最小编号的 Server 死去，由于是 EPHEMERAL 节点，死去的 Server 对应的节点也被删除，所以当前的节点列表中又出现一个最小编号的节点，我们就选择这个节点为当前 Master。这样就实现了动态选择 Master，避免了传统意义上单 Master 容易出现单点故障的问题 12345678910111213141516protected InetSocketAddress findLeader() &#123; InetSocketAddress addr = null; // Find the leader by id Vote current = self.getCurrentVote(); for (QuorumServer s : self.getView().values()) &#123; if (s.id == current.getId()) &#123; addr = s.addr; break; &#125; &#125; if (addr == null) &#123; LOG.warn("Couldn't find the leader with id = " + current.getId()); &#125; return addr; &#125; 共享锁（Locks）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;共享锁在同一个进程中很容易实现，但是在跨进程或者在不同 Server 之间就不好实现了。Zookeeper 却很容易实现这个功能，实现方式也是需要获得锁的 Server 创建一个 EPHEMERAL_SEQUENTIAL 目录节点，然后调用 getChildren方法获取当前的目录节点列表中最小的目录节点是不是就是自己创建的目录节点，如果正是自己创建的，那么它就获得了这个锁，如果不是那么它就调用 exists(String path, boolean watch) 方法并监控 Zookeeper 上目录节点列表的变化，一直到自己创建的节点是列表中最小编号的目录节点，从而获得锁，释放锁很简单，只要删除前面它自己所创建的目录节点就行了。 队列管理参考链接: ZooKeeper学习第一期—Zookeeper简单介绍https://www.cnblogs.com/wuxl360/p/5817471.html Zookeeper的功能以及工作原理https://www.cnblogs.com/felixzh/p/5869212.html 分布式服务框架Zookeeper(IBM)https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql一些常用sql语句]]></title>
    <url>%2F2018%2F01%2F03%2Fmysql%2F2018-01-03%2F</url>
    <content type="text"><![CDATA[E1获取当前时间select now&amp;#40; &amp;#4 #E2获取当前时间戳 123SELECT UNIX_TIMESTAMPSELECT UNIX_TIMESTAMP*1000 毫秒级SELECT UNIX_TIMESTAMP*1000*1000 微秒级]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机vm-tools安装]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-01-1%2F</url>
    <content type="text"><![CDATA[虚拟机vm-tools安装##centos下 ###点击vm fusion下安装VMware Tools ###解压 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在点击上面安装之后会出现一个CD文件，里面存在VmwareTools-10* 的包 这是一个tar.gz的压缩包，现在我们通过tar -zxvf 文件名tar.gz来进行解压（可以自行存放位置） ###安装 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;转到上面解压文件的目录vmware-tools-distrib 下，运行./vmware-install.pl 在安装的过程中不断点击enter 直到安装完成，之后调用reboot重新启动就完成了]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware Fusion实现虚拟机拷贝]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-01-2%2F</url>
    <content type="text"><![CDATA[参考链接:http://www.linuxidc.com/Linux/2017-06/144720.htm #拷贝&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;点击需要拷贝的文件,然后进行复制-粘贴,如下: #打开&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;打开相应的虚拟机&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;点击已拷贝 #修改hostname vi /etc/sysconfig/network 将”HOSTNAME=”后的内容改成机器名，比如centos.04，保存退出 vi /etc/hosts 在最后添加一行 127.0.0.1 centos.04，保存退出 如果要马上生效，可再输入hostname centos.04，否则要重启才能生效 shutdown -h now关机 注意最好执行这个命令，下面生成mac地址需要关机 #给新虚拟机的网卡，生成一个新mac地址在设置里面点击网络适配器生成一个新的mac地址 #修改网卡信息 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vi /etc/udev/rules.d/70-persistent-net.rules&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;编辑这个文件，它记录了当前机器上的所有网卡信息根据刚才新生成的mac地址，找到对应的行，把网卡名称改成 eth0，其它的全删除 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vi /etc/sysconfig/network-scripts/ifcfg-eth0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;把uuid随便改一个数字，保证它跟原来的系统不同即可，然后把HWADDR改成新生成的mac地址，保存退出]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 环境安装]]></title>
    <url>%2F2018%2F01%2F01%2Fzookeeper%2F2017-12-30%2F</url>
    <content type="text"><![CDATA[解压tar -zvxf zookeeper-3.4.5.tar.gz -C /usr/local #配置环境变量vim /etc/profile 12export ZOOKEEPER_HOME =/usr/local/zookeeper-3.4.5export PATH=$ZOOKEEPER_HOME/bin:$PATH source /etc/profile #修改配置文件 相对路径:/ZOOKEEPER_HOME/conf/zoo.cfg 修改 1.datadir=/ZOOKEEPER_HOME/data 2.server0=ip地址。。。。。。 ZOOKEEPER_HOME下面创建data文件并创建脚本文件myid #启动 1zkServer.sh start]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux修改ip为静态ip]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-01-3%2F</url>
    <content type="text"><![CDATA[#修改网卡信息 vi /etc/sysconfig/network-scripts/ifcfg-eth0 123456BOOTPROTO=&quot;static&quot; #注意：原值为dhcpHWADDR=&quot;00:0c:29:ba:18:25&quot;IPV6INIT=&quot;yes&quot;NM_CONTROLLED=&quot;yes&quot;ONBOOT=&quot;yes&quot;TYPE=&quot;Ethernet&quot; 以下是修改为静态时需要加IPADDR=192.168.1.200GATEWAY=192.168.1.1NETMASK=255.255.255.0 重启网卡service network restart #设置DNS vim /ect/resolv.conf 12nameserver 8.8.8.8nameserver 114.114.114.114]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux卸载openJDK安装sun下jdk]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[卸载openJDK查看相应openJDK的信息rpm -qa | grep java 123tzdata-java-2014g-1.el6.noarchjava-1.6.0-openjdk-1.6.0.0-11.1.13.4.el6.x86_64java-1.7.0-openjdk-1.7.0.65-2.5.1.2.el6_5.x86_64 删除相应的文件123rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-11.1.13.4.el6.x86_64rpm -e --nodeps java-1.7.0-openjdk-1.7.0.65-2.5.1.2.el6_5.x86_64rpm -e --nodeps tzdata-java-2014g-1.el6.noarch 安装JDK找到相应的jdk资源，将其解压到指定目录 配置环境打开环境变量存储文件vi /etc/profile 12345JAVA_HOME=/usr/java/jdk1.7JRE_HOME=/usr/java/jdk1.7/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH CLASSPATH 编译环境变量存储文件source /etc/profile]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Working principle of the Netty]]></title>
    <url>%2F2017%2F12%2F20%2Fnetty%2Fnetty3%2F</url>
    <content type="text"></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉堆]]></title>
    <url>%2F2017%2F12%2F17%2Farithmetic%2F2018-01-26%2F</url>
    <content type="text"><![CDATA[二叉堆是二叉堆是完全二元树或者是近似完全二元树,所以利用数组很好实现,a[0]保持为空,从a[1]开始，实现上浮，下沉，比较，交换四个方法. 上浮:当前节点比父节点大，while循环不断交换 下沉:当前节点比子节点小，while循环 循环条件2k小于数组长度，同较大的一个进行交换 基于上面，插入一个元素插入到最后，不断调用上浮就可以 删除最大元素，获取数组a[1]的元素，与最后一个交换，然后将这个位置置空，并返回，实现有序，则需将调换到第一个的元素进行下沉ihh 时间复杂度:插入lgN+1 删除2lgN]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Huffman Coding Greedy Algorithm]]></title>
    <url>%2F2017%2F12%2F17%2Farithmetic%2Fhuffmancoding%2F</url>
    <content type="text"><![CDATA[What is Huffman Coding&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Huffman coding is Data Compression Algorithm,Based on lengths of assigned codes based on frequencies, Variable Length Codes are known as Prefix Codes The GoalTry to reduce the total number of bits used without losing any information The process of Huffman coding Scan text to be compressed and tally occurrence of all characters. Sort or prioritize characters based on number of occurrences in text. Build Huffman code tree based on prioritized list. Perform a traversal of tree to determine all code words. Scan text again and create new file using the Huffman codes. The Schematic diagram Code process #The code of Huffman&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Now, we specific display Huffman code. By code, we analysis of its process step by step. ##The structure of Node&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In its structure, We define the frequency to statistic the number of occurrences of the characters. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Node implements Comparable&lt;Node&gt; &#123; private String chars = ""; private int frequence = 0; private Node parent; private Node leftNode; private Node rightNode; @Override public int compareTo(Node node) &#123; return frequence - node.frequence; &#125; public String getChars() &#123; return chars; &#125; public void setChars(String chars) &#123; this.chars = chars; &#125; public int getFrequence() &#123; return frequence; &#125; public void setFrequence(int frequence) &#123; this.frequence = frequence; &#125; public Node getParent() &#123; return parent; &#125; public void setParent(Node parent) &#123; this.parent = parent; &#125; public Node getLeftNode() &#123; return leftNode; &#125; public void setLeftNode(Node leftNode) &#123; this.leftNode = leftNode; &#125; public Node getRightNode() &#123; return rightNode; &#125; public void setRightNode(Node rightNode) &#123; this.rightNode = rightNode; &#125;&#125; statistic frequency of every character&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this part, Our main purpose is to statistic frequency of every character. so we structure a HashMap to store data, when we get data from the HashMap by key, we add one to the number of it and store into The value of the current mapping as new value 12345678910111213public static Map&lt;Character, Integer&gt; statistics(char[] charArray) &#123; Map&lt;Character, Integer&gt; map = new HashMap&lt;Character, Integer&gt;(); for (char c : charArray) &#123; Character character = new Character(c); if (map.containsKey(character)) &#123; map.put(character, map.get(character) + 1); &#125; else &#123; map.put(character, 1); &#125; &#125; return map; &#125; build a tree&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PriorityQueue will Retrieves and removes the head of this queue, or returns null if this queue is empty. PriorityQueue maintain a heap what you can poll the smallest element every time actually. so we will obtain the two minimum elements and build Node, By this way, we will get a complete binary tree.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The idea of algorithm: transfer statistical information to Node and stored in a priority queue. each time it pop-up two minimum frequency nodes the queue to build a new parent node. The frequency of characters is the sum of two pop-up Node.he first pop-up as the left child node, the back one as the right child node, and the newly built parent node inside the queue. Repeat the above action N-1 times. 1234567891011121314151617181920212223242526272829303132333435private static Tree buildTree(Map&lt;Character, Integer&gt; statistics, List&lt;Node&gt; leafs) &#123; Character[] keys = statistics.keySet().toArray(new Character[0]); PriorityQueue&lt;Node&gt; priorityQueue = new PriorityQueue&lt;Node&gt;(); for (Character character : keys) &#123; Node node = new Node(); node.setChars(character.toString()); node.setFrequence(statistics.get(character)); priorityQueue.add(node); leafs.add(node); &#125; int size = priorityQueue.size(); for (int i = 1; i &lt;= size - 1; i++) &#123; Node node1 = priorityQueue.poll(); Node node2 = priorityQueue.poll(); Node sumNode = new Node(); sumNode.setChars(node1.getChars()+node2.getChars()); sumNode.setFrequence(node1.getFrequence()+node2.getFrequence()); sumNode.setLeftNode(node1); sumNode.setRightNode(node2); node1.setParent(sumNode); node2.setParent(sumNode); priorityQueue.add(sumNode); &#125; Tree tree = new Tree(); tree.setRoot(priorityQueue.poll()); return tree; &#125; encode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this part, we will invoke buildTree to let the Node produce associated. searching up from the leaf node of current character, if the character is the parent node of the left node, add 0 before the coded character , otherwise if it is right node, add 1, until the root node. 12345678910111213141516171819public static String encode(String originalStr, Map&lt;Character, Integer&gt; statistics) &#123; if (originalStr == null || originalStr.equals("")) &#123; return ""; &#125; char[] charArray = originalStr.toCharArray(); List&lt;Node&gt; leafNodes = new ArrayList&lt;Node&gt;(); buildTree(statistics, leafNodes); Map&lt;Character, String&gt; encodInfo = buildEncodingInfo(leafNodes); StringBuffer buffer = new StringBuffer(); for (char c : charArray) &#123; Character character = new Character(c); buffer.append(encodInfo.get(character)); &#125; return buffer.toString(); &#125; decode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Huffman coding algorithm can ensure any binary code is not going to be another code prefix, decoding is simple, each in turn to take out the binary, search down from the root, 1 to the right, 0 to the left, to the leaf node (hit), return a root node continue to repeat the action 12345678910111213141516171819202122232425262728293031323334public static String decode(String binaryStr, Map&lt;Character, Integer&gt; statistics) &#123; if (binaryStr == null || binaryStr.equals("")) &#123; return ""; &#125; char[] binaryCharArray = binaryStr.toCharArray(); LinkedList&lt;Character&gt; binaryList = new LinkedList&lt;Character&gt;(); int size = binaryCharArray.length; for (int i = 0; i &lt; size; i++) &#123; binaryList.addLast(new Character(binaryCharArray[i])); &#125; List&lt;Node&gt; leafNodes = new ArrayList&lt;Node&gt;(); Tree tree = buildTree(statistics, leafNodes); StringBuffer buffer = new StringBuffer(); while (binaryList.size() &gt; 0) &#123; Node node = tree.getRoot(); do &#123; Character c = binaryList.removeFirst(); if (c.charValue() == '0') &#123; node = node.getLeftNode(); &#125; else &#123; node = node.getRightNode(); &#125; &#125; while (!node.isLeaf()); buffer.append(node.getChars()); &#125; return buffer.toString();&#125; The Test Result123456789101112public static void main(String[] args) &#123; String oriStr = "Huffman codes compress data very effectively"; Map&lt;Character, Integer&gt; statistics = statistics(oriStr.toCharArray()); String encodedBinariStr = encode(oriStr, statistics); String decodedStr = decode(encodedBinariStr, statistics); System.out.println("Original sstring: " + oriStr+"\n"); System.out.println("Huffman encoed binary string: " + encodedBinariStr+"\n"); System.out.println("decoded string from binariy string: " + decodedStr); &#125; result: 12345Original sstring: Huffman codes compress data very effectivelyHuffman encoed binary string: 11111011010101001011100100011011001111000010111011011001011110000101110011011100111011001100101111101100000011000011111101010011000001110101001010111000001111111111101011101000000decoded string from binariy string: Huffman codes compress data very effectively]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EightQueen]]></title>
    <url>%2F2017%2F12%2F17%2Farithmetic%2F2017-12-18%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The N queens puzzle is the problem of placing N chess queens on an N×N chessboard so that no two queens threaten each other. Thus, a solution requires that no two queens share the same row, column, or diagonal.For example, below is one of the solution for famous 8 Queen problem. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Backtracking Algorithm for N-Queen is already discussed here. In backtracking solution we backtrack when we hit a dead end. In Branch and Bound solution, after building a partial solution, we figure out that there is no point going any deeper as we are going to hit a dead end. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Let’s begin by describing backtracking solution. “The idea is to place queens one by one in different columns, starting from the leftmost column. When we place a queen in a column, we check for clashes with already placed queens. In the current column, if we find a row for which there is no clash, we mark this row and column as part of the solution. If we do not find such a row due to clashes, then we backtrack and return false.” &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.For the 1st Queen, there are total 8 possibilities as we can place 1st Queen in any row of first column. Let’s place Queen 1 on row 3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.After placing 1st Queen, there are 7 possibilities left for the 2nd Queen. But wait, we don’t really have 7 possibilities. We cannot place Queen 2 on rows 2, 3 or 4 as those cells are under attack from Queen 1. So, Queen 2 has only 8 – 3 = 5 valid positions left.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.After picking a position for Queen 2, Queen 3 has even fewer options as most of the cells in its column are under attack from the first 2 Queens. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We need to figure out an efficient way of keeping track of which cells are under attack. In previous solution we kept an 8­-by­-8 Boolean matrix and update it each time we placed a queen, but that required linear time to update as we need to check for safe cells. Basically, we have to ensure 4 things: No two queens share a column. No two queens share a row. No two queens share a top-right to left-bottom diagonal. No two queens share a top-left to bottom-right diagonal &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Number 1 is automatic because of the way we store the solution. For number 2, 3 and 4, we can perform updates in O(1) time. The idea is to keep three Boolean arrays that tell us which rows and which diagonals are occupied. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Lets do some pre-processing first. Let’s create two N x N matrix one for / diagonal and other one for \ diagonal. Let’s call them slashCode and backslashCode respectively. The trick is to fill them in such a way that two queens sharing a same /­diagonal will have the same value in matrix slashCode, and if they share same \­diagonal, they will have the same value in backslashCode matrix. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; For an N x N matrix, fill slashCode and backslashCode matrix using below formula – cols[N] != cols[N-1] cols[N] != cols[N-1]-1 cols[N]!=cols[N-1]+1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class Queen8 &#123; public static int num = 0; //累计方案总数 public static final int MAXQUEEN = 8;//皇后个数，同时也是棋盘行列总数 public static int[] cols = new int[MAXQUEEN]; //定义cols数组，表示8列棋子摆放情况 public Queen8() &#123; //核心函数 getArrangement(0); System.out.print("/n"); System.out.println(MAXQUEEN+"皇后问题有"+num+"种摆放方法。"); &#125; public void getArrangement(int n)&#123; //遍历该列所有不合法的行，并用rows数组记录，不合法即rows[i]=true boolean[] rows = new boolean[MAXQUEEN]; for(int i=0;i&lt;n;i++)&#123; rows[cols[i]]=true; int d = n-i; if(cols[i]-d &gt;= 0)rows[cols[i]-d]=true; if(cols[i]+d &lt;= MAXQUEEN-1)rows[cols[i]+d]=true; &#125; for(int i=0;i&lt;MAXQUEEN;i++)&#123; //判断该行是否合法 if(rows[i])continue; //设置当前列合法棋子所在行数 cols[n] = i; //当前列不为最后一列时 if(n&lt;MAXQUEEN-1)&#123; getArrangement(n+1); &#125;else&#123; //累计方案个数 num++; //打印棋盘信息 printChessBoard(); &#125; &#125; &#125; public void printChessBoard()&#123; System.out.print("第"+num+"种走法 /n"); for(int i=0;i&lt;MAXQUEEN;i++)&#123; for(int j=0;j&lt;MAXQUEEN;j++)&#123; if(i==cols[j])&#123; System.out.print("0 "); &#125;else System.out.print("+ "); &#125; System.out.print("/n"); &#125; &#125; public static void main(String args[])&#123; Queen8 queen = new Queen8(); &#125; &#125; output: 12345678910111213141516171819第1种走法 0 + + + + + + + + + + + + + 0 + + + + + 0 + + + + + + + + + + 0 + 0 + + + + + + + + + 0 + + + + + + + + + 0 + + + + 0 + + + + + 第2种走法 0 + + + + + + + + + + + + + 0 + + + + 0 + + + + + + + + + 0 + + + + + + + + + 0 + 0 + + + + + + + + + + 0 + + + + + 0 + + + + + .......]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat源码解读六 tomcat中的session生命历程]]></title>
    <url>%2F2017%2F12%2F16%2Ftomcat%2F2018-01-23-11%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;session的作用是在一次会话中（从打开浏览器到关闭浏览器同当前服务器的交流）当客户端第一次请求session对象时候，服务器会为客户端创建一个session，并将通过特殊算法算出一个session的ID，用来标识该session对象，当浏览器下次（session继续有效时）请求别的资源的时候，浏览器会sessionID放置到请求头中，服务器接收到请求后就得到该请求的sessionID，服务器根据当前sessionId找到对应的session实例。 UML关系图 Session的获取api&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;session的创建与tomcat请求没有什么很大的直接关系,主要是在进行servlet处理（jsp最终也是被编译成servlet）来获取，获取方式如下： 123456/获取此次会话的session//如果参数为true表明当没有获取到对应的session实例会自己创建一个,且默认为真HttpSession session = request.getSession(true);HttpSession session1 = request.getSession();//如果参数为false表明当没有获取到对应的session实例则会返回空HttpSession session2 = request.getSession(false); sessionId的获取&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里是在request请求已经解析了头部的情况下,根据配置文件获取相应的参数最终得到sessionId的值,这个值得优先级是URL&gt;cookie 最终这个值将会注册到request属性中去 123456789101112131415161718192021/** * 这段代码的意义:向request中注入requestedSessionId并设置其是来与URL Cookie 还是SSL * 具体判断是通过requestedSessionURL和requestedSessionSSL这些布尔类型 * 另一个作用是在下文的重定向过程决定是否需要将sessionCookieName给加入进去以;XXX=XXXXXX形式 * 在域名泛解析过程中针对访问不同的二级域名,sessionId是默认不共享的 * */String sessionID;if (request.getServletContext().getEffectiveSessionTrackingModes().contains(SessionTrackingMode.URL)) &#123; //根据当前sessionCookieName从request的参数中获取相应sessionId， sessionID = request.getPathParameter(SessionConfig.getSessionUriParamName(request.getContext())); //如果sessionId不为空,将其注入request的requestedSessionId属性 if (sessionID != null) &#123; request.setRequestedSessionId(sessionID); //获取解析到说明请求是从URL中解析出来 request.setRequestedSessionURL(true); &#125;&#125;//在cookies和SSL中寻找sessionId,如果requestedSessionId不存在,则直接注入parseSessionCookiesId(request);parseSessionSslId(request);sessionID = request.getRequestedSessionId(); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里会有个问题,在URL中都是以k,v的形式存在，那么这个k是来自于哪个地方,一下代码展示： 1234567891011121314151617181920212223242526272829303132 * 获取配置的sessionCookieName * 第一种是配置Web应用的时候 Context标签下 * 1 &lt;Context path='' docBase='ROOT' sessionCookiePath='/' sessionCookieName='' /&gt; * 2 &lt;session-config&gt; * &lt;cookie-config&gt; * &lt;name id="sessionId"&gt;sessionName&lt;/name&gt; * &lt;/cookie-config&gt; * &lt;/session-config&gt; * */private static String getConfiguredSessionCookieName(Context context) &#123; // Priority is: // 1. Cookie name defined in context // 2. Cookie name configured for app // 3. Default defined by spec if (context != null) &#123; //获取sessionCookieName,这个来自于解析自己的Context标签 String cookieName = context.getSessionCookieName(); if (cookieName != null &amp;&amp; cookieName.length() &gt; 0) &#123; return cookieName; &#125; //获取定义在应用的中的web.xml session-config/cookie-config SessionCookieConfig scc = context.getServletContext().getSessionCookieConfig(); cookieName = scc.getName(); if (cookieName != null &amp;&amp; cookieName.length() &gt; 0) &#123; return cookieName; &#125; &#125; return null;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据代码可以看出k可以是在配置Context应用的时候添加,也可以是在web.xml配置，这样就可以获取对应的sessionId。那么这个sessionId使用户自己产生还是怎么来的？一般直接在URL上添加,或者可以通过过滤器等方式将请求进行处理,由于缺少具体开发环境所以不能够很全面的解述.针对在URL上处理会有一个问题,就是重定向,这样不必担心,因为在CoyoteAdapter.java中对重定向处理会获取URL中是否存在,如果存在则直接添加, 代码如下： 123456789101112131415161718MessageBytes redirectPathMB = request.getMappingData().redirectPath;if (!redirectPathMB.isNull()) &#123; String redirectPath = URLEncoder.DEFAULT.encode(redirectPathMB.toString(), "UTF-8"); String query = request.getQueryString(); //如果SessionId是从URL中解析出来的,则直接添加到URL上面 if (request.isRequestedSessionIdFromURL()) &#123; redirectPath = redirectPath + ";" + SessionConfig.getSessionUriParamName( request.getContext()) + "=" + request.getRequestedSessionId(); &#125; //添加参数 if (query != null) &#123; redirectPath = redirectPath + "?" + query; &#125; response.sendRedirect(redirectPath); request.getContext().logAccess(request, response, 0, true); return false;&#125; session的实例化过程 session的实例化是在具体的Servlet方法中,调用getSession的API之后,首先是利用门面模式获取到真正的Connector/Request,而后其方法如下： 12345678910/**返回与当前请求相关的session*/@Overridepublic HttpSession getSession(boolean create) &#123; //创建session的核心方法 Session session = doGetSession(create); if (session == null) &#123; return null; &#125; return session.getSession();&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个方法中首先调用doGetSession在这个过程中我们创建了HttpSession（利用了门面模式）然后将其作为StandardSession的句柄,最终返回的是StandardSession实例，利用其getSession获取对应的HttpSession即我们所需要的session, doGetSession的方法如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102protected Session doGetSession(boolean create) &#123; //获取与当前请求对应的Context Context context = getContext(); if (context == null) &#123; return (null); &#125; /** * 如果存在session并且可利用则直接返回,如果不可利用则将session置为空 * 不可利用是在request的recycle中设置为不可利用 */ if ((session != null) &amp;&amp; !session.isValid()) &#123; session = null; &#125; if (session != null) &#123; return (session); &#125; //获取会话管理器 Manager manager = context.getManager(); if (manager == null) &#123; return (null); // Sessions are not supported &#125; if (requestedSessionId != null) &#123; try &#123; //根据sessionId从会话管理器中找到对应session session = manager.findSession(requestedSessionId); &#125; catch (IOException e) &#123; session = null; &#125; if ((session != null) &amp;&amp; !session.isValid()) &#123; session = null; &#125; if (session != null) &#123; session.access(); return (session); &#125; &#125; //session为false表示如果没有获取到对应session则直接返回空 if (!create) &#123; return (null); &#125; if (response != null &amp;&amp; context.getServletContext().getEffectiveSessionTrackingModes().contains(SessionTrackingMode.COOKIE) &amp;&amp; response.getResponse().isCommitted()) &#123; throw new IllegalStateException(sm.getString("coyoteRequest.sessionCreateCommitted")); &#125; //获取客户端提供的sessionId String sessionId = getRequestedSessionId(); if (requestedSessionSSL) &#123; //在server.xml文件中配置sessionCookiePath="/"，并且该sessionId来自于cookie &#125; else if (("/".equals(context.getSessionCookiePath()) &amp;&amp; isRequestedSessionIdFromCookie())) &#123; if (context.getValidateClientProvidedNewSessionId()) &#123; boolean found = false; /** * 找到当前主机下所有的web应用获取其会话管理器 * 从对应会话管理器中找若找到相应sessionId不为空，则跳出循环 * * 这样做的目的是可能在不同web应用中sessionId需要保持相同 * 多个web应用构成一个整体的项目 */ for (Container container : getHost().findChildren()) &#123; Manager m = ((Context) container).getManager(); if (m != null) &#123; try &#123; if (m.findSession(sessionId) != null) &#123; found = true; break; &#125; &#125; catch (IOException e) &#123; &#125; &#125; &#125; //如果没有发现则sessionId置为空,表明当前sessionId没有被任何会话管理器使用 if (!found) &#123; sessionId = null; &#125; &#125; &#125; else &#123; sessionId = null; &#125; //创建一个sessionId session = manager.createSession(sessionId); //将session添加到cookie中去 利用Set-Cookie将其添加到HTTP首部 if (session != null &amp;&amp; context.getServletContext().getEffectiveSessionTrackingModes() .contains(SessionTrackingMode.COOKIE)) &#123; Cookie cookie = ApplicationSessionCookieConfig.createSessionCookie( context, session.getIdInternal(), isSecure()); response.addSessionCookieInternal(cookie); &#125; if (session == null) &#123; return null; &#125; session.access(); return session;&#125;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A example of Netty]]></title>
    <url>%2F2017%2F12%2F12%2Fnetty%2Fnetty1%2F</url>
    <content type="text"><![CDATA[The introduce of Netty&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; we often use an HTTP client library to retrieve information from a web server and to invoke a remote procedure call via web services. Netty is an NIO client server framework which enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server development. A example of NettyThe Main class&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this part, we introduce a simple process for a netty service. At first, we create multithreaded event loop that handles I/O operation and add them into corresponding server and add corresponding channel to transmit message. In this channel, we will create corresponding handle to receive the message, In this process, some handle can encode or decode the message. In the end, it will wait the message from client. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class DiscardServer &#123; private int port; public DiscardServer(int port) &#123; this.port = port; &#125; public void run() throws Exception &#123; //bossGroup will accept an incoming connection EventLoopGroup bossGroup = new NioEventLoopGroup(); //workerGroup handles the traffic of the accepted connection once the bossGroup accepts the connection //and registers the accepted the connection to the worker EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; //ServerBootstrap is a helper class that sets up a server. you can set up the server using channel ServerBootstrap serverBootstrap = new ServerBootstrap(); //we specify to use the NioServerSocketChannel class which is used to a new channel to accept incoming connection serverBootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) //the handler specified here will always be evaluated by a newly channel //The ChannelInitializer's purpose is to help user configure a new channel and add some handler which can implement network application .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new DiscardServerHandler()); &#125; &#125;) //you can set some socket option by this way //option() is for the NioServerSocketChannel that accepts incoming connections. //childOption() is for the Channels accepted by the parent ServerChannel, which is NioServerSocketChannel in this case. .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); // Bind and start to accept incoming connections. ChannelFuture f = serverBootstrap.bind(port).sync(); System.out.println("before closeFuture.."); // Wait until the server socket is closed. // In this example, this does not happen, but you can do that to gracefully // shut down your server. f.channel().closeFuture().sync(); System.out.println("after closeFuture.."); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; int port; if (args.length &gt; 0) &#123; port = Integer.parseInt(args[0]); &#125; else &#123; port = 8080; &#125; new DiscardServer(port).run(); &#125;&#125;``` ## The corresponding handle &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; In this handle, we override the channelRead method from the interface of ChannelInboundHandler to receive the message and do some operation. ```java/*** * * ChannelInboundHandlerAdapter is a implementation for ChannelHandlerAdapter (abstract class) and ChannelInboundHandler(interface) * ChannelInboundHandler provides various event handler methods that you can override * For now, it is just enough to extend ChannelInboundHandlerAdapter rather than to implement the handler interface by yourself. * */public class DiscardServerHandler extends ChannelInboundHandlerAdapter &#123; /** * we override the channelRead method from the interface of ChannelInboundHandler * Invoked when the current channel has read a message from the peer. * * @param ctx this variable provide various operations that enable you to trigger various I/O operations and event * @param msg receive the message from channel * */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf in = (ByteBuf) msg; char temp ; try &#123; ctx.write("you message:"); while (in.isReadable()) &#123; temp = (char)in.readByte(); System.out.print(temp); ctx.write(temp); System.out.flush(); &#125; ctx.flush(); &#125; finally &#123; ReferenceCountUtil.release(msg); &#125; &#125; /** * The exceptionCaught() event handler method s called with a Throwable * when an exception was raised by Netty due to an I/O error or by a handler implementation due to the exception thrown while processing events * */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // Close the connection when an exception is raised. System.out.println("channelRead..."); cause.printStackTrace(); ctx.close(); &#125;&#125; ##The result of this example]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java NIO Selector]]></title>
    <url>%2F2017%2F12%2F11%2FNIO%2Fnio4%2F</url>
    <content type="text"><![CDATA[#The Selector, SelectableChannel, and SelectionKey Classes Selector&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The Selector class manages information about a set of registered channel and their readies state. Channels are registered with selectors, and a selector can be asked to update readies state of channels. When doing so, the invoking thread can optionally indicate that it would prefer to be suspended until one of the registered channel is ready. ##]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QuickSort]]></title>
    <url>%2F2017%2F12%2F11%2Farithmetic%2FquickSort%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Like Merge Sort, QuickSort is a Divide and Conquer algorithm. It picks an element as pivot and partitions the given array around the picked pivot. There are many different versions of quickSort that pick pivot in different ways. 1.Always pick first element as pivot.2.Always pick last element as pivot (implemented below)3.Pick a random element as pivot.4.Pick median as pivot. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The key process in quickSort is partition(). Target of partitions is, given an array and an element x of array as pivot, put x at its correct position in sorted array and put all smaller elements (smaller than x) before x, and put all greater elements (greater than x) after x. All this should be done in linear time. Pseudo Code for recursive QuickSort function :12345678910111213/* low --&gt; Starting index, high --&gt; Ending index */quickSort(arr[], low, high)&#123; if (low &lt; high) &#123; /* pi is partitioning index, arr[p] is now at right place */ pi = partition(arr, low, high); quickSort(arr, low, pi - 1); // Before pi quickSort(arr, pi + 1, high); // After pi &#125;&#125; Partition Algorithm&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There can be many ways to do partition, following pseudo code adopts the method given in CLRS book. The logic is simple, we start from the leftmost element and keep track of index of smaller (or equal to) elements as i. While traversing, if we find a smaller element, we swap current element with arr[i]. Otherwise we ignore current element. 12345678910111213/* low --&gt; Starting index, high --&gt; Ending index */quickSort(arr[], low, high)&#123; if (low &lt; high) &#123; /* pi is partitioning index, arr[p] is now at right place */ pi = partition(arr, low, high); quickSort(arr, low, pi - 1); // Before pi quickSort(arr, pi + 1, high); // After pi &#125;&#125; Pseudo code for partition()12345678910111213141516171819202122232425/* This function takes last element as pivot, places the pivot element at its correct position in sorted array, and places all smaller (smaller than pivot) to left of pivot and all greater elements to right of pivot */partition (arr[], low, high)&#123; // pivot (Element to be placed at right position) pivot = arr[high]; i = (low - 1) // Index of smaller element for (j = low; j &lt;= high- 1; j++) &#123; // If current element is smaller than or // equal to pivot if (arr[j] &lt;= pivot) &#123; i++; // increment index of smaller element swap arr[i] and arr[j] &#125; &#125; swap arr[i + 1] and arr[high]) return (i + 1)&#125; Illustration of partition()12345678910111213141516171819202122232425262728293031323334353637arr[] = &#123;10, 80, 30, 90, 40, 50, 70&#125;Indexes: 0 1 2 3 4 5 6 low = 0, high = 6, pivot = arr[h] = 70Initialize index of smaller element, i = -1Traverse elements from j = low to high-1j = 0 : Since arr[j] &lt;= pivot, do i++ and swap(arr[i], arr[j])i = 0 arr[] = &#123;10, 80, 30, 90, 40, 50, 70&#125; // No change as i and j // are samej = 1 : Since arr[j] &gt; pivot, do nothing// No change in i and arr[]j = 2 : Since arr[j] &lt;= pivot, do i++ and swap(arr[i], arr[j])i = 1arr[] = &#123;10, 30, 80, 90, 40, 50, 70&#125; // We swap 80 and 30 j = 3 : Since arr[j] &gt; pivot, do nothing// No change in i and arr[]j = 4 : Since arr[j] &lt;= pivot, do i++ and swap(arr[i], arr[j])i = 2arr[] = &#123;10, 30, 40, 90, 80, 50, 70&#125; // 80 and 40 Swappedj = 5 : Since arr[j] &lt;= pivot, do i++ and swap arr[i] with arr[j] i = 3 arr[] = &#123;10, 30, 40, 50, 80, 90, 70&#125; // 90 and 50 Swapped We come out of loop because j is now equal to high-1.Finally we place pivot at correct position by swappingarr[i+1] and arr[high] (or pivot) arr[] = &#123;10, 30, 40, 50, 70, 90, 80&#125; // 80 and 70 Swapped Now 70 is at its correct place. All elements smaller than70 are before it and all elements greater than 70 are afterit. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// Java program for implementation of QuickSortclass QuickSort&#123; /* This function takes last element as pivot, places the pivot element at its correct position in sorted array, and places all smaller (smaller than pivot) to left of pivot and all greater elements to right of pivot */ int partition(int arr[], int low, int high) &#123; int pivot = arr[high]; int i = (low-1); // index of smaller element for (int j=low; j&lt;high; j++) &#123; // If current element is smaller than or // equal to pivot if (arr[j] &lt;= pivot) &#123; i++; // swap arr[i] and arr[j] int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; &#125; // swap arr[i+1] and arr[high] (or pivot) int temp = arr[i+1]; arr[i+1] = arr[high]; arr[high] = temp; return i+1; &#125; /* The main function that implements QuickSort() arr[] --&gt; Array to be sorted, low --&gt; Starting index, high --&gt; Ending index */ void sort(int arr[], int low, int high) &#123; if (low &lt; high) &#123; /* pi is partitioning index, arr[pi] is now at right place */ int pi = partition(arr, low, high); // Recursively sort elements before // partition and after partition sort(arr, low, pi-1); sort(arr, pi+1, high); &#125; &#125; /* A utility function to print array of size n */ static void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i]+" "); System.out.println(); &#125; // Driver program public static void main(String args[]) &#123; int arr[] = &#123;10, 7, 8, 9, 1, 5&#125;; int n = arr.length; QuickSort ob = new QuickSort(); ob.sort(arr, 0, n-1); System.out.println("sorted array"); printArray(arr); &#125;&#125; output: 12Sorted array:1 5 7 8 9 10]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基本指令]]></title>
    <url>%2F2017%2F12%2F11%2Flinux%2F2018-01-01%2F</url>
    <content type="text"><![CDATA[解压1tar -zxvf 文件名 移动文件移动命令mv 命令格式：mv [-fiv] source destination 参数说明： -f:force，强制直接移动而不询问 -i:若目标文件(destination)已经存在，就会询问是否覆盖 -u:若目标文件已经存在，且源文件比较新，才会更新 如将/test1目录下的file1复制到/test3 目录，并将文件名改为file2,可输入以下命令： mv /test1/file1 /test3/file2 重命名关机poweroff 立刻关机shutdown -h now 立刻关机shutdown -h 10 10分钟后自动关机 关闭防火墙关闭命令： service iptables stop永久关闭防火墙：chkconfig iptables off永久关闭需要两条语句都运行 关闭端口1lsof -i:]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java NIO channel]]></title>
    <url>%2F2017%2F12%2F11%2FNIO%2Fnio3%2F</url>
    <content type="text"><![CDATA[java NIO channel&emsp;&emsp; When it comes to NIO, the first New concept we approach is channel, we operate data by using it instead of stream in traditional IO. The introduce of channelWhat is channel?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Channels is the second invocation of java NIO, they used to transmit data to the corresponding entity in both sides of the channel. Channels are gateways through which the native I/O services of the operating system can be accessed with a minimum of overhead, and buffers are the internal endpoints used by channels to send and receive data. The feature of channel 1.channel both can read data also can write data2.channel can read or write data from asynchronous3.channel must have a buffer to transmit data The family of channeljava.nio.channels.Channel 接口： |--FileChannel |--SocketChannel |--ServerSocketChannel |--DatagramChannel The use of channel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In the above, we know about what is channel roughly. Now, we tell channel by using it. Copy file by channel1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public void copyFile()&#123; FileInputStream fis = null; FileOutputStream fos = null; //Getting channel FileChannel inChannel = null; FileChannel outChannel = null; try &#123; fis = new FileInputStream("1.txt"); fos = new FileOutputStream("2.txt"); inChannel = fis.getChannel(); outChannel = fos.getChannel(); //allocate specified size buffer ByteBuffer buf = ByteBuffer.allocate(1024); //Getting data from channel, and storage it in buffer while(inChannel.read(buf) != -1)&#123; buf.flip(); //Flips this buffer //write the data in the buffer into the channel outChannel.write(buf); //clear buffer, The position is set to zero, the limit is set to the capacity buf.clear(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; //handle corresponding exception &#125; &#125;``` &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; above the code, we get corresponding stream from File stream, then we write data to FileOutputStream. Now, we detail some of these method. `FileChannelImpl.open` will create corresponding instance.# A set of method of channel## getChannel()&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; `getChannel`method will Returns the unique FileChannel object associated with this file input stream.```java /** * * &lt;p&gt; The initial &#123;@link java.nio.channels.FileChannel#position() * position&#125; of the returned channel will be equal to the * number of bytes read from the file so far. Reading bytes from this * stream will increment the channel's position. Changing the channel's * position, either explicitly or by reading, will change this stream's * file position. * * @return the file channel associated with this file input stream * * @since 1.4 * @spec JSR-51 */ public FileChannel getChannel() &#123; synchronized (this) &#123; if (channel == null) &#123; channel = FileChannelImpl.open(fd, path, true, false, this); &#125; return channel; &#125; &#125; read(ByteBuffer dst)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; read is abstract method, it will read a sequence of bytes from this channel into the given buffer. Bytes are read starting at this channel’s current file position, and then file position is updated with the number of bytes actually read. 1234567891011121314151617181920212223public int read(ByteBuffer dst) throws IOException &#123; ensureOpen(); if (!readable) throw new NonReadableChannelException(); synchronized (positionLock) &#123; int n = 0; int ti = -1; try &#123; begin(); ti = threads.add(); if (!isOpen()) return 0; do &#123; n = IOUtil.read(fd, dst, -1, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); end(n &gt; 0); assert IOStatus.check(n); &#125; &#125; &#125; write(ByteBuffer src)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Writes a sequence of bytes to this channel from given buffer. 1234567891011121314151617181920212223public int write(ByteBuffer src) throws IOException &#123; ensureOpen(); if (!writable) throw new NonWritableChannelException(); synchronized (positionLock) &#123; int n = 0; int ti = -1; try &#123; begin(); ti = threads.add(); if (!isOpen()) return 0; do &#123; n = IOUtil.write(fd, src, -1, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); end(n &gt; 0); assert IOStatus.check(n); &#125; &#125; &#125;]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java NIO buffer]]></title>
    <url>%2F2017%2F12%2F10%2FNIO%2Fnio2%2F</url>
    <content type="text"><![CDATA[java NIO buffer&emsp;&emsp; A buffer Object is a container of a fixed amount of data, it acts as a block or staging area, where data can be stored and later retrieved.Buffers work hand in glove with channels, Channels are portals through which i/o transfers take place, and buffers are the sources or targets of those data transfers. The family of buffer in java nio &emsp;&emsp; From the system diagram, we can find each of the basic data types has their own corresponding buffer class. as follows: ByteBuffershortBufferCharBufferIntBufferLongBufferFloatBufferDoubleBufferMappedByteBuffer Attributes&emsp;&emsp; Buffer is mainly has four attributes Capacity: The maximum number of data elements the buffer can hold. The capacity is set when the buffer is created and can never be changed. Limit: The first element of the buffer that should not be read or written. In other words, the count of live elements in the buffer. Position:The index of next element to be read or written. The position is updated automatically by get() and put() methods. Mark: A remembered position,Mark() and reset() are used together. when we use Mark(), we will record the position so that calling reset() sets position = mark The following relationship between these four attributes always holds: 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity Buffer interface The Usage of Buffer&emsp;&emsp; Now, i show how to use it and explain the source code through it’s the implementation class — ByteBuffer The constructor of it12345678910ByteBuffer(int mark, int pos, int lim, int cap, byte[] hb, int offset) &#123; super(mark, pos, lim, cap); this.hb = hb; this.offset = offset; &#125; // Creates a new buffer with the given mark, position, limit, and capacity ByteBuffer(int mark, int pos, int lim, int cap) &#123; this(mark, pos, lim, cap, null, 0); &#125; &emsp;&emsp;&emsp; we can find the core of it invoke the superclass, at first we see the parent class constructor. it easy to find the superclass is Buffer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657Buffer(int mark, int pos, int lim, int cap) &#123; if (cap &lt; 0) throw new IllegalArgumentException("Negative capacity: " + cap); this.capacity = cap; limit(lim); position(pos); if (mark &gt;= 0) &#123; if (mark &gt; pos) throw new IllegalArgumentException("mark &gt; position: (" + mark + " &gt; " + pos + ")"); this.mark = mark; &#125; &#125; /** * Sets this buffer's limit. If the position is larger than the new limit * then it is set to the new limit. If the mark is defined and larger than * the new limit then it is discarded. * * @param newLimit * The new limit value; must be non-negative * and no larger than this buffer's capacity * * @return This buffer * * @throws IllegalArgumentException * If the preconditions on &lt;tt&gt;newLimit&lt;/tt&gt; do not hold */ public final Buffer limit(int newLimit) &#123; if ((newLimit &gt; capacity) || (newLimit &lt; 0)) throw new IllegalArgumentException(); limit = newLimit; if (position &gt; limit) position = limit; if (mark &gt; limit) mark = -1; return this; &#125; /** * Sets this buffer's position. If the mark is defined and larger than the * new position then it is discarded. * * @param newPosition * The new position value; must be non-negative * and no larger than the current limit * * @return This buffer * * @throws IllegalArgumentException * If the preconditions on &lt;tt&gt;newPosition&lt;/tt&gt; do not hold */ public final Buffer position(int newPosition) &#123; if ((newPosition &gt; limit) || (newPosition &lt; 0)) throw new IllegalArgumentException(); position = newPosition; if (mark &gt; position) mark = -1; return this; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this constructor, Main purpose is to give the corresponding handle to set the appropriate attribute values through the way of refs, these attributes was introduced in the above. Each method of them has corresponding judgment whether the property value whether meet the conditions. if not, it will throws corresponding exception. allocate a specify memory space12345//allocate a specify memory spaceByteBuffer buf = ByteBuffer.allocate(1024);System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); 1234result:010241024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In the beginning of allocate a memory space to buffer, we can find the property value of position is 0, property values of limit and capacity is the value of the incoming. Buffer after five put( )s123456String str = "Hello"; //put data in the bufferbuf.put(str.getBytes());System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); 1234result:510241024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Follow the above code, I convert a string into a byte array and store it the buf instance. From the result, we can find the position has some change, limit and capacity don’t have any change. The model is shown. Switch to Read data mode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Continuing to follow the above code, we begin to read the data which we put in the above. At first we switch to read data mode by calling the flip() method. 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; 1234buf.flip();System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); result: 123051024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Flips this buffer. The limit is set to the current position and then the position is set to zero. If the mark is defined then it is discarded.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; After invoking the flip(), we begin to read the data in the buffer. Read data from buffer123456byte[] dst = new byte[buf.limit()];buf.get(dst);System.out.println(new String(dst, 0, dst.length));System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); result: 1234hello551024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; From the code, we can find we build a byte array to read data from buffer. after reading it, The property value of position changed. The principle of it is after we invoke the get() method It can read the Reads the byte at this buffer’s current position, and then increments the position. The process of get() method is in its implementation class. Rewinds this buffer12345public final Buffer rewind() &#123; position = 0; mark = -1; return this; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The position is set to zero and the mark is discarded. Invoking this method before a sequence of channel-write or get operations, assuming that the limit has already been set appropriately. Clears this buffer&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The position is set to zero, the limit is set to the capacity, and the mark is discarded.This method does not actually erase the data in the buffer, but it is named as if it did because it will most often be used in situations in which that might as well be the case. 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; hasRemaining()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Tells whether there are any elements between the current position and the limit. if true, there is at least one element remaining in this buffer 123public final boolean hasRemaining() &#123; return position &lt; limit; &#125; The Compare BuffersDirect byte buffers&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Direct byte buffers are usually the best choice for I/O operations. By design, they support the most efficient I/O mechanism available to the JVM.Direct buffers are optimal for I/O, but they may be more expensive to create than non direct byte buffers. The memory used by direct buffers is allocated by calling through to native, operating system-specific code, by passing the standard JVM heap. Setting up and tearing down direct buffers could be significantly more expensive than heap-resident buffers, depending on the host operating system and JVM implementation. The memory-storage areas of direct buffers are not subject to garbage collection because they are outside the standard JVM heap. —reference O’reilly java NIO The Method of creationstatic ByteBuffer allocateDirect(int capacity) 12345678910111213141516171819/** * Allocates a new direct byte buffer. * * &lt;p&gt; The new buffer's position will be zero, its limit will be its * capacity, its mark will be undefined, and each of its elements will be * initialized to zero. Whether or not it has a * &#123;@link #hasArray backing array&#125; is unspecified. * * @param capacity * The new buffer's capacity, in bytes * * @return The new byte buffer * * @throws IllegalArgumentException * If the &lt;tt&gt;capacity&lt;/tt&gt; is a negative integer */public static ByteBuffer allocateDirect(int capacity) &#123; return new DirectByteBuffer(capacity);&#125; 12345678910111213141516171819202122232425262728DirectByteBuffer(int cap) &#123; // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; base = unsafe.allocateMemory(size); &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null;&#125; Non direct byte buffers&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Non direct byte buffers can be passed to channels, but doing so may incur a performance penalty. It’s usually not possible for a non direct buffer to be the target of a native I/O operation. If you pass a non direct ByteBuffer object to a channel for write, the channel may implicitly do the following on each call: Create a temporary direct ByteBuffer object. Copy the content of the non direct buffer to the temporary buffer. Perform the low-level I/O operation using the temporary buffer. The temporary buffer object goes out of scope and is eventually garbage collected. —reference O‘reilly java NIO The Method of creation123456789101112131415161718192021/** * Allocates a new byte buffer. * * &lt;p&gt; The new buffer's position will be zero, its limit will be its * capacity, its mark will be undefined, and each of its elements will be * initialized to zero. It will have a &#123;@link #array backing array&#125;, * and its &#123;@link #arrayOffset array offset&#125; will be zero. * * @param capacity * The new buffer's capacity, in bytes * * @return The new byte buffer * * @throws IllegalArgumentException * If the &lt;tt&gt;capacity&lt;/tt&gt; is a negative integer */ public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity); &#125; 12345678910111213141516171819HeapByteBuffer(int cap, int lim) &#123; super(-1, 0, lim, cap, new byte[cap], 0); &#125;HeapByteBuffer(byte[] buf, int off, int len) &#123; super(-1, off, off + len, buf.length, buf, 0);&#125;protected HeapByteBuffer(byte[] buf, int mark, int pos, int lim, int cap, int off) &#123; super(mark, pos, lim, cap, buf, off); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We can see it invoke superclass’s constructor, so its data will store in the Heap.]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The introduce of NIO]]></title>
    <url>%2F2017%2F12%2F09%2FNIO%2Fnio1%2F</url>
    <content type="text"><![CDATA[The introduce of NIOWhat is NIO？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; java.nio (non-blocking I/O) is a collection of Java programming language APIs that offer features for intensive I/O operations. It was introduced with the J2SE 1.4 release of Java by Sun Microsystems to complement an existing standard I/O —reference wiki The compare between NIO and IO IO NIO Stream Oriented Buffer Oriented Blocking IO Non Blocking IO Selectors The function of NIO&emsp;&emsp; When it comes to NIO, we should what is IO. In the traditional IO, we read or store data in the form of stream, so it is easy to cause obstruction that we difficult calls in multiple threads.But in NIO,The problem has a good way to solve it, the way is that we convey information by channel. in the channel, we can construct the corresponding buffer to transfer data. so we can say it is base on Buffer Oriented.]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat源码解读五 Tomcat中Request的生命历程]]></title>
    <url>%2F2017%2F11%2F16%2Ftomcat%2F2018-01-23-10%2F</url>
    <content type="text"><![CDATA[Request在tomcat中是一个非常核心的的实例，下面以NIO为例来解读一下在各个时期下的状态（其实在Tomcat的几种模式中到了这里之后的处理都是差不多的） 创建coyote/Request 这个request并不是我们最终在servlet中使用的Request,它是tomcat内部处理请求的一种有效方法,其创建过程是在接收到客户请求处理套接字构建Processor具体实现类的构造器中构建，以NIO模式为例则是在实例化请求处理类Http11NioProcessor时候构建，具体执行流程如下： Http11NioProcessor.java 12345678910111213public Http11NioProcessor(int maxHttpHeaderSize, NioEndpoint endpoint, int maxTrailerSize, Set&lt;String&gt; allowedTrailerHeaders, int maxExtensionSize, int maxSwallowSize) &#123; super(endpoint); inputBuffer = new InternalNioInputBuffer(request, maxHttpHeaderSize); request.setInputBuffer(inputBuffer); outputBuffer = new InternalNioOutputBuffer(response, maxHttpHeaderSize); response.setOutputBuffer(outputBuffer); initializeFilters(maxTrailerSize, allowedTrailerHeaders, maxExtensionSize, maxSwallowSize);&#125; AbstractHttp11Processor.java 1234public AbstractHttp11Processor(AbstractEndpoint&lt;S&gt; endpoint) &#123; super(endpoint); userDataHelper = new UserDataHelper(getLog());&#125; AbstractProcessor.java 123456789public AbstractProcessor(AbstractEndpoint&lt;S&gt; endpoint) &#123; this.endpoint = endpoint; asyncStateMachine = new AsyncStateMachine(this); request = new Request(); response = new Response(); response.setHook(this); request.setResponse(response); request.setHook(this);&#125; 根据这个过程不难看出在实例化中逐级显示调用父级有参构造器，将对应的endpoint赋给Processor实现类的句柄,而后继续实例化Request,并将当前实例注入到新构建的request实例,另外response也被注入request作为句柄。 Coyote/Request的执行与结束 Coyote/Request的执行与结束主要是在Processor. process在这个过程中会获取RequestInfo这个句柄其是一个request初始化实例句柄,在这个方法中通过setRequestLineReadTimeout方法解析了请求行如Method URL HTTP/1.1利用parseRequestLine剩余的首部信息最终调用request中相关的方法将解析的信息(大部分是MessageByte)注入到其成员属性中(详见requets解析http头部请求),然后进行的是调用Adapter的service方法进行处理（见下一小节）,之后利用endRequest将当前请求处理完成,在这个过程还包含将流给提交http中去,最后调用nextRequest将当前request实例部分属性置空，所以当前实例依旧存在。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public SocketState process(SocketWrapper&lt;S&gt; socketWrapper) throws IOException &#123; //获取请求信息句柄,其在定义的时候直接初始化的一个RequestInfo实例 RequestInfo rp = request.getRequestProcessor(); //设置RequestInfo的状态为解析状态 stage_parse rp.setStage(org.apache.coyote.Constants.STAGE_PARSE); 。。。。。。 while (!getErrorState().isError() &amp;&amp; keepAlive &amp;&amp; !comet &amp;&amp; !isAsync() &amp;&amp; upgradeToken == null &amp;&amp; !endpoint.isPaused()) &#123; 。。。。。。 //设置请求阅读时间,以及将socketInputStream中的数据写入到buf setRequestLineReadTimeout(); //if判断里只是解析了第一行，方法名 请求URL 协议 if (!getInputBuffer().parseRequestLine(keptAlive)) &#123; //如果解析失败，处理未完成的请 if (handleIncompleteRequestLineRead()) &#123; break; &#125;。。。。。。。。 &#125; if (!getErrorState().isError()) &#123; //设置过滤器准备解析 rp.setStage(org.apache.coyote.Constants.STAGE_PREPARE); try &#123; //解析请求，根据url将对应的Host Context Wrapper匹配到该请request的属性中 prepareRequest(); &#125; catch (Throwable t) &#123; 。。。。。。。。 &#125; &#125; //最大的长连接数 if (maxKeepAliveRequests == 1) &#123; keepAlive = false; &#125; else if (maxKeepAliveRequests &gt; 0 &amp;&amp; socketWrapper.decrementKeepAlive() &lt;= 0) &#123; keepAlive = false; &#125; // 在适配器中执行请求 if (!getErrorState().isError()) &#123; //设置request的状态为开始调用适配器的service rp.setStage(org.apache.coyote.Constants.STAGE_SERVICE); //调用适配器的service方法 getAdapter().service(request, response); 。。。。。。。 &#125; rp.setStage(org.apache.coyote.Constants.STAGE_ENDINPUT); if (!isAsync() &amp;&amp; !comet) &#123; 。。。。。。 endRequest(); &#125; rp.setStage(org.apache.coyote.Constants.STAGE_ENDOUTPUT); if (!isAsync() &amp;&amp; !comet || getErrorState().isError()) &#123; request.updateCounters(); if (getErrorState().isIoAllowed()) &#123; getInputBuffer().nextRequest(); getOutputBuffer().nextRequest(); &#125; &#125; 。。。。。。 rp.setStage(org.apache.coyote.Constants.STAGE_KEEPALIVE); &#125; rp.setStage(org.apache.coyote.Constants.STAGE_ENDED); &#125; 创建Coonnector/Request和Connector/Response 这两个实例和是从相应的Coyote对应实例的Notes 数组中获取的,如果没有则实例化一个并且注入，这是因为Coyote和Coonnector中相关实例是一一对应,只不过Coyote主要是负责和http打交道而Coonnector是和程序员打交道，但是请注意我们并不是直接使用的Coonnector中Request/Response。后面讲述 1234567891011121314151617181920212223242526//从org.apache.coyote.Request的note数组属性中获取Request对象Request request = (Request) req.getNote(ADAPTER_NOTES);//从org.apache.coyote.Response的note数组属性中获取Response对象Response response = (Response) res.getNote(ADAPTER_NOTES);//解析：ADAPTER_NOTES=1 这是因为notes这个数组不知存放了相应request/Response实例 还有cookie等 1代表的是Request/Responseif (request == null) &#123; //创建一个connector的request对象 request = connector.createRequest(); //将Coyote中request注入连接器中 request.setCoyoteRequest(req); response = connector.createResponse(); response.setCoyoteResponse(res); //request response相互关联 request.setResponse(response); response.setRequest(request); //设置为notes req.setNote(ADAPTER_NOTES, request); res.setNote(ADAPTER_NOTES, response); req.getParameters().setQueryStringEncoding (connector.getURIEncoding());&#125;if (connector.getXpoweredBy()) &#123; response.addHeader("X-Powered-By", POWERED_BY);&#125; Coonnector/Request和Connector/Response的执行过程 其创建之后就直接通过获取service不断调用管道一下向下执行找到对应的servlet进行执行，其过程如下： connector.getService().getContainer().getPipeline().getFirst().invoke(request, response); 在这个过程中，针对Request/Response的生命历程，我们应该提的是StandardWrapperValve这个阀门执行的代码是如下： filterChain.doFilter(request.getRequest(),response.getResponse()) 123456public HttpServletRequest getRequest() &#123; if (facade == null) &#123; facade = new RequestFacade(this); &#125; return facade;&#125; 可以看出在这里采用了外观模式创建了RequestFacade实例,并作为参数不断向下传递,这就是我们在servlet中使用的RequestFacade这个实例在servlet执行完毕,接着管道继续向下执到finishRequest， finishResponse完成当前请求，其中finishResponse是将最终的相应数据给发送到客户端 Coonnector/Request和Connector/Response的结束处理 Request/Response也不是直接从内存释放,仅仅只是其中部分属性给置空,下一个socket请求的时候调用的是对应的Processor具体实现类则可以直接进行获取。置空代码如下： 12345678if (!comet &amp;&amp; !async) &#123; request.recycle(); response.recycle();&#125; else &#123; request.clearEncoders(); response.clearEncoders();&#125; 由于Request请求跟浏览器无关,可能多次请求是一个Request实例，也可能是不同实例，但是在请求中Request实例中对应的成员属性都被清空,所以可以说Request的作用域是单个请求，Response也是同样的道理]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat源码解读四 tomcat中的processer]]></title>
    <url>%2F2017%2F11%2F15%2Ftomcat%2F2018-01-23-9%2F</url>
    <content type="text"><![CDATA[Processor是一个接口，针对于不同协议下具有不同的具体实现类，其实现类的具体功能是处理http请求,主要是对协议进行解析，状态处理以及响应。然后起一个中间作用转发到 Adater,下面是其类的关系图 其实现类中我们常用的http协议，所以一般是左边的部分,用红线标注 循环队列 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849protected static class RecycledProcessors&lt;P extends Processor&lt;S&gt;, S&gt; extends SynchronizedStack&lt;Processor&lt;S&gt;&gt; &#123; private final transient AbstractConnectionHandler&lt;S,P&gt; handler; protected final AtomicInteger size = new AtomicInteger(0); public RecycledProcessors(AbstractConnectionHandler&lt;S,P&gt; handler) &#123; this.handler = handler; &#125; @SuppressWarnings("sync-override") // Size may exceed cache size a bit @Override public boolean push(Processor&lt;S&gt; processor) &#123; //获取Processor能够缓存的大小 int cacheSize = handler.getProtocol().getProcessorCache(); boolean offer = cacheSize == -1 ? true : size.get() &lt; cacheSize; //向栈中压入当前processor boolean result = false; if (offer) &#123; result = super.push(processor); if (result) &#123; size.incrementAndGet(); &#125; &#125; //取消当前processor实例的JMX if (!result) handler.unregister(processor); return result; &#125; @SuppressWarnings("sync-override") // OK if size is too big briefly @Override public Processor&lt;S&gt; pop() &#123; Processor&lt;S&gt; result = super.pop(); if (result != null) &#123; size.decrementAndGet(); &#125; return result; &#125; @Override public synchronized void clear() &#123; Processor&lt;S&gt; next = pop(); while (next != null) &#123; handler.unregister(next); next = pop(); &#125; super.clear(); size.set(0); &#125; &#125; 在讲述Processor的获取以及处理过程之前先看一个类,姑且命名为循环队列, 它主要是继承了SynchronizedStack这个栈（tomcat自己实现）里面实现了进栈出栈两种方法。 Processor的创建 根据栈中执行的流程可以看出调用的是协议句柄的抽象类中的process方法，所以针对于四种模式其实现过程大致相同，具体代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232public SocketState process(SocketWrapper&lt;S&gt; wrapper, SocketStatus status) &#123; //如果socketWrapper为空则证明不存在socket则直接将状态设置为CLOSED if (wrapper == null) &#123; return SocketState.CLOSED; &#125; //获取当前SocketWrapper实例对应的NIO通道 S socket = wrapper.getSocket(); if (socket == null) &#123; //什么也不做 socket已经关闭 return SocketState.CLOSED; &#125; /** * 从connections中根据socket获取Processor，如果没有则在下面创建 connections句柄类型Map&lt;S,Processor&lt;S&gt;&gt; * 在以下情况下connections中存在值 * 1.websocket中 * 2.异步servlet * 3.发送文件 * */ Processor&lt;S&gt; processor = connections.get(socket); if (status == SocketStatus.DISCONNECT &amp;&amp; processor == null) &#123; // Nothing to do. Endpoint requested a close and there is no // longer a processor associated with this socket. return SocketState.CLOSED; &#125; wrapper.setAsync(false); //标记当前线程是否是容器线程 set则是容器线程 ContainerThreadMarker.set(); /** * * 创建一个Http11NioProcessor 实例里面构造了request 和response成员变量 * 各封装了一个InternalNioInputBuffer实例 * 其中request中封装了成员属性名inputBuffer * response中封装了成员属性名outputBuffer * */ try &#123; if (processor == null) &#123; processor = recycledProcessors.pop(); &#125; if (processor == null) &#123; processor = createProcessor(); &#125; initSsl(wrapper, processor); SocketState state = SocketState.CLOSED; Iterator&lt;DispatchType&gt; dispatches = null; do &#123; if (dispatches != null) &#123; // Associate the processor with the connection as // these calls may result in a nested call to process() connections.put(socket, processor); DispatchType nextDispatch = dispatches.next(); if (processor.isUpgrade()) &#123; state = processor.upgradeDispatch( nextDispatch.getSocketStatus()); &#125; else &#123; state = processor.asyncDispatch( nextDispatch.getSocketStatus()); &#125; &#125; else if (processor.isComet()) &#123; state = processor.event(status); &#125; else if (processor.isUpgrade()) &#123; state = processor.upgradeDispatch(status); &#125; else if (status == SocketStatus.DISCONNECT) &#123; // Comet and upgrade need to see DISCONNECT but the // others don't. NO-OP and let socket close. &#125; else if (processor.isAsync() || state == SocketState.ASYNC_END) &#123; state = processor.asyncDispatch(status); if (state == SocketState.OPEN) &#123; // release() won't get called so in case this request // takes a long time to process, remove the socket from // the waiting requests now else the async timeout will // fire getProtocol().endpoint.removeWaitingRequest(wrapper); // There may be pipe-lined data to read. If the data // isn't processed now, execution will exit this // loop and call release() which will recycle the // processor (and input buffer) deleting any // pipe-lined data. To avoid this, process it now. state = processor.process(wrapper); &#125; &#125; else if (status == SocketStatus.OPEN_WRITE) &#123; // Extra write event likely after async, ignore state = SocketState.LONG; &#125; else &#123; //这个是在第一次请求的时候执行 state = processor.process(wrapper); &#125; //根据异步asyncStateMachine的状态设置Socket的状态 if (state != SocketState.CLOSED &amp;&amp; processor.isAsync()) &#123; state = processor.asyncPostProcess(); &#125; if (state == SocketState.UPGRADING) &#123; // Get the HTTP upgrade handler UpgradeToken upgradeToken = processor.getUpgradeToken(); HttpUpgradeHandler httpUpgradeHandler = upgradeToken.getHttpUpgradeHandler(); // Retrieve leftover input ByteBuffer leftoverInput = processor.getLeftoverInput(); // Release the Http11 processor to be re-used release(wrapper, processor, false, false); // Create the upgrade processor processor = createUpgradeProcessor( wrapper, leftoverInput, upgradeToken); // Mark the connection as upgraded wrapper.setUpgraded(true); // Associate with the processor with the connection connections.put(socket, processor); // Initialise the upgrade handler (which may trigger // some IO using the new protocol which is why the lines // above are necessary) // This cast should be safe. If it fails the error // handling for the surrounding try/catch will deal with // it. if (upgradeToken.getInstanceManager() == null) &#123; httpUpgradeHandler.init((WebConnection) processor); &#125; else &#123; ClassLoader oldCL = upgradeToken.getContextBind().bind(false, null); try &#123; httpUpgradeHandler.init((WebConnection) processor); &#125; finally &#123; upgradeToken.getContextBind().unbind(false, oldCL); &#125; &#125; &#125; if (getLog().isDebugEnabled()) &#123; getLog().debug("Socket: [" + wrapper + "], Status in: [" + status + "], State out: [" + state + "]"); &#125; if (dispatches == null || !dispatches.hasNext()) &#123; // Only returns non-null iterator if there are // dispatches to process. dispatches = wrapper.getIteratorAndClearDispatches(); &#125; &#125; while (state == SocketState.ASYNC_END || state == SocketState.UPGRADING || dispatches != null &amp;&amp; state != SocketState.CLOSED); if (state == SocketState.LONG) &#123; // In the middle of processing a request/response. Keep the // socket associated with the processor. Exact requirements // depend on type of long poll //异步在第一次处理的时候会将其设置到当前connections中去 connections.put(socket, processor); longPoll(wrapper, processor); &#125; else if (state == SocketState.OPEN) &#123; // In keep-alive but between requests. OK to recycle // processor. Continue to poll for the next request. connections.remove(socket); release(wrapper, processor, false, true); &#125; else if (state == SocketState.SENDFILE) &#123; // Sendfile in progress. If it fails, the socket will be // closed. If it works, the socket either be added to the // poller (or equivalent) to await more data or processed // if there are any pipe-lined requests remaining. connections.put(socket, processor); &#125; else if (state == SocketState.UPGRADED) &#123; // Don't add sockets back to the poller if this was a // non-blocking write otherwise the poller may trigger // multiple read events which may lead to thread starvation // in the connector. The write() method will add this socket // to the poller if necessary. if (status != SocketStatus.OPEN_WRITE) &#123; longPoll(wrapper, processor); &#125; &#125; else &#123; // Connection closed. OK to recycle the processor. Upgrade // processors are not recycled. connections.remove(socket); if (processor.isUpgrade()) &#123; UpgradeToken upgradeToken = processor.getUpgradeToken(); HttpUpgradeHandler httpUpgradeHandler = upgradeToken.getHttpUpgradeHandler(); InstanceManager instanceManager = upgradeToken.getInstanceManager(); if (instanceManager == null) &#123; httpUpgradeHandler.destroy(); &#125; else &#123; ClassLoader oldCL = upgradeToken.getContextBind().bind(false, null); try &#123; httpUpgradeHandler.destroy(); &#125; finally &#123; try &#123; instanceManager.destroyInstance(httpUpgradeHandler); &#125; catch (Throwable e) &#123; ExceptionUtils.handleThrowable(e); getLog().error(sm.getString("abstractConnectionHandler.error"), e); &#125; upgradeToken.getContextBind().unbind(false, oldCL); &#125; &#125; &#125; else &#123; release(wrapper, processor, true, false); &#125; &#125; return state; &#125; catch(java.net.SocketException e) &#123; // SocketExceptions are normal getLog().debug(sm.getString( "abstractConnectionHandler.socketexception.debug"), e); &#125; catch (java.io.IOException e) &#123; // IOExceptions are normal getLog().debug(sm.getString( "abstractConnectionHandler.ioexception.debug"), e); &#125; // Future developers: if you discover any other // rare-but-nonfatal exceptions, catch them here, and log as // above. catch (Throwable e) &#123; ExceptionUtils.handleThrowable(e); // any other exception or error is odd. Here we log it // with "ERROR" level, so it will show up even on // less-than-verbose logs. getLog().error( sm.getString("abstractConnectionHandler.error"), e); &#125; finally &#123; ContainerThreadMarker.clear(); &#125; // Make sure socket/processor is removed from the list of current // connections connections.remove(socket); // Don't try to add upgrade processors back into the pool if (processor !=null &amp;&amp; !processor.isUpgrade()) &#123; release(wrapper, processor, true, false); &#125; return SocketState.CLOSED; &#125; 从代码中可以看出获取Processor共经过三种途径，首先在connections这个map根据socket找到对应的Processor实例，也许你会有疑惑socket为什么会相同,目前我知道的有基于长连接和Upgrade来实现的socket,这样就有效的保留其中的协议状态，以及部分请求数据。如果从其中并没有获取则在循环队列中获取（下文讲述循环队列），这相当于从栈中获取元素，这是因为当一个实例化后的Processor处理完之后，并不会回收，而是释放存入栈中供下次来可以直接进行使用，如果栈中不存在则自己再实例化一个。由这种方式可以看出其实例化跟浏览器的请求没有多大关系，在一次会话中可能使用不同的，在不同会话中也可能使用相同的Processor Processor的释放 在当前socket处理完之后，会将Processor给释放,在这里将其部分句柄给重置之后,然后就压入循环队列供下次使用，其具体处理过程在BIO NIO 和AIO中有所出入 123protected abstract void release(SocketWrapper&lt;S&gt; socket, Processor&lt;S&gt; processor, boolean socketClosing, boolean addToPoller);]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat源码解读三 jmx]]></title>
    <url>%2F2017%2F11%2F14%2Ftomcat%2F2018-01-23-8%2F</url>
    <content type="text"><![CDATA[JMX即Java 管理扩展（Java Management Extensions，JMX）用来管理检测 Java 程序（同时 JMX 也在 J2EE 1.4 中被发布）它的作用是可以在程序运行的时候对其进行动态处理,调用相应方法来进行对指定属性值进行修改,在下面我将以代码结合jconsole进行分析（注意:在实际的程序管理过程中并不支持使用jconsole,因为它是一个java的客户端）源代码在下一节进行分析 tomcat中JMX的使用Demo 请注意这个JMX的展示仅仅针对与tomcat中的,因为tomcat对JMX做了改动,导致setter和getter方法不显示以及其他相关属性操作展示与原生jmx有所出入 java代码: 父类: 1234567891011121314151617181920212223242526272829303132333435public class MbeanTestExtend &#123; private String unSetGetAttrP; private String onlySetAttrP; private String onlyGetAttrP; private String includeSetGetAttrP; public void setOnlySetAttrP(String onlySetAttr) &#123; this.onlySetAttrP = onlySetAttr; &#125; public String getOnlyGetAttrP() &#123; return onlyGetAttrP; &#125; public String getIncludeSetGetAttrP() &#123; return includeSetGetAttrP; &#125; public void setIncludeSetGetAttrP(String includeSetGetAttrP) &#123; this.includeSetGetAttrP = includeSetGetAttrP; &#125; public String setAttrTestP(String attrTestP)&#123; return "attrTestP"; &#125; public void invokeMethodP()&#123; System.out.println("invokeMethodP..."); &#125;&#125; 子类: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class MBeanTest extends MbeanTestExtend implements MBeanRegistration&#123; private String unSetGetAttr; private String onlySetAttr; private String onlyGetAttr; private String includeSetGetAttr; public void setOnlySetAttr(String onlySetAttr) &#123; this.onlySetAttr = onlySetAttr; &#125; public String getOnlyGetAttr() &#123; return onlyGetAttr; &#125; public String getIncludeSetGetAttr() &#123; return includeSetGetAttr; &#125; public void setIncludeSetGetAttr(String includeSetGetAttr) &#123; this.includeSetGetAttr = includeSetGetAttr; &#125; public String setAttrTest(String attrTest)&#123; return "attrTest"; &#125; public void invokeMethod(String value)&#123; System.out.println("传入值:"+value); &#125; public String getUnHandle()&#123; return "测试"; &#125; public String getDomain()&#123; return "mainTest1"; &#125; public static void main(String[] args) throws IOException &#123; //MBeanServer实例能够用MBeanServerFactory类提供的方法获取 //MBeanServer mserver = null; MBeanTest mBeanTest = new MBeanTest(); mBeanTest.register(mBeanTest, "type=MBeanTest"); while (true)&#123;&#125; &#125; protected final ObjectName register(Object obj, String objectNameKeyProperties) &#123; //根据domain构造一个对象名 形式一般 domain:type=className 这个最终构成 jmxStudy:type=mainTest //StringBuilder name = new StringBuilder(getDomain()); StringBuilder name = new StringBuilder("jmxStudy"); name.append(':'); name.append(objectNameKeyProperties); ObjectName on = null; try &#123; //将上面构建的对象名字符串转化为对应的对象 on = new ObjectName(name.toString()); //获取MBeans建模注册表并注册组件 Registry.getRegistry(null, null).registerComponent(obj, on, null); &#125; catch (MalformedObjectNameException e) &#123; throw new RuntimeException(e.toString()); &#125; catch (Exception e) &#123; throw new RuntimeException(e.toString()); &#125; return on; &#125; @Override public ObjectName preRegister(MBeanServer server, ObjectName name) throws Exception &#123; throw new RuntimeException("preRegister......."); &#125; @Override public void postRegister(Boolean registrationDone) &#123; throw new RuntimeException("postRegister......."); &#125; @Override public void preDeregister() throws Exception &#123; throw new RuntimeException("preDeregister......."); &#125; @Override public void postDeregister() &#123; throw new RuntimeException("postDeregister......."); &#125;&#125; jconsole效果 结论 1.无setter和getter方法的变量不会显示 2.有getter方法无setter方法的即使没有变量会去掉前面get然后显示属性 3.有setter方法无getter方法且无变量的不会显示 4.有setter方法无getter方法存在变量的属性会显示 5.由1 2 3 4可知一个属性是否显示跟其句柄和setter/getter方法有关 6.一个属性显示后仅当具有getter方法的则这个属性可读,在值的地方会显示 7.一个属性显示后仅当具有setter方法的则这个属性可写,在值得地方输入新值会进行更新 8.一个操作方法必须满足一下的条件才能显示并且实现调用 ①public修饰 ②不是static方法 ③不是setter/getter方法 ④不是Object类中的方法（这是由于继承类中的方法也会被显示） tomcat中JMX的源码分析 在这里我是将tomcat中的jmx给拆分出来进行单独分析,希望通过此种方式能够尽可能的出现更多的问题,以便对其有更多的了解,首先需要声明的是tomcat的JMX是在jsvase原有的基础上做了一些复用,这就必须了解一些JMX的实现过程 tomcat中JMX的UML图 启动代码解析 注意：本人是在剥离下来的代码上分析的,跟源代码可能有所出入,但不会太大，主要是将它的思想分析一下在这个分析过程中以LifecycleMBeanBase类的register方法为入口分析 1.1.2.1 register方法 这个方法是总共分为三步逻辑如下： 第一步：构建ObjectName 第二步：获取Mbean的注册表 第三步 : 注册当前Mbean组件 12345678910111213141516171819protected final ObjectName register(Object obj, String objectNameKeyProperties) &#123; //根据domain构造一个对象名 形式一般 domain:type=className 这个最终构成 jmxStudy:type=mainTest //StringBuilder name = new StringBuilder(getDomain()); StringBuilder name = new StringBuilder("jmxStudy"); name.append(':'); name.append(objectNameKeyProperties); ObjectName on = null; try &#123; //将上面构建的对象名字符串转化为对应的对象 on = new ObjectName(name.toString()); //获取MBeans建模注册表并注册组件 Registry.getRegistry(null, null).registerComponent(obj, on, null); &#125; catch (MalformedObjectNameException e) &#123; throw new RuntimeException(e.toString()); &#125; catch (Exception e) &#123; throw new RuntimeException(e.toString()); &#125; return on;&#125; 就这样tomcat的JMX是注册成功的,但是既然分析源码,我们肯定要知根问底,下面就看看如何获取Mbean注册表以及注册组件 获取Mbean注册表 主要调用Registry类的静态方法getRegistry 1234567891011121314151617181920212223242526272829303132333435363738/** * tomcat中的JMX传入的两个参数都是null * 所以最终返回registry这个静态句柄的值 当然第一次为空是实例化了一个Registry实例 * */public static synchronized Registry getRegistry(Object key, Object guard) &#123; Registry localRegistry; //perLoaderRegistries是一个HashMap集合 if( perLoaderRegistries!=null ) &#123; if( key==null )&#123; //获取当前线程加载器 key=Thread.currentThread().getContextClassLoader(); &#125; //如果key不为空 则从perLoaderRegistries中获取,如果没有的话实例化一个并放入perLoaderRegistries句柄 if( key != null ) &#123; localRegistry = perLoaderRegistries.get(key); if( localRegistry == null ) &#123; localRegistry=new Registry(); localRegistry.guard=guard; perLoaderRegistries.put( key, localRegistry ); return localRegistry; &#125; if( localRegistry.guard != null &amp;&amp; localRegistry.guard != guard ) &#123; return null; &#125; return localRegistry; &#125; &#125; //实例化一个静态的Registry if (registry == null) &#123; registry = new Registry(); &#125; //这里的逻辑就是guard不为空则必须与传入的相同 if( registry.guard != null &amp;&amp; registry.guard != guard ) &#123; return null; &#125; return (registry);&#125; 注册Mbean组件 注册Mbean组件即注册当前实例,在验证注册实例不为空之后,根据其全限定类型在mbean管理器中找到相应的ManagedBean实例,如果找不到则创建一个,并在验证ObjectName（如果有则将原有的注册的取消掉）情况下将当前Mbean注册进去 主要调用Registry类的静态方法getRegistry 123456789101112131415161718192021222324252627282930313233343536373839/** * tomcat中的JMX传入的两个参数都是null * 所以最终返回registry这个静态句柄的值 当然第一次为空是实例化了一个Registry实例 * */public static synchronized Registry getRegistry(Object key, Object guard) &#123; Registry localRegistry; //perLoaderRegistries是一个HashMap集合 if( perLoaderRegistries!=null ) &#123; if( key==null )&#123; //获取当前线程加载器 key=Thread.currentThread().getContextClassLoader(); &#125; //如果key不为空 则从perLoaderRegistries中获取,如果没有的话实例化一个并放入perLoaderRegistries句柄 if( key != null ) &#123; localRegistry = perLoaderRegistries.get(key); if( localRegistry == null ) &#123; localRegistry=new Registry(); localRegistry.guard=guard; perLoaderRegistries.put( key, localRegistry ); return localRegistry; &#125; if( localRegistry.guard != null &amp;&amp; localRegistry.guard != guard ) &#123; return null; &#125; return localRegistry; &#125; &#125; //实例化一个静态的Registry if (registry == null) &#123; registry = new Registry(); &#125; //这里的逻辑就是guard不为空则必须与传入的相同 if( registry.guard != null &amp;&amp; registry.guard != guard ) &#123; return null; &#125; return (registry);&#125; 注册Mbean组件 注册Mbean组件即注册当前实例,在验证注册实例不为空之后,根据其全限定类型在mbean管理器中找到相应的ManagedBean实例,如果找不到则创建一个,并在验证ObjectName（如果有则将原有的注册的取消掉）情况下将当前Mbean注册进去 1234567891011121314151617181920212223242526272829public void registerComponent(Object bean, ObjectName oname, String type) throws Exception&#123; //如果要注册的bean为空 则直接返回 if( bean ==null ) &#123; return; &#125; try &#123; //如果类型为空则获取bean的全限定类名 if( type==null ) &#123; type=bean.getClass().getName(); &#125; //mbean的管理器 ManagedBean managed = findManagedBean(null, bean.getClass(), type); //真实的mbean DynamicMBean mbean = managed.createMBean(bean); //如果当前oname被注册先解除其注册 if( getMBeanServer().isRegistered( oname )) &#123; getMBeanServer().unregisterMBean( oname ); &#125; //传入的mbean==&gt;JMX.MBeanTest oname==&gt;mainTest1:type=MBeanTest getMBeanServer().registerMBean( mbean, oname); &#125; catch( Exception ex) &#123; ex.printStackTrace(); throw ex; &#125;&#125; 查找Mbean管理器 根据类型从descriptors和descriptorsByClass这两个HashMap结构中去寻找，优先级descriptors&gt;descriptorsByClass。在没有找到的情况下会进行一下操作: 1. findDescriptor 方法根据bean找到对应描述文件,将实例加载到Registry类的registry句柄中去,然后再进行查找(后文描述),一般这种情况是找的到的 2. 在1中没有找到的情况下,修改ModelerSource再进行查找 依上面顺序找到了就返回,没找到则返回空 123456789101112131415161718192021222324252627282930public ManagedBean findManagedBean(Object bean, Class&lt;?&gt; beanClass, String type) throws Exception &#123; //如果bean不为空 beanClass为空 获取beanClass if( bean!=null &amp;&amp; beanClass==null ) &#123; beanClass=bean.getClass(); &#125; //如果type为空 获取beanClass的name if( type==null ) &#123; type=beanClass.getName(); &#125; //从descriptors和descriptorsByClass中获取相应的ManagedBean实例 这里首次回去的为空 ManagedBean managed = findManagedBean(type); // 寻找相同包下的描述符 if( managed==null ) &#123; // check package and parent packages findDescriptor( beanClass, type ); managed=findManagedBean(type); &#125; // 还是没有找到 再根据beanClass来load一遍 if( managed==null ) &#123; // introspection load("MbeansDescriptorsIntrospectionSource", beanClass, type); managed=findManagedBean(type); if( managed==null ) &#123; return null; &#125; managed.setName( type ); addManagedBean(managed); &#125; return managed;&#125; 创建最终使用的Mbean 这个过程中最终创建的是BaseModelMBean实例其继承了DynamicMBean接口,并将mbean管理器注入到其句柄 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public DynamicMBean createMBean(Object instance) throws InstanceNotFoundException, MBeanException, RuntimeOperationsException &#123; BaseModelMBean mbean = null; // 如果当前ManagedBean继承了BASE_MBEAN 则实例化一个BaseModelMBean tomcat的默认实现方式就是这种方式 if(getClassName().equals(BASE_MBEAN)) &#123; mbean = new BaseModelMBean(); &#125; else &#123; //跟还有全限定类名实例化mbean Class&lt;?&gt; clazz = null; Exception ex = null; try &#123; clazz = Class.forName(getClassName()); &#125; catch (Exception e) &#123; &#125; if( clazz==null ) &#123; try &#123; ClassLoader cl= Thread.currentThread().getContextClassLoader(); if ( cl != null)&#123; clazz= cl.loadClass(getClassName()); &#125; &#125; catch (Exception e) &#123; ex=e; &#125; &#125; if( clazz==null) &#123; throw new MBeanException (ex, "Cannot load ModelMBean class " + getClassName()); &#125; try &#123; // Stupid - this will set the default minfo first.... mbean = (BaseModelMBean) clazz.newInstance(); &#125; catch (RuntimeOperationsException e) &#123; throw e; &#125; catch (Exception e) &#123; throw new MBeanException (e, "Cannot instantiate ModelMBean of class " + getClassName()); &#125; &#125; //设置当前对象为实例化mbean的managedBean句柄 mbean.setManagedBean(this); try &#123; if (instance != null)&#123; mbean.setManagedResource(instance, "ObjectReference"); &#125; &#125; catch (InstanceNotFoundException e) &#123; throw e; &#125; return mbean;&#125; registerMBean注册组件 从管理工厂ManagementFactory获取MbeanServer,并通过registerMBean方法将属性和操作注册到Mbean 栈帧如下: 1234567891011registerComponent(Object, ObjectName, String):127, Registry (JMX), Registry.javaregisterMBean(Object, ObjectName):522, JmxMBeanServer (com.sun.jmx.mbeanserver), JmxMBeanServer.javaregisterMBean(Object, ObjectName):319, DefaultMBeanServerInterceptor (com.sun.jmx.interceptor), DefaultMBeanServerInterceptor.javagetNewMBeanClassName(Object):333, DefaultMBeanServerInterceptor (com.sun.jmx.interceptor), DefaultMBeanServerInterceptor.javagetMBeanInfo():88, BaseModelMBean (JMX), BaseModelMBean.javagetMBeanInfo():160, ManagedBean (JMX), ManagedBean.java 通过getMBeanInfo方法会将属性、操作和通知注册到对应实例MBeanAttributeInfo、MBeanOperationInfo以及NotificationInfo然后统一注入到MBeanInfo,最终其会注入到Mbean的管理器从而实现在jconsole等上进行使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051MBeanInfo getMBeanInfo() &#123; mBeanInfoLock.readLock().lock(); try &#123; if (info != null) &#123; return info; &#125; &#125; finally &#123; mBeanInfoLock.readLock().unlock(); &#125; mBeanInfoLock.writeLock().lock(); try &#123; if (info == null) &#123; //创建必要的信息说明 AttributeInfo attrs[] = getAttributes(); MBeanAttributeInfo attributes[] = new MBeanAttributeInfo[attrs.length]; for (int i = 0; i &lt; attrs.length; i++)&#123; attributes[i] = attrs[i].createAttributeInfo(); &#125; OperationInfo opers[] = getOperations(); MBeanOperationInfo operations[] = new MBeanOperationInfo[opers.length]; for (int i = 0; i &lt; opers.length; i++)&#123; operations[i] = opers[i].createOperationInfo(); &#125; //获取所有的通知对象 NotificationInfo notifs[] = getNotifications(); //MBeanNotificationInfo类用于描述由MBean发出的不同通知实例的特征 MBeanNotificationInfo notifications[] = new MBeanNotificationInfo[notifs.length]; for (int i = 0; i &lt; notifs.length; i++)&#123; notifications[i] = notifs[i].createNotificationInfo(); &#125; //创建一个MBeanInfo对象实例 注入相关属性和操作 info = new MBeanInfo(getClassName(), getDescription(), attributes, new MBeanConstructorInfo[] &#123;&#125;, operations, notifications); &#125; return info; &#125; finally &#123; mBeanInfoLock.writeLock().unlock(); &#125;&#125; 加载资源描述 这是一个比较核心的方法,其获取相应的类加载器,找到相应包下的mbeans-descriptors.xml，然后获取模型资源实例，根据字符串MbeansDescriptorsIntrospectionSource的到其实例,注入相应registry，然后在其execute方法中根据createManagedBean 创建ManagedBean，也就是在这里根据对象方法设置属相的的具体操作(如:是否可读,可写),根据initMethods方法将相关属相操作进行区分，下面展示execute和initMethods方法代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public ManagedBean createManagedBean(Registry registry, String domain, Class&lt;?&gt; realClass, String type) &#123; ManagedBean mbean= new ManagedBean(); Method methods[]=null; Hashtable&lt;String,Method&gt; attMap = new Hashtable&lt;&gt;(); // key: attribute val: getter method Hashtable&lt;String,Method&gt; getAttMap = new Hashtable&lt;&gt;(); // key: attribute val: setter method Hashtable&lt;String,Method&gt; setAttMap = new Hashtable&lt;&gt;(); // key: operation val: invoke method Hashtable&lt;String,Method&gt; invokeAttMap = new Hashtable&lt;&gt;(); methods = realClass.getMethods(); //初始化属性与操作 在这个过程主要将方法加载到对应Hashtable集合 从而分成属性 操作 以及后面在JMX中设置值调用的setAttMap initMethods(realClass, methods, attMap, getAttMap, setAttMap, invokeAttMap ); try &#123; //将所有的attMap中的属性添加到ManagedBean的attributes句柄中 Enumeration&lt;String&gt; en = attMap.keys(); while( en.hasMoreElements() ) &#123; String name = en.nextElement(); AttributeInfo ai=new AttributeInfo(); ai.setName( name ); //根据name从getAttMap获取相关方法 如果不为空 给属性设置这个get方法 如果返回类型不为空 设置相应的返回类型 Method gm = getAttMap.get(name); if( gm!=null ) &#123; ai.setGetMethod( gm.getName()); Class&lt;?&gt; t=gm.getReturnType(); if( t!=null )&#123; ai.setType(t.getName() ); &#125; &#125; //根据name从setAttMap获取相关方法 如果不为空 给属性设置这个set方法 如果返回类型不为空 设置相应的返回类型 Method sm = setAttMap.get(name); if( sm!=null ) &#123; Class&lt;?&gt; t = sm.getParameterTypes()[0]; if( t!=null )&#123; ai.setType( t.getName()); ai.setSetMethod( sm.getName()); &#125; &#125; ai.setDescription("自省属性" + name); //如果gm为空 设置当前属性不可读 if( gm==null )&#123; ai.setReadable(false); &#125; //如果sm为空 设置当前属性不可写 if( sm==null )&#123; ai.setWriteable(false); &#125; //主要sm和gm中有一个不为 则像mbean中添加当前属性 if( sm!=null || gm!=null )&#123; mbean.addAttribute(ai); &#125; &#125; //遍历所有invokeAttMap中的方法 这些方法排除的有setter getter方法 静态方法 非public方法 object类中的方法 for (Map.Entry&lt;String,Method&gt; entry : invokeAttMap.entrySet()) &#123; String name = entry.getKey(); Method m = entry.getValue(); if(m != null) &#123; OperationInfo op=new OperationInfo(); op.setName(name); op.setReturnType(m.getReturnType().getName()); op.setDescription("自省操作 " + name); Class&lt;?&gt; parms[] = m.getParameterTypes(); for(int i=0; i&lt;parms.length; i++ ) &#123; ParameterInfo pi=new ParameterInfo(); pi.setType(parms[i].getName()); pi.setName( "参数名" + i); pi.setDescription("参数说明" + i); op.addParameter(pi); &#125; mbean.addOperation(op); &#125; else &#123; throw new RuntimeException("Null arg method for [" + name + "]"); &#125; &#125; //设置mbean的name mbean.setName( type ); return mbean; &#125; catch( Exception ex ) &#123; ex.printStackTrace(); return null; &#125;&#125; initMethods方法代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475private void initMethods(Class&lt;?&gt; realClass, Method methods[], Hashtable&lt;String,Method&gt; attMap, Hashtable&lt;String,Method&gt; getAttMap, Hashtable&lt;String,Method&gt; setAttMap, Hashtable&lt;String,Method&gt; invokeAttMap)&#123; for (int j = 0; j &lt; methods.length; ++j) &#123; String name=methods[j].getName(); //如果是一个静态方法则跳过 if( Modifier.isStatic(methods[j].getModifiers()))&#123; continue; &#125; //不是public方法 跳过 if( ! Modifier.isPublic( methods[j].getModifiers() ) ) &#123; continue; &#125; //获取该方法所在的类这是因为Object类中的方法都不需要注册到Mbean if( methods[j].getDeclaringClass() == Object.class )&#123; continue; &#125; Class&lt;?&gt; params[] = methods[j].getParameterTypes(); //如果方法以get开始并且参数个数为0,其返回类型是支持的返回类型 则获取其添加到attMap和getAttMap if( name.startsWith( "get" ) &amp;&amp; params.length==0) &#123; Class&lt;?&gt; ret = methods[j].getReturnType(); if(!supportedType(ret) ) &#123; continue; &#125; name=unCapitalize( name.substring(3)); getAttMap.put( name, methods[j] ); attMap.put( name, methods[j] ); &#125; else if( name.startsWith( "is" ) &amp;&amp; params.length==0) &#123; //如果方法是is开头 则如果其返回类型为Boolean 则获取其添加到attMap和getAttMap Class&lt;?&gt; ret = methods[j].getReturnType(); if( Boolean.TYPE != ret ) &#123; continue; &#125; name=unCapitalize( name.substring(2)); getAttMap.put( name, methods[j] ); // just a marker, we don't use the value attMap.put( name, methods[j] ); &#125; else if( name.startsWith( "set" ) &amp;&amp; params.length==1) &#123; //如果方法是set开头 则如果其返回类型为Boolean 则获取其添加到attMap和setAttMap if( ! supportedType( params[0] ) ) &#123; continue; &#125; name=unCapitalize( name.substring(3)); setAttMap.put( name, methods[j] ); attMap.put( name, methods[j] ); &#125; else &#123; //如果参数长度为0,根据方法名从specialMethods中获取,如果不为空则直接返回 反之将其添加到invokeAttMap //默认去掉preDeregister postDeregister if( params.length == 0 ) &#123; if( specialMethods.get( methods[j].getName() ) != null )&#123; continue; &#125; invokeAttMap.put( name, methods[j]); &#125; else &#123; //如果参数长度不为空 满足所有参数类型是支持类型将其添加到invokeAttMap中 boolean supported=true; for( int i=0; i&lt;params.length; i++ ) &#123; if( ! supportedType( params[i])) &#123; supported=false; break; &#125; &#125; if( supported )&#123; invokeAttMap.put( name, methods[j]); &#125; &#125; &#125; &#125;&#125; 调用代码解析 在这例结合jconsole的Mbean对tomcat代码中的设置属性值、获取属性值、调用方法、发送通知四种方法进行分析。为减少篇幅在这里只是展示入口方法,核心调用的方法都标红 设置属性值 设置属性值是BaseModelMBean中setAttribute方法作为入口根据方法名获取相关属性，根据Mbean实例来获取相应的方法,并进行调用 12345678910111213141516171819202122232425262728293031323334353637383940@Overridepublic void setAttribute(Attribute attribute) throws AttributeNotFoundException, MBeanException, ReflectionException&#123; //如果是动态Mbean并且不是BaseModelMBean 将属性直接设置到资源 if( (resource instanceof DynamicMBean) &amp;&amp; ! ( resource instanceof BaseModelMBean )) &#123; try &#123; ((DynamicMBean)resource).setAttribute(attribute); &#125; catch (InvalidAttributeValueException e) &#123; throw new MBeanException(e); &#125; return; &#125; // 验证输入参数 if (attribute == null)&#123; throw new RuntimeOperationsException(new IllegalArgumentException("Attribute is null"), "Attribute is null"); &#125; String name = attribute.getName(); Object value = attribute.getValue(); if (name == null)&#123; throw new RuntimeOperationsException(new IllegalArgumentException("Attribute name is null"), "Attribute name is null"); &#125; Object oldValue=null; //根据name获取指定的方法并调用相应的方法 Method m=managedBean.getSetter(name,this,resource); try &#123; //检查这个方法所在的类是否与当前实例类相同或是当前实例的超类或接口 如果是调用当前实例的方法 反之调用资源类的方法 if( m.getDeclaringClass().isAssignableFrom( this.getClass()) ) &#123; m.invoke(this, new Object[] &#123; value &#125;); &#125; else &#123; m.invoke(resource, new Object[] &#123; value &#125;); &#125; &#125; catch (InvocationTargetException e) &#123; 。。。。 &#125;&#125; 获取属性值 获取属性入口 BaseModelMBean—》getAttribute 获取属性是点击到管理界面具体属性的时候进行显示然后会调用到当前方法 12345678910111213141516171819202122232425262728293031public Object getAttribute(String name) throws AttributeNotFoundException, MBeanException, ReflectionException &#123; //如果name为空扔出异常 if (name == null)&#123; throw new RuntimeOperationsException(new IllegalArgumentException("Attribute name is null"), "Attribute name is null"); &#125; //如果实例是继承DynamicMBean并且不是BaseModelMBean则调用其自己获取属性的方式 //这种情况在tomcat比较常见 如ConnectorMBean它利用自己的setter/getter属性 resource是注册的实例 if( (resource instanceof DynamicMBean) &amp;&amp; ! ( resource instanceof BaseModelMBean )) &#123; return ((DynamicMBean)resource).getAttribute(name); &#125; //这个方法的功能是根据name获取的相关属性,再根据属性实例找到方法名,利用反射获取这个方法 Method m=managedBean.getGetter(name, this, resource); Object result = null; try &#123; //获取这个方法所在的类 可能是当前类也有可能是其父类 Class&lt;?&gt; declaring = m.getDeclaringClass(); //如果条件为真,declaring是其父类 这直接通过当前实例调用 这样完全java继承方法的实现思想 //这种情况出现于Mbean实例继承BaseModelMBean if( declaring.isAssignableFrom(this.getClass()) ) &#123; result = m.invoke(this, NO_ARGS_PARAM ); &#125; else &#123; //利用Mbean实例直接调用方法 这种情况是常见的 result = m.invoke(resource, NO_ARGS_PARAM ); &#125; &#125; catch (InvocationTargetException e) &#123; 。。。。。。 return (result);&#125; 调用方法 调用入口: BaseModelMBean—》invoke 点击相应操作则会调用 123456789101112131415161718192021222324252627@Overridepublic Object invoke(String name, Object[] params, String[] signature) throws MBeanException, ReflectionException &#123; if( (resource instanceof DynamicMBean) &amp;&amp; ! ( resource instanceof BaseModelMBean )) &#123; return ((DynamicMBean)resource).invoke(name, params, signature); &#125; if (name == null)&#123; throw new RuntimeOperationsException(new IllegalArgumentException("Method name is null"), "Method name is null"); &#125; //根据参数和签名获取相应的方法 Method method= managedBean.getInvoke(name, params, signature, this, resource); Object result = null; try &#123; if( method.getDeclaringClass().isAssignableFrom( this.getClass()) ) &#123; result = method.invoke(this, params ); &#125; else &#123; result = method.invoke(resource, params); &#125; &#125; catch (InvocationTargetException e) &#123; 。。。。。。 return (result);&#125; 发送通知 发送通知需要从两方面进行考虑,第一方面是客户端进行连接要将相应的监听器加入另一方面是在调用相应事件则通过相应方法发送给注入的监听器，这样就实现了相应的消息通知 接受接听器: BaseModelMBean –》addNotificationListener 1234567891011121314151617181920public void addNotificationListener(NotificationListener listener, NotificationFilter filter, Object handback) throws IllegalArgumentException &#123; //如果监听器为空 则扔出异常不合法参数 if (listener == null)&#123; throw new IllegalArgumentException("Listener is null"); &#125; //广播实例句柄为空则实例化一个BaseNotificationBroadcaster实例 if (generalBroadcaster == null)&#123; generalBroadcaster = new BaseNotificationBroadcaster(); &#125; generalBroadcaster.addNotificationListener(listener, filter, handback); if (attributeBroadcaster == null)&#123; attributeBroadcaster = new BaseNotificationBroadcaster(); &#125; attributeBroadcaster.addNotificationListener(listener, filter, handback);&#125; 发送消息: BaseModelMBean –-&gt; sendAttributeChangeNotification 12345678910111213@Overridepublic void sendAttributeChangeNotification(AttributeChangeNotification notification) throws MBeanException, RuntimeOperationsException &#123; //这个通知是在做了修改操作之后构建的一个操作 如果为空 则必然扔出异常 if (notification == null)&#123; throw new RuntimeOperationsException(new IllegalArgumentException("Notification is null"), "Notification is null"); &#125; //如果广播为空则意味着没有监听器 其是在连接的时候实例化了一个BaseNotificationBroadcaster if (attributeBroadcaster == null)&#123; //意味着没有注册监听器 return; &#125; attributeBroadcaster.sendNotification(notification);&#125; 由上可值Mbean得动态操作都是在BaseModelMBean这个类中，JMX的分析到这里告一段落 要想更清除的理解则需要再次到tomcat这个环境以及从底层rmi实现方面进行了解，后期会补上这些内容]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat源码解读二 tomcat的生命周期]]></title>
    <url>%2F2017%2F11%2F13%2Ftomcat%2F2018-01-23-7%2F</url>
    <content type="text"><![CDATA[生命周期 观察者模型 tomcat生命周期采用了观察者模式，所以在介绍生命周期的时候不得不介绍观察者模式 观察者模式定义了对象间的一种一对多依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到通知并被自动更新 观察者模式: 根据UML图可以看出所有被观察的对象Observer的实现类(可以有多个具体实现类)被添加到观察者Subject的实现类SubjectImpl中的observerList集合中去，这样SubjectImpl对象可以通过遍历observerList中对象并调用其方法实现对所有观察对象的改变，subject这个句柄也存在与Observer的实现类中,所以当某个观察对象改变了就可以直接改变所有观察对象的信息。这就是简单的观察者模式的实现原理,现在我们来看一下tomcat生命周期是如何使用观察者的 生命周期时序图 这里只展示唤醒的时序图，添加一般是在解析标签实例化通过在规则begin中添加 生命周期源码解读 由于生命周期采用的是观察者,所以我将以观察者模式的角度来解读，下面首先展示一张以standHost HostConfig举例的观察者模式的类图 生命周期中与观察者相对应的类 LifecycleSupport 对应的观察者接口 LifecycleBase 对应的是观察者的实例但是其是一个抽象类,具体实现是StandardHost等 LifecycleListener 对应的观察对象接口 HostConfig 对应的观察对象的实现 添加监听器 tomcat的架构设计是以组件的方式进行加载启动,所以很多东西具有共用型,在其中有很多观察者模式如在StandardContext和ContextConfig中standardContext是观察者，在StandardHost和HostConfig中HostConfig是一个观察者,按照观察者模式这个类应该直接实现Lifecycle进行实现,但是他们有存在一些共有的方法实现如添加监听器，并且声明周期不仅仅是简单的唤醒，它存在多种状态,根据这些状态在唤醒观察对象的时候会根据其状态不同会调用不同的方法。而这些实现逻辑是相同的,所以将其提出来让所有观察者继承,但是调用各组件具体功能方法是不同的所以将其抽象化,所以不能被直接实例化.最红形成抽象类LifecycleBase 部分代码如下： 12345678public abstract class LifecycleBase implements Lifecycle &#123; private final LifecycleSupportlifecycle = new LifecycleSupport(this);/**添加监听器*/ @Override public void addLifecycleListener(LifecycleListenerlistener)&#123; lifecycle.addLifecycleListener(listener); &#125;&#125; 这就是一个添加监听器的方法（对应与观察者模式中的添加观察对象）,至于如何将观察对象添加到观察者中去，下面以StandardHost为例。 根据digester构建规则然后在解析server.xml文件的时候根据Host标签解析对应的StandardHost实例,并给其添加规则LifecycleListenerRule,这个规则的作用就是StandardHost是实例化后会调用addLifecycleListenerHostConfig实例添加到其LifecycleSupport句柄,具体代码执行如下： HostRuleSet.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061digester.addObjectCreate(prefix + "Host", "org.apache.catalina.core.StandardHost", "className");digester.addSetProperties(prefix + "Host");digester.addRule(prefix + "Host", new CopyParentClassLoaderRule());digester.addRule(prefix + "Host", new LifecycleListenerRule ("org.apache.catalina.startup.HostConfig", "hostConfigClass"));digester.addSetNext(prefix + "Host", "addChild", "org.apache.catalina.Container"); /** * 这个解析规则的主要目的是将监听器添加到对应的实例 * StandardEngine ==&gt; EngineConfig * StandardHost ==&gt; HostConfig * 针对StandardHost来进行分析 * */ @Override public void begin(Stringnamespace, String name, Attributes attributes) throws Exception &#123; //获取元素 Container c =(Container) digester.peek(); Container p = null; //获取栈底元素如果继承Container赋给p 这里是StandardEngine由于其继承Container 所以p为StandardEngine //这一步作用只是为了后面看能否从其实例中获取configClass,一般都为空 Object obj = digester.peek(1); if (obj instanceof Container) &#123; p = (Container) obj; &#125; String className = null; //检查是否有特定的属性名如果有从标签中获取这个元素为hostConfigClass if (attributeName!= null) &#123; String value =attributes.getValue(attributeName); if (value != null) className = value; &#125; // 在p这个实例调用getHostConfigClass方法获取className值如果存在会覆盖上面的值 if (p != null &amp;&amp;className == null) &#123; String configClass = (String)IntrospectionUtils.getProperty(p, attributeName); if (configClass!= null &amp;&amp; configClass.length() &gt; 0) &#123; className = configClass; &#125; &#125; //如果className为空则使用默认的,即构建实例传入的 if (className ==null) &#123; className = listenerClass; &#125; //实例化这个监听器即观察对象的实例 Class&lt;?&gt; clazz =Class.forName(className); LifecycleListener listener =(LifecycleListener) clazz.newInstance(); //添加监听器到对应的组件 hostConfig则是添加到StandardHost c.addLifecycleListener(listener); &#125; 唤醒监听器 所谓唤醒观察对象就是触发所有其观察者方法,针对于生命周期就是当某个组件调用fireLifecycleEvent方法的时候根据当前组件所处于的状态来触发相应的事件,还是以StandardHost和HostConfig来进行演示。 ①在组件初始化前后都设置了一下当前组件的生命状态，状态是一种枚举类型里面包含两个值，一个是是否可以利用（这个值得作用时候来判断在某种状态下是否可以执行后续方法），第二个值是状态的属性值字符串变量（用来根据进行判断比较调用状态对应的方法） standardHost.java 12345678910111213141516171819202122232425262728@Overridepublic final synchronized void init() throws LifecycleException&#123; try &#123; //设置状态为INITIALIZING setStateInternal(LifecycleState.INITIALIZING, null, false); initInternal();//这是一个抽象类其实现方法在具体的实现类 //设置状态为INITIALIZED setStateInternal(LifecycleState.INITIALIZED, null, false); &#125; catch (Throwable t)&#123; ……… &#125;&#125; public enum LifecycleState &#123; 。。。。。。 INITIALIZED(false, Lifecycle.AFTER_INIT_EVENT)。。。。。。 private final boolean available; private final String lifecycleEvent; private LifecycleState(boolean available,String lifecycleEvent) &#123; this.available = available; this.lifecycleEvent= lifecycleEvent; &#125;&#125; public static final String AFTER_INIT_EVENT = "after_init"; ②在设置声明状态之后,根据状态字符串常量值继续调用fireLifecycleEvent方法，在其中根据LifecycleSupport的句柄lifecycle调用fireLifecycleEvent 1234567891011121314private synchronized void setStateInternal(LifecycleStatestate, Object data, boolean check) throws LifecycleException&#123; this.state = state; String lifecycleEvent =state.getLifecycleEvent(); if (lifecycleEvent!= null) &#123; fireLifecycleEvent(lifecycleEvent,data); &#125;&#125; LifecycleBase.javaprotected void fireLifecycleEvent(String type, Object data) &#123; lifecycle.fireLifecycleEvent(type,data);&#125; ③fireLifecycleEvent方法则具体实现将当前组件以及状态字符串常量属性和数据封装到LifecycleEvent实例作为形式参数传递给其所有监听器对象并调用其具体方法 123456public void fireLifecycleEvent(String type, Object data) &#123; LifecycleEvent event = new LifecycleEvent(lifecycle, type,data); for (LifecycleListenerlistener : listeners) &#123; listener.lifecycleEvent(event); &#125;&#125; 1.3.3 监听器实现过程 在这里以HostConfig为例,看其lifecycleEvent方法实现过程可以看出其根据组件不同的状态会调用不同的方法来进行实现。 123456789101112131415161718192021@Overridepublic void lifecycleEvent(LifecycleEvent event) &#123; try &#123; host = (Host)event.getLifecycle(); if (host instanceof StandardHost)&#123; setCopyXML(((StandardHost) host).isCopyXML()); 。。。。。。。 &#125; &#125; catch (ClassCastExceptione) &#123; 。。。。。。 &#125; if (event.getType().equals(Lifecycle.PERIODIC_EVENT)) &#123; check(); &#125; else if (event.getType().equals(Lifecycle.BEFORE_START_EVENT)) &#123; beforeStart(); &#125; else if (event.getType().equals(Lifecycle.START_EVENT)) &#123; start(); &#125; else if (event.getType().equals(Lifecycle.STOP_EVENT)) &#123; stop(); &#125;&#125;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat源码解读一 Digester的解析方式]]></title>
    <url>%2F2017%2F11%2F12%2Ftomcat%2F2018-01-23-6%2F</url>
    <content type="text"><![CDATA[# Digester Digester在tomcat中的作用是对conf下的server.xml文件进行实例化，其是从Catalian这个组件开始，创建Digester实例，再添加对应的规则，然后将其实例化，通过setServer方法，将其实例话的对象作为当前Catalian实例的句柄。这样就实现了对象句柄之间的关联引用，从而实现整个平台的递进启动。 UML类图 UML时序图 规则添加解析 添加对应解析规则 规则的添加实在Catalia.java的load（）方法之中。规则主要是根据各个标签创建对应对象的规则,以及解析对象的通过何种方法设为相应句柄属性。其主要实现过程是创建Digester实例，设置规则 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117protected Digester createStartDigester() &#123; long t1=System.currentTimeMillis(); //创建一个digester实例 Digesterdigester = new Digester(); //是否需要验证xml文档的合法性，false表示不需要进行DTD规则校验 digester.setValidating(false); //是否需要进行节点设置规则校验 digester.setRulesValidation(true); //将xml节点中的className作为假属性，不用调用默认的setter方法 //在解析时，调用相应对象的setter方法来设置属性值，setter的参数就是节点属性， //而有className的话，则直接使用className来直接实例化对象 HashMap&lt;Class&lt;?&gt;,List&lt;String&gt;&gt; fakeAttributes = new HashMap&lt;&gt;(); ArrayList&lt;String&gt; attrs = new ArrayList&lt;&gt;(); attrs.add("className"); fakeAttributes.put(Object.class, attrs); digester.setFakeAttributes(fakeAttributes); digester.setUseContextClassLoader(true); //遇到xml中Server节点，就创建一个StandardServer对象注意在这里只是添加了这个规则 digester.addObjectCreate("Server", "org.apache.catalina.core.StandardServer", "className"); //根据Server节点中的属性信息，调用属性的setter方法，比如说server节点中会有port=“8080”属性，则会调用setPort方法 digester.addSetProperties("Server"); //在上面的load方法中有个digester.push(this)，this对象就是栈顶了 //这里将Server节点对应的对象作为参数，调用this对象，也就是Catalina对象的setServer方法 //意思即将addObjectCreate 在解析后的对象通过this在digester.push(this)中通过setServer方法注入当前server对象 //注意这里只是添加规则 digester.addSetNext("Server", "setServer", "org.apache.catalina.Server"); //Server节点下的GlobalNamingResources节点，创建一个NamingResource对象 digester.addObjectCreate("Server/GlobalNamingResources", "org.apache.catalina.deploy.NamingResourcesImpl"); digester.addSetProperties("Server/GlobalNamingResources"); digester.addSetNext("Server/GlobalNamingResources", "setGlobalNamingResources", "org.apache.catalina.deploy.NamingResourcesImpl"); //Server下的Listener节点 digester.addObjectCreate("Server/Listener", null, // MUST bespecified in the element "className"); digester.addSetProperties("Server/Listener"); digester.addSetNext("Server/Listener", "addLifecycleListener", "org.apache.catalina.LifecycleListener"); //Server下的Service节点 digester.addObjectCreate("Server/Service", "org.apache.catalina.core.StandardService", "className"); digester.addSetProperties("Server/Service"); digester.addSetNext("Server/Service", "addService", "org.apache.catalina.Service"); //Service节点下的Listener节点 digester.addObjectCreate("Server/Service/Listener", null, // MUST bespecified in the element "className"); digester.addSetProperties("Server/Service/Listener"); digester.addSetNext("Server/Service/Listener", "addLifecycleListener", "org.apache.catalina.LifecycleListener"); //Executor节点 digester.addObjectCreate("Server/Service/Executor", "org.apache.catalina.core.StandardThreadExecutor", "className"); digester.addSetProperties("Server/Service/Executor"); digester.addSetNext("Server/Service/Executor", "addExecutor", "org.apache.catalina.Executor"); //给Connector添加规则，就是当遇到Connector的时候，会调用ConnectorCreateRule里面定义的规则 //跟上面的作用是一样的，只不过该节点的规则比较多，就创建一个规则类 digester.addRule("Server/Service/Connector", new ConnectorCreateRule()); digester.addRule("Server/Service/Connector", new SetAllPropertiesRule(new String[]&#123;"executor"&#125;)); digester.addSetNext("Server/Service/Connector", "addConnector", "org.apache.catalina.connector.Connector"); digester.addObjectCreate("Server/Service/Connector/Listener", null, // MUST bespecified in the element "className"); digester.addSetProperties("Server/Service/Connector/Listener"); digester.addSetNext("Server/Service/Connector/Listener", "addLifecycleListener", "org.apache.catalina.LifecycleListener"); // AddRuleSets for nested elements digester.addRuleSet(new NamingRuleSet("Server/GlobalNamingResources/")); digester.addRuleSet(new EngineRuleSet("Server/Service/")); digester.addRuleSet(new HostRuleSet("Server/Service/Engine/")); digester.addRuleSet(new ContextRuleSet("Server/Service/Engine/Host/")); addClusterRuleSet(digester, "Server/Service/Engine/Host/Cluster/"); digester.addRuleSet(new NamingRuleSet("Server/Service/Engine/Host/Context/")); // Whenthe 'engine' is found, set the parentClassLoader. digester.addRule("Server/Service/Engine", new SetParentClassLoaderRule(parentClassLoader)); addClusterRuleSet(digester, "Server/Service/Engine/Cluster/"); long t2=System.currentTimeMillis(); if (log.isDebugEnabled()) &#123; log.debug("Digester for server.xml created " + (t2-t1 )); &#125; return (digester);&#125; 注入栈顶对象 将当前catalina压入栈顶，stack 是一个ArrayStack实例 digester.push(this); 具体代码如下： 如果stack的大小为0,则将当前对象赋值给root,这样做的目的是在解析之后，能够直接根据root句柄，返回当前对象 123456789101112131415public void push(Object object) &#123; if (stack.size() == 0) &#123; root = object; &#125; stack.push(object);&#125; public Object parse(InputSource input) throws IOException,SAXException &#123; configure(); getXMLReader().parse(input); return (root);&#125; 解析标签创建实例 在解析xml直接首先要获取的xml阅读器，在这里获取的是,其过程是通过getParser方法获取对应的SAXParserImpl工厂,然后调用SAXParserImpl实例的newSAXParser方法,创建SAXParserImpl实例,然后设置相关属性 12345678910111213141516171819public XMLReader getXMLReader() throws SAXException&#123; if (reader == null) &#123; reader =getParser().getXMLReader(); &#125; reader.setDTDHandler(this); reader.setContentHandler(this); if (entityResolver== null) &#123; reader.setEntityResolver(this); &#125; else &#123; reader.setEntityResolver(entityResolver); &#125; reader.setProperty("http://xml.org/sax/properties/lexical-handler", this); reader.setErrorHandler(this); return reader;&#125; 根据上述代码，可以知道getXMLReader().parse(input);实际上调用的是SAXParserImpl中的 parse方法对input资源进行解析。方法如下： 1234567891011public void parse(InputSource inputSource) throws SAXException,IOException &#123; if (fSAXParser != null &amp;&amp; fSAXParser.fSchemaValidator!= null) &#123; if (fSAXParser.fSchemaValidationManager!= null) &#123; fSAXParser.fSchemaValidationManager.reset(); fSAXParser.fUnparsedEntityHandler.reset(); &#125; resetSchemaValidator(); &#125; super.parse(inputSource);&#125; 由上看出其继续调用父类AbstractSAXParser的parse方法，在这个父类方法，其主要将资源文件转化为了XMLInputSource,设置其相关属性,而后调用其重载方法,对XMLInputSource进行解析最终经过一系列转化调用Digester的startDocument方法。这个方法主要是设置了一下编码。在startDocument之后继续开始扫描文档,主要方法是scanDocument,开始对整个文档开始进行解析,方法如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public boolean scanDocument(boolean complete)throws IOException, XNIException &#123; fEntityManager.setEntityHandler(this); int event =next(); do &#123; switch (event) &#123; case XMLStreamConstants.START_DOCUMENT: break; case XMLStreamConstants.START_ELEMENT: break; case XMLStreamConstants.CHARACTERS : fDocumentHandler.characters(getCharacterData(),null); break; case XMLStreamConstants.SPACE: break; case XMLStreamConstants.ENTITY_REFERENCE: break; case XMLStreamConstants.PROCESSING_INSTRUCTION: fDocumentHandler.processingInstruction(getPITarget(),getPIData(),null); break; case XMLStreamConstants.COMMENT : fDocumentHandler.comment(getCharacterData(),null); break; case XMLStreamConstants.DTD : break; case XMLStreamConstants.CDATA: fDocumentHandler.startCDATA(null); //xxx: checkif CDATA values comes from getCharacterData() function fDocumentHandler.characters(getCharacterData(),null); fDocumentHandler.endCDATA(null); //System.out.println("in CDATA of the XMLNSDocumentScannerImpl"); break; case XMLStreamConstants.NOTATION_DECLARATION: break; case XMLStreamConstants.ENTITY_DECLARATION: break; case XMLStreamConstants.NAMESPACE : break; case XMLStreamConstants.ATTRIBUTE : break; case XMLStreamConstants.END_ELEMENT: break; default : throw new InternalError("processingevent: " + event); &#125; event = next(); &#125; while (event!=XMLStreamConstants.END_DOCUMENT&amp;&amp; complete); if(event ==XMLStreamConstants.END_DOCUMENT) &#123; fDocumentHandler.endDocument(null); return false; &#125; return true;&#125; 开始调用startElement对元素开始解析,先拼接模式然后获取其对应的规则,遍历所有规则,调用其对应规则实例的begin方法,这要求所有规则实现抽象类Rule，规则的添加在上文解析过程中。 12345678910111213141516171819202122232425262728293031public void startElement(String namespaceURI, String localName, String qName, Attributes list) throws SAXException &#123; list = updateAttributes(list); bodyTexts.push(bodyText); bodyText = new StringBuilder(); String name = localName; if ((name == null) || (name.length() &lt; 1)) &#123; name = qName; &#125; StringBuilder sb = new StringBuilder(match); if (match.length() &gt; 0) &#123; sb.append('/'); &#125; sb.append(name); match = sb.toString(); if (debug) &#123; log.debug(" New match='" + match + "'"); &#125; List&lt;Rule&gt; rules = getRules().match(namespaceURI, match); matches.push(rules); if ((rules != null) &amp;&amp; (rules.size() &gt; 0)) &#123; for (int i = 0; i &lt; rules.size(); i++) &#123; Rule rule = rules.get(i); rule.begin(namespaceURI, name, list); &#125; &#125; Rule实现类begin方法 对应规则: ObjectCreateRule的begin方法 创建对象是根据realClassName,根据类加载器创建其对应的实例,然后将这个实例给压入digester的栈中，在这里有必要解释一下attributes这个属性的集合来自于配置文件, getValue这个方法是根据attributeName==》className来获取对应的类名，这些值来自于server.xml中的解析，所以可以看出如果xml中存在，则优先使用xml中的值。只是默认server.xml中为空 123456789101112131415@Overridepublic void begin(Stringnamespace, String name, Attributes attributes) throws Exception &#123; String realClassName = className; if (attributeName!= null) &#123; String value =attributes.getValue(attributeName); if (value != null) &#123; realClassName = value; &#125; &#125;…………………… Class&lt;?&gt; clazz = digester.getClassLoader().loadClass(realClassName); Object instance =clazz.newInstance(); digester.push(instance);&#125; SetPropertiesRule 当前方法主要是对属性进行规则验证，如果需要进行规则验证，且其是一个不合法的属性，则输出警告日志。 12345678910111213141516171819202122public void begin(String namespace, String theName,Attributes attributes) throws Exception &#123; // Populate thecorresponding properties of the top object Object top = digester.peek(); for (int i = 0; i &lt;attributes.getLength(); i++) &#123; String name =attributes.getLocalName(i); if ("".equals(name))&#123; name =attributes.getQName(i); &#125; String value =attributes.getValue(i); if (!digester.isFakeAttribute(top,name) &amp;&amp; !IntrospectionUtils.setProperty(top,name, value) &amp;&amp; digester.getRulesValidation())&#123; digester.log.warn("[SetPropertiesRule]&#123;"+ digester.match + "&#125;Setting property '" + name + "' to '" + value + "' didnot find a matching property."); &#125; &#125;&#125; SetNextRule 这个方法的begin什么事情都没有做 Rule实现类的body方法 这部分方法没有进行任何处理 Rule实现类的end方法 SetNextRule: SetNextRule[methodName=,paramType=org.apache.catalina.LifecycleListener] 该方法是在标签元素结束的时候调用，获取当前对象以及其父级对象，然后根据方法名和参数类型调用调用父类方法,将当前实例注入作为其句柄属性。 1234567public void end(String namespace, String name) throws Exception &#123; Object child = digester.peek(0); Object parent = digester.peek(1); IntrospectionUtils.callMethod1(parent,methodName, child, paramType, digester.getClassLoader());&#125; SetNextRule 这个方法的end什么事情都没有做 ObjectCreateRule 这个方法是将当前实例元素给移除栈顶 123public void end(String namespace, String name) throws Exception &#123; Object top = digester.pop();&#125; 标签解析值 Server标签 1[className=org.apache.catalina.core.StandardServer,attributeName=className] 其创建了一个StandardServer对象 此时stack栈中的集合: Catalina@1590 StandardServer@1788 SetNextRule[methodName=setServer,paramType=org.apache.catalina.Server] 默认实现方法中begin方法什么也没有做 SetPropertiesRule[] 验证属性是否符合规范并注入相应的值,在这里给StandardServer注入了port=8005shutdown=SHUTDOWN Server/Listener标签 begin =============================================================== ObjectCreateRule[className=null, attributeName=className] attributeName=&gt;org.apache.catalina.startup.VersionLoggerListener 从而创建对应实例然后压入到stack栈: Catalina@1590 StandardServer@1788 VersionLoggerListener@1974 begin =============================================================== SetPropertiesRule[] 这里并没有什么属性设置到当前实例 begin =============================================================== SetNextRule[methodName=addLifecycleListener,paramType=org.apache.catalina.LifecycleListener] 默认实现方法中begin方法什么也没有做 end =============================================================== SetNextRule[methodName=addLifecycleListener,paramType=org.apache.catalina.LifecycleListener] 调用StandardServer@1788这个实例中的addLifecycleListener (LifecycleListener lifecycleListener)方法,将VersionLoggerListener添加到其句柄lifecycle这个LifecycleSupport实例中去 end =============================================================== SetPropertiesRule[] 这里什么也没有做 end =============================================================== ObjectCreateRule[className=null, attributeName=className] 将栈顶元素从stack中移除,这里移除的是VersionLoggerListener@1974 实例,所以此时栈顶元素 Catalina@1590 StandardServer@1788 相同原理依次加入 AprLifecycleListener JreMemoryLeakPreventionListener GlobalResourcesLifecycleListener ThreadLocalLeakPrevent Server/Service标签 begin ============================================================= ObjectCreateRule[className=org.apache.catalina.core.StandardService,attributeName=className] 创建StandardService实例压入到栈中，此时栈中的元素： Catalina@1590 StandardServer@1788 StandardService begin ============================================================ SetPropertiesRule[] 设置属性值,这里将其name设置为catalina begin =============================================================== SetNextRule[methodName=addService,paramType=org.apache.catalina.Service] Server/Service/Connector标签 Server/Service/Engine标签 Server/Service/Realm标签 Server/Service/Host标签]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat请求处理分析(六)servlet的处理过程]]></title>
    <url>%2F2017%2F08%2F20%2Ftomcat%2F2018-01-23-5%2F</url>
    <content type="text"><![CDATA[servlet的解析过程 servlet的解析分为两步实现，第一个是匹配到对应的Wrapper,第二个是加载对应的servlet并进行数据，这些数据是怎么到界面的，response.getWrite()获取对应的流，然后写入这个流中，这个流中就有上文的outputBuffer。 匹配到对应Wrapper 在上文中我们曾经走到过了doRun方法，现在就直接从这里开始 执行顺序如下： NioEndpoint（run）==&gt;下步调用doRun NioEndpoint（doRun）==&gt;下步调用state = &lt;em style=&quot;color:red&quot;&gt;handler&lt;/em&gt;.process(ka,status); handler实例对象Http11ConnectionHandler其继承AbstractConnectionHandler AbstractConnectionHandler（process） ==》下步调用 state = &lt;em style=&quot;color:red&quot;&gt;processor&lt;/em&gt;.process(wrapper); processor实例对象Http11NioProcessor 其继承AbstractHttp11Processor AbstractHttp11Processor（process） ==》下步调用getAdapter().service(request, response); &lt;em style=&quot;color:red&quot;&gt;CoyoteAdapter&lt;/em&gt;.service(request,response)这个方法就已经接近核心处理了，代码如下： 在第一处标红的地方，对请求进行了解析，并且匹配到对应的主机和context和wrapper 在第二处标红的地方是加载servlet并进行调用处理 在第三处标红的地方是刷新流，响应到界面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119@SuppressWarnings("deprecation")@Overridepublicvoid service(org.apache.coyote.Request req, org.apache.coyote.Responseres) throws Exception &#123; Request request = (Request)req.getNote(ADAPTER_NOTES); Response response =(Response) res.getNote(ADAPTER_NOTES); if (request == null) &#123; //创建一个request对象 request = connector.createRequest(); request.setCoyoteRequest(req); response = connector.createResponse(); response.setCoyoteResponse(res); // Link objects request.setResponse(response); response.setRequest(request); // Set as notes req.setNote(ADAPTER_NOTES,request); res.setNote(ADAPTER_NOTES,response); // Set query string encoding req.getParameters().setQueryStringEncoding (connector.getURIEncoding()); &#125; if (connector.getXpoweredBy())&#123; response.addHeader("X-Powered-By",POWERED_BY); &#125; boolean comet =false; boolean async = false; boolean postParseSuccess = false; try &#123; //设置执行线程线程名 req.getRequestProcessor().setWorkerThreadName(THREAD_NAME.get()); //对uri进行解码，主要是解析报文，如果不合法返回响应码400 postParseSuccess = postParseRequest(req,request, res, response); if (postParseSuccess) &#123; //设置是否支持异步 request.setAsyncSupported(connector.getService().getContainer().getPipeline().isAsyncSupported()); //不断调用管道加载对应的servlet进行调用,其中传递了response参数，所以可以放入流数据 connector.getService().getContainer().getPipeline().getFirst().invoke(request,response); if (request.isComet()) &#123; if (!response.isClosed()&amp;&amp; !response.isError()) &#123; comet = true; res.action(ActionCode.COMET_BEGIN, null); if (request.getAvailable()|| (request.getContentLength() &gt;0 &amp;&amp;(!request.isParametersParsed()))) &#123; event(req, res,SocketStatus.OPEN_READ); &#125; &#125; else &#123; request.setFilterChain(null); &#125; &#125; &#125; //如果是异步请求 if (request.isAsync())&#123; async = true; ReadListener readListener= req.getReadListener(); if (readListener != null&amp;&amp;request.isFinished()) &#123; ClassLoader oldCL =null; try &#123; oldCL =request.getContext().bind(false, null); if (req.sendAllDataReadEvent())&#123; req.getReadListener().onAllDataRead(); &#125; &#125; finally &#123; request.getContext().unbind(false,oldCL); &#125; &#125; Throwable throwable = (Throwable)request.getAttribute(RequestDispatcher.ERROR_EXCEPTION); if (!request.isAsyncCompleting()&amp;&amp; throwable !=null) &#123; request.getAsyncContextInternal().setErrorState(throwable, true); &#125; &#125; else if (!comet) &#123; //如果为同步请求，Flush并关闭输入输出流 request.finishRequest(); response.finishResponse(); &#125; &#125; catch (IOExceptione) &#123; // Ignore &#125; finally&#123; AtomicBoolean error = new AtomicBoolean(false); res.action(ActionCode.IS_ERROR,error); if (request.isAsyncCompleting()&amp;&amp; error.get()) &#123; res.action(ActionCode.ASYNC_POST_PROCESS, null); async = false; &#125; if (!async&amp;&amp; !comet) &#123; if (postParseSuccess)&#123; request.getMappingData().context.logAccess( request, response, System.currentTimeMillis()- req.getStartTime(), false); &#125; &#125; req.getRequestProcessor().setWorkerThreadName(null); if (!comet &amp;&amp;!async) &#123; request.recycle(); response.recycle(); &#125; else&#123; request.clearEncoders(); response.clearEncoders(); &#125; &#125;&#125; 构造对应request的MappingData属性 12345678postParseRequest:CoyoteAdapter(org.apache.catalina.connector)connector.getService().getMapper().map(serverName,decodedURI,version, request.getMappingData()); 下面是request部分构造代码protected final MappingDatamappingData =new MappingData();public MappingDatagetMappingData() &#123; return mappingData;&#125; 根据调用方法，我们可以知道其传入的参数有request实例成员对象mappingData的引用类型，所以下面的匹配的Context以及Wrapper所到的mappingData都是当前request的属性 ============================================ map: Mapper (org.apache.catalina.mapper) internalMap(host.getCharChunk(),uri.getCharChunk(), version, mappingData); internalMap:758,Mapper (org.apache.catalina.mapper) 在这里面匹配到了对应的虚拟主机，存放到了mappingData中去，以及Context主要采用了二分查找获取游标进行匹配然后其调用internalMapWrapper(contextVersion,uri, mappingData);匹配到了Wrapper存放到mappingData，其匹配规则如下 123456789101112131415161718192021222324252627282930313233/** * a: 对全新的路径进行精准匹配 * b: 对全新的路径进行通配符匹配 * c: 根据全新的路径，进行查找是否存在相应的文件，如果存在相应的文件，则需要将该文件返回。在回前我们需要进一步确认，这个文件是不是讲文件内容源码返回，还是像jsp文件一样，进行一定的处理然后再返回，所以又要确认下文件的扩展名是怎样的 * c1: 尝试寻找能够处理该文件扩展名的servlet，即进行扩展名匹配,如果找到，则使用对应的servlet * c2: 如果没找到，则默认使用defaultWrapper，即DefaultServlet（它只会将文件内容源码返回，不做任何处理） * d: 对全新的路径进行扩展名匹配（与c的目的不同，c的主要目的是想返回一个文件的内容，在返回内容前涉及到扩展名匹配，所以4c的前提是存在对应路径的文件） * 案例1： a.html，a、b没有匹配到，到c的时候，找到了该文件，然后又尝试扩展名匹配，来决定是走c1还是c2，由于.html还没有对应的servlet来处理，就使用了默认的DefaultServlet * 案例2： a.jsp，同上，在走到c的时候，找到了处理.jsp对应的servlet，所以走了c1 * 案例3： a.action,如果根目录下有a.action文件，则走到c1的时候，进行扩展名匹配，匹配到了SecondServlet，即走了c1，使用SecondServlet来处理请求；如果根目录下没有a.action文件，则走到了d，进行扩展名匹配，同样匹配到了SecondServlet，即走了d，同样使用SecondServlet来处理请求 * 案例4： first/abc，执行b的时候，就匹配到了FirstServlet，所以使用FirstServlet来处理请求 * */private final void internalMapWrapper(ContextVersioncontextVersion, CharChunkpath, MappingDatamappingData)throws IOException &#123; 。。。。。。。 if (found) &#123; mappingData.wrapperPath.setString(wrappers[pos].name); if (path.getLength() &gt;length) &#123; mappingData.pathInfo.setChars (path.getBuffer(), path.getOffset()+ length, path.getLength()- length); &#125; mappingData.requestPath.setChars (path.getBuffer(), path.getOffset(),path.getLength()); mappingData.wrapper=wrappers[pos].object; mappingData.jspWildCard=wrappers[pos].jspWildCard; &#125; &#125;&#125; 加载servlet并调用 一起执行顺序来看一下一个servlet如何进行加载 invoke:98,StandardEngineValve (org.apache.catalina.core) 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 基于请求的服务名选择合适的虚拟主机进行请求处理 * * 如果不能匹配到对应主机，返回对应的http错误 * * @param request 执行请求 * @param response Response tobe produced * */@Overridepublicfinal void invoke(Request request,Response response) throws IOException,ServletException&#123; //根据请求找到对应的host Host host =request.getHost(); if (host == null) &#123; response.sendError (HttpServletResponse.SC_BAD_REQUEST, sm.getString("standardEngine.noHost", request.getServerName())); return; &#125; //设置当前请求是否支持异步 if (request.isAsyncSupported())&#123; request.setAsyncSupported(host.getPipeline().isAsyncSupported()); &#125; //org.apache.catalina.valves.AccessLogValve[localhost] //org.apache.catalina.valves.ErrorReportValve[localhost] //org.apache.catalina.core.StandardHostValve[localhost] /** * 调用host的第一个valve * * 其执行原理是获取根据管道获取第一个阀门AccessLogValve调用其invoke方法 * * AccessLogValve的invoke第一行调用getNext().invoke()调用了ErrorReportValve * * 同理调用了StandardHostValve的invoke方法所以实际调用的最先的是invoke方法 * */ host.getPipeline().getFirst().invoke(request,response);&#125; invoke:143,StandardHostValve (org.apache.catalina.core) 下步调用context.getPipeline().getFirst().invoke(request,response); invoke:504,AuthenticatorBase(org.apache.catalina.authenticator) 下步调用getNext().invoke(request, response); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * * 基于URI的request获取对应的Wrapper如果没有匹配到返回一个HTTP错误 * * 在这个方法中做的事情主要是获取wrapper然后进行对应管道的阀门进行调用 * @param request Request tobe processed * @param response Response tobe produced * * @exception IOException if aninput/output error occurred * @exception ServletException ifa servlet error occurred */@Overridepublicfinal void invoke(Request request,Response response) throws IOException,ServletException&#123; // Disallow any directaccess to resources under WEB-INF or META-INF MessageBytesrequestPathMB = request.getRequestPathMB(); if ((requestPathMB.startsWithIgnoreCase("/META-INF/",0)) ||(requestPathMB.equalsIgnoreCase("/META-INF")) ||(requestPathMB.startsWithIgnoreCase("/WEB-INF/",0)) ||(requestPathMB.equalsIgnoreCase("/WEB-INF"))) &#123; response.sendError(HttpServletResponse.SC_NOT_FOUND); return; &#125; //获取当前request利用的wrapper Wrapper wrapper =request.getWrapper(); if (wrapper == null||wrapper.isUnavailable()) &#123; response.sendError(HttpServletResponse.SC_NOT_FOUND); return; &#125; // Acknowledge the request try &#123; response.sendAcknowledgement(); &#125; catch(IOExceptionioe) &#123; container.getLogger().error(sm.getString( "standardContextValve.acknowledgeException"),ioe); request.setAttribute(RequestDispatcher.ERROR_EXCEPTION,ioe); response.sendError(HttpServletResponse.SC_INTERNAL_SERVER_ERROR); return; &#125; if (request.isAsyncSupported())&#123; request.setAsyncSupported(wrapper.getPipeline().isAsyncSupported()); &#125; wrapper.getPipeline().getFirst().invoke(request,response);&#125; invoke:98,StandardWrapperValve (org.apache.catalina.core) 其主要操作如下：获取到对应的StandardWrapper，然后分配一个servlet,具体在loadServlet中进行实例话，再分配由于是成员变量，只有第一次调用的时候才会进行分配，之后直接返回第一次的实例化对一下对象，具体看allocate方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public final void invoke(Request request,Responseresponse) throws IOException,ServletException&#123; //获取到对应的StandardWrapper StandardWrapper wrapper= (StandardWrapper) getContainer(); //每个请求开始servlet都是为空 Servlet servlet = null; Context context =(Context) wrapper.getParent(); try &#123; if (!unavailable)&#123; servlet = wrapper.allocate(); &#125; &#125; MessageBytes requestPathMB =request.getRequestPathMB(); DispatcherTypedispatcherType = DispatcherType.REQUEST; if (request.getDispatcherType()==DispatcherType.ASYNC)dispatcherType = DispatcherType.ASYNC; request.setAttribute(Globals.DISPATCHER_TYPE_ATTR,dispatcherType); request.setAttribute(Globals.DISPATCHER_REQUEST_PATH_ATTR, requestPathMB); // 创建过滤器实例 ApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request,wrapper, servlet); if ((servlet !=null) &amp;&amp;(filterChain !=null)) &#123; if (context.getSwallowOutput()) &#123; try &#123; SystemLogHandler.startCapture(); if (request.isAsyncDispatching())&#123; request.getAsyncContextInternal().doInternalDispatch(); &#125; else if(comet) &#123; filterChain.doFilterEvent(request.getEvent()); &#125; else&#123; filterChain.doFilter(request.getRequest(), response.getResponse()); &#125; &#125; finally &#123; String log =SystemLogHandler.stopCapture(); if (log != null&amp;&amp;log.length() &gt; 0) &#123; context.getLogger().info(log); &#125; &#125; &#125; else &#123; if (request.isAsyncDispatching())&#123; request.getAsyncContextInternal().doInternalDispatch(); &#125; else if(comet) &#123; filterChain.doFilterEvent(request.getEvent()); &#125; else&#123; filterChain.doFilter (request.getRequest(), response.getResponse()); &#125; &#125; &#125; &#125; //释放过滤器 if (filterChain!=null) &#123; if (request.isComet())&#123; // If this is a Cometrequest, then the same chain will be used for the // processing of allsubsequent events. filterChain.reuse(); &#125; else&#123; filterChain.release(); &#125; &#125; // Deallocate theallocated servlet instance try &#123; if (servlet !=null) &#123; wrapper.deallocate(servlet); &#125; &#125; catch (Throwablee) &#123; ExceptionUtils.handleThrowable(e); container.getLogger().error(sm.getString("standardWrapper.deallocateException", wrapper.getName()),e); if (throwable == null) &#123; throwable = e; exception(request,response, e); &#125; &#125; try &#123; if ((servlet !=null) &amp;&amp; (wrapper.getAvailable() ==Long.MAX_VALUE)) &#123; wrapper.unload(); &#125; &#125; catch (Throwablee) &#123; ExceptionUtils.handleThrowable(e); container.getLogger().error(sm.getString("standardWrapper.unloadException", wrapper.getName()),e); if (throwable == null) &#123; throwable = e; exception(request,response, e); &#125; &#125; long t2=System.currentTimeMillis(); long time=t2-t1; processingTime += time; if( time &gt; maxTime)maxTime=time; if( time &lt; minTime)minTime=time;&#125; servlet的调用 按照这个顺序执行完所有过滤器就会执行对应的servlet,这是因为在创建过滤器 ApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request,wrapper, servlet); 的时候，将servlet给注入进去了，当过滤器执行完了，会执行调用servlet的service, 由于自己写的servlet是会继承HttpServlet的，所以将调用其service方法 调用如下： internalDoFilter:,ApplicationFilterChain 方法如下：下面展示了两个service ,同在HttpServlet只是方法的参数有所不同，加载过程先调用一个，然后第一个再调用第二个，根据请求方法调用自己对应的Servlet中的doGet等一些列方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172protected void service(HttpServletRequest req,HttpServletResponseresp) throws ServletException,IOException&#123; //获取对应的方法 String method = req.getMethod(); /** * 根据请求method调用对应方法 * GET ==&gt;doGet(req, resp) * head ==&gt; doHead(req, resp) * post ==&gt;doPost(req,resp) * * */ if (method.equals(METHOD_GET)) &#123; long lastModified= getLastModified(req); if (lastModified == -1) &#123; // servlet doesn't supportif-modified-since, no reason // to go through furtherexpensive logic doGet(req,resp); &#125; else&#123; long ifModifiedSince; try &#123; ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); &#125; catch(IllegalArgumentExceptioniae) &#123; // Invalid date header -proceed as if none was set ifModifiedSince = -1; &#125; if (ifModifiedSince&lt; (lastModified /1000 * 1000)) &#123; // If the servlet mod timeis later, call doGet() // Round down to thenearest second for a proper compare // A ifModifiedSince of-1 will always be less maybeSetLastModified(resp,lastModified); doGet(req,resp); &#125; else&#123; resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123; long lastModified =getLastModified(req); maybeSetLastModified(resp,lastModified); doHead(req,resp); &#125; else if(method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if(method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if(method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if(method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if(method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; // // Note that this means NOservlet supports whatever // method was requested, anywhereon this server. // String errMsg = lStrings.getString("http.method_not_implemented"); Object[] errArgs = newObject[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg,errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED,errMsg); &#125;&#125; 上面已经讲述了一个servlet调用的过程，他的信息是如何返回掉流中，我们的看一下response,getWrite方法可以看出这个流最终将outputBuffer给封装，其write方法所以是写到上文封装的流中，最后一并解析到页面，可以参照请求到响应流。]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat请求处理分析(五) 请求到响应流]]></title>
    <url>%2F2017%2F08%2F20%2Ftomcat%2F2018-01-23-4%2F</url>
    <content type="text"><![CDATA[请求到响应界面流&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;请求处理的过程主要是将所有的东西解析成流，转化成对应的http报文，所以在这里我先不关注servlet因为它最终也就是解析成流里面的数据processKey里面最终执行的是processSocket，它是线从缓存中获取对应的线程池，没有的话就创建一个，然后进行执行 123456789101112131415161718192021222324252627protected boolean processSocket(KeyAttachmentattachment, SocketStatus status, boolean dispatch) &#123; try &#123; if (attachment== null) &#123; return false; &#125; SocketProcessor sc = processorCache.pop(); if ( sc == null ) sc = new SocketProcessor(attachment, status); else sc.reset(attachment, status); Executor executor =getExecutor(); if (dispatch &amp;&amp;executor != null) &#123; executor.execute(sc); &#125; else &#123; sc.run(); &#125; &#125; catch (RejectedExecutionExceptionree) &#123; log.warn(sm.getString("endpoint.executor.fail", attachment.getSocket()), ree); return false; &#125; catch (Throwablet) &#123; ExceptionUtils.handleThrowable(t); // This means we got anOOM or similar creating a thread, or that // the pool and its queue arefull log.error(sm.getString("endpoint.process.fail"), t); return false; &#125; return true;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在上面描述的线程中，响应到页面主要是先构建对应的缓冲流，然后将缓冲流中的数据写入到sockt通道，这样就实现到了页面，具体操作逻辑如下：（自下向上执行） 下面我将与流相关的几步，进行一下讲述： process:,AbstractProtocol$AbstractConnectionHandler (org.apache.coyote) 12345678910111213141516if (processor == null) &#123; processor = createProcessor();&#125;protected Http11Processor createProcessor() &#123; Http11Processor processor = new Http11Processor( proto.getMaxHttpHeaderSize(), (JIoEndpoint)proto.endpoint, proto.getMaxTrailerSize(), proto.getAllowedTrailerHeadersAsSet(), proto.getMaxExtensionSize(), proto.getMaxSwallowSize()); proto.configureProcessor(processor); // BIO specificconfiguration processor.setDisableKeepAlivePercentage(proto.getDisableKeepAlivePercentage()); register(processor); return processor;&#125; 1234567891011121314public Http11Processor(int headerBufferSize, JIoEndpointendpoint, int maxTrailerSize, Set&lt;String&gt;allowedTrailerHeaders, int maxExtensionSize, int maxSwallowSize)&#123; super(endpoint); inputBuffer = new InternalInputBuffer(request, headerBufferSize); request.setInputBuffer(inputBuffer); outputBuffer = new InternalOutputBuffer(response, headerBufferSize); response.setOutputBuffer(outputBuffer); initializeFilters(maxTrailerSize, allowedTrailerHeaders, maxExtensionSize, maxSwallowSize);&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里不难看出构建了的outputBuffer这InternalOutputBuffer实例并与response进行关联，所以后面通过response进行一些相关属性操作就可以直接到缓冲流 process:,AbstractHttp11Processor(org.apache.coyote.http11) 12345678910111213141516getOutputBuffer().init(socketWrapper, endpoint);/** * 给当前实例 outputBuffer即response封装的对象 * * 给其成员变量NioChannel socket 以及pool进行赋值 * * */@Overridepublicvoid init(SocketWrapper&lt;NioChannel&gt; socketWrapper, AbstractEndpoint&lt;NioChannel&gt;endpoint) throws IOException &#123; socket =socketWrapper.getSocket(); pool =((NioEndpoint)endpoint).getSelectorPool();&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这一步进行的操作主要是将outputBuffer这个实例关联对应的socket通道，为最后将缓冲流的数据放入到sockt做铺垫 123456789101112131415161718public void close() throws IOException&#123; if (closed) &#123; return; &#125; if (suspended) &#123; return; &#125; //将缓冲去的字符刷新给页面 if (cb.getLength()&gt; 0) &#123; cb.flushBuffer(); &#125; 。。。。。。&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最终是将cb给刷新到了然后将数据返回到页面，看一下cb是怎么来的,由下不难看出将OutputBuffer给注入其通道 1234567891011public OutputBuffer(int size) &#123; bb = new ByteChunk(size); bb.setLimit(size); bb.setByteOutputChannel(this); cb = new CharChunk(size); cb.setLimit(size); cb.setOptimizedWrite(false); cb.setCharOutputChannel(this);&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样做最后怎么获取数据呢？由下面可以看出其一层一层不断的拆解最后还是到InternalOutputBuffer缓冲实例，所以解析的流数据最终还是经过这个进行处理 addToBB:,InternalNioOutputBuffer(org.apache.coyote.http11) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那最终它又是怎么到流中去，得看一下addToBB方法,由两步比较和核心，第一步就是将buf即InternalNioOutputBuffer实例中的数据拷贝到niochannel总去，第二步将niochannel通道中的数据写入到socket通道 123456789101112131415161718192021222324252627282930313233private synchronized void addToBB(byte[] buf, int offset, int length) throws IOException&#123; if (length == 0) return; //首先尝试先将数据发送出去 boolean dataLeft = flushBuffer(isBlocking()); //这里只有在缓冲区里面已经没有数据了才继续发送 while (!dataLeft&amp;&amp; length &gt; 0) &#123; //首先将要发送的数据copy到niochanel的发送buffer里面去 int thisTime =transfer(buf,offset,length,socket.getBufHandler().getWriteBuffer()); //计算还剩下多少字节没有写到niochannel的buffer里面，其实这里也就当做将数据转移到了niochannel的buffer就算是写出去了 length = length -thisTime; //这里用于调整偏移量 offset = offset +thisTime; //调用writeToSocket方法将niochannel的buffer的里面的数据通过socket写出去 int written =writeToSocket(socket.getBufHandler().getWriteBuffer(), isBlocking(), true); //如果在tomcat的response里面有writelistener的话，可以异步的写 if (written == 0) &#123; dataLeft = true; &#125; else &#123; dataLeft =flushBuffer(isBlocking()); &#125; &#125; NioEndpoint.KeyAttachment ka =(NioEndpoint.KeyAttachment)socket.getAttachment(); if (ka != null)ka.access();//prevent timeouts for just doing client writes if (!isBlocking()&amp;&amp; length &gt; 0) &#123; //在非阻塞的发送中，如果实在发送不出去，需要保存在额外的buffer里面 addToBuffers(buf, offset, length); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面在看一下具体怎么写到通道里面去 1234567891011121314151617181920212223242526272829private synchronized int writeToSocket(ByteBufferbytebuffer, boolean block, boolean flip) throws IOException&#123; if ( flip ) &#123; bytebuffer.flip(); flipped = true; &#125; int written = 0; NioEndpoint.KeyAttachmentatt = (NioEndpoint.KeyAttachment)socket.getAttachment(); if ( att == null ) throw new IOException("Keymust be cancelled"); long writeTimeout =att.getWriteTimeout(); Selector selector = null; try &#123; selector = pool.get(); &#125; catch (IOException x ) &#123; &#125; try &#123; written = pool.write(bytebuffer, socket,selector, writeTimeout, block); do &#123; if (socket.flush(true,selector,writeTimeout))break; &#125;while ( true ); &#125; finally &#123; if ( selector!= null)pool.put(selector); &#125; if ( block ||bytebuffer.remaining()==0) &#123; bytebuffer.clear(); flipped = false; &#125; return written;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pool实例，即NioBlockingSelector，可以看出其有阻塞和非组合两种写入方式，但最后都是通过socket.write(buf)写入socket通道就返回到页面，至于为什么写入到socket通道就能响应到页面可以看一下基于NIO的httpserver实现，主要SocketChannelImpl这个类,这里又一个简易的httpserver的实现，参考链接： http://www.cnblogs.com/a294098789/p/5676566.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public int write(ByteBuffer buf, NioChannelsocket, Selector selector, long writeTimeout, boolean block) throws IOException&#123; if ( SHARED &amp;&amp;block ) &#123; return blockingSelector.write(buf,socket,writeTimeout); &#125; SelectionKey key = null; int written = 0; boolean timedout = false; int keycount = 1; //assume we canwrite long time =System.currentTimeMillis(); //start the timeout timer try &#123; while ((!timedout) &amp;&amp; buf.hasRemaining() ) &#123; int cnt = 0; if ( keycount &gt; 0 ) &#123; //only write ifwe were registered for a write cnt = socket.write(buf);//write thedata if (cnt == -1) throw new EOFException(); written += cnt; if (cnt &gt; 0) &#123; time = System.currentTimeMillis(); //reset ourtimeout timer continue; //wesuccessfully wrote, try again without a selector &#125; if (cnt==0 &amp;&amp;(!block)) break; //don't block &#125; if ( selector!= null)&#123; //register OP_WRITE to theselector if (key==null) key =socket.getIOChannel().register(selector, SelectionKey.OP_WRITE); else key.interestOps(SelectionKey.OP_WRITE); if (writeTimeout==0) &#123; timedout =buf.hasRemaining(); &#125; else if (writeTimeout&lt;0) &#123; keycount =selector.select(); &#125; else &#123; keycount =selector.select(writeTimeout); &#125; &#125; if (writeTimeout&gt; 0 &amp;&amp; (selector == null || keycount== 0) ) timedout= (System.currentTimeMillis()-time)&gt;=writeTimeout; &#125;//while if ( timedout )thrownew SocketTimeoutException(); &#125; finally &#123; if (key != null) &#123; key.cancel(); if (selector != null)selector.selectNow();//removes the key from this selector &#125; &#125; return written;&#125;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat请求处理分析(四) 监听请求轮询处理]]></title>
    <url>%2F2017%2F08%2F18%2Ftomcat%2F2018-01-23-3%2F</url>
    <content type="text"><![CDATA[startInternal方法 这个方法是核心的启动方法，目前理解主要做了两件事情，第一件是创建轮询线程,即具体的读取线程,它是进行具体的处理，第二个是创建创建监听请求线程，它是等待请求，然后交给轮训进行处理。 1234567891011121314151617181920212223242526272829303132333435public void startInternal() throws Exception &#123; if (!running) &#123; running = true; paused = false; //一种带锁的栈，processorCache processorCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getProcessorCache()); //事件缓存 eventCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getEventCache()); //nio管道 nioChannels = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getBufferPool()); // Create workercollection if (getExecutor() == null ) &#123; createExecutor(); //实例化当前对象的成员变量executor，构建了一个线程池 &#125; initializeConnectionLatch(); //Poller的数量控制如果不设置的话最大就是2 pollers = new Poller[getPollerThreadCount()]; for (int i=0; i&lt;pollers.length; i++) &#123; pollers[i] = new Poller(); Thread pollerThread = new Thread(pollers[i], getName() + "-ClientPoller-"+i); pollerThread.setPriority(threadPriority);//用来设置进程、进程组和用户的进程执行优先权 pollerThread.setDaemon(true);//设置为守护线程 pollerThread.start(); &#125; startAcceptorThreads(); &#125;&#125; Poller启动 它是被设计成了守护线程,并且进行启动，其run方法如下，采用选择器的非阻塞方式，如果没有获取到注册事件返回空，下面迭代为空所以就什么都没有执行，如果返回不为空则会执行processKey方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public void run() &#123; //这是一个线程,所以进行死循环 while (true) &#123; try &#123; //如果是暂停并且未关闭则睡10s while (paused &amp;&amp;(!close) ) &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedExceptione) &#123; &#125; &#125; boolean hasEvents = false; //如果关闭之后,执行完毕时间后，关闭选择器 if (close) &#123; events(); timeout(0, false); try &#123; selector.close(); &#125; catch (IOExceptionioe) &#123; log.error(sm.getString( "endpoint.nio.selectorCloseFail"), ioe); &#125; break; &#125; else &#123; hasEvents = events(); &#125; /** * 如果endpoint是正常工作状态，处理已有的数据。 * 通过events方法来处理当前Poller中已有的事件（数据）。 * 同时使用selector.select或者selectNow来获取这个Poller上 * */ try &#123; if ( !close ) &#123; if (wakeupCounter.getAndSet(-1) &gt; 0) &#123; //if we are here, means we have other stuff to do //do a nonblocking select keyCount =selector.selectNow(); &#125; else &#123; keyCount =selector.select(selectorTimeout); &#125; wakeupCounter.set(0); &#125; if (close) &#123; events(); timeout(0, false); try &#123; selector.close(); &#125; catch (IOExceptionioe) &#123; log.error(sm.getString( "endpoint.nio.selectorCloseFail"), ioe); &#125; break; &#125; &#125; catch (Throwablex) &#123; ExceptionUtils.handleThrowable(x); log.error("",x); continue; &#125; //either we timed out orwe woke up, process events first if ( keyCount == 0 ) hasEvents= (hasEvents | events()); //正常状态下的数据处理，通过processKey来实现。获取对应的渠道的key，然后调用processKey方法 Iterator&lt;SelectionKey&gt;iterator = keyCount &gt; 0 ? selector.selectedKeys().iterator(): null; // Walk through thecollection of ready keys and dispatch // any active event. while (iterator !=null&amp;&amp;iterator.hasNext()) &#123; SelectionKey sk =iterator.next(); KeyAttachmentattachment = (KeyAttachment)sk.attachment(); if (attachment== null) &#123; iterator.remove(); &#125; else &#123; attachment.access(); iterator.remove(); //processKey的主要工作是调用NioEndpoint的processSocket来实现socket的读写。 processKey(sk, attachment); &#125; &#125;//while timeout(keyCount,hasEvents); if ( oomParachute&gt;0&amp;&amp;oomParachuteData==null)checkParachute(); &#125; stopLatch.countDown();&#125; Acceptor 这是一个接受请求的线程，调用的是startAcceptorThreads方法，方法代码如下： 1234567891011121314151617181920protected final void startAcceptorThreads() &#123; int count =getAcceptorThreadCount(); acceptors = new Acceptor[count]; for (int i = 0; i &lt; count; i++) &#123; acceptors[i] = createAcceptor(); String threadName =getName() + "-Acceptor-" + i; acceptors[i].setThreadName(threadName); Thread t = new Thread(acceptors[i], threadName); t.setPriority(getAcceptorThreadPriority()); t.setDaemon(getDaemon()); t.start(); &#125;&#125; protectedAbstractEndpoint.AcceptorcreateAcceptor() &#123; return new Acceptor();&#125; 所以启动的事Acceptor的线程，主要调用的是其run方法，它做的事情是等待客户端请求，由于在bind方法中ServerSocketChannel这个设置阻塞方式，所以socket = serverSock.accept();在接受请求之后才会进行处理，具体的处理过程在setSocketOptions方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * Acceptor负责用来管理连接到tomcat服务器的数量 * socket连接建立成功之后,读写是交由Poller机制去完成。 * */protected class Acceptor extends AbstractEndpoint.Acceptor&#123; @Override public void run() &#123; int errorDelay =0; while (running) &#123; while (paused &amp;&amp; running) &#123; state =AcceptorState.PAUSED; try &#123; Thread.sleep(50); &#125; catch (InterruptedExceptione) &#123; &#125; &#125; if (!running) &#123; break; &#125; state =AcceptorState.RUNNING; try &#123; countUpOrAwaitConnection(); //计数+1，达到最大值则等待 SocketChannel socket = null; try &#123; //ServerSocketChannel 一个阻塞监听等待请求 socket = serverSock.accept(); &#125; catch (IOExceptionioe) &#123; //we didn't geta socket countDownConnection(); // Introducedelay if necessary errorDelay =handleExceptionWithDelay(errorDelay); // re-throw throw ioe; &#125; // Successful accept,reset the error delay errorDelay = 0; // setSocketOptions() willadd channel to the poller // if successful if (running &amp;&amp; !paused) &#123; //将请求连接放入队列等待处理 if (!setSocketOptions(socket)) &#123; countDownConnection(); closeSocket(socket); &#125; &#125; else &#123; countDownConnection(); //计数-1 closeSocket(socket); //关闭当前socket套接字 &#125; &#125; catch (SocketTimeoutExceptionsx) &#123; // Ignore: Normalcondition &#125; catch (IOExceptionx) &#123; if (running) &#123; log.error(sm.getString("endpoint.accept.fail"), x); &#125; &#125; catch (OutOfMemoryErroroom) &#123; try &#123; oomParachuteData=null; releaseCaches(); log.error("", oom); &#125;catch ( Throwableoomt ) &#123; try &#123; try &#123; System.err.println(oomParachuteMsg); oomt.printStackTrace(); &#125;catch (ThrowableletsHopeWeDontGetHere)&#123; ExceptionUtils.handleThrowable(letsHopeWeDontGetHere); &#125; &#125;catch (ThrowableletsHopeWeDontGetHere)&#123; ExceptionUtils.handleThrowable(letsHopeWeDontGetHere); &#125; &#125; &#125; catch (Throwablet) &#123; ExceptionUtils.handleThrowable(t); log.error(sm.getString("endpoint.accept.fail"), t); &#125; &#125; state =AcceptorState.ENDED; &#125;&#125; acceptor线程转交到poller进行处理 setSocketOptions方法通过通道获取真实的socket注入一些属性,然后构造NioChannel，将socket通道注入到对应的NioChannel实例，利用getPoller0用的循环的方式来返回Poller然后将NioChannel实例注册 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859protected boolean setSocketOptions(SocketChannel socket)&#123; // Process the connection try &#123; //设置为非阻塞 socket.configureBlocking(false); //获取socket Socket sock = socket.socket();//实际socket //配置socket信息 socketProperties.setProperties(sock); //创建一个NioChannel 他封装了SocketChannel NioChannel channel = nioChannels.pop(); if ( channel == null ) &#123; //如果为null 创建一个NioChannel 这里使用系统内存 //使用系统内存可以省去一步从系统内存拷贝到堆内存的动作、性能上会有很大的提升，nioChannels初始化默认为128个 //当socket 关闭的重新清理NioChannel而不是销毁这个对象可以达到对象复用的效果、因为申请系统内存的开销比申请堆内存的开销要大很多 if (sslContext != null) &#123; SSLEngine engine =createSSLEngine(); int appbufsize =engine.getSession().getApplicationBufferSize(); //NioBufferHandler里分别分配了读缓冲区和写缓冲区 NioBufferHandler bufhandler= newNioBufferHandler(Math.max(appbufsize,socketProperties.getAppReadBufSize()), Math.max(appbufsize,socketProperties.getAppWriteBufSize()), socketProperties.getDirectBuffer()); channel = new SecureNioChannel(socket, engine, bufhandler, selectorPool); &#125; else &#123; // normal tcp setup NioBufferHandlerbufhandler = new NioBufferHandler(socketProperties.getAppReadBufSize(), socketProperties.getAppWriteBufSize(), socketProperties.getDirectBuffer()); channel = new NioChannel(socket, bufhandler); &#125; &#125; else &#123; //如果存在通道，则直接将当前socket注入 channel.setIOChannel(socket); if ( channel instanceof SecureNioChannel) &#123; SSLEngine engine =createSSLEngine(); ((SecureNioChannel)channel).reset(engine); &#125; else &#123; channel.reset(); &#125; &#125; // 这里就是将SocketChannel注册到Poller了。 // getPoller0用的循环的方式来返回Poller，即Poller 1, 2,3... n 然后再回到1, 2, 3.. getPoller0().register(channel); &#125; catch (Throwablet) &#123; ExceptionUtils.handleThrowable(t); try &#123; log.error("",t); &#125; catch (Throwablett) &#123; ExceptionUtils.handleThrowable(tt); &#125; // Tell to close thesocket return false; &#125; return true;&#125; 上文注册还不是选择器的注入方式，而是在NioEndpoint内部类Poller类的register方法，其代码如下：在前面设置了一些基本属性，然后调用addEvent唤醒对应的选择器，这个selector实例是Poller对象的一个成员变量，对应的非阻塞过程在run方法，所以监听请求世实际还是在Poller的run方法中selectNow后面进行处理 123456789101112131415161718192021222324252627public void register(final NioChannelsocket) &#123; //给当前socket设置为这个Poller实例 socket.setPoller(this); //构造KeyAttachment实例，其继承SocketWrapper KeyAttachment ka = new KeyAttachment(socket); //设置其轮询实例 ka.setPoller(this); ka.setTimeout(getSocketProperties().getSoTimeout()); ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests()); ka.setSecure(isSSLEnabled()); // 从Poller的事件对象缓存中取出一个PollerEvent，并用socket初始化事件对象 PollerEvent r = eventCache.pop(); // 设置读操作为感兴趣的操作 ka.interestOps(SelectionKey.OP_READ); if ( r==null) r = new PollerEvent(socket,ka,OP_REGISTER); else r.reset(socket,ka,OP_REGISTER); // 加入到Poller对象里的事件队列 addEvent(r);&#125; private void addEvent(PollerEvent event) &#123; events.offer(event); if ( wakeupCounter.incrementAndGet()== 0)selector.wakeup();&#125; 具体执行的接受到通道注册的时间之后，往下执行，就能够产生相应的选择键，这样会执行processKey这个方法，然后将请求进行处理，并解析成相关的流，返回到界面。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public void run() &#123; …… /** * 如果endpoint是正常工作状态，处理已有的数据。 * 通过events方法来处理当前Poller中已有的事件（数据）。 * 同时使用selector.select或者selectNow来获取这个Poller上 * */ try &#123; if ( !close ) &#123; if (wakeupCounter.getAndSet(-1) &gt; 0) &#123; keyCount = selector.selectNow(); &#125; else &#123; keyCount = selector.select(selectorTimeout); &#125; wakeupCounter.set(0); &#125; if (close) &#123; events(); timeout(0, false); try &#123; selector.close(); &#125; catch (IOExceptionioe) &#123; log.error(sm.getString( "endpoint.nio.selectorCloseFail"), ioe); &#125; break; &#125; &#125; catch (Throwablex) &#123; ExceptionUtils.handleThrowable(x); log.error("",x); continue; &#125; if ( keyCount == 0 ) hasEvents= (hasEvents | events()); //正常状态下的数据处理，通过processKey来实现。获取对应的渠道的key，然后调用processKey方法 Iterator&lt;SelectionKey&gt;iterator = keyCount &gt; 0 ? selector.selectedKeys().iterator(): null; // Walk through thecollection of ready keys and dispatch // any active event. while (iterator !=null&amp;&amp;iterator.hasNext()) &#123; SelectionKey sk =iterator.next(); KeyAttachmentattachment = (KeyAttachment)sk.attachment(); // Attachment may be nullif another thread has called // cancelledKey() if (attachment== null) &#123; iterator.remove(); &#125; else &#123; attachment.access(); iterator.remove(); //processKey的主要工作是调用NioEndpoint的processSocket来实现socket的读写。 processKey(sk, attachment); &#125; &#125;//while //process timeouts timeout(keyCount,hasEvents); if ( oomParachute&gt;0&amp;&amp;oomParachuteData==null)checkParachute(); &#125; catch (OutOfMemoryErroroom) &#123; try &#123; oomParachuteData = null; releaseCaches(); log.error("", oom); &#125;catch ( Throwableoomt ) &#123; try &#123; System.err.println(oomParachuteMsg); oomt.printStackTrace(); &#125;catch (ThrowableletsHopeWeDontGetHere)&#123; ExceptionUtils.handleThrowable(letsHopeWeDontGetHere); &#125; &#125; &#125; &#125;//while stopLatch.countDown();&#125;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat请求处理分析(三) 绑定本地端口监听请求]]></title>
    <url>%2F2017%2F08%2F18%2Ftomcat%2F2018-01-23-2%2F</url>
    <content type="text"><![CDATA[bind方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意：这个bind可能在load的过程就已经加载，这里只是验证 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NioEndpoint就是使用Java中的NIO技术，来实行对Socket的处理。它主要包含两个部业务处理部分：Poller线程组和Acceptor线程组。 解析过程&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先我们应该知道其bind方法做了一些什么操作,代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142public void bind() throws Exception &#123; // 打开监听信道 serverSock =ServerSocketChannel.open(); socketProperties.setProperties(serverSock.socket()); InetSocketAddress addr= (getAddress()!=null?new InetSocketAddress(getAddress(),getPort()):new InetSocketAddress(getPort())); serverSock.socket().bind(addr,getBacklog()); serverSock.configureBlocking(true); //mimic APRbehavior serverSock.socket().setSoTimeout(getSocketProperties().getSoTimeout()); if (acceptorThreadCount==0) &#123; // FIXME:Doesn't seem to work that well with multiple accept threads acceptorThreadCount = 1; &#125; if (pollerThreadCount&lt;=0) &#123; //minimum one pollerthread pollerThreadCount = 1; &#125; stopLatch = new CountDownLatch(pollerThreadCount); // Initialize SSL ifneeded if (isSSLEnabled())&#123; SSLUtil sslUtil = handler.getSslImplementation().getSSLUtil(this); sslContext =sslUtil.createSSLContext(); sslContext.init(wrap(sslUtil.getKeyManagers()), sslUtil.getTrustManagers(), null); SSLSessionContextsessionContext = sslContext.getServerSessionContext(); if (sessionContext != null) &#123; sslUtil.configureSessionContext(sessionContext); &#125; // Determine which ciphersuites and protocols to enable enabledCiphers =sslUtil.getEnableableCiphers(sslContext); enabledProtocols =sslUtil.getEnableableProtocols(sslContext); &#125; if (oomParachute&gt;0)reclaimParachute(true); selectorPool.open();&#125; 实例化ServerSocketChannelImpl serverSock =ServerSocketChannel.open(); 其方法具体实现： 123public static ServerSocketChannel open() throws IOException&#123; return SelectorProvider.provider().openServerSocketChannel();&#125; 在这个方法中进行了两步操作，第一步调用SelectorProvider的provider方法 1234567891011121314151617181920public static SelectorProvider provider() &#123; synchronized (lock) &#123; if (provider != null) return provider; //在与当前线程相同访问控制权限的环境中，加载SelectorProvider实例 return AccessController.doPrivileged( new PrivilegedAction&lt;SelectorProvider&gt;() &#123; public SelectorProvider run() &#123; if (loadProviderFromProperty()) return provider; //获取系统配置的SelectorProvider if (loadProviderAsService()) return provider; //获取类加载路径下的SelectorProvider //加载默认的SelectorProvider provider = sun.nio.ch.DefaultSelectorProvider.create(); return provider; &#125; &#125;); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;判断provider在当前进程是否已经被实例化过了，如果已经被实例化过了，那么就直接返回当前provider，不再执行后面的代码；否者就执行后面的代码实例化provider,AccessController.doPrivileged()在与当前线程相同访问控制权限的环境中，加载SelectorProvider实例 loadProviderFromProperty()这个函数判断如果系统属性java.nio.channels.spi.SelectorProvider 已经被定义了，则该属性名看作具体提供者类的完全限定名。加载并实例化该类；如果此进程失败，则抛出未指定的错误。 loadProviderAsService()这个函数判断：如果在对系统类加载器可见的 jar 文件中安装了提供者类，并且该 jar 文件包含资源目录 META-INF/services 中名为java.nio.channels.spi.SelectorProvider 的提供者配置文件，则采用在该文件中指定的第一个类名称。加载并实例化该类；如果此进程失败，则抛出未指定的错误。最后，如果未通过上述的方式制定任何provider，则实例化系统默认的provider并返回该结果(一般情况下，都是这种情况。)这个地方需要注意的是：这里系统默认的provider在不同系统上是不一样的，下面用一个表格来表示： 系统 provider macOSX KQueueSelectorProvider Linux KQueueSelectorProvider Windows WindowsSelectorProvider &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进入sun.nio.ch.DefaultSelectorProvider.create(); 这里系统会根据不同的操作系统返回不同的provider；具体信息在上面的表格 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总结：该方法的作用完成建立Pipe，并把pipe的读写文件描述符放入pollArray中,这个pollArray是Selector的枢纽 ====================方法分界线======================= &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述是调用provider方法的具体过程，下面讲解一下调用其之后继续调用openServerSocketChannel的过程 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以osx系统为例其返回了KQueueSelectorProvider，所以调用的方法是KQueueSelectorProvider.openServerSocketChannel 注意：其实这个方法不在KQueueSelectorProvider这个类中，而在其父类SelectorProviderImpl中,方法如下： 1234publicServerSocketChannelopenServerSocketChannel() throws IOException &#123; return new ServerSocketChannelImpl(this);&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;即ServerSocketChannel.open()方法实际上是产生了一个子类ServerSocketChannelImpl的对象实例。其构造器如下： 123456ServerSocketChannelImpl(SelectorProvider var1) throws IOException &#123; super(sp); this.fd = Net.serverSocket(true); //获取ServerSocket的文件描述符 this.fdVal = IOUtil.fdVal(this.fd); //获取文件描述的id this.state = ST_INUSE; //类变量 private static final int ST_INUSE = 0;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以在这里，serverSock = ServerSocketChannel.open();这个方法的作用是实例化ServerSocketChannelImpl,其成员变量具体实现代码如下： //获取ServerSocket的文件描述符 123456789101112131415161718192021222324252627282930class Net&#123; private static volatile boolean checkedIPv6 = false; private static volatile boolean isIPv6Available; public static final int SHUT_RD = 0;//关闭读操作 public static final int SHUT_WR = 1;//关闭写操作 public static final int SHUT_RDWR = 2;//关闭读写操作 static &#123; //加载nio和net资源库 Util.load(); initIDs(); &#125; private static native void initIDs(); //默认协议 static final ProtocolFamily UNSPEC = new ProtocolFamily() &#123; public String name() &#123; return "UNSPEC"; &#125; &#125;; //获取ServerSocket文件描述 static FileDescriptor serverSocket(boolean flag) &#123; return IOUtil.newFD(socket0(isIPv6Available(), flag, true)); &#125; private static native int socket0(boolean flag, boolean flag1, boolean flag2);&#125; ============================================================= 12345678910111213141516class IOUtil&#123; static final int IOV_MAX = iovMax(); static final boolean $assertionsDisabled = !sun/nio/ch/IOUtil.desiredAssertionStatus(); static &#123; Util.load(); &#125; 创建文件描述符 static FileDescriptor newFD(int i) &#123; FileDescriptor filedescriptor = new FileDescriptor(); setfdVal(filedescriptor, i); return filedescriptor; &#125;&#125; //获取文件描述的id 12345static native int fdVal(FileDescriptor filedescriptor);``` ### 构建socket并设置相关属性 socketProperties.setProperties(serverSock.socket());1234567891011121314151617181920 serverSock.socket()的具体实现```javapublicServerSocket socket() &#123; synchronized(stateLock) &#123; // stateLock是一个new Object() 加载进行 if(socket == null) socket =ServerSocketAdaptor.create(this); returnsocket; &#125;&#125; ============================create方法============================== 12345678910111213publicstatic ServerSocket create(ServerSocketChannelImpl ssc) &#123; try &#123; return new ServerSocketAdaptor(ssc); &#125; catch (IOException x) &#123; throw new Error(x); &#125; &#125; ==============================构造器============================= 123456789private(ServerSocketChannelImpl ssc) throws IOException &#123; this.ssc = ssc;&#125; ====================ServerSocketChannelImpl类属性=============== 123private final ServerSocketChannelImpl ssc;private volatile int timeout = 0; =============================================================== &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;此方法返回的是一个ServerSocket对象，其中利用同步保证了socket是一个单例到了这里socketProperties.setProperties(serverSock.socket());这个方法就等价于socketProperties.setProperties(ServerSocket),其代码如下： 1234567891011121314public void setProperties(ServerSocket socket) throws SocketException&#123; if (rxBufSize != null) socket.setReceiveBufferSize(rxBufSize.intValue()); //设置输入流缓冲大小 if (performanceConnectionTime!=null&amp;&amp;performanceLatency!=null&amp;&amp; performanceBandwidth != null) socket.setPerformancePreferences(//设置网络传输指标相对重要性 performanceConnectionTime.intValue(), performanceLatency.intValue(), performanceBandwidth.intValue()); if (soReuseAddress!=null) socket.setReuseAddress(soReuseAddress.booleanValue()); if (soTimeout != null &amp;&amp; soTimeout.intValue()&gt;= 0) socket.setSoTimeout(soTimeout.intValue());&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总结：这段代码的作用是创建socket实例并给当前socket设置一些属性，包括输入流缓冲区、网络传输三项指标的相对重要性、端口是否可复用、设置读取超时时间，其实在启动过程中这些都是null,所以并没有进行什么设置 123public int getReceiveBufferSize() throws SocketExceptionpublic void setReceiveBufferSize(int size) throwsSocketException &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在默认情况下，输入流的接收缓冲区是8096个字节（8K）。这个值是Java所建议的输入缓冲区的大小。如果这个默认值不能满足要求，可以用setReceiveBufferSize方法来重新设置缓冲区的大小。但最好不要将输入缓冲区设得太小，否则会导致传输数据过于频繁，从而降低网络传输的效率。如果底层的Socket实现不支持SO_RCVBUF选项，这两个方法将会抛出SocketException例外。必须将size设为正整数，否则setReceiveBufferSize方法将抛出IllegalArgumentException例外 =================================================================== 1public void setPerformancePreferences(int connectionTime,intlatency,int bandwidth) 以上方法的三个参数表示网络传输数据的三项指标： 参数connectionTime：表示用最少时间建立连接。 参数latency：表示最小延迟。 参数bandwidth：表示最高带宽。 setPerformancePreferences()方法用来设定这三项指标之间的相对重要性。可以为这些参数赋予任意的整数，这些整数之间的相对大小就决定了相应参数的相对重要性。例如，如果参数connectionTime为2，参数latency为1，而参数bandwidth为3，就表示最高带宽最重要，其次是最少连接时间，最后是最小延迟。 123public boolean getReuseAddress() throws SocketException public void setReuseAddress(boolean on) throws SocketException 错误的说法： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过这个选项，可以使多个Socket对象绑定在同一个端口上。 正确的说明是： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果端口忙，但TCP状态位于 TIME_WAIT ，可以重用端口。如果端口忙，而TCP状态位于其他状态，重用端口时依旧得到一个错误信息，抛出“Addressalready in use： JVM_Bind”。如果你的服务程序停止后想立即重启，不等60秒，而新套接字依旧使用同一端口，此时SO_REUSEADDR 选项非常有用。必须意识到，此时任何非期望数据到达，都可能导致服务程序反应混乱，不过这只是一种可能，事实上很不可能。这个参数在Windows平台与Linux平台表现的特点不一样。在Windows平台表现的特点是不正确的，在Linux平台表现的特点是正确的。在Windows平台，多个Socket新建立对象可以绑定在同一个端口上，这些新连接是非TIME_WAIT状态的。这样做并没有多大意义。在Linux平台，只有TCP状态位于 TIME_WAIT ，才可以重用端口。这才是正确的行为。 使用SO_REUSEADDR选项时有两点需要注意： 1. 必须在调用bind方法之前使用setReuseAddress方法来打开SO_REUSEADDR选项。因此，要想使用SO_REUSEADDR选项，就不能通过Socket类的构造方法来绑定端口。 2. 必须将绑定同一个端口的所有的Socket对象的SO_REUSEADDR选项都打开才能起作用。如在例程4-12中，socket1和socket2都使用了setReuseAddress方法打开了各自的SO_REUSEADDR选项。 在Windows操作系统上运行上面的代码的运行结果如下： 这种结果是不正确的。 socket1.getReuseAddress():true socket2.getReuseAddress():true 在Linux操作系统上运行上面的代码的运行结果如下： 这种结果是正确的。因为第一个连接不是TIME_WAIT状态的，第二个连接就不能使用8899端口； 只有第一个连接是TIME_WAIT状态的，第二个连接就才能使用8899端口； public int getSoTimeout() throws SocketException public void setSoTimeout(int timeout) throws SocketException 这个Socket选项在前面已经讨论过。可以通过这个选项来设置读取数据超时。当输入流的read方法被阻塞时，如果设置timeout（timeout的单位是毫秒），那么系统在等待了timeout毫秒后会抛出一个InterruptedIOException例外。在抛出例外后，输入流并未关闭，你可以继续通过read方法读取数据。如果将timeout设为0，就意味着read将会无限等待下去，直到服务端程序关闭这个Socket.这也是timeout的默认值。如下面的语句将读取数据超时设为30秒： 创建套接字地址1InetSocketAddress addr = (getAddress()!=null?new InetSocketAddress(getAddress(),getPort()):new InetSocketAddress(getPort())); 创建套接字地址，并设置其端口 绑定地址和端口serverSock.socket().bind(addr,getBacklog());socket()是一个单例模式创建其实例，所以在这里还是上面的ServerSocketChannelImpl实例，然后调用其bind方法，方法代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public ServerSocketChannel bind(SocketAddress socketaddress, int i) throws IOException &#123; synchronized(lock) &#123; if(!isOpen()) //如果socket关闭，则抛出ClosedChannelException throw new ClosedChannelException(); if(isBound()) //如果已绑定，则抛出AlreadyBoundException throw new AlreadyBoundException(); //确定inetsocketaddress InetSocketAddress inetsocketaddress = socketaddress != null ? Net.checkAddress(socketaddress) : new InetSocketAddress(0); SecurityManager securitymanager = System.getSecurityManager(); if(securitymanager != null) //检查地址端口监听权限 securitymanager.checkListen(inetsocketaddress.getPort()); //绑定前工作 NetHooks.beforeTcpBind(fd, inetsocketaddress.getAddress(), inetsocketaddress.getPort()); //实际地址绑定 Net.bind(fd, inetsocketaddress.getAddress(), inetsocketaddress.getPort()); //开启监听，如果参数i小于1，默认接受50个连接 Net.listen(fd, i &gt;= 1 ? i : 50); synchronized(stateLock) &#123; //更新ocalAddress localAddress = Net.localAddress(fd); &#125; &#125; return this; &#125;``` &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;从上面可以看出，bind首先检查ServerSocket是否关闭，是否绑定地址，如果既没有绑定也没关闭，则检查绑定的socketaddress是否正确或合法；然后通过Net工具类的bind（native）和listen（native），完成实际的ServerSocket地址绑定和开启监听，如果绑定是开启的参数小于1，则默认接受50个连接。 ### serverSock设置成阻塞IOserverSock.configureBlocking(true);代码如下：```javapublic finalSelectableChannelconfigureBlocking(boolean block) throws IOException&#123; synchronized (regLock) &#123; if (!isOpen()) throw new ClosedChannelException(); if (blocking == block) return this; if (block &amp;&amp; haveValidKeys()) throw new IllegalBlockingModeException(); implConfigureBlocking(block); blocking = block; &#125; return this;&#125;``` 1.1.1.1.1.6 设置读取超时时间```javaserverSock.socket().setSoTimeout(getSocketProperties().getSoTimeout()); 初始化线程数123456789//初始化acceptor和poller线程数if (acceptorThreadCount == 0) &#123; // FIXME: Doesn't seem to work that well with multiple accept threads acceptorThreadCount = 1;&#125;if (pollerThreadCount &lt;= 0) &#123; //minimum one poller thread pollerThreadCount = 1;&#125; 实例化线程同步辅助类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ountDownLatch类是一个同步计数器,构造时传入int参数,该参数就是计数器的初始值，每调用一次countDown()方法，计数器减1,计数器大于0 时，await()方法会阻塞程序继续执行stopLatch = new CountDownLatch(pollerThreadCount);参考链接：http://www.cnblogs.com/yezhenhan/archive/2012/01/07/2315652.html &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个属性的作用是为了在关闭的时候确定所有的pollers关闭才继续向后执行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void stopInternal() &#123; releaseConnectionLatch(); if (!paused) &#123; pause(); &#125; if (running) &#123; running = false; unlockAccept(); for (int i=0; pollers!=null &amp;&amp;i&lt;pollers.length; i++) &#123; if (pollers[i]==null) continue; pollers[i].destroy(); pollers[i] = null; &#125; try &#123; stopLatch.await(selectorTimeout+100, TimeUnit.MILLISECONDS); &#125; catch (InterruptedExceptionignore) &#123; &#125; shutdownExecutor(); eventCache.clear(); nioChannels.clear(); processorCache.clear(); &#125;&#125;``` ### NioSelectorPool实例设置属性selectorPool.open();其中selectorPool是成员变量 private NioSelectorPool selectorPool = new NioSelectorPool(); 在分析selectorPool.open();这段代码之前，我们必须了解Selector open()这个方法是干嘛，这个方法也在NioSelectorPool中代码如下：```javapublic staticSelector open() throws IOException &#123; returnSelectorProvider.provider().openSelector();&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过调用系统默认的SelectorProvider(这里不同的系统会有不同的SelectorProvider实现类)的openSelector()方法来创建新的selector SelectorProvider.provider()这个方法我们已经在上文分析过，这里获取的就是同一个KQueueSelectorProvider实例后面调用的也就是KQueueSelectorProvider.openSelector();源码如下： 12345public AbstractSelector openSelector()throws IOException &#123; returnnew KQueueSelectorImpl(this);&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据代码可以看出其实例化了一个KQueueSelectorImpl,这是一个选择器，看一下选择器的作用，Selector选择器类管理着一个被注册的通道集合的信息和它们的就绪状态。通道是和选择器一起被注册的，并且使用选择器来更新通道的就绪状态。当这么做的时候，可以选择将被激发的线程挂起，直到有就绪的的通道。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以下面代码的则用是构建blockingSelector实例，并将KQueueSelectorImpl给注入sharedSelector，这两个变量都是NioSelectorPool的属性 123456789101112131415161718192021222324252627282930public void open() throws IOException&#123; enabled = true; getSharedSelector(); if (SHARED) &#123; blockingSelector = new NioBlockingSelector(); blockingSelector.open(getSharedSelector()); &#125;&#125; protected Selector getSharedSelector() throws IOException&#123; if (SHARED &amp;&amp; SHARED_SELECTOR==null) &#123; synchronized ( NioSelectorPool.class ) &#123; if ( SHARED_SELECTOR==null) &#123; synchronized (Selector.class) &#123; SHARED_SELECTOR=Selector.open(); &#125; log.info("Usinga shared selector for servlet write/read"); &#125; &#125; &#125; return SHARED_SELECTOR;&#125; public static Selector open() throws IOException&#123; return SelectorProvider.provider().openSelector();&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面这个方法是创建一个轮询线程，然后将选择器赋值给这个公司，并设置起为守护线程 12345678public void open(Selector selector) &#123; sharedSelector = selector; poller = new BlockPoller(); poller.selector = sharedSelector; poller.setDaemon(true); poller.setName("NioBlockingSelector.BlockPoller-"+(++threadCounter)); poller.start();&#125;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat请求处理分析(二) 启动mapperListener]]></title>
    <url>%2F2017%2F08%2F18%2Ftomcat%2F2018-01-23-1%2F</url>
    <content type="text"><![CDATA[启动mapperListener 这个方法的核心就是注册Host的 123456789101112131415161718192021222324public void startInternal() throws LifecycleException&#123; setState(LifecycleState.STARTING); //获取当前service的container，其实也就是engine @SuppressWarnings("deprecation") Engine engine = (Engine) service.getContainer(); if (engine == null) &#123; return; &#125; findDefaultHost();//获取当前engine默认的host addListeners(engine);//给当前Mapper添加监听时间 //找到当前engine下所有host主机 Container[] conHosts =engine.findChildren(); for (Container conHost :conHosts) &#123; Host host = (Host) conHost; if (!LifecycleState.NEW.equals(host.getState()))&#123; // 登记host会注册context和 wrappers registerHost(host); &#125; &#125;&#125; 注册Host 注册Host主要进行了两步操作，第一步是添加Host 第二步是registerContext 123456789101112131415private void registerHost(Host host) &#123; String[] aliases = host.findAliases(); mapper.addHost(host.getName(), aliases, host); for (Container container :host.findChildren()) &#123; if (container.getState().isAvailable())&#123; registerContext((Context)container); &#125; &#125; if(log.isDebugEnabled())&#123; log.debug(sm.getString("mapperListener.registerHost", host.getName(), domain, service)); &#125;&#125; 添加Host 123456789101112131415161718192021222324252627282930313233343536public synchronizedvoid addHost(String name, String[]aliases, Host host) &#123; //StandardEngine[Catalina].StandardHost[localhost] //创建MappedHost对象的数组，这里长度需要加1 MappedHost[]newHosts = new MappedHost[hosts.length + 1]; //创建一个MappedHost对象，用于保存host的map信息 MappedHostnewHost = new MappedHost(name, host); //insertMap将hosts这个数组迁移到newHosts并将newHost按name添加到指定位置 if (insertMap(hosts, newHosts, newHost)) &#123; hosts= newHosts; //指向新的数组 if (log.isDebugEnabled()) &#123; log.debug(sm.getString("mapper.addHost.success", name)); &#125; &#125; else&#123; //不能插入这说明有相同名字的,有两种情况，第一种是在先前通过addContextVersion加入让那个newHost指向，另一种名字相同则直接返回 MappedHostduplicate = hosts[find(hosts, name)]; if (duplicate.object == host) &#123; if(log.isDebugEnabled()) &#123; log.debug(sm.getString("mapper.addHost.sameHost", name)); &#125; newHost = duplicate; &#125;else &#123; log.error(sm.getString("mapper.duplicateHost", name, duplicate.getRealHostName())); return; &#125; &#125; List&lt;MappedHost&gt; newAliases = new ArrayList&lt;&gt;(aliases.length); for (Stringalias : aliases) &#123; MappedHost newAlias = new MappedHost(alias, newHost); if (addHostAliasImpl(newAlias)) &#123; newAliases.add(newAlias); &#125; &#125; newHost.addAliases(newAliases);&#125; 这个方法的作用将新的host插入到已有的集合，如果存在，直接返回，不存在则按字母排序有序插入，其中实现有序插入主要是调用了find这个二分查找，找到跟当前name最近的一个，然后进行插入，数组迁移 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private static final &lt;T&gt; boolean insertMap (MapElement&lt;T&gt;[]oldMap, MapElement&lt;T&gt;[] newMap, MapElement&lt;T&gt;newElement) &#123; int pos = find(oldMap, newElement.name);//在old里面，最近接新的元素的name的位置，这里返回的pos要么name相当，要么最左侧 if ((pos != -1) &amp;&amp;(newElement.name.equals(oldMap[pos].name))) &#123; //这里表示有名字相同的，那么失败 return false; &#125; //分段拷贝，这样拷贝完了之后也是排好序的 System.arraycopy(oldMap, 0, newMap, 0, pos + 1); //对数组拷贝，这里相当于先拷贝小的 newMap[pos + 1] =newElement; System.arraycopy (oldMap, pos + 1, newMap, pos + 2, oldMap.length - pos - 1); return true;&#125;``` 二分查找方法如下:```javaprivate static final &lt;T&gt; int find(MapElement&lt;T&gt;[] map, String name)&#123; int a = 0; int b = map.length - 1; // Special cases: -1 and 0 if (b == -1) &#123; return -1; &#125; if (name.compareTo(map[0].name) &lt; 0) &#123; return -1; &#125; if (b == 0) &#123; return 0; &#125; int i = 0; while (true) &#123; i = (b + a) / 2; int result =name.compareTo(map[i].name); if (result &gt; 0) &#123; a = i; &#125; else if (result == 0) &#123; return i; &#125; else &#123; b = i; &#125; if ((b - a) == 1) &#123; int result2 =name.compareTo(map[b].name); if (result2 &lt; 0) &#123; return a; &#125; else &#123; return b; &#125; &#125; &#125;&#125; 注册web应用 在这里注册路由，经过http请求能够找到对应的web 应用，一个context对应一个web应用 123456789101112131415161718192021222324252627282930313233private void registerContext(Context context) &#123; String contextPath =context.getPath(); //获取context的路径 if ("/".equals(contextPath))&#123; contextPath = ""; &#125; Host host = (Host)context.getParent(); //获取的其host WebResourceRootresources = context.getResources(); //获取root String[] welcomeFiles =context.findWelcomeFiles(); //获取欢迎页 // 准备context 下的所有 wrapper 信息 List&lt;WrapperMappingInfo&gt;wrappers = new ArrayList&lt;&gt;(); for (Container container :context.findChildren()) &#123; prepareWrapperMappingInfo(context, (Wrapper)container, wrappers); if(log.isDebugEnabled())&#123; log.debug(sm.getString("mapperListener.registerWrapper", container.getName(), contextPath, service)); &#125; &#125; // 添加 contextVersion，在这里面会将该context下的所有wrapper映射信息也构建 mapper.addContextVersion(host.getName(), host, contextPath, context.getWebappVersion(), context, welcomeFiles, resources, wrappers); if(log.isDebugEnabled())&#123; log.debug(sm.getString("mapperListener.registerContext", contextPath, service)); &#125;&#125;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat请求处理分析(一) 启动container实例]]></title>
    <url>%2F2017%2F08%2F18%2Ftomcat%2F2018-01-23%2F</url>
    <content type="text"><![CDATA[启动container实例 其主要是进行了生命周期中一系列的操作之后调用StandardEngine中的 startInternal方法,不难看出其调用其父类的startInternal方法, 其父类是ContainerBase.java 12345protected synchronized void startInternal() throws LifecycleException&#123; if(log.isInfoEnabled()) log.info( "StartingServlet Engine: " + ServerInfo.getServerInfo()); super.startInternal();&#125; 父类ContainerBase.java中的startInternal 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** @author 郑小康 * * 1.如果配置了集群组件Cluster则启动 * * 2.如果配置了安全组件,则启动 * * 3启动子节点，默认为StandContext * * 4.启动Host所持有的Pipeline组件 * * 5.设置Host状态为STARTING 此时会触发START_EVENT生命周期事件 * HostConfig 中的lifecycleEvent 为START_EVENT时会调用其start方法 * HostConfig监听该事件扫描web部署对于部署文件、WAR包、会自动创建StandardContext实例，添加到Host并启动 * * 6.启动Host层级的后台任务处理包括部署变更 * * */@Overrideprotectedsynchronized void startInternal() throws LifecycleException&#123; // Start our subordinatecomponents, if any logger = null; getLogger(); //集群 Cluster cluster =getClusterInternal(); if ((cluster != null) &amp;&amp;(cluster instanceof Lifecycle)) ((Lifecycle) cluster).start(); Realm realm =getRealmInternal(); if ((realm != null) &amp;&amp;(realm instanceof Lifecycle)) ((Lifecycle) realm).start(); // 获取子容器获取HOST Container children[] =findChildren(); List&lt;Future&lt;Void&gt;&gt;results = new ArrayList&lt;&gt;(); for (int i = 0; i &lt;children.length; i++) &#123; results.add(startStopExecutor.submit(new StartChild(children[i]))); &#125; boolean fail = false; for (Future&lt;Void&gt;result : results) &#123; try &#123; result.get(); &#125; catch (Exceptione) &#123; log.error(sm.getString("containerBase.threadedStartFailed"), e); fail = true; &#125; &#125; if (fail) &#123; throw new LifecycleException( sm.getString("containerBase.threadedStartFailed")); &#125; // Start the Valves in ourpipeline (including the basic), if any if (pipeline instanceof Lifecycle) ((Lifecycle) pipeline).start(); //当前方法加载web应用 setState(LifecycleState.STARTING); // Start our thread threadStart();&#125; 启动StandHost 获取engine下所有的host的实例，这个是在server.xml文件中定义的，其默认实现类是StandHost,在这里通过future模式进行处理,将所有StandHost给启动,默认server.xml中只有一个实例，所以在这里只是启动了一个标准的host虚拟主机 123456789101112131415Container children[] =findChildren();List&lt;Future&lt;Void&gt;&gt;results = new ArrayList&lt;&gt;();for (int i = 0; i &lt;children.length; i++) &#123; results.add(startStopExecutor.submit(new StartChild(children[i])));&#125;boolean fail = false;for (Future&lt;Void&gt;result : results) &#123; try &#123; result.get(); &#125; catch (Exceptione) &#123; log.error(sm.getString("containerBase.threadedStartFailed"), e); fail = true; &#125;&#125; StartChild类的内部结构，通过future模式进行get的时候会调用其call方法，将standHost给启动 1234567891011121314private static class StartChild implements Callable&lt;Void&gt;&#123; private Container child; public StartChild(Containerchild) &#123; this.child = child; &#125; @Override public Void call() throws LifecycleException&#123; child.start(); return null; &#125;&#125; 向standHost管道里面加入阀门 其添加的方式是获取管道并调用其addValve方法进行添加,管道是在其父类ContainerBase中,其是一个成员变量,并且将this即standHost注入当前管道， 12345678910111213141516public Pipeline getPipeline() &#123; return (this.pipeline);&#125; protected final Pipeline pipeline = newStandardPipeline(this); public StandardPipeline(Container container) &#123; super(); setContainer(container);&#125; 上面描述了获取管道的过程，下面是具体向管道中添加对应的阀门 12345678910111213141516171819202122232425262728protectedsynchronized void startInternal() throws LifecycleException&#123; // 获取错误报告阀门,该类的作用主要是在服务器处理异常的时输出错误界面 String errorValve =getErrorReportValveClass(); if ((errorValve != null) &amp;&amp;(!errorValve.equals(""))) &#123; try &#123; boolean found = false; //org.apache.catalina.core.StandardHostValve[localhost] //org.apache.catalina.valves.AccessLogValve[localhost] //errorValve==org.apache.catalina.valves.ErrorReportValve给添加进去 Valve[] valves =getPipeline().getValves(); for (Valve valve : valves)&#123; if (errorValve.equals(valve.getClass().getName()))&#123; found = true; break; &#125; &#125; if(!found) &#123; Valve valve = (Valve) Class.forName(errorValve).newInstance(); getPipeline().addValve(valve); &#125; &#125; catch (Throwablet) &#123; ExceptionUtils.handleThrowable(t); &#125; &#125; super.startInternal();&#125; 启动管道 该方法是遍历管道里面所有的阀门，然后将他们依次给启动 12345678910111213protected synchronized void startInternal() throws LifecycleException&#123; Valve current = first; if (current == null) &#123; current = basic; &#125; while (current != null) &#123; if (current instanceof Lifecycle) ((Lifecycle) current).start(); current =current.getNext(); &#125; setState(LifecycleState.STARTING);&#125; org.apache.catalina.valves.AccessLogValve[localhost] 日志记录类 org.apache.catalina.valves.ErrorReportValve[localhost] 异常状态返回报告页 参考链接：http://www.10tiao.com/html/308/201702/2650076436/1.html org.apache.catalina.core.StandardHostValve[localhost] HostConfig org.apache.catalina.LifecycleEvent[source=StandardEngine[Catalina].StandardHost[localhost]] StandardEngine[Catalina].StandardHost[localhost] 加载web应用 setState(LifecycleState.STARTING); 加载web应用是在改变当前HostConfig类的状态为start的时候,调用其对应的监听时间，从而调用了该类的start方法,有下面该类的lifecycleEvent方法可以看出 12345678910111213141516171819202122232425public void lifecycleEvent(LifecycleEvent event)&#123; try &#123; host = (Host)event.getLifecycle(); if (host instanceof StandardHost)&#123; setCopyXML(((StandardHost) host).isCopyXML()); setDeployXML(((StandardHost)host).isDeployXML()); //liveDeploy属性指明host是否要周期性的检查是否有新的应用部署 setUnpackWARs(((StandardHost)host).isUnpackWARs()); setContextClass(((StandardHost)host).getContextClass()); &#125; &#125; catch (ClassCastException e)&#123; log.error(sm.getString("hostConfig.cce", event.getLifecycle()), e); return; &#125; // Process the event thathas occurred if (event.getType().equals(Lifecycle.PERIODIC_EVENT)) &#123; check(); &#125; else if (event.getType().equals(Lifecycle.BEFORE_START_EVENT)) &#123; beforeStart(); &#125; else if (event.getType().equals(Lifecycle.START_EVENT)) &#123; start(); &#125; else if (event.getType().equals(Lifecycle.STOP_EVENT)) &#123; stop(); &#125;&#125; 具体的start方法代码如下： 123456789101112131415161718192021222324public void start() &#123; if (log.isDebugEnabled()) log.debug(sm.getString("hostConfig.start")); try &#123; ObjectName hostON = host.getObjectName(); oname = new ObjectName (hostON.getDomain() + ":type=Deployer,host="+host.getName()); Registry.getRegistry(null, null).registerComponent (this, oname, this.getClass().getName()); &#125; catch (Exceptione) &#123; log.error(sm.getString("hostConfig.jmx.register", oname), e); &#125; if (!host.getAppBaseFile().isDirectory())&#123; log.error(sm.getString("hostConfig.appBase", host.getName(), host.getAppBaseFile().getPath())); host.setDeployOnStartup(false); host.setAutoDeploy(false); &#125; if (host.getDeployOnStartup()) deployApps();&#125; 根据代码不难发现共做了三件事，第一件是注册MBServer,第二件是监测其时候是文件，第三件是进行部署 部署web应用 该方法是上面方法的具体实现，其先获取应用文件夹的路径，再获取配置文件的路径,然后进行三种应用加载方式，第一种，加载配置文件中所有web应用，第二种加载WARS形式所有应用，第三中加载webapps下所有的应用 1234567891011121314protected void deployApps() &#123; //获取基本文件夹路径/project/eclipseWS/tomcatMac/output/build/webapps File appBase = host.getAppBaseFile(); //获取配置文件路径/project/eclipseWS/tomcatMac/output/build/conf/Catalina/localhost File configBase = host.getConfigBaseFile(); //将webapps下的文件路径以字符串存放 String[]filteredAppPaths = filterAppPaths(appBase.list()); //根据配置文件部署web应用 deployDescriptors(configBase, configBase.list()); // 部署WARs deployWARs(appBase, filteredAppPaths); // 部署应用在webapps下 deployDirectories(appBase, filteredAppPaths);&#125; 根据配置文件加载web应用 根据配置文件，顾名思义就是通过指向的方式即config/catalina/localhost下的配置文件进行部署 12345678910111213141516171819202122232425262728293031protected void deployDescriptors(File configBase, String[]files) &#123; if (files == null) return; ExecutorService es = host.getStartStopExecutor(); List&lt;Future&lt;?&gt;&gt;results = new ArrayList&lt;&gt;(); for (int i = 0; i &lt;files.length; i++) &#123; // File contextXml = new File(configBase, files[i]); if (files[i].toLowerCase(Locale.ENGLISH).endsWith(".xml")) &#123; ContextName cn = new ContextName(files[i], true); if (isServiced(cn.getName())|| deploymentExists(cn.getName())) continue; results.add( es.submit(new DeployDescriptor(this, cn, contextXml))); &#125; &#125; for (Future&lt;?&gt;result : results) &#123; try &#123; result.get(); &#125; catch (Exceptione) &#123; log.error(sm.getString( "hostConfig.deployDescriptor.threaded.error"), e); &#125; &#125;&#125; 第一步：检测文件夹是否为空，为空则返回 第二步：获取线程池,该线程是在初始化HostConfig的时候实例化的 1234567891011protected void initInternal() throws LifecycleException&#123; BlockingQueue&lt;Runnable&gt;startStopQueue = new LinkedBlockingQueue&lt;&gt;(); startStopExecutor = new ThreadPoolExecutor( getStartStopThreadsInternal(), getStartStopThreadsInternal(), 10, TimeUnit.SECONDS, startStopQueue, new StartStopThreadFactory(getName()+ "-startStop-")); startStopExecutor.allowCoreThreadTimeOut(true); super.initInternal();&#125; 第三步：遍历所有后缀名为.xml构建其DeployDescriptor实例添加到future集合中去，进行异步执行，其中DeployDescriptor类结构如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227private static class DeployDescriptor implements Runnable &#123; private HostConfig config; private ContextName cn; private File descriptor; public DeployDescriptor(HostConfigconfig, ContextName cn, File descriptor) &#123; this.config = config; this.cn = cn; this.descriptor= descriptor; &#125; @Override public void run() &#123; config.deployDescriptor(cn, descriptor); &#125;&#125;``` 由上可见根据配置文件最终执行的还是deployDescriptor方法，该方法的操做有构建DeployedApplication实例，获取配置文件名，以及将文件流标签解析成对应的ContextConfig对象，创建监听器，获取docBase的值，通过host.addChild(context)将其加到文件监听中，这样修改该文件夹中的文件，就会通过监听线程进行获取，下文会分析监听线程的具体操作，这里不讲述，在这之后finally里面的操作是解析配置文件，找到docBase,把应用存放到deployed里面，这样做的目的是一个虚拟主机可能能存在多个web应用，在deployed这个map里面存放的key是web应用，v是对应的deployedApp，这里面的存放了web.xml等文件的位置如下例子：成员变量：redeployResources0 = &#123;LinkedHashMap$Entry@3050&#125; "/project/eclipseWS/tomcatMac/output/build/conf/Catalina/localhost/test.xml"-&gt; "1502378759000"1 = &#123;LinkedHashMap$Entry@3051&#125;"/project/eclipseWS/tomcatMac/output" -&gt; "1501518597000"2 = &#123;LinkedHashMap$Entry@3052&#125;"/project/eclipseWS/tomcatMac/output/build/conf/context.xml" -&gt;"1501478677000"成员变量：reloadResources 0 = &#123;HashMap$Node@2944&#125;"/project/eclipseWS/tomcatMac/output/WEB-INF/web.xml" -&gt;"0"1= &#123;HashMap$Node@3062&#125;"/project/eclipseWS/tomcatMac/output/build/conf/web.xml" -&gt;"1502089964000" 代码具体执行过程如下： protected void deployDescriptor(ContextName cn, FilecontextXml) &#123; // 构建DeployedApplication实例主要是将web应用名赋值 DeployedApplicationdeployedApp = new DeployedApplication(cn.getName(), true); long startTime = 0; // Assume this is aconfiguration descriptor and deploy it if(log.isInfoEnabled())&#123; startTime = System.currentTimeMillis(); log.info(sm.getString("hostConfig.deployDescriptor", contextXml.getAbsolutePath())); &#125; Context context = null; boolean isExternalWar = false; boolean isExternal = false; File expandedDocBase = null; //获取文件流解析成对应的context实例,在生成之后，它会清空digester为下次解析流做准备 try (FileInputStreamfis = new FileInputStream(contextXml)) &#123; synchronized (digesterLock) &#123; try &#123; context = (Context) digester.parse(fis); &#125; catch (Exceptione) &#123; log.error(sm.getString( "hostConfig.deployDescriptor.error", contextXml.getAbsolutePath()), e); &#125; finally &#123; digester.reset(); if (context == null) &#123; context = new FailedContext(); &#125; &#125; &#125; //class org.apache.catalina.startup.ContextConfig Class&lt;?&gt; clazz =Class.forName(host.getConfigClass()); LifecycleListenerlistener = (LifecycleListener)clazz.newInstance(); //给当前StandContext添加ContextConfig这个监听器 context.addLifecycleListener(listener); //设置配置文件的路径 context.setConfigFile(contextXml.toURI().toURL()); //给当前容器设置名字 context.setName(cn.getName()); //设置web用用的上下文路径 context.setPath(cn.getPath()); //设置web应用的版本 context.setWebappVersion(cn.getVersion()); // Add the associateddocBase to the redeployed list if it's a WAR if (context.getDocBase()!= null) &#123; File docBase = new File(context.getDocBase()); if (!docBase.isAbsolute())&#123; docBase = new File(host.getAppBaseFile(), context.getDocBase()); &#125; /** * 给部署的deployedApp实例的redeployResources这个Map集合添加两条记录 * 第一条是以配置文件路径为key 时间为v * 第二提是配置文件的odcBase指向的路径 * 如果docBase所指向的是一个war包，将isExternalWar标记为true */ if (!docBase.getCanonicalPath().startsWith( host.getAppBaseFile().getAbsolutePath()+ File.separator)) &#123; isExternal = true; deployedApp.redeployResources.put(contextXml.getAbsolutePath(), Long.valueOf(contextXml.lastModified())); deployedApp.redeployResources.put(docBase.getAbsolutePath(), Long.valueOf(docBase.lastModified())); if (docBase.getAbsolutePath().toLowerCase(Locale.ENGLISH).endsWith(".war")) &#123; isExternalWar = true; &#125; &#125; else &#123; log.warn(sm.getString("hostConfig.deployDescriptor.localDocBaseSpecified", docBase)); // Ignore specifieddocBase context.setDocBase(null); &#125; &#125; host.addChild(context); &#125; catch (Throwable t)&#123; ExceptionUtils.handleThrowable(t); log.error(sm.getString("hostConfig.deployDescriptor.error", contextXml.getAbsolutePath()), t); &#125; finally &#123; //检查是否存在默认的appBase 即在webapps下面有没有对应该项目名的文件夹,简而言之就是后面路径存在就覆盖，不存在就是用默认的 expandedDocBase = new File(host.getAppBaseFile(), cn.getBaseName()); //如果docBase不为空，并且不是以后缀名.war结束的,获取当前文件路径 if (context.getDocBase()!= null &amp;&amp;!context.getDocBase().toLowerCase(Locale.ENGLISH).endsWith(".war")) &#123; expandedDocBase = new File(context.getDocBase()); //如果不是绝对路径，则获取的基本应用路径+docBase的路径 if (!expandedDocBase.isAbsolute())&#123; expandedDocBase = new File(host.getAppBaseFile(), context.getDocBase()); &#125; &#125; boolean unpackWAR = unpackWARs; //为true才会每次重新解压war包 if (unpackWAR&amp;&amp; context instanceof StandardContext) &#123; unpackWAR =((StandardContext) context).getUnpackWAR(); &#125; // Add the eventualunpacked WAR and all the resources which will be // watched inside it //如果是war包，并且unpackWAR为true则将其加到redeployResources集合,并且添加监听 if (isExternalWar)&#123; if (unpackWAR)&#123; deployedApp.redeployResources.put(expandedDocBase.getAbsolutePath(), Long.valueOf(expandedDocBase.lastModified())); addWatchedResources(deployedApp, expandedDocBase.getAbsolutePath(), context); &#125; else &#123; addWatchedResources(deployedApp, null, context); &#125; &#125; else &#123; // Find an existingmatching war and expanded folder if (!isExternal)&#123; File warDocBase = new File(expandedDocBase.getAbsolutePath()+ ".war"); if (warDocBase.exists())&#123; deployedApp.redeployResources.put(warDocBase.getAbsolutePath(), Long.valueOf(warDocBase.lastModified())); &#125; else &#123; // Trigger a redeploy if aWAR is added deployedApp.redeployResources.put( warDocBase.getAbsolutePath(), Long.valueOf(0)); &#125; &#125; if (unpackWAR)&#123; deployedApp.redeployResources.put(expandedDocBase.getAbsolutePath(), Long.valueOf(expandedDocBase.lastModified())); //将其下所有web.xml文件加到deployedApp的reloadResources里面 addWatchedResources(deployedApp, expandedDocBase.getAbsolutePath(), context); &#125; else &#123; addWatchedResources(deployedApp, null, context); &#125; if (!isExternal)&#123; // For external docBases,the context.xml will have been // added above. deployedApp.redeployResources.put( contextXml.getAbsolutePath(), Long.valueOf(contextXml.lastModified())); &#125; &#125; // Add the global redeployresources (which are never deleted) at // the end so they don'tinterfere with the deletion process addGlobalRedeployResources(deployedApp);//添加全局的资源文件 &#125; //将其以应用名为key deployedApp实例为key存放到当前HostConfig实例里面 if (host.findChild(context.getName())!= null) &#123; deployed.put(context.getName(), deployedApp); &#125; if (log.isInfoEnabled())&#123; log.info(sm.getString("hostConfig.deployDescriptor.finished", contextXml.getAbsolutePath(), Long.valueOf(System.currentTimeMillis()- startTime))); &#125;&#125;在上面讲述了配置文件的方式，默认文件夹和war包部署大同小异，不做解释。## 加载wraper这个是在部署web应用的一个具体操作，每部署一个Web引用 ```javahost.addChild(context);public void addChild(Container child) &#123; if (Globals.IS_SECURITY_ENABLED) &#123; PrivilegedAction&lt;Void&gt; dp = new PrivilegedAddChild(child); AccessController.doPrivileged(dp); &#125; else &#123; addChildInternal(child); &#125;&#125; 根据代码可以看出调用的是addChildInternal方法,其中child是StandardEngine[Catalina].StandardHost[localhost].StandardContext[/test]这个实例，代码如下： 12345678910111213141516171819202122232425private void addChildInternal(Container child) &#123; if( log.isDebugEnabled()) log.debug("Addchild " + child + " " + this); synchronized(children) &#123; if (children.get(child.getName())!= null) throw new IllegalArgumentException("addChild: Child name '" + child.getName() + "' is not unique"); child.setParent(this); // May throw IAE children.put(child.getName(), child); &#125; try &#123; if ((getState().isAvailable()|| LifecycleState.STARTING_PREP.equals(getState()))&amp;&amp; startChildren) &#123; child.start(); &#125; &#125; catch (LifecycleExceptione) &#123; log.error("ContainerBase.addChild:start: ", e); throw new IllegalStateException("ContainerBase.addChild:start: " + e); &#125; finally &#123; fireContainerEvent(ADD_CHILD_EVENT, child); &#125;&#125; 主要是会调用start方法，根据上文知道其是一个StandardContext实例，所以调用的是StandardContext.start()方法，start都是LifecycleBase里面，最终调用的还是StandardContext中的startInternal方法 这个方法做了很多操作，如设置上下文参数，启动监听器过滤器，但是这些不是我主要要描述的内容，我要描述的如何将web应用的具体servlet给封装 12345protected synchronized void startInternal() throws LifecycleException&#123; //触发CONFIGURE_START_EVENT事件 fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null); &#125; 而后会执行其监听器ContextConfig,的configureStart方法，这个方法的核心是执行里面的webConfig 执行顺序configureStart==》webConfig==》 configureContext(webXml) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public void lifecycleEvent(LifecycleEvent event)&#123; // Identify the context weare associated with try &#123; context = (Context)event.getLifecycle(); &#125; catch (ClassCastExceptione) &#123; log.error(sm.getString("contextConfig.cce", event.getLifecycle()), e); return; &#125; if (event.getType().equals(Lifecycle.CONFIGURE_START_EVENT))&#123; configureStart(); &#125;else if (event.getType().equals(Lifecycle.BEFORE_START_EVENT)) &#123; beforeStart(); &#125; else if (event.getType().equals(Lifecycle.AFTER_START_EVENT)) &#123; if (originalDocBase!=null) &#123; context.setDocBase(originalDocBase); &#125; &#125; else if (event.getType().equals(Lifecycle.CONFIGURE_STOP_EVENT)) &#123; configureStop(); &#125; else if (event.getType().equals(Lifecycle.AFTER_INIT_EVENT)) &#123; init(); &#125; else if (event.getType().equals(Lifecycle.AFTER_DESTROY_EVENT)) &#123; destroy(); &#125;&#125;``` &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;下面这个方法就是configureContext中具体构造wrapper对象并添加到StandWrapper,在这里只需要明确的事实例化对象是在这个过程，至于具体的使用在后面会进行讲解```javafor (ServletDef servlet : webxml.getServlets().values()) &#123; Wrapper wrapper = context.createWrapper(); // Description is ignored // Display name is ignored // Icons are ignored // jsp-file gets passed to the JSPServlet as an init-param if (servlet.getLoadOnStartup()!= null) &#123; wrapper.setLoadOnStartup(servlet.getLoadOnStartup().intValue()); &#125; if (servlet.getEnabled()!= null) &#123; wrapper.setEnabled(servlet.getEnabled().booleanValue()); &#125; wrapper.setName(servlet.getServletName()); Map&lt;String,String&gt;params = servlet.getParameterMap(); for (Entry&lt;String, String&gt;entry : params.entrySet()) &#123; wrapper.addInitParameter(entry.getKey(), entry.getValue()); &#125; wrapper.setRunAs(servlet.getRunAs()); Set&lt;SecurityRoleRef&gt;roleRefs = servlet.getSecurityRoleRefs(); for (SecurityRoleRefroleRef : roleRefs) &#123; wrapper.addSecurityReference( roleRef.getName(), roleRef.getLink()); &#125; wrapper.setServletClass(servlet.getServletClass()); MultipartDefmultipartdef = servlet.getMultipartDef(); if (multipartdef != null) &#123; if (multipartdef.getMaxFileSize()!= null&amp;&amp; multipartdef.getMaxRequestSize()!= null &amp;&amp; multipartdef.getFileSizeThreshold() != null) &#123; wrapper.setMultipartConfigElement(new MultipartConfigElement( multipartdef.getLocation(), Long.parseLong(multipartdef.getMaxFileSize()), Long.parseLong(multipartdef.getMaxRequestSize()), Integer.parseInt( multipartdef.getFileSizeThreshold()))); &#125; else &#123; wrapper.setMultipartConfigElement(new MultipartConfigElement( multipartdef.getLocation())); &#125; &#125; if (servlet.getAsyncSupported()!= null) &#123; wrapper.setAsyncSupported( servlet.getAsyncSupported().booleanValue()); &#125; wrapper.setOverridable(servlet.isOverridable()); context.addChild(wrapper);&#125; 监听文件修改重部署 这个是开启了一个线程进行处理的，在上文加载了web应用之后,可能存在修改里面的文件，这样在重新访问的时候应该访问到的新界面,这个就是threadStart();这个方法所做的事情，下面我们看一下它究竟是怎么处理 12345678910111213141516171819202122232425262728293031/** *@author 郑小康 * 校验条件通过的话将会启动一个线程 * * 并且线程的名字即以"ContainerBackgroundProcessor[ "开头，线程名字后面取的是对象的toString方法 * * 其中backgroundProcessorDelay的作用是： * * StandardEngine，StandardHost都继承了当前类，是否都启动了这个线程 * * 其实不然，这就是backgroundProcessorDelay的作用，在StandardEngine实例化的时候其赋值为10 * 而StandardHost却并没有，所以只有在StandardEngine调用startInternal的时候才会启动线程 */protected void threadStart() &#123; //检验线程是否存在，存在直接返回，这样做的目的是避免该类的线程二次启动 if (thread != null) return; if (backgroundProcessorDelay&lt;=0) return; threadDone = false; String threadName = "ContainerBackgroundProcessor["+toString() + "]"; thread = new Thread(new ContainerBackgroundProcessor(), threadName); thread.setDaemon(true); thread.start();&#125; 由上不难看出其会构建ContainerBackgroundProcessor实例，并调用其run方法，ContainerBackgroundProcessor类的结构如下 12345678910111213141516171819202122232425262728293031/** * 在run方法中它会先暂停一段时间之后调用processChildren方法 * */protected class ContainerBackgroundProcessor implements Runnable &#123; @Override public void run() &#123; Throwable t = null; StringunexpectedDeathMessage = sm.getString( "containerBase.backgroundProcess.unexpectedThreadDeath", Thread.currentThread().getName()); try &#123; while (!threadDone) &#123; try &#123; Thread.sleep(backgroundProcessorDelay*1000L); &#125; catch (InterruptedExceptione) &#123; &#125; if (!threadDone) &#123; processChildren(ContainerBase.this); &#125; &#125; &#125; catch (RuntimeException|Errore) &#123; t = e; throw e; &#125; finally &#123; if (!threadDone) &#123; log.error(unexpectedDeathMessage, t); &#125; &#125;&#125; 看一下processChildren方法的实现，如下： 123456789101112131415161718192021222324252627282930protected void processChildren(Container container) &#123; ClassLoader originalClassLoader =null; try &#123; if (container instanceof Context) &#123; Loader loader =((Context) container).getLoader(); // Loader will be null forFailedContext instances if (loader == null) &#123; return; &#125; originalClassLoader =((Context) container).bind(false, null); &#125; container.backgroundProcess(); Container[] children =container.findChildren(); for (int i = 0; i &lt;children.length; i++) &#123; if (children[i].getBackgroundProcessorDelay()&lt;= 0) &#123; processChildren(children[i]); &#125; &#125; &#125; catch (Throwablet) &#123; ExceptionUtils.handleThrowable(t); log.error("Exceptioninvoking periodic operation: ", t); &#125; finally &#123; if (container instanceof Context) &#123; ((Context)container).unbind(false, originalClassLoader); &#125; &#125; &#125;&#125; processChildren方法做了两件事，一是调用容器组件自身的backgroundProcess方法，二是取出该容器组件的所有子容器组件并调用它们的processChildren方法。归结起来这个线程的实现就是定期通过递归的方式调用当前容器及其所有子容器的backgroundProcess方法。而这个backgroundProcess方法在ContainerBase内部已经给出了实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * 1.获取所有集群 (不是我研究的重点） * * 2.获取用户管理（不是我研究的重点） * * 3.执行其阀门下面所有的backgroundProcess方法，可以看出这是一个递归执行backgroundProcess * * engine --&gt; host ----&gt; context 这是一个大致过程 * * 4.调用生命周期的监听方法，修改状态为PERIODIC_EVENT * */@Overridepublicvoid backgroundProcess() &#123; if (!getState().isAvailable()) return; Cluster cluster =getClusterInternal(); if (cluster != null) &#123; try &#123; cluster.backgroundProcess(); &#125; catch (Exceptione) &#123; log.warn(sm.getString("containerBase.backgroundProcess.cluster", cluster), e); &#125; &#125; Realm realm = getRealmInternal(); if (realm != null) &#123; try &#123; realm.backgroundProcess(); &#125; catch (Exceptione) &#123; log.warn(sm.getString("containerBase.backgroundProcess.realm", realm), e); &#125; &#125; Valve current = pipeline.getFirst(); while (current != null) &#123; try &#123; current.backgroundProcess(); &#125; catch (Exceptione) &#123; log.warn(sm.getString("containerBase.backgroundProcess.valve", current), e); &#125; current = current.getNext(); &#125; fireLifecycleEvent(Lifecycle.PERIODIC_EVENT,null);&#125; 这样做的目的，我觉得主要是找到所有HostConfig，然后修改其状态为PERIODIC_EVENT，这样就可以执行对应的方法 public void lifecycleEvent(LifecycleEvent event)&#123; // Identify the host weare associated with try &#123; host = (Host)event.getLifecycle(); if (host instanceof StandardHost)&#123; setCopyXML(((StandardHost) host).isCopyXML()); setDeployXML(((StandardHost)host).isDeployXML()); //liveDeploy属性指明host是否要周期性的检查是否有新的应用部署 setUnpackWARs(((StandardHost)host).isUnpackWARs()); setContextClass(((StandardHost)host).getContextClass()); &#125; &#125; catch (ClassCastExceptione) &#123; log.error(sm.getString("hostConfig.cce", event.getLifecycle()), e); return; &#125; if(event.getType().equals(Lifecycle.PERIODIC_EVENT)) &#123; check(); &#125; else if (event.getType().equals(Lifecycle.BEFORE_START_EVENT)) &#123; beforeStart(); &#125; else if (event.getType().equals(Lifecycle.START_EVENT)) &#123; start(); &#125; else if (event.getType().equals(Lifecycle.STOP_EVENT)) &#123; stop(); &#125;&#125; check方法代码如下： 1234567891011121314151617protected void check() &#123; if (host.getAutoDeploy())&#123; DeployedApplication[]apps = deployed.values().toArray(new DeployedApplication[0]); for (int i = 0; i &lt; apps.length; i++) &#123; if (!isServiced(apps[i].name)) checkResources(apps[i], false); &#125; // Check for old versionsof applications that can now be undeployed if (host.getUndeployOldVersions())&#123; checkUndeploy(); &#125; deployApps(); &#125;&#125; 现在我们值得讨论的是，为什么在启动之后，修改配置文件会加载新的内容，这是因为ContainerBackgroundProcessor这个新开的线程实例里面的run方法是一个死循环，每隔10秒都会执行一下，调用HostConfig的声明周期事件，并传入状态为PERIODIC_EVENT,这样的话就会不断的调用check方法，不断的进行重部署（注意：这并不是热部署，热部署是修改了java文件，只收class文件发生了修改,但是java文件在修改之后，编辑器能够自动编译成class文件,但是这需要涉及到class文件的重加载，因为它不像静态文件直接读取，所以这只是java文件重新加载的一部分，另一部分则是实例化）]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(九) 多租户]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz9%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819/** * @author 郑小康 * 设置完整的delegator 其可能形式有 default 或者defalut#tenantDelegatorName * 针对于第一种情况 delegatorBaseName =="default" delegatorTenantId=null * 针对第二种情况 delegatorBaseName =="default" delegatorTenantId="tenantDelegatorName" * 为什么存在第二种情况，是因为在多租户中要实现数据独立，所以获取基础delagtor 和租户delegator,注意这时并未创建实例更没有建立数据库连接 * 其再获取了默认的delegator中的信息之后，如果存在delegatorBaseName 则将 uri username password进行覆盖 * */ protected void setDelegatorNames(String delegatorFullName) &#123; this.delegatorFullName = delegatorFullName; int hashSymbolIndex = delegatorFullName.indexOf('#'); if (hashSymbolIndex == -1) &#123; this.delegatorBaseName = delegatorFullName; &#125; else &#123; this.delegatorBaseName = delegatorFullName.substring(0, hashSymbolIndex); this.delegatorTenantId = delegatorFullName.substring(hashSymbolIndex + 1); &#125; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//多租户 根据默认baseDelegator获取域名对应TenantId 拼接DelegatorName获取其实例if (useMultitenant) &#123; // get tenant delegator by domain name，获取服务名 String serverName = httpRequest.getServerName(); try &#123; // if tenant was specified, replace delegator with the new per-tenant delegator and set tenantId to session attribute Delegator delegator = getDelegator(config.getServletContext()); //Use base delegator for fetching data from entity of entityGroup com.hanlin.fadp.tenant Delegator baseDelegator = DelegatorFactory.getDelegator(delegator.getDelegatorBaseName()); GenericValue tenantDomainName = EntityQuery.use(baseDelegator).from("TenantDomainName").where("domainName", serverName).queryOne(); String tenantId = null; if(UtilValidate.isNotEmpty(tenantDomainName)) &#123; tenantId = tenantDomainName.getString("tenantId"); &#125; if(UtilValidate.isEmpty(tenantId)) &#123; tenantId = (String) httpRequest.getAttribute("userTenantId"); &#125; if(UtilValidate.isEmpty(tenantId)) &#123; tenantId = (String) httpRequest.getParameter("userTenantId"); &#125; if (UtilValidate.isNotEmpty(tenantId)) &#123; // if the request path is a root mount then redirect to the initial path if (UtilValidate.isNotEmpty(requestPath) &amp;&amp; requestPath.equals(contextUri)) &#123; GenericValue tenant = EntityQuery.use(baseDelegator).from("Tenant").where("tenantId", tenantId).queryOne(); String initialPath = tenant.getString("initialPath"); if (UtilValidate.isNotEmpty(initialPath) &amp;&amp; !"/".equals(initialPath)) &#123; ((HttpServletResponse)response).sendRedirect(initialPath); return; &#125; &#125; // make that tenant active, setup a new delegator and a new dispatcher String tenantDelegatorName = delegator.getDelegatorBaseName() + "#" + tenantId; httpRequest.getSession().setAttribute("delegatorName", tenantDelegatorName); // after this line the delegator is replaced with the new per-tenant delegator delegator = DelegatorFactory.getDelegator(tenantDelegatorName); config.getServletContext().setAttribute("delegator", delegator); // clear web context objects config.getServletContext().setAttribute("security", null); config.getServletContext().setAttribute("dispatcher", null); /** * 初始化security，根据delegatorName先从缓存中获取，如果缓存中不存在对应的security，则实例化一个 * 由于该过滤器是每次请求都会经过，所以根据域名不同，获取的security就有所不同，这样就可以实现共用一套用户表在不同租户中权限不同 */ Security security = getSecurity(); // initialize the services dispatcher LocalDispatcher dispatcher = getDispatcher(config.getServletContext()); // set web context objects request.setAttribute("dispatcher", dispatcher); request.setAttribute("security", security); request.setAttribute("userTenantId", tenantId); &#125; // NOTE DEJ20101130: do NOT always put the delegator name in the user's session because the user may // have logged in and specified a tenant, and even if no Tenant record with a matching domainName field // is found this will change the user's delegator back to the base one instead of the one for the // tenant specified on login // httpRequest.getSession().setAttribute("delegatorName", delegator.getDelegatorName()); &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, "Unable to get Tenant没有获取这个租户", module); &#125; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(八) 创建表]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz8%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158/** * @author 郑小康 * * 1.检验实体是否为空 * * 2.检验视图实体是否为空 * * 3.获取数据库连接 * * 4.根据对应的ModelEntity来创建表 其中modelEntities是关系表的集合 * * */public String createTable(ModelEntity entity, Map&lt;String, ModelEntity&gt; modelEntities, boolean addFks) &#123; if (entity == null) &#123; return "ModelEntity was null and is required to create a table ModelEntity是空，不能创建表"; &#125; if (entity instanceof ModelViewEntity) &#123; return "ERROR: Cannot create table for a view entity 不能为视图实体创建表"; &#125; Connection connection = null; Statement stmt = null; try &#123; connection = getConnection(); &#125; catch (SQLException e) &#123; String errMsg = "在建表过程中Unable to establish a connection with the database for helperName [" + this.helperInfo.getHelperFullName() + "]... Error was: " + e.toString(); Debug.logError(e, errMsg, module); return errMsg; &#125; catch (GenericEntityException e) &#123; String errMsg = "在建表过程中 Unable to establish a connection with the database for helperName [" + this.helperInfo.getHelperFullName() + "]... Error was: " + e.toString(); Debug.logError(e, errMsg, module); return errMsg; &#125; StringBuilder sqlBuf = new StringBuilder("CREATE TABLE "); sqlBuf.append(entity.getTableName(this.datasourceInfo)); sqlBuf.append(" ("); Iterator&lt;ModelField&gt; fieldIter = entity.getFieldsIterator(); while (fieldIter.hasNext()) &#123; ModelField field = fieldIter.next(); ModelFieldType type = modelFieldTypeReader.getModelFieldType(field.getType()); if (type == null) &#123; return "Field type [" + type + "] not found for field [" + field.getName() + "] of entity [" + entity.getEntityName() + "], not creating table."; &#125; sqlBuf.append(field.getColName()); sqlBuf.append(" "); sqlBuf.append(type.getSqlType()); if ("String".equals(type.getJavaType()) || "java.lang.String".equals(type.getJavaType())) &#123; // if there is a characterSet, add the CHARACTER SET arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCharacterSet())) &#123; sqlBuf.append(" CHARACTER SET "); sqlBuf.append(this.datasourceInfo.getCharacterSet()); &#125; // if there is a collate, add the COLLATE arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCollate())) &#123; sqlBuf.append(" COLLATE "); sqlBuf.append(this.datasourceInfo.getCollate()); &#125; &#125; if (field.getIsNotNull() || field.getIsPk()) &#123; if (this.datasourceInfo.getAlwaysUseConstraintKeyword()) &#123; sqlBuf.append(" CONSTRAINT NOT NULL, "); &#125; else &#123; sqlBuf.append(" NOT NULL, "); &#125; &#125; else &#123; sqlBuf.append(", "); &#125; &#125; String pkName = makePkConstraintName(entity, this.datasourceInfo.getConstraintNameClipLength()); if (this.datasourceInfo.getUsePkConstraintNames()) &#123; sqlBuf.append("CONSTRAINT "); sqlBuf.append(pkName); &#125; sqlBuf.append(" PRIMARY KEY ("); entity.colNameString(entity.getPkFieldsUnmodifiable(), sqlBuf, ""); sqlBuf.append(")"); if (addFks) &#123; // NOTE: This is kind of a bad idea anyway since ordering table creations is crazy, if not impossible // go through the relationships to see if any foreign keys need to be added Iterator&lt;ModelRelation&gt; relationsIter = entity.getRelationsIterator(); while (relationsIter.hasNext()) &#123; ModelRelation modelRelation = relationsIter.next(); if ("one".equals(modelRelation.getType())) &#123; ModelEntity relModelEntity = modelEntities.get(modelRelation.getRelEntityName()); if (relModelEntity == null) &#123; Debug.logError("Error adding foreign key: ModelEntity was null for related entity name " + modelRelation.getRelEntityName(), module); continue; &#125; if (relModelEntity instanceof ModelViewEntity) &#123; Debug.logError("Error adding foreign key: related entity is a view entity for related entity name " + modelRelation.getRelEntityName(), module); continue; &#125; String fkConstraintClause = makeFkConstraintClause(entity, modelRelation, relModelEntity, this.datasourceInfo.getConstraintNameClipLength(), this.datasourceInfo.getFkStyle(), this.datasourceInfo.getUseFkInitiallyDeferred()); if (UtilValidate.isNotEmpty(fkConstraintClause)) &#123; sqlBuf.append(", "); sqlBuf.append(fkConstraintClause); &#125; else &#123; continue; &#125; &#125; &#125; &#125; sqlBuf.append(")"); // if there is a tableType, add the TYPE arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getTableType())) &#123; // jaz:20101229 - This appears to be only used by mysql and now mysql has // deprecated (and in 5.5.x removed) the use of the TYPE keyword. This is // changed to ENGINE which is supported starting at 4.1 sqlBuf.append(" ENGINE "); //sqlBuf.append(" TYPE "); sqlBuf.append(this.datasourceInfo.getTableType()); &#125; // if there is a characterSet, add the CHARACTER SET arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCharacterSet())) &#123; sqlBuf.append(" CHARACTER SET "); sqlBuf.append(this.datasourceInfo.getCharacterSet()); &#125; // if there is a collate, add the COLLATE arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCollate())) &#123; sqlBuf.append(" COLLATE "); sqlBuf.append(this.datasourceInfo.getCollate()); &#125; if (Debug.verboseOn()) Debug.logVerbose("[createTable] sql=" + sqlBuf.toString(), module); try &#123; stmt = connection.createStatement(); stmt.executeUpdate(sqlBuf.toString()); &#125; catch (SQLException e) &#123; return "SQL Exception while executing the following:\n" + sqlBuf.toString() + "\nError was: " + e.toString(); &#125; finally &#123; try &#123; if (stmt != null) stmt.close(); &#125; catch (SQLException e) &#123; Debug.logError(e, module); &#125; try &#123; if (connection != null) &#123; connection.close(); &#125; &#125; catch (SQLException e) &#123; Debug.logError(e, module); &#125; &#125; return null;&#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(七) 检查数据源]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz7%2F</url>
    <content type="text"><![CDATA[123456789101112/** * Check the datasource to make sure the entity definitions are correct, optionally adding missing entities or fields on the server *@param modelEntities Map of entityName names and ModelEntity values *@param messages List to put any result messages in *@param addMissing Flag indicating whether or not to add missing entities and fields on the server * * 检查数据源确保实体正确定义,选择性添加没有的实体和字段 */ public void checkDataSource(Map&lt;String, ModelEntity&gt; modelEntities, List&lt;String&gt; messages, boolean addMissing) throws GenericEntityException &#123; genericDAO.checkDb(modelEntities, messages, addMissing); &#125;&#125; 值得一提helper的实例化的是GenericHelperDAO 所以checkDb调用的是GenericHeleper中的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * @author 郑小康 * * 1.从缓存中获取helperFullName的GenericHelper * * 2.如果为空根据helperBaseName(localmysql)获取Datasource标签实例 * * 3.根据Datasource标签的helperClass,创造构造器,构建对应实例 * * 4.以HelperFullName为k 实例为v存入到缓存 * * 5.返回当前实例化的GenericHelper * * */ public static GenericHelper getHelper(GenericHelperInfo helperInfo) &#123; GenericHelper helper = helperCache.get(helperInfo.getHelperFullName()); if (helper == null) &#123; // don't want to block here synchronized (GenericHelperFactory.class) &#123; // must check if null again as one of the blocked threads can still enter helper = helperCache.get(helperInfo.getHelperFullName()); if (helper == null) &#123; try &#123; Datasource datasourceInfo = EntityConfig.getDatasource(helperInfo.getHelperBaseName()); if (datasourceInfo == null) &#123; throw new IllegalStateException("Could not find datasource definition with name " + helperInfo.getHelperBaseName()); &#125; String helperClassName = datasourceInfo.getHelperClass(); Class&lt;?&gt; helperClass = null; if (UtilValidate.isNotEmpty(helperClassName)) &#123; try &#123; ClassLoader loader = Thread.currentThread().getContextClassLoader(); helperClass = loader.loadClass(helperClassName); &#125; catch (ClassNotFoundException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; &#125; Class&lt;?&gt;[] paramTypes = new Class&lt;?&gt;[] &#123;GenericHelperInfo.class&#125;; Object[] params = new Object[] &#123;helperInfo&#125;; java.lang.reflect.Constructor&lt;?&gt; helperConstructor = null; if (helperClass != null) &#123; try &#123; helperConstructor = helperClass.getConstructor(paramTypes); &#125; catch (NoSuchMethodException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; &#125; try &#123; helper = (GenericHelper) helperConstructor.newInstance(params); &#125; catch (IllegalAccessException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; catch (InstantiationException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; catch (java.lang.reflect.InvocationTargetException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; if (helper != null) helperCache.put(helperInfo.getHelperFullName(), helper); &#125; catch (SecurityException e) &#123; Debug.logError(e, module); throw new IllegalStateException("Error loading GenericHelper class: " + e.toString()); &#125; &#125; &#125; &#125; return helper; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(六) GenericHelper的初始化创建]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz6%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * @author 郑小康 * * 1.根据groupName获取GenericHelperInfo * * 2.获取GenericHelperInfo的helperBaseName * * 3.如果HelperFullName不为空,则进行下面的操作 HelperFullName可能是default,也可能是default#tenantId * * 4.根据helperBaseName(localmysql),获取对应的ModelFieldTypeReader 字段类型阅读器,这个是为了在建表的时候的创建对应字段类型 * * 5.根据helperInfo通过GenericHelperFactory工厂获取GenericHelper,实际是GenericHelperDAO * * 6.根据helperBaseName获取对应的Datasource标签实例 * * 7.根据GenericHelper所构建的实例,调用其checkDataSource检查数据源,向其中添加未添加的表和字段 * * */ private void initializeOneGenericHelper(String groupName) &#123; //根据groupName获取GenericHelperInfo GenericHelperInfo helperInfo = this.getGroupHelperInfo(groupName); if (helperInfo == null) &#123; if (Debug.infoOn()) &#123; Debug.logInfo("Delegator \"" + delegatorFullName + "\" NOT initializing helper for entity group \"" + groupName + "\" because the group is not associated to this delegator.", module); &#125; return; &#125; String helperBaseName = helperInfo.getHelperBaseName(); if (Debug.infoOn()) &#123; Debug.logInfo("Delegator \"" + delegatorFullName + "\" initializing helper \"" + helperBaseName + "\" for entity group \"" + groupName + "\".", module); &#125; if (UtilValidate.isNotEmpty(helperInfo.getHelperFullName())) &#123; // pre-load field type defs, the return value is ignored ModelFieldTypeReader.getModelFieldTypeReader(helperBaseName); // get the helper and if configured, do the datasource check GenericHelper helper = GenericHelperFactory.getHelper(helperInfo); try &#123; Datasource datasource = EntityConfig.getDatasource(helperBaseName); if (datasource.getCheckOnStart()) &#123; if (Debug.infoOn()) &#123; Debug.logInfo("Doing database check as requested in entityengine.xml with addMissing=" + datasource.getAddMissingOnStart(), module); &#125; helper.checkDataSource(this.getModelEntityMapByGroup(groupName), null, datasource.getAddMissingOnStart()); &#125; &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, e.getMessage(), module); &#125; &#125; &#125; protected Callable&lt;Void&gt; createHelperCallable(final String groupName) &#123; return new Callable&lt;Void&gt;() &#123; @Override public Void call() &#123; initializeOneGenericHelper(groupName); return null; &#125; &#125;; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(五) ModelGroupReader]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz5%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246public class ModelGroupReader implements Serializable &#123; public static final String module = ModelGroupReader.class.getName(); //缓存所有ModelGroupReader,其k是entity-group-reader属性值 private static final UtilCache&lt;String, ModelGroupReader&gt; readers = UtilCache.createUtilCache("entity.ModelGroupReader", 0, 0); private Map&lt;String, String&gt; groupCache = null;//以entityName为k groupName为v private Set&lt;String&gt; groupNames = null;//delegator所有的组名 public String modelName;//entity-group-reader属性值 public List&lt;ResourceHandler&gt; entityGroupResourceHandlers = new LinkedList&lt;ResourceHandler&gt;();//存放像entity-resource这样标签实例 /** * @author 郑小康 * 1.获取当前delegatorName的delegator标签的DelegatorElement实例 * * 2.获取delegator的entity-group-reader属性值 * * 3.根据属性值获取ModelGroupReader * * 4.如果没有获取到根据delegatorName和entity-group-reader属性值构造一个ModelGroupReader实例,具体过程就在本类中 * * */ public static ModelGroupReader getModelGroupReader(String delegatorName) throws GenericEntityConfException &#123; DelegatorElement delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorName); if (delegatorInfo == null) &#123; throw new GenericEntityConfException("不能发现叫做" + delegatorName+"的delegator"); &#125; String tempModelName = delegatorInfo.getEntityGroupReader(); ModelGroupReader reader = readers.get(tempModelName); if (reader == null) &#123; reader = readers.putIfAbsentAndGet(tempModelName, new ModelGroupReader(delegatorName, tempModelName)); &#125; return reader; &#125; /** * @author 郑小康 * 1. 赋值entity-group-reader的属性值 * * 2. 根据entity-group-reader的属性值获取其对应的EntityGroupReader实例,如果为空就抛出异常 * 原因:其获取的是EntityConfig实例的中的属性,EntityGroupReader是在EntityConfig实例化是加载的属性标签的对象,所以没有是肯定有问题的 * * 3. 添加entityngine.xml中的句柄属性标签MainResourceHandler实例 * * 4. 获取component.xml文件中entity-resource标签类型为group,根据与entity-group-reader的属性值对应reader-name构建ComponentResourceHandler实例添加到entityGroupResourceHandlers这个集合 * 作用是通过这个属性在对应文件中entityName所在的组,后续将其放入到对应的组中，与具体的数据源关联 * * 5. 获取delegator中与entity-group-reader的属性值对应的entity-resource中reader-name相同的标签实例 * 根据entity-resource的路径获取文件下所有entity-group实例,将其以entityName为k,groupNam为v存入到具体的groupCache中 * */ public ModelGroupReader(String delegatorName, String modelName) throws GenericEntityConfException &#123; this.modelName = modelName; EntityGroupReader entityGroupReaderInfo = EntityConfig.getInstance().getEntityGroupReader(modelName); if (entityGroupReaderInfo == null) &#123; throw new GenericEntityConfException("Cound not find an entity-group-reader with the name " + modelName); &#125; for (Resource resourceElement: entityGroupReaderInfo.getResourceList()) &#123; this.entityGroupResourceHandlers.add(new MainResourceHandler(EntityConfig.ENTITY_ENGINE_XML_FILENAME, resourceElement.getLoader(), resourceElement.getLocation())); &#125; // get all of the component resource group stuff, ie specified in each fadp-component.xml file for (ComponentConfig.EntityResourceInfo componentResourceInfo: ComponentConfig.getAllEntityResourceInfos("group")) &#123; if (modelName.equals(componentResourceInfo.readerName)) &#123; this.entityGroupResourceHandlers.add(componentResourceInfo.createResourceHandler()); &#125; &#125; // preload caches... getGroupCache(delegatorName); &#125; /** * @author 郑小康 * 如果groupCache为空则将当前delegator下,如果不为空才进行下面的操作 * * 1.构建对应的groupCache和groupNames * * 2.加载所有资源句柄文件 * 即根据与当前entity-group-reader的属性值相同的entity-resource中reader-name的entity-resource标签 * 根据entity-resource的路径获取文件下所有entity-group实例,将其以entityName为k,groupNam为v存入到具体的groupCache中 * 以entityName为k groupName为v 这样做的作用就是像getEntityGroupName等方法可以根据实体名获取对应的组名 * */ public Map&lt;String, String&gt; getGroupCache(String delegatorName) &#123; if (this.groupCache == null) &#123; // don't want to block here synchronized (ModelGroupReader.class) &#123; //再次检查groupCache是否为空,避免其它线程创建 if (this.groupCache == null) &#123; //构造groupCache这个hashMap 和groupNames这个TreeSet this.groupCache = new HashMap&lt;String, String&gt;(); this.groupNames = new TreeSet&lt;String&gt;(); //做一些时间的通知 UtilTimer utilTimer = new UtilTimer(); utilTimer.timerString("[ModelGroupReader.getGroupCache] Before getDocument"); int i = 0; //遍历所有entity-resource标签对应ComponentResourceHandler实例 for (ResourceHandler entityGroupResourceHandler: this.entityGroupResourceHandlers) &#123; Document document = null; try &#123; //解析为文档元素 document = entityGroupResourceHandler.getDocument(); &#125; catch (GenericConfigException e) &#123; Debug.logError(e, "Error loading entity group model", module); &#125; //如果document为空,缓存置为空,并且返回 if (document == null) &#123; this.groupCache = null; return null; &#125; // utilTimer.timerString("[ModelGroupReader.getGroupCache] Before getDocumentElement"); Element docElement = document.getDocumentElement(); if (docElement == null) &#123; continue; &#125; //移除空的文本节点 docElement.normalize(); //以获取首个节点,而后进行遍历,处理所有entity-group节点将其组名加到groupNames这个集合,并以entityName为k,groupName为v存到对应groupCache中 //注意有一个检查,检查是否具有entityengine.xml对应的group-map的实例,如果没有加载就没有任何意义 Node curChild = docElement.getFirstChild(); if (curChild != null) &#123; utilTimer.timerString("[ModelGroupReader.getGroupCache] Before start of entity loop"); do &#123; if (curChild.getNodeType() == Node.ELEMENT_NODE &amp;&amp; "entity-group".equals(curChild.getNodeName())) &#123; Element curEntity = (Element) curChild; String entityName = UtilXml.checkEmpty(curEntity.getAttribute("entity")).intern(); String groupName = UtilXml.checkEmpty(curEntity.getAttribute("group")).intern(); if (groupName == null || entityName == null) continue; try &#123; if (null == EntityConfig.getInstance().getDelegator(delegatorName).getGroupDataSource(groupName)) &#123; Debug.logError("The declared group name " + groupName + " has no corresponding group-map in entityengine.xml: ", module); &#125; &#125; catch (GenericEntityConfException e) &#123; Debug.logWarning(e, "Exception thrown while getting group name: ", module); &#125; this.groupNames.add(groupName); this.groupCache.put(entityName, groupName); i++; &#125; &#125; while ((curChild = curChild.getNextSibling()) != null); &#125; else &#123; Debug.logWarning("[ModelGroupReader.getGroupCache] No child nodes found.", module); &#125; &#125; utilTimer.timerString("[ModelGroupReader.getGroupCache] FINISHED - Total Entity-Groups: " + i + " FINISHED"); &#125; &#125; &#125; return this.groupCache; &#125; /** * @author 郑小康 * 方法作用:根据entityName和delegatorBaseName获取其对应的组名 * * 1.根据方法获取groupCache * * 2.根据entityName获取组名 * * 3.如果组名为空,获取delegator标签实体，获取其默认组名 * * 4.返回组名 * */ public String getEntityGroupName(String entityName, String delegatorBaseName) &#123; Map&lt;String, String&gt; gc = getGroupCache(delegatorBaseName); if (gc != null) &#123; String groupName = gc.get(entityName); if (groupName == null) &#123; DelegatorElement delegatorInfo = null; try &#123; delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorBaseName); &#125; catch (GenericEntityConfException e) &#123; Debug.logWarning(e, "Exception thrown while getting delegator config: ", module); &#125; if (delegatorInfo == null) &#123; throw new RuntimeException("Could not find DelegatorInfo for delegatorBaseName [" + delegatorBaseName + "]"); &#125; groupName = delegatorInfo.getDefaultGroupName(); &#125; return groupName; &#125; else &#123; return null; &#125; &#125; /** * @author 郑小康 * * 1.确保delegatorName是默认的delegatorName * * 2.调用getGroupCache方法的作用确保将对应的groupCache给加载到类属性 * * 3.根据delegator的default-group-name获取所有其下面默认group-name标签实例的name,将其添加到一个HashSet集合 * * 4.向该集合中添加已经通过getGroupCache方法加载的存放过entityName的groupNames集合 * */ public Set&lt;String&gt; getGroupNames(String delegatorBaseName) &#123; if (delegatorBaseName.indexOf('#') &gt;= 0) &#123; delegatorBaseName = delegatorBaseName.substring(0, delegatorBaseName.indexOf('#')); &#125; getGroupCache(delegatorBaseName); if (this.groupNames == null) return null; Set&lt;String&gt; newSet = new HashSet&lt;String&gt;(); try &#123; newSet.add(EntityConfig.getInstance().getDelegator(delegatorBaseName).getDefaultGroupName()); &#125; catch (GenericEntityConfException e) &#123; Debug.logWarning(e, "Exception thrown while getting delegator config: ", module); &#125; newSet.addAll(this.groupNames); return newSet; &#125; /** * * @author 郑小康 * * 1.构造一个Set根据delegatorBaseName和groupName,向该set注入该组里面所有的实体名 * * 2.遍历groupCache,将组名相同的entityName添加到enames这个HashSet * * 3.返回对应的enames */ public Set&lt;String&gt; getEntityNamesByGroup(String delegatorBaseName, String groupName) &#123; Map&lt;String, String&gt; gc = getGroupCache(delegatorBaseName); Set&lt;String&gt; enames = new HashSet&lt;String&gt;(); if (groupName == null || groupName.length() &lt;= 0) return enames; if (UtilValidate.isEmpty(gc)) return enames; for (Map.Entry&lt;String, String&gt; entry: gc.entrySet()) &#123; if (groupName.equals(entry.getValue())) enames.add(entry.getKey()); &#125; return enames; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(四) ModelReader的作用]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz4%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668public class ModelReader implements Serializable &#123; public static final String module = ModelReader.class.getName(); private static final UtilCache&lt;String, ModelReader&gt; readers = UtilCache.createUtilCache("entity.ModelReader", 0, 0); protected Map&lt;String, ModelEntity&gt; entityCache = null; protected int numEntities = 0; protected int numViewEntities = 0; protected int numFields = 0; protected int numRelations = 0; protected int numAutoRelations = 0; protected String modelName; /**实体资源句柄文件集合*/ protected Collection&lt;ResourceHandler&gt; entityResourceHandlers; /**实体资源句柄文件为key,其下面entityName的集合为v*/ protected Map&lt;ResourceHandler, Collection&lt;String&gt;&gt; resourceHandlerEntities; /**entityName为k 实体资源句柄文件 为v*/ protected Map&lt;String, ResourceHandler&gt; entityResourceHandlerMap; /** * @author 郑小康 * * 1.根据delegatorName获取对应DelegatorElement标签实例 * * 2.获取Delegator的entity-model-reader属性值 * * 3.根据entity-model-reader属性值获取ModelReader实例 * * 4.如果ModelReader实例为空,则创建其对应的ModelReader,并获取所有实体缓存 * * 5.以entity-model-reader属性值为k ModelReader实例为v存放到readers这个UtilCache中去 * * 6.返回当前ModelReader实例 * */ public static ModelReader getModelReader(String delegatorName) throws GenericEntityException &#123; DelegatorElement delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorName); if (delegatorInfo == null) &#123; throw new GenericEntityConfException("Could not find a delegator with the name " + delegatorName); &#125; String tempModelName = delegatorInfo.getEntityModelReader(); ModelReader reader = readers.get(tempModelName); if (reader == null) &#123; reader = new ModelReader(tempModelName); // preload caches... reader.getEntityCache(); reader = readers.putIfAbsentAndGet(tempModelName, reader); &#125; return reader; &#125; /** * @author 郑小康 * * 1.赋值entity-model-reader的属性 * * 2.根据entity-model-reader的属性值获取其对应的EntityModelReader实例,如果为空就抛出异常 * 原因:其获取的是EntityConfig实例的中的属性,EntityModelReader是在EntityConfig实例化是加载的属性标签的对象,所以没有是肯定有问题的 * * 3.添加entityngine.xml中的句柄属性标签MainResourceHandler实例 * * 4.获取*****-component.xml文件中entity-resource标签类型为model,根据与entity-model-reader的属性值对应reader-name构建ComponentResourceHandler实例添加到entityModelResourceHandlers这个集合 * * 注意:这个构造器主要是给entityResourceHandlers这个集合中添加了当前EntityModelReader 对应entity-resource对应的实例 * 它是一个私有构造器,通过getModelReader方法来创建对应实例,后续操作在getModelReader这个静态方法中 * */ private ModelReader(String modelName) throws GenericEntityException &#123; this.modelName = modelName; entityResourceHandlers = new LinkedList&lt;ResourceHandler&gt;(); resourceHandlerEntities = new HashMap&lt;ResourceHandler, Collection&lt;String&gt;&gt;(); entityResourceHandlerMap = new HashMap&lt;String, ResourceHandler&gt;(); EntityModelReader entityModelReaderInfo = EntityConfig.getInstance().getEntityModelReader(modelName); if (entityModelReaderInfo == null) &#123; throw new GenericEntityConfException("Cound not find an entity-model-reader with the name " + modelName); &#125; // get all of the main resource model stuff, ie specified in the entityengine.xml file for (Resource resourceElement : entityModelReaderInfo.getResourceList()) &#123; ResourceHandler handler = new MainResourceHandler(EntityConfig.ENTITY_ENGINE_XML_FILENAME, resourceElement.getLoader(), resourceElement.getLocation()); entityResourceHandlers.add(handler); &#125; // get all of the component resource model stuff, ie specified in each fadp-component.xml file for (ComponentConfig.EntityResourceInfo componentResourceInfo: ComponentConfig.getAllEntityResourceInfos("model")) &#123; if (modelName.equals(componentResourceInfo.readerName)) &#123; entityResourceHandlers.add(componentResourceInfo.createResourceHandler()); &#125; &#125; &#125; /** * @author 郑小康 * 1.判断节点元素是否是entity * * 2.获取entity-name的值 * * 3.获取entity的redefinition属性,这个属性的作用是说明这个实体不能被覆盖,即entity节点元素不能定义两遍 * 但这仅仅是一个警告,定义了后面的就会覆盖钱买呢 * * 4.获取当前资源句柄文件的实体名集合,为空则实例化一个LinkedList集合 * 将当前实体名添加到集合 * * 5.以entityName为k entityResourceHandler为v存放在entityResourceHandlerMap,这样做的好处是根据entityName获取其资源句柄文件 * * 6.实体不为空,构造对应的modelEntity或者ModelViewEntity * * 7.将实体的资源句柄文件路径添加到当前modelEntity * * 8.返回当前modelEntity * * 注意:这里只是构造modelEntity,并没有在数据库建表 * */ private ModelEntity buildEntity(ResourceHandler entityResourceHandler, Element curEntityElement, int i, ModelInfo def) throws GenericEntityException &#123; boolean isEntity = "entity".equals(curEntityElement.getNodeName()); String entityName = UtilXml.checkEmpty(curEntityElement.getAttribute("entity-name")).intern(); //获取entity的redefinition属性,这个属性的作用是 boolean redefinedEntity = "true".equals(curEntityElement.getAttribute("redefinition")); //获取当前entityResourceHandler的resourceHandlerEntityNames,里面存放的是这个句柄文件中存在entity,在这里获取的目的是将当前构建的entity的entityName添加进去 Collection&lt;String&gt; resourceHandlerEntityNames = resourceHandlerEntities.get(entityResourceHandler); if (resourceHandlerEntityNames == null) &#123; resourceHandlerEntityNames = new LinkedList&lt;String&gt;(); resourceHandlerEntities.put(entityResourceHandler, resourceHandlerEntityNames); &#125; resourceHandlerEntityNames.add(entityName); //检查缓存中是包含 如果缓存中包含,且它不允许重定义(entity属性中默认是false) 这样就会报一些井盖 if (entityCache.containsKey(entityName) &amp;&amp; !redefinedEntity) &#123; Debug.logWarning("实体 " + entityName + " 被再次定义,其将覆盖原有的", module); Debug.logWarning("Entity " + entityName + " 被发现在资源句柄文件 " + entityResourceHandler + ", 但是已经被定义在 " + entityResourceHandlerMap.get(entityName).toString(), module); &#125; //以entityName为k entityResourceHandler为v存放在entityResourceHandlerMap,这样做的好处是根据entityName获取其资源句柄文件 entityResourceHandlerMap.put(entityName, entityResourceHandler); //构造对应的modelEntity或者ModelViewEntity ModelEntity modelEntity = null; if (isEntity) &#123; modelEntity = createModelEntity(curEntityElement, null, def); &#125; else &#123; modelEntity = createModelViewEntity(curEntityElement, null, def); &#125; //获取句柄资源文件的路径 String resourceLocation = entityResourceHandler.getLocation(); try &#123; resourceLocation = entityResourceHandler.getURL().toExternalForm(); &#125; catch (GenericConfigException e) &#123; Debug.logError(e, "Could not get resource URL", module); &#125; //如果modelEntity不为空,将实体的路径注入到modelEntity if (modelEntity != null) &#123; modelEntity.setLocation(resourceLocation); // utilTimer.timerString(" After entityCache.put -- " + i + " --"); if (isEntity) &#123; if (Debug.verboseOn()) Debug.logVerbose("-- [Entity]: #" + i + ": " + entityName, module); &#125; else &#123; if (Debug.verboseOn()) Debug.logVerbose("-- [ViewEntity]: #" + i + ": " + entityName, module); &#125; &#125; else &#123; Debug.logWarning("-- -- ENTITYGEN ERROR:getModelEntity: Could not create " + "entity for entityName: " + entityName, module); &#125; return modelEntity; &#125; /** * @author 郑小康 * 1.检查entityCache是否为空,如果不为空直接返回当前缓存,如果为空才向下执行 * * 2.再次检查,避免其他线程在这个过程创建entityCache * * 3.对类属性进行初始化 numEntities:实体数量 numViewEntities:视图实体数量 numFields:字段数量 * numRelations: numAutoRelations numAutoRelations: * * 4.创建tempViewEntityList&lt;ModelViewEntity&gt;:临时视图模型实体集合 tempExtendEntityElementList&lt;Element&gt; 扩展实体元素 * * 5.遍历所有资源句柄文件,包括entity-model-reader中孩子标签Resource 和对应的组件下entity-resource * * 6.根据entityResourceHandler的路径,获取其对应的文档的Document实例 * * 7.从首个节点开始,首先构造ModelInfo,获取当前entity的属性 * * 8.节点有三种 entity view-entity extend-entity * 如果是实体或者视图实体,调用buildEntity,构造对应的ModelEntity * 视图实体:构造后,添加到tempViewEntityList集合 * 实体:构造后以entityName为k modelEntity为v放入到entityCache * * 如果是extend-entity,直接将节点元素添加到对应的tempExtendEntityElementList集合 * * 9.从缓存中获取extend-entity的name相同的ModelEntity,然后对这个ModelEntity进行扩展字段,并且其会覆盖原有entity的属性 * * 10.将视图实体添加到对应的成员ModelEntity,这样就可以通过ModelEntity获取其下面所有ModelViewEntity * 并将视图以entityName为k ModelViewEntity为v存放到缓存 * * 11.检查出某些视图存在有些成员实体不存在，列举出来,这些ModelViewEntity并没有加到entitycache中 * * 12构建关系,主要是给当前实体添加其存在的关系集合,关系的实体中也添加这个ModelRelation到CopyOnWriteArrayList&lt;ModelRelation&gt; relations * CopyOnWrite容器即写时复制的容器。 * 读取的时候拷贝一个副本,进行读取 * 写入的需要加锁,对副本进行写入之后,再将原容器的引用指向新的容器 * 这样的好处是可以进行并发的读 * * */ public Map&lt;String, ModelEntity&gt; getEntityCache() throws GenericEntityException &#123; if (entityCache == null) &#123; // don't want to block here synchronized (ModelReader.class) &#123; // must check if null again as one of the blocked threads can still enter if (entityCache == null) &#123; // now it's safe numEntities = 0; numViewEntities = 0; numFields = 0; numRelations = 0; numAutoRelations = 0; entityCache = new HashMap&lt;String, ModelEntity&gt;(); List&lt;ModelViewEntity&gt; tempViewEntityList = new LinkedList&lt;ModelViewEntity&gt;(); List&lt;Element&gt; tempExtendEntityElementList = new LinkedList&lt;Element&gt;(); UtilTimer utilTimer = new UtilTimer(); for (ResourceHandler entityResourceHandler: entityResourceHandlers) &#123; // utilTimer.timerString("Before getDocument in file " + entityFileName); Document document = null; try &#123; document = entityResourceHandler.getDocument(); &#125; catch (GenericConfigException e) &#123; throw new GenericEntityConfException("Error getting document from resource handler 获取entitymodel.xml文件失败", e); &#125; if (document == null) &#123; throw new GenericEntityConfException("Could not get document for " + entityResourceHandler.toString()); &#125; // utilTimer.timerString("Before getDocumentElement in " + entityResourceHandler.toString()); Element docElement = document.getDocumentElement(); if (docElement == null) &#123; return null; &#125; docElement.normalize(); Node curChild = docElement.getFirstChild(); ModelInfo def = ModelInfo.createFromElements(ModelInfo.DEFAULT, docElement); int i = 0; if (curChild != null) &#123; utilTimer.timerString("Before start of entity loop in " + entityResourceHandler.toString()); do &#123; boolean isEntity = "entity".equals(curChild.getNodeName()); boolean isViewEntity = "view-entity".equals(curChild.getNodeName()); boolean isExtendEntity = "extend-entity".equals(curChild.getNodeName()); if ((isEntity || isViewEntity) &amp;&amp; curChild.getNodeType() == Node.ELEMENT_NODE) &#123; i++; ModelEntity modelEntity = buildEntity(entityResourceHandler, (Element) curChild, i, def); // put the view entity in a list to get ready for the second pass to populate fields... if (isViewEntity) &#123; tempViewEntityList.add((ModelViewEntity) modelEntity); &#125; else &#123; entityCache.put(modelEntity.getEntityName(), modelEntity); &#125; &#125; else if (isExtendEntity &amp;&amp; curChild.getNodeType() == Node.ELEMENT_NODE) &#123; tempExtendEntityElementList.add((Element) curChild); &#125; &#125; while ((curChild = curChild.getNextSibling()) != null); &#125; else &#123; Debug.logWarning("No child nodes found.", module); &#125; utilTimer.timerString("Finished " + entityResourceHandler.toString() + " - Total Entities: " + i + " FINISHED"); &#125; //从缓存中获取extend-entity的name相同的ModelEntity,然后对这个ModelEntity进行扩展字段,并且其会覆盖原有entity的属性 for (Element extendEntityElement: tempExtendEntityElementList) &#123; String entityName = UtilXml.checkEmpty(extendEntityElement.getAttribute("entity-name")); ModelEntity modelEntity = entityCache.get(entityName); if (modelEntity == null) throw new GenericEntityConfException("Entity to extend does not exist: " + entityName); modelEntity.addExtendEntity(this, extendEntityElement); &#125; //如果视图不为空,获取视图的大小 while (!tempViewEntityList.isEmpty()) &#123; int startSize = tempViewEntityList.size(); //对视图进行迭代 Iterator&lt;ModelViewEntity&gt; mveIt = tempViewEntityList.iterator();TEMP_VIEW_LOOP: while (mveIt.hasNext()) &#123; ModelViewEntity curViewEntity = mveIt.next(); //遍历当前视图的所有ModelMemberEntity(member-entity)成员,如果在缓存中不存在就不执行,存在则继续执行 for (ModelViewEntity.ModelMemberEntity mve: curViewEntity.getAllModelMemberEntities()) &#123; if (!entityCache.containsKey(mve.getEntityName())) &#123; continue TEMP_VIEW_LOOP; &#125; &#125; mveIt.remove(); //注入视图实体所有字段 curViewEntity.populateFields(this); //加视图实体添加到其下面所有成员实体ModelEntity下,以为这可以根据ModelEntity查询其所有视图实体 for (ModelViewEntity.ModelMemberEntity mve: curViewEntity.getAllModelMemberEntities()) &#123; ModelEntity me = entityCache.get(mve.getEntityName()); me.addViewEntity(curViewEntity); &#125; entityCache.put(curViewEntity.getEntityName(), curViewEntity); &#125; //这段代码的作用是标识tempViewEntityList集合中的成员是都存在不包含在entityCache if (tempViewEntityList.size() == startSize) &#123; // Oops, the remaining views reference other entities // that can't be found, or they reference other views // that have some reference problem. break; &#125; &#125; //这段代码的作用是在上面遍历tempViewEntityList,有些MemberEntity在缓存中不存在 //检查不存在的memberEntity添加到perViewMissingEntities这个SET集合,并将其给输出 if (!tempViewEntityList.isEmpty()) &#123; StringBuilder sb = new StringBuilder("View entities reference non-existant members:\n"); Set&lt;String&gt; allViews = new HashSet&lt;String&gt;(); for (ModelViewEntity curViewEntity: tempViewEntityList) &#123; allViews.add(curViewEntity.getEntityName()); &#125; for (ModelViewEntity curViewEntity: tempViewEntityList) &#123; Set&lt;String&gt; perViewMissingEntities = new HashSet&lt;String&gt;(); Iterator&lt;ModelViewEntity.ModelMemberEntity&gt; mmeIt = curViewEntity.getAllModelMemberEntities().iterator(); while (mmeIt.hasNext()) &#123; ModelViewEntity.ModelMemberEntity mme = mmeIt.next(); String memberEntityName = mme.getEntityName(); if (!entityCache.containsKey(memberEntityName)) &#123; // this member is not a real entity // check to see if it is a view if (!allViews.contains(memberEntityName)) &#123; // not a view, it's a real missing entity perViewMissingEntities.add(memberEntityName); &#125; &#125; &#125; for (String perViewMissingEntity: perViewMissingEntities) &#123; sb.append("\t[").append(curViewEntity.getEntityName()).append("] missing member entity [").append(perViewMissingEntity).append("]\n"); &#125; &#125; throw new GenericEntityConfException(sb.toString()); &#125; /** * @author 郑小康 * 1.遍历当前ModelReader下所有实体名 * 2.获取对应ModelEntity * 3.将其关系进行迭代处理 * 4.如果类型是one 或者one-nofk(不是AutoRelation) 获取其关系ModelEntity * 5.将所有key-map的name添加到curEntityKeyFields集合 * 6.实例化ModelRelation * 7.如果是自关联,将ModelRealation添加到当前实体 * 如果不是在相关实体加入ModelRealation * */ TreeSet&lt;String&gt; orderedMessages = new TreeSet&lt;String&gt;(); for (String curEntityName: new TreeSet&lt;String&gt;(this.getEntityNames())) &#123; ModelEntity curModelEntity = this.getModelEntity(curEntityName); if (curModelEntity instanceof ModelViewEntity) &#123; // for view-entities auto-create relationships for all member-entity relationships that have all corresponding fields in the view-entity &#125; else &#123; // for entities auto-create many relationships for all type one relationships // just in case we add a new relation to the same entity, keep in a separate list and add them at the end List&lt;ModelRelation&gt; newSameEntityRelations = new LinkedList&lt;ModelRelation&gt;(); Iterator&lt;ModelRelation&gt; relationsIter = curModelEntity.getRelationsIterator(); while (relationsIter.hasNext()) &#123; ModelRelation modelRelation = relationsIter.next(); if (("one".equals(modelRelation.getType()) || "one-nofk".equals(modelRelation.getType())) &amp;&amp; !modelRelation.isAutoRelation()) &#123; ModelEntity relatedEnt = null; try &#123; /** 得到参考的 RelEntityName. */ relatedEnt = this.getModelEntity(modelRelation.getRelEntityName()); &#125; catch (GenericModelException e) &#123;// com.hanlin.fadp.petrescence.datasource.FindMissedEntity.addMissed(modelRelation.getRelEntityName()); throw new GenericModelException("Error getting related entity [" + modelRelation.getRelEntityName() + "] definition from entity [" + curEntityName + "]", e); &#125; if (relatedEnt != null) &#123; // create the new relationship even if one exists so we can show what we are looking for in the info message // don't do relationship to the same entity, unless title is "Parent", then do a "Child" automatically String title = modelRelation.getTitle(); if (curModelEntity.getEntityName().equals(relatedEnt.getEntityName()) &amp;&amp; "Parent".equals(title)) &#123; title = "Child"; &#125; String description = ""; String type = ""; String relEntityName = curModelEntity.getEntityName(); String fkName = ""; ArrayList&lt;ModelKeyMap&gt; keyMaps = new ArrayList&lt;ModelKeyMap&gt;(); boolean isAutoRelation = true; Set&lt;String&gt; curEntityKeyFields = new HashSet&lt;String&gt;(); for (ModelKeyMap curkm : modelRelation.getKeyMaps()) &#123; keyMaps.add(new ModelKeyMap(curkm.getRelFieldName(), curkm.getFieldName())); curEntityKeyFields.add(curkm.getFieldName()); &#125; keyMaps.trimToSize(); // decide whether it should be one or many by seeing if the key map represents the complete pk of the relEntity if (curModelEntity.containsAllPkFieldNames(curEntityKeyFields)) &#123; // always use one-nofk, we don't want auto-fks getting in for these automatic ones type = "one-nofk"; // to keep it clean, remove any additional keys that aren't part of the PK List&lt;String&gt; curPkFieldNames = curModelEntity.getPkFieldNames(); Iterator&lt;ModelKeyMap&gt; nrkmIter = keyMaps.iterator(); while (nrkmIter.hasNext()) &#123; ModelKeyMap nrkm =nrkmIter.next(); String checkField = nrkm.getRelFieldName(); if (!curPkFieldNames.contains(checkField)) &#123; nrkmIter.remove(); &#125; &#125; &#125; else &#123; type= "many"; &#125; ModelRelation newRel = ModelRelation.create(relatedEnt, description, type, title, relEntityName, fkName, keyMaps, isAutoRelation); ModelRelation existingRelation = relatedEnt.getRelation(title + curModelEntity.getEntityName()); if (existingRelation == null) &#123; numAutoRelations++; if (curModelEntity.getEntityName().equals(relatedEnt.getEntityName())) &#123; newSameEntityRelations.add(newRel); &#125; else &#123; relatedEnt.addRelation(newRel); &#125; &#125; else &#123; if (newRel.equals(existingRelation)) &#123; // don't warn if the target title+entity = current title+entity if (Debug.infoOn() &amp;&amp; !(title + curModelEntity.getEntityName()).equals(modelRelation.getTitle() + modelRelation.getRelEntityName())) &#123; //String errorMsg = "Relation already exists to entity [] with title [" + targetTitle + "],from entity []"; String message = "Entity [" + relatedEnt.getPackageName() + ":" + relatedEnt.getEntityName() + "] already has identical relationship to entity [" + curModelEntity.getEntityName() + "] title [" + title + "]; would auto-create: type [" + newRel.getType() + "] and fields [" + newRel.keyMapString(",", "") + "]"; orderedMessages.add(message); &#125; &#125; else &#123; String message = "Existing relationship with the same name, but different specs found from what would be auto-created for Entity [" + relatedEnt.getEntityName() + "] and relationship to entity [" + curModelEntity.getEntityName() + "] title [" + title + "]; would auto-create: type [" + newRel.getType() + "] and fields [" + newRel.keyMapString(",", "") + "]"; Debug.logVerbose(message, module); &#125; &#125; &#125; else &#123; String errorMsg = "Could not find related entity [" + modelRelation.getRelEntityName() + "], no reverse relation added."; Debug.logWarning(errorMsg, module); &#125; &#125; &#125; if (newSameEntityRelations.size() &gt; 0) &#123; for (ModelRelation newRel: newSameEntityRelations) &#123; curModelEntity.addRelation(newRel); &#125; &#125; &#125; &#125; if (Debug.infoOn()) &#123; for (String message : orderedMessages) &#123; Debug.logInfo(message, module); &#125; Debug.logInfo("Finished loading entities; #Entities=" + numEntities + " #ViewEntities=" + numViewEntities + " #Fields=" + numFields + " #Relationships=" + numRelations + " #AutoRelationships=" + numAutoRelations, module); &#125; &#125; &#125; &#125; return entityCache; &#125; /** * rebuilds the resourceHandlerEntities Map of Collections based on the current * entityResourceHandlerMap Map, must be done whenever a manual change is made to the * entityResourceHandlerMap Map after the initial load to make them consistent again. * * Map&lt;ResourceHandler, Collection&lt;String&gt;&gt; resourceHandlerEntities * Map&lt;String, ResourceHandler&gt; entityResourceHandlerMap * 依据entityResourceHandlerMap来更新resourceHandlerEntities * FIXME:暂时不理解为什么会出现这种情况 */ public void rebuildResourceHandlerEntities() &#123; resourceHandlerEntities = new HashMap&lt;ResourceHandler, Collection&lt;String&gt;&gt;(); Iterator&lt;Map.Entry&lt;String, ResourceHandler&gt;&gt; entityResourceIter = entityResourceHandlerMap.entrySet().iterator(); while (entityResourceIter.hasNext()) &#123; Map.Entry&lt;String, ResourceHandler&gt; entry = entityResourceIter.next(); // add entityName to appropriate resourceHandlerEntities collection Collection&lt;String&gt; resourceHandlerEntityNames = resourceHandlerEntities.get(entry.getValue()); if (resourceHandlerEntityNames == null) &#123; resourceHandlerEntityNames = new LinkedList&lt;String&gt;(); resourceHandlerEntities.put(entry.getValue(), resourceHandlerEntityNames); &#125; resourceHandlerEntityNames.add(entry.getKey()); &#125; &#125; /**获取当前模型阅读器的resourceHandler迭代器*/ public Iterator&lt;ResourceHandler&gt; getResourceHandlerEntitiesKeyIterator() &#123; if (resourceHandlerEntities == null) return null; return resourceHandlerEntities.keySet().iterator(); &#125; public Collection&lt;String&gt; getResourceHandlerEntities(ResourceHandler resourceHandler) &#123; if (resourceHandlerEntities == null) return null; return resourceHandlerEntities.get(resourceHandler); &#125; public void addEntityToResourceHandler(String entityName, String loaderName, String location) &#123; entityResourceHandlerMap.put(entityName, new MainResourceHandler(EntityConfig.ENTITY_ENGINE_XML_FILENAME, loaderName, location)); &#125; public ResourceHandler getEntityResourceHandler(String entityName) &#123; return entityResourceHandlerMap.get(entityName); &#125; /** Gets an Entity object based on a definition from the specified XML Entity descriptor file. * @param entityName The entityName of the Entity definition to use. * @return An Entity object describing the specified entity of the specified descriptor file. */ public ModelEntity getModelEntity(String entityName) throws GenericEntityException &#123; if (entityName == null) &#123; throw new IllegalArgumentException("Tried to find entity definition for a null entityName"); &#125; Map&lt;String, ModelEntity&gt; ec = getEntityCache(); if (ec == null) &#123; throw new GenericEntityConfException("ERROR: Unable to load Entity Cache"); &#125; ModelEntity modelEntity = ec.get(entityName); if (modelEntity == null) &#123; String errMsg = "Could not find definition for entity name " + entityName; // Debug.logError(new Exception("Placeholder"), errMsg, module);// com.hanlin.fadp.petrescence.datasource.FindMissedEntity.addMissed(entityName); throw new GenericModelException(errMsg); &#125; return modelEntity; &#125; public ModelEntity getModelEntityNoCheck(String entityName) &#123; Map&lt;String, ModelEntity&gt; ec = null; try &#123; ec = getEntityCache(); &#125; catch (GenericEntityException e) &#123; Debug.logError(e, "Error getting entity cache", module); &#125; if (ec == null) &#123; return null; &#125; ModelEntity modelEntity = ec.get(entityName); return modelEntity; &#125; /** Creates a Iterator with the entityName of each Entity defined in the specified XML Entity Descriptor file. * @return A Iterator of entityName Strings */ public Iterator&lt;String&gt; getEntityNamesIterator() throws GenericEntityException &#123; Collection&lt;String&gt; collection = getEntityNames(); if (collection != null) &#123; return collection.iterator(); &#125; else &#123; return null; &#125; &#125; /** Creates a Set with the entityName of each Entity defined in the specified XML Entity Descriptor file. * @return A Set of entityName Strings */ public Set&lt;String&gt; getEntityNames() throws GenericEntityException &#123; Map&lt;String, ModelEntity&gt; ec = getEntityCache(); if (ec == null) &#123; throw new GenericEntityConfException("ERROR: Unable to load Entity Cache"); &#125; return ec.keySet(); &#125; /** Get all entities, organized by package */ public Map&lt;String, TreeSet&lt;String&gt;&gt; getEntitiesByPackage(Set&lt;String&gt; packageFilterSet, Set&lt;String&gt; entityFilterSet) throws GenericEntityException &#123; Map&lt;String, TreeSet&lt;String&gt;&gt; entitiesByPackage = new HashMap&lt;String, TreeSet&lt;String&gt;&gt;(); //put the entityNames TreeSets in a HashMap by packageName Iterator&lt;String&gt; ecIter = this.getEntityNames().iterator(); while (ecIter.hasNext()) &#123; String entityName = ecIter.next(); ModelEntity entity = this.getModelEntity(entityName); String packageName = entity.getPackageName(); if (UtilValidate.isNotEmpty(packageFilterSet)) &#123; // does it match any of these? boolean foundMatch = false; for (String packageFilter: packageFilterSet) &#123; if (packageName.contains(packageFilter)) &#123; foundMatch = true; &#125; &#125; if (!foundMatch) &#123; //Debug.logInfo("Not including entity " + entityName + " becuase it is not in the package set: " + packageFilterSet, module); continue; &#125; &#125; if (UtilValidate.isNotEmpty(entityFilterSet) &amp;&amp; !entityFilterSet.contains(entityName)) &#123; //Debug.logInfo("Not including entity " + entityName + " because it is not in the entity set: " + entityFilterSet, module); continue; &#125; TreeSet&lt;String&gt; entities = entitiesByPackage.get(entity.getPackageName()); if (entities == null) &#123; entities = new TreeSet&lt;String&gt;(); entitiesByPackage.put(entity.getPackageName(), entities); &#125; entities.add(entityName); &#125; return entitiesByPackage; &#125; /** Util method to validate an entity name; if no entity is found with the name, * characters are stripped from the beginning of the name until a valid entity name is found. * It is intended to be used to determine the entity name from a relation name. * @return A valid entityName or null */ public String validateEntityName(String entityName) throws GenericEntityException &#123; if (entityName == null) &#123; return null; &#125; Set&lt;String&gt; allEntities = this.getEntityNames(); while (!allEntities.contains(entityName) &amp;&amp; entityName.length() &gt; 0) &#123; entityName = entityName.substring(1); &#125; return (entityName.length() &gt; 0? entityName: null); &#125; ModelEntity createModelEntity(Element entityElement, UtilTimer utilTimer, ModelInfo def) &#123; if (entityElement == null) return null; this.numEntities++; ModelEntity entity = new ModelEntity(this, entityElement, utilTimer, def); return entity; &#125; ModelEntity createModelViewEntity(Element entityElement, UtilTimer utilTimer, ModelInfo def) &#123; if (entityElement == null) return null; this.numViewEntities++; ModelViewEntity entity = new ModelViewEntity(this, entityElement, utilTimer, def); return entity; &#125; public ModelRelation createRelation(ModelEntity entity, Element relationElement) &#123; this.numRelations++; ModelRelation relation = ModelRelation.create(entity, relationElement, false); return relation; &#125; /**增加当前ModelReader字段个数*/ public void incrementFieldCount(int amount) &#123; this.numFields += amount; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(三) GenericDelegator实例化的具体过程]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz3%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * @author 郑小康 * 1.设置delegatorFullName 基本delegatorName+"#"+tenantId 如果tenantId为空 则就是默认的delegatorName * * 2.获取EntityConfig实例,并获取基本delegatorBaseName的delegator标签,并解析为对应的DelegatorElement实例 * &lt;delegator name="default" entity-model-reader="main" entity-group-reader="main"&gt;&lt;/delegator&gt; * * 3.判断delegatorTenantId是否为空,这是租户id * 第一种情况租户id不为空:获取默认的Delegator,用delegator查询Tenant表中当前tenantId的对应GenericValue * :获取对应租户的kekText FIXME:暂时未应用 网上搜索说对数据库连接密码进行解密的操作 * 第二种情况租户id为空 :获取delegator标签实例的key-encrypting-key * * 4.获取ModelReader 检查了实体缓存之类的操作,获取所有ModelEntity * * 5.获取所有ModelGroupReader * 该类的主要操作是构造对应groupCache缓存,将entity-name为k,groupName为v这样存放,并提供一些获取方法,如获取所有组名,根据实体名获取组名 * * 6.缓存当前delegatorFullName * * 7.对实体进行检查 有检查组里面是否有对应实体 实体名是否是保留字 建立视图一个字段是否被引用多次 * * 8.获取组名集合 * * 9.遍历delegaot组,通过ThreadPoolExecutor线程池提交Future中任务,对每个组的实体创建到其组对应数据源的数据库 * 调用Future的原因是,是因为建表很耗时间,所以采用异步执行 * * */ protected GenericDelegator(String delegatorFullName) throws GenericEntityException &#123; this.setDelegatorNames(delegatorFullName); //获取基本的delegator中的信息 this.delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorBaseName); String kekText; // before continuing, if there is a tenantId use the base delegator to see if it is valid if (UtilValidate.isNotEmpty(this.delegatorTenantId)) &#123; Delegator baseDelegator = DelegatorFactory.getDelegator(this.delegatorBaseName); GenericValue tenant = EntityQuery.use(baseDelegator).from("Tenant").where("tenantId", this.delegatorTenantId).cache(true).queryOne(); if (tenant == null) &#123; throw new GenericEntityException("No Tenant record found for delegator [" + this.delegatorFullName + "] with tenantId [" + this.delegatorTenantId + "]"); &#125; else if ("Y".equals(tenant.getString("disabled"))) &#123; throw new GenericEntityException("No Tenant record found for delegator [" + this.delegatorFullName + "] with tenantId [" + this.delegatorTenantId + "]"); &#125; GenericValue kekValue = EntityQuery.use(baseDelegator).from("TenantKeyEncryptingKey").where("tenantId", getDelegatorTenantId()).cache(true).queryOne(); if (kekValue != null) &#123; kekText = kekValue.getString("kekText"); &#125; else &#123; kekText = this.delegatorInfo.getKeyEncryptingKey(); &#125; &#125; else &#123; kekText = this.delegatorInfo.getKeyEncryptingKey(); &#125; this.modelReader = ModelReader.getModelReader(delegatorBaseName); this.modelGroupReader = ModelGroupReader.getModelGroupReader(delegatorBaseName); cache = new Cache(delegatorFullName); //对实体进行检查 有检查组里面是否有对应实体 实体名是否是保留字 建立视图一个字段是否被引用多次 List&lt;String&gt; warningList = new LinkedList&lt;String&gt;(); Debug.logInfo("Doing entity definition check...", module); ModelEntityChecker.checkEntities(this, warningList); if (warningList.size() &gt; 0) &#123; Debug.logWarning("=-=-=-=-= Found " + warningList.size() + " warnings when checking the entity definitions:", module); for (String warning: warningList) &#123; Debug.logWarning(warning, module); &#125; &#125; //获取当前delegator中的groupNames集合,遍历创建对应的GenericHelper,同时在数据库中创建未创建的表和字段 Set&lt;String&gt; groupNames = getModelGroupReader().getGroupNames(delegatorBaseName); List&lt;Future&lt;Void&gt;&gt; futures = new LinkedList&lt;Future&lt;Void&gt;&gt;(); for (String groupName: groupNames) &#123; futures.add(ExecutionPool.GLOBAL_BATCH.submit(createHelperCallable(groupName))); &#125; ExecutionPool.getAllFutures(futures); // NOTE: doing some things before the ECAs and such to make sure it is in place just in case it is used in a service engine startup thing or something // setup the crypto class; this also after the delegator is in the cache otherwise we get infinite recursion this.crypto = new EntityCrypto(this, kekText); &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(二) delegator实例化具体方式]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz2%2F</url>
    <content type="text"><![CDATA[123456789101112131415/** * @author 郑小康 * 采用spi创建对应实例DelegatorFactoryImpl * */ public static &lt;A, R&gt; R getObjectFromFactory(Class&lt;? extends Factory&lt;R, A&gt;&gt; factoryInterface, A obj) throws ClassNotFoundException &#123; Iterator&lt;? extends Factory&lt;R, A&gt;&gt; it = ServiceLoader.load(factoryInterface).iterator(); while (it.hasNext()) &#123; Factory&lt;R, A&gt; factory = it.next(); R instance = factory.getInstance(obj); if (instance != null) &#123; return instance; &#125; &#125; throw new ClassNotFoundException(factoryInterface.getClass().getName()); &#125; 注：上下代码不是在一个类 1234567891011121314151617181920 /** * @author 郑小康 * 根据delegatorName创建一个GenericDelegator * 所以实际delegator引用的是一个GenericDelegator实例 * */public class DelegatorFactoryImpl extends DelegatorFactory &#123; public static final String module = DelegatorFactoryImpl.class.getName(); public Delegator getInstance(String delegatorName) &#123; if (Debug.infoOn()) Debug.logInfo("Creating new delegator [" + delegatorName + "] (" + Thread.currentThread().getName() + ")", module); //Debug.logInfo(new Exception(), "Showing stack where new delegator is being created...", module); try &#123; return new GenericDelegator(delegatorName); &#125; catch (GenericEntityException e) &#123; Debug.logError(e, "Error creating delegator", module); return null; &#125; &#125;&#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(一) 获取Delegator]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz1%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public abstract class DelegatorFactory implements Factory&lt;Delegator, String&gt; &#123; public static final String module = DelegatorFactoryImpl.class.getName(); private static final ConcurrentHashMap&lt;String, Future&lt;Delegator&gt;&gt; delegators = new ConcurrentHashMap&lt;String, Future&lt;Delegator&gt;&gt;(); private static final ThreadGroup DELEGATOR_THREAD_GROUP = new ThreadGroup("DelegatorFactory"); private static final ScheduledExecutorService executor = ExecutionPool.getScheduledExecutor(DELEGATOR_THREAD_GROUP, "delegator-startup", Runtime.getRuntime().availableProcessors(), 10, true); /** *@author 郑小康 * * 根据delegatorName调用getDelegatorFuture方法,获取当前delegator的 Future&lt;Delegator&gt; * * 而后调用get方法获取Delegator实例 * * */ public static Delegator getDelegator(String delegatorName) &#123; Future&lt;Delegator&gt; future = getDelegatorFuture(delegatorName); try &#123; return future.get(); &#125; catch (ExecutionException e) &#123; Debug.logError(e, module); return null; &#125; catch (InterruptedException e) &#123; Debug.logError(e, module); return null; &#125; &#125; /** * @author 郑小康 * * 根据delegatorName获取Future&lt;Delegator&gt; 如果为空,新创建一个FutureTask&lt;Delegator&gt;将其加入到缓存中去 * * 将这个futureTask给提交到线程池,futureTask中存放的是DelegatorConfigurable实例对象 * * * */ public static Future&lt;Delegator&gt; getDelegatorFuture(String delegatorName) &#123; if (delegatorName == null) &#123; delegatorName = "default"; //Debug.logWarning(new Exception("Location where getting delegator with null name"), "Got a getGenericDelegator call with a null delegatorName, assuming default for the name.", module); &#125; do &#123; Future&lt;Delegator&gt; future = delegators.get(delegatorName); if (future != null) &#123; //Debug.logInfo("got delegator(future(" + delegatorName + ")) from cache", module); return future; &#125; FutureTask&lt;Delegator&gt; futureTask = new FutureTask&lt;Delegator&gt;(new DelegatorConfigurable(delegatorName)); //Debug.logInfo("putting delegator(future(" + delegatorName + ")) into cache", module); if (delegators.putIfAbsent(delegatorName, futureTask) != null) &#123; continue; &#125; executor.submit(futureTask); &#125; while (true); &#125; public static final class DelegatorConfigurable implements Callable&lt;Delegator&gt; &#123; private final String delegatorName; public DelegatorConfigurable(String delegatorName) &#123; this.delegatorName = delegatorName; &#125; /** * 获取delegator的具体方法 * 并做了分布式缓存和ECA Handler FIXME:未研究 * */ public Delegator call() throws ClassNotFoundException &#123; try &#123; Delegator delegator = UtilObject.getObjectFromFactory(DelegatorFactory.class, delegatorName); // setup the Entity ECA Handler delegator.initEntityEcaHandler(); // setup the distributed CacheClear delegator.initDistributedCacheClear(); return delegator; &#125; catch (ClassNotFoundException e) &#123; Debug.logError(e, module); throw e; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz方法之FreeMarkerWorker的makeConfiguration]]></title>
    <url>%2F2017%2F06%2F26%2Fofbiz%2Fofbiz10%2F</url>
    <content type="text"><![CDATA[代码展示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133public static Configuration makeConfiguration(BeansWrapper wrapper) &#123; /** * freemarker.template.Configuration实例并调整其设置。 * 一个Configuration实例是存储FreeMarker应用程序级别设置的中心。 * 另外，它处理预先解析的模板（即 对象）的创建和 缓存Template * */ Configuration newConfig = new Configuration(version); /** * @author jack * * 对象包装器 * wrapper == &gt;freemarker.ext.beans.BeansWrapper * 这是一个最原始的对象包装器，主要用来映射java * 虽然原始，但是也有使用的时候，比如collection-s和map-s被允许修改模板时执行 * 参考资料 http://freemarker.org/docs/pgui_misc_beanwrapper.html * */ newConfig.setObjectWrapper(wrapper); /** * @author jack * * 从beanswrapper返回TemplateHashModel。 * getstaticmodels()可以用来访问静态方法和任意一类的字段创建哈希模型。 * */ TemplateHashModel staticModels = wrapper.getStaticModels(); /** * @author jack * 将TemplateHashModel通过Static注入 以后就可以直接通过Static进行访问 * Shared variables共享变量是为所有模板定义的变量 * 形式：statics["java.lang.System"].currentTimeMillis() 这是一种调用java方法的处理方式 ftl中的用法 * */ newConfig.setSharedVariable("Static", staticModels); /** * @author jack * * #assign ls = EntityQuery.use(delegator).from("DictType").() ftl中的用法 * 注入后就可以直接使用EntityQuery了 * */ try &#123; newConfig.setSharedVariable("EntityQuery", staticModels.get("com.hanlin.fadp.entity.util.EntityQuery")); &#125; catch (TemplateModelException e) &#123; Debug.logError(e, module); &#125; /** * @author jack * * 当一个模板包含另一个模板时，它试图加载以相同的本地化环境加载模板。 * 假定你的模板以本地化en_US来加载，那就意味着是U.S. English。当你包含另外一个模板：那么引擎实际上就会寻找一些模板，并按照这个顺序： * footer_en_US.ftl * footer_en.ftl * footer.ftl * 设置成为false就不会有这些问题 * */ newConfig.setLocalizedLookup(false); //创建StringUtil这个工具类共享变量 newConfig.setSharedVariable("StringUtil", new BeanModel(StringUtil.INSTANCE, wrapper)); /** * @author jack * * 如果在这些内建的模版加载器中没有一个符合你的要求， * 那么你可以自己定制一个模版加载器，只需要实现freemarker.cache.TemplateLoader 接口就可以了， * 然后通过方法setTemplateLoader(TemplateLoader loader)把其传递给Configuration对象。 * 主要业务处理不是很清楚 * */ newConfig.setTemplateLoader(new FlexibleTemplateLoader()); /** * @author jack * * 导入库也就是说，它创建一个新的空命名空间 然后执行path在该命名空间中使用参数给出的模板 * 导入法则： * #import "/lib/example.ftl" as e * &lt;@e.copyright date="1999-2002"/&gt; * 属性文件中的模板就是通过这种方式加载进去 * 所以在调用的时候需要加入命令空间 * */ newConfig.setAutoImports(UtilProperties.getProperties("freemarkerImports")); /** * @author jack * * 自定义类实现TemplateExceptionHandler * 当ftl渲染出现异常调用这个类的handleTemplateException * */ newConfig.setTemplateExceptionHandler(new FreeMarkerWorker.OFBizTemplateExceptionHandler()); try &#123; newConfig.setSetting("datetime_format", "yyyy-MM-dd HH:mm:ss.SSS"); newConfig.setSetting("number_format", "0.##########"); &#125; catch (TemplateException e) &#123; Debug.logError("Unable to set date/time and number formats in FreeMarker: " + e, module); &#125; // Transforms properties file set up as key=transform name, property=transform class name /** * @author jack * * 获取上下文加载器，当前加载器在webapp,随意加载其中config的freemarkerTransforms.properties所有值 * */ ClassLoader loader = Thread.currentThread().getContextClassLoader(); Enumeration&lt;URL&gt; resources; try &#123; resources = loader.getResources("freemarkerTransforms.properties"); &#125; catch (IOException e) &#123; Debug.logError(e, "Could not load list of freemarkerTransforms.properties", module); throw UtilMisc.initCause(new InternalError(e.getMessage()), e); &#125; /** * @author jack * * 创建其中资源文件值得实例并通过key用setSharedVariable设置进入共享变量 * */ while (resources.hasMoreElements()) &#123; URL propertyURL = resources.nextElement(); Debug.logInfo("loading properties: " + propertyURL, module); Properties props = UtilProperties.getProperties(propertyURL); if (UtilValidate.isEmpty(props)) &#123; Debug.logError("Unable to locate properties file " + propertyURL, module); &#125; else &#123; loadTransforms(loader, props, newConfig); &#125; &#125; return newConfig; &#125; 用例说明1&lt;#assign displayApps = Static[&quot;org.ofbiz.webapp.control.LoginWorker&quot;].getAppBarWebInfos(security, userLogin, ofbizServerName, &quot;main&quot;)&gt; StringUtil1&lt;link rel=&quot;shortcut icon&quot; href=&quot;&lt;@ofbizContentUrl&gt;$&#123;StringUtil.wrapString(shortcutIcon)&#125;&lt;/@ofbizContentUrl&gt;&quot; /&gt;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz方法之条件查询createConditionList]]></title>
    <url>%2F2017%2F06%2F26%2Fofbiz%2Fofbiz11%2F</url>
    <content type="text"><![CDATA[方法代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110/** * Parses input parameters and returns an &lt;code&gt;EntityCondition&lt;/code&gt; list. * * @param parameters * @param fieldList * @param queryStringMap * @param delegator * @param context * @return returns an EntityCondition list * * @author jack * 第一步：获取所有字段信息 存入到Map&lt;String, ModelField&gt; fieldMap * 第二步：将上下文这个map进行遍历,这个map是传进来的参数 * 由于是根据参数，一个字段最多具有三个条件 _op _fld0_op _fld1_op * 第三步: 调用createSingleCondition创造条件，添加到集合 * * @param parameters 获取传入的参数 * @param fieldList 传入当前实体所有字段 * @param queryStringMap * @param delegator 操作数据库的实例 * @param context 获取上下文 */ public static List&lt;EntityCondition&gt; createConditionList(Map&lt;String, ? extends Object&gt; parameters, List&lt;ModelField&gt; fieldList, Map&lt;String, Object&gt; queryStringMap, Delegator delegator, Map&lt;String, ?&gt; context) &#123; Set&lt;String&gt; processed = new LinkedHashSet&lt;String&gt;(); Set&lt;String&gt; keys = new LinkedHashSet&lt;String&gt;(); Map&lt;String, ModelField&gt; fieldMap = new LinkedHashMap&lt;String, ModelField&gt;(); for (ModelField modelField : fieldList) &#123; fieldMap.put(modelField.getName(), modelField); &#125; List&lt;EntityCondition&gt; result = new LinkedList&lt;EntityCondition&gt;(); for (Map.Entry&lt;String, ? extends Object&gt; entry : parameters.entrySet()) &#123; String parameterName = entry.getKey(); //获取上下文中的键值 //如果已经有了这个键值在进程中就不在对它进行处理 if (processed.contains(parameterName)) &#123; continue; &#125; keys.clear(); String fieldName = parameterName; Object fieldValue = null; String operation = null; boolean ignoreCase = false; /** * 将参数名截断对应实体中的字段名，这样做的方式是先获取字段名 * (如果包含fld0 fld1下面则需要再截断）， * 下面进行连接，针对几种不同的情况进行处理 */ if (parameterName.endsWith("_ic") || parameterName.endsWith("_op")) &#123; fieldName = parameterName.substring(0, parameterName.length() - 3); &#125; else if (parameterName.endsWith("_value")) &#123; fieldName = parameterName.substring(0, parameterName.length() - 6); &#125; //_ic连接 是判断条件查找是否忽略大小写 String key = fieldName.concat("_ic"); if (parameters.containsKey(key)) &#123; keys.add(key); ignoreCase = "Y".equals(parameters.get(key)); &#125; //获取字段要进行的操作 key = fieldName.concat("_op"); if (parameters.containsKey(key)) &#123; keys.add(key); operation = (String) parameters.get(key); &#125; //获取字段的值,如果具有_fld0 这些可能获取不到，后面会进一步截断获取 key = fieldName.concat("_value"); if (parameters.containsKey(key)) &#123; keys.add(key); fieldValue = parameters.get(key); &#125; //主要是对时间进行处理，一个条件大于多少 小于多少 if (fieldName.endsWith("_fld0") || fieldName.endsWith("_fld1")) &#123; if (parameters.containsKey(fieldName)) &#123; keys.add(fieldName); &#125; fieldName = fieldName.substring(0, fieldName.length() - 5); &#125; //将字段名，之所以这样不断截断是为了获取对应与实体中的真实字段名 if (parameters.containsKey(fieldName)) &#123; keys.add(fieldName); &#125; processed.addAll(keys); ModelField modelField = fieldMap.get(fieldName); if (modelField == null) &#123; continue; &#125; //获取字段值 if (fieldValue == null) &#123; fieldValue = parameters.get(fieldName); &#125; //如果值为空，则不进行任何操作 if (ObjectType.isEmpty(fieldValue) &amp;&amp; !"empty".equals(operation)) &#123; continue; &#125; //将创建的条件加入list集合 即AND关系 result.add(createSingleCondition(modelField, operation, fieldValue, ignoreCase, delegator, context)); for (String mapKey : keys) &#123; queryStringMap.put(mapKey, parameters.get(mapKey)); &#125; &#125; return result; &#125; 方法使用1234567&lt;select name=&quot;visitId_op&quot; class=&quot;selectBox&quot;&gt; &lt;option value=&quot;equals&quot;&gt;等于&lt;/option&gt; &lt;option value=&quot;like&quot;&gt;开头字符&lt;/option&gt; &lt;option value=&quot;contains&quot; selected=&quot;selected&quot;&gt;包含&lt;/option&gt; &lt;option value=&quot;empty&quot;&gt;为空&lt;/option&gt; &lt;option value=&quot;notEqual&quot;&gt;不等于&lt;/option&gt;&lt;/select&gt;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz view渲染处理机制]]></title>
    <url>%2F2017%2F06%2F16%2Fofbiz%2Fofbiz12%2F</url>
    <content type="text"><![CDATA[初始化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ControlServlet.java 这是一个servlet,其配置文件在web.xml里 1234567891011&lt;servlet&gt; &lt;servlet-name&gt;ControlServlet&lt;/servlet-name&gt; &lt;display-name&gt;ControlServlet&lt;/display-name&gt; &lt;description&gt;MainControl Servlet&lt;/description&gt; &lt;servlet-class&gt;org.apache.ofbiz.webapp.control.ControlServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;ControlServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/control/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这也是为什么大多数请求都是组件名/control/* 首先在第一次请求时经过Servlet的init方法，该Servlet方法如下： 123456789101112131415public void init(ServletConfig config) throws ServletException &#123; super.init(config); if (Debug.infoOn()) &#123; ServletContext servletContext = config.getServletContext(); String webappName = servletContext.getContextPath().length() != 0 ?servletContext.getContextPath().substring(1) : ""; Debug.logInfo("Loading webapp [" + webappName + "],located at " + servletContext.getRealPath("/"), module);&#125; //配置默认脚本引擎，默认有beanshell和平台自定义的minilang脚本，可扩展其它脚本 configureBsf(); // 初始化request处理句柄，实质就是加载controller.xml中handler节点中class属性值对应类的实例化和初始化 getRequestHandler();&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 该方法中的getRequestHandler就是获取所有的handler节点，加载方式如下 123456789/** * @Title: getRequestHandler * @Description: 获取request的处理句柄，request处理分两类，一类是view， * 另一类是event，对应controller.xml中handler节点的配置信息的获取 * @return: RequestHandler */ protected RequestHandler getRequestHandler() &#123; return RequestHandler.getRequestHandler(getServletContext());&#125; 12345678910111213141516/** * @Title: getRequestHandler * @Description: 在上下文中新建一个requesthandler，命名为_REQUEST_HANDLER_， * 构造方法为private，此方法共外界获取实例，为单例模式使用，requesthandler配置来至 * 处理controller.xml中handler节点的配置数据 * @param servletContext * @return: RequestHandler */ public static RequestHandler getRequestHandler(ServletContextservletContext) &#123; RequestHandler rh = (RequestHandler)servletContext.getAttribute("_REQUEST_HANDLER_"); if (rh == null) &#123; rh = newRequestHandler(servletContext); servletContext.setAttribute("_REQUEST_HANDLER_", rh); &#125; return rh;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 其中的RequestHandler方法如下 12345678910111213141516171819202122232425/** * @author jack * 第一步:将controller.xml的解析信息加入到缓存中 * */ private RequestHandler(ServletContext context) &#123; // init the ControllerConfig, but don't save it anywhere, just load itinto the cache this.controllerConfigURL = ConfigXMLReader.getControllerConfigURL(context); try &#123; //将controller.xml的解析信息加入到缓存中 ConfigXMLReader.getControllerConfig(this.controllerConfigURL); &#125; catch (WebAppConfigurationException e) &#123; // FIXME: controller.xml errors should throw an exception. Debug.logError(e, "Exception thrown while parsing controller.xmlfile: ", module); &#125; //加载ViewHandler实现类的实例，其为controller.xml中handler的类型为view this.viewFactory = new ViewFactory(context,this.controllerConfigURL); //加载EventHandler实现类的实例，其为controller.xml中handler的类型为非view的情况 this.eventFactory = new EventFactory(context, this.controllerConfigURL); this.forceHttpSession ="true".equalsIgnoreCase(context.getInitParameter("forceHttpSession")); this.trackServerHit =!"false".equalsIgnoreCase(context.getInitParameter("track-serverhit")); this.trackVisit =!"false".equalsIgnoreCase(context.getInitParameter("track-visit")); this.cookies = !"false".equalsIgnoreCase(context.getInitParameter("cookies")); this.charset = context.getInitParameter("charset");&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 其具体存储方式如下 12345678910111213141516171819202122232425262728293031/** * @author jack * 构建ViewHandler实现类的map，对handler节点的class属性值对应的类进行实例化和初始化， * 并设置key=default时，其value=com.hanlin.fadp.webapp.view.JspViewHandler的实例 * @param context * @param controllerConfigURL */ public ViewFactory(ServletContext context, URL controllerConfigURL) &#123; // load all the view handlers try &#123; Set&lt;Map.Entry&lt;String,String&gt;&gt; handlerEntries =ConfigXMLReader.getControllerConfig(controllerConfigURL).getViewHandlerMap().entrySet(); if (handlerEntries != null) &#123; for(Map.Entry&lt;String,String&gt; handlerEntry: handlerEntries) &#123; //将对应的handler给实例化 ViewHandlerhandler = (ViewHandler) ObjectType.getInstance(handlerEntry.getValue()); handler.setName(handlerEntry.getKey()); handler.init(context); this.handlers.put(handlerEntry.getKey(),handler); &#125; &#125; // load the "default" type if (!this.handlers.containsKey("default")) &#123; ViewHandler defaultHandler =(ViewHandler) ObjectType.getInstance("com.hanlin.fadp.webapp.view.JspViewHandler"); defaultHandler.init(context); this.handlers.put("default", defaultHandler); &#125; &#125; catch (Exception e) &#123; Debug.logError(e, module); throw new GeneralRuntimeException(e); &#125; &#125; 渲染处理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在经过多contoller文件的request 和response标签处理后，其中的response中对应type=“view”会到对应的view-map标签处理，最终处理如下： 123456789try &#123; if (Debug.verboseOn())Debug.logVerbose("Rendering view [" + nextPage + "] of type[" + viewMap.type + "]", module); ViewHandlervh = viewFactory.getViewHandler(viewMap.type); vh.render(view,nextPage, viewMap.info, contentType, charset, req, resp); &#125; catch (ViewHandlerException e) &#123; Throwable throwable = e.getNested()!= null ? e.getNested() : e; throw newRequestHandlerException(e.getNonNestedMessage(), throwable); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 标记的第一步是根据key获取上文初始化中的对应ViewHandler实例，这个key来自于view-map中的screen.具体操作如下 1234567891011public ViewHandlergetViewHandler(String type) throws ViewHandlerException &#123; if (UtilValidate.isEmpty(type)) &#123; type = "default"; &#125; // get the view handler by type fromthe contextHandlers ViewHandler handler =handlers.get(type); if (handler == null) &#123; throw newViewHandlerException("No handler found for type: " + type); &#125; return handler; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 标记的第二步是进行具体的渲染，针对于不同类型有不同实现类进行处理，在这里只是展示一下它的接口 1234567891011/** * Render the page. * * @param name The name of the view. * @param page The source of the view;could be a page, url, etc depending on the type of handler. * @param info An info string attached tothis view * @param request The HttpServletRequestobject used when requesting this page. * @param response The HttpServletResponseobject to be used to present the page. * @throws ViewHandlerException */ public void render(String name, Stringpage, String info, String contentType, String encoding, HttpServletRequestrequest, HttpServletResponse response) throws ViewHandlerException;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring IOC源码分析]]></title>
    <url>%2F2017%2F01%2F07%2Fspring%2F2018-01-07%2F</url>
    <content type="text"><![CDATA[What is IOC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ioc—Inversion of Control，即“控制反转”，不是什么技术，而是一种设计思想&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 谁控制谁，控制什么：Ioc容器来控制对象的创建,控制了外部资源获取&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为何是反转，哪些方面反转了：因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转,依赖对象的获取被反转了 传统程序设计: IOC容器模型: IOC的作用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IoC是一个重要的面向对象编程的法则，它能指导我们如何设计出松耦合、更优良的程序。即由IoC容器帮对象找相应的依赖对象并注入，而不是由对象主动去找。 bean的装载过程 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个过程中首先将设置资源文件路径为AbstractRefreshableConfigApplicationContext的句柄属性configLocations。之后在refresh方法,具体在AbstractRefreshableConfigApplicationContext中获取相关BeanFactory并且在其中调用loadBeanDefinitions正在相应BeanDefinition注入到工厂,再通过主方法调用getBean来获取Bean,具体由doGetBean来实现。下面展示一个关键方法: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; //准备工作包括设置启动时间，是否激活标识位，初始化属性源(property source)配置 prepareRefresh(); // 创建beanFactory（过程是根据xml为每个bean生成BeanDefinition并注册到生成的beanFactory） ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); /** * 准备创建好的beanFactory（给beanFactory设置ClassLoader，设置SpEL表达式解析器，设置类型转化器 * 能将xml String类型转成相应对象】，增加内置ApplicationContextAwareProcessor对象， * 忽略各种Aware对象，注册各种内置的对账对象【BeanFactory，ApplicationContext】等， * 注册AOP相关的一些东西，注册环境相关的一些bean * */ prepareBeanFactory(beanFactory); try &#123; //实例化并调用BeanFactory中扩展了BeanFactoryPostProcessor的Bean的postProcessBeanFactory方法 postProcessBeanFactory(beanFactory); //实例化并调用BeanFactory中扩展了BeanFactoryPostProcessor的Bean的postProcessBeanFactory方法 invokeBeanFactoryPostProcessors(beanFactory); //实例化和注册beanFactory中扩展了BeanPostProcessor的bean registerBeanPostProcessors(beanFactory); //实例化，注册和设置国际化工具类MessageSource initMessageSource(); //实例化，注册和设置消息广播类（如果没有自己定义使用默认的SimpleApplicationEventMulticaster实现，此广播使用同步的通知方式） initApplicationEventMulticaster(); // 设置样式工具ThemeSource onRefresh(); // 添加用户定义的消息接收器到上面设置的消息广播ApplicationEventMulticaster registerListeners(); /** * 设置自定义的类型转化器ConversionService，设置自定义AOP相关的类LoadTimeWeaverAware， * 清除临时的ClassLoader，冻结配置（没看明白干什么的），实例化所有的类（懒加载的类除外） * */ finishBeanFactoryInitialization(beanFactory); /** * 注册和设置跟bean生命周期相关的类（默认使用DefaultLifecycleProcessor）， * 调用扩展了SmartLifecycle接口的start方法， * 使用上注册的广播类消息广播类ApplicationEventMulticaster广播ContextRefreshedEvent事件 * */ finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; createBeanFactory方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该方法主要是为了获取bean工厂,方法所属类:AbstractRefreshableApplicationContext &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;获取内部工厂方法所获取的结果会设置为parentBeanFactory作为AbstractBeanFactory的句柄,开始初始化为空值。之后实例化DefaultListableBeanFactory,注意在这个过程中,在其父类会忽略一些接口的自动装配功能&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;举例来说，当A中有属性B,那么当Spring在获取A的Bean的时候如果其M性B还没有 初始化，那么Spring会自动初始化B,这也是Spring中提供的一个重要特性。但是，某些情况下，B不会被初始化，其中的一种情况就是B实现了BeanNameAware接口。Spring中是这样介绍的：A动装配时忽略给定的依赖接口，典型应用是通过其他方式解析Application上下文注册依赖，类似于BeanFactory通过BeanFactoryAware进行注入或者ApplicationContext通过 ApplicationContextAware进行注入。 loadBeanDefinitions(beanFactory);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个是整个资源加载的切入点即根据xml文件解析相应BeanDefinition &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个过程主要是将相应BeanDefinition实例放入Bean工厂,供下文进行实例化。首先将BeanFactory封装到XmlBeanDefinitionReader之后在加载过程将XmlBeanDefinitionReader封装到Reader上下文,并且在注册Bean定义的时候会创建一个文档阅读器,这样封装进去之后,在解析文档的过程中解析出来BeanDefinition就可以通过这个上下文阅读器获取相关BeanFactory然后将BeanDefinition实例存入到相关Map句柄。 getBean &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; getBean就会获取相关的Bean实例,在这里首先获取相关的BeanFacotry, 根据BeanFacoty找到相应的BeanDefinition,在这里有一个合并是因为这个Bean可能继承了其它Bean,之后根据BeanDefinition调用CreateBean进行实例化。 参考链接：http://jinnianshilongnian.iteye.com/category/206533 spring源码深度解析]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git基本指令]]></title>
    <url>%2F2017%2F01%2F02%2Fgit%2F2017-12-29%2F</url>
    <content type="text"><![CDATA[The knowledge of gitbase codegit init在当前目录生成的一个管理git仓库的文件夹，这里包含所有git操作所需要的东西 1 hooks:这个目录存放一些shell脚本，可以设置特定的git命令后触发相应的脚本；在搭建gitweb系统或其他git托管系统会经常用到hook script。 2 info:包含仓库的一些信息 3 logs:保存所有更新的引用记录 4 objects:该目录存放所有的Git对象，对象的SHA1哈希值的前两位是文件夹名称，后38位作为对象文件名。比如前面log里的HEAD文件里有个哈希值5426426e3ccc9ab4e3330640862a7b96e28828af 5 refs:具体的引用，Reference Specification，这个目录一般包括三个子文件夹，heads、remotes和tags，比如，heads中的master文件标识了项目中的master分支指向的当前commit，其他类似。 6 COMMIT_EDITMSG:保存最新的commit message，Git系统不会用到这个文件，只是给用户一个参考 7 config:这个是GIt仓库的配置文件 8 description:仓库的描述信息，主要给gitweb等git托管系统使用 9 index:这个文件就是我们前面提到的暂存区（stage），是一个二进制文件 10 HEAD:这个文件包含了一个分支（branch）的引用，通过这个文件Git可以得到下一次commit的parent，什么是引用呢，你可以理解为指针，哪儿都可以指，但是不能指向没有的东西哦。详细介绍请看这里： ###git add git add . ：他会监控工作区的状态树，使用它会把工作时的所有变化提交到暂存区，包括文件内容修改(modified)以及新文件(new)，但不包括被删除的文件。 git add -u ：他仅监控已经被add的文件（即tracked file），他会将被修改的文件提交到暂存区。add -u 不会提交新文件（untracked file）。（git add –update的缩写） git add -A ：是上面两个功能的合集（git add –all的缩写） git remotegit remote add:命令用于添加远程主机 1git remote add &lt;主机名&gt; &lt;网址&gt; src refspec master does not match any.]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo环境搭建]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[#解压dubbo-admin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将dubbo-admin解压到tomcat的webapps下面 解压命令unzip dubbo-admin.war -d dubbp-admin #修改属性文件 1.将用户密码都改成root2.修改相应地址 截图如下: #启动tomcat&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;直接将tomcat启动，启动之后可以查看相应的日志，启动命令：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在相应的bin目录下执行startup.sh日志命令:tail -f -n 500 /usr/local/dubbo-tomcat/logs/catalina.out]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo源码分析1-spring方式启动]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2F2018-01-07%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在一下的代码中主要是装载标签元素并进行解析，其中装载是根据namespaceUri找到对应的句柄，然后通过句柄来解析自己定义的元素. 123456789public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; String namespaceUri = getNamespaceURI(ele); NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error("Unable to locate Spring NamespaceHandler for XML schema namespace [" + namespaceUri + "]", ele); return null; &#125; return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));&#125; 装载标签元素Spring为了支持用户自定义类加载到Spring容器，提供了org.springframework.beans.factory.xml.NamespaceHandler接口org.springframework.beans.factory.xml.NamespaceHandlerSupport抽象类，NamespaceHandler#init方法会在对象的构造函数调用之后、属性初始化之前被DefaultNamespaceHandlerResolver调用。dubbo的DubboNamespaceHandler类正是继承了NamespaceHandlerSupport所以在spring加载过程中会执行这个类中的内容 1234567891011121314151617181920public class DubboNamespaceHandler extends NamespaceHandlerSupport &#123; static &#123; Version.checkDuplicate(DubboNamespaceHandler.class); &#125; public void init() &#123; registerBeanDefinitionParser("application", new DubboBeanDefinitionParser(ApplicationConfig.class, true)); registerBeanDefinitionParser("module", new DubboBeanDefinitionParser(ModuleConfig.class, true)); registerBeanDefinitionParser("registry", new DubboBeanDefinitionParser(RegistryConfig.class, true)); registerBeanDefinitionParser("monitor", new DubboBeanDefinitionParser(MonitorConfig.class, true)); registerBeanDefinitionParser("provider", new DubboBeanDefinitionParser(ProviderConfig.class, true)); registerBeanDefinitionParser("consumer", new DubboBeanDefinitionParser(ConsumerConfig.class, true)); registerBeanDefinitionParser("protocol", new DubboBeanDefinitionParser(ProtocolConfig.class, true)); registerBeanDefinitionParser("service", new DubboBeanDefinitionParser(ServiceBean.class, true)); registerBeanDefinitionParser("reference", new DubboBeanDefinitionParser(ReferenceBean.class, false)); registerBeanDefinitionParser("annotation", new DubboBeanDefinitionParser(AnnotationBean.class, true)); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过上面发现所有的标签元素都是通过registerBeanDefinitionParser注册，这个方法主要是将所有的标签对应的解析定义注入一个parsers这个Map 123protected final void registerBeanDefinitionParser(String elementName, BeanDefinitionParser parser) &#123; this.parsers.put(elementName, parser);&#125; #解析标签元素&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将所有dubbo的标签给装载之后，就是对具体的标签进行解析，首先展示一下解析逻辑,从这里可以看出来，它是根据具体的标签元素找到DubboBeanDefinitionParser这个实例,然后开始进行解析。 12345678910111213141516171819202122232425/** * Parse the elements at the root level in the document: * "import", "alias", "bean". * @param root the DOM root element of the document */protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; else &#123; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125;&#125; 123456789public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; String namespaceUri = getNamespaceURI(ele); NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error("Unable to locate Spring NamespaceHandler for XML schema namespace [" + namespaceUri + "]", ele); return null; &#125; return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));&#125; 1234@Overridepublic BeanDefinition parse(Element element, ParserContext parserContext) &#123; return findParserForElement(element, parserContext).parse(element, parserContext);&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意在这里将上面注册的beanClass给传入进去，所以在解析beanDefinition的时候就可以获取到这个标签的具体类实例 123public BeanDefinition parse(Element element, ParserContext parserContext) &#123; return parse(element, parserContext, beanClass, required);&#125;]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo源码分析2-远程接口暴露过程]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2FReferenceConfig%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在提供接口服务的过程，都是围绕着一行代码展开，如下:&lt;dubbo:reference interface=&quot;cfs.com.facade.SysUserFacade&quot; id=&quot;sysUserFacade&quot; /&gt; 获取相应ReferenceBean&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里我们先要获取的是相应的ReferenceFactoryBean具体过程在dubbo源码分析1-spring方式启动中,首先装载所有标签相应的 DubboNamespaceHandler.java 1registerBeanDefinitionParser("reference", new DubboBeanDefinitionParser(ReferenceBean.class, false)); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据DubboBeanDefinitionParser来解析，在loadBeanDefinitions中将所有的BeanDefinition解析出来生成形影的ReferenceBean DubboBeanDefinitionParser.java 1private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) &#123;&#125; 调用ReferenceBean的get方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于ReferenceBean继承ReferenceConfig，且自身没有覆盖get方法所以调用的是ReferenceConfig中. 123456789public synchronized T get() &#123; if (destroyed)&#123; throw new IllegalStateException("Already destroyed!"); &#125; if (ref == null) &#123; init(); &#125; return ref;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由上可以看出其核心方法是调用init 1.验证时候初始化，如果已经初始化直接返回2.保证接口名长度不为空或者03.配置消费者和提供者全局属性4.获取相应的接口全限定类名5.设置基础属性6.将属性添加到context_map这个静态map中去7.创建相应的代理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142 private void init() &#123; if (initialized) &#123; return; &#125; initialized = true; if (interfaceName == null || interfaceName.length() == 0) &#123; throw new IllegalStateException("&lt;dubbo:reference interface=\"\" /&gt; interface not allow null!"); &#125; // 获取消费者全局配置 checkDefault(); appendProperties(this); if (getGeneric() == null &amp;&amp; getConsumer() != null) &#123; setGeneric(getConsumer().getGeneric()); &#125; if (ProtocolUtils.isGeneric(getGeneric())) &#123; interfaceClass = GenericService.class; &#125; else &#123; try &#123; interfaceClass = Class.forName(interfaceName, true, Thread.currentThread() .getContextClassLoader());&#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e);&#125; checkInterfaceAndMethods(interfaceClass, methods); &#125; String resolve = System.getProperty(interfaceName); String resolveFile = null; if (resolve == null || resolve.length() == 0) &#123; resolveFile = System.getProperty("dubbo.resolve.file"); if (resolveFile == null || resolveFile.length() == 0) &#123; File userResolveFile = new File(new File(System.getProperty("user.home")), "dubbo-resolve.properties"); if (userResolveFile.exists()) &#123; resolveFile = userResolveFile.getAbsolutePath(); &#125; &#125; if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) &#123; Properties properties = new Properties(); FileInputStream fis = null; try &#123; fis = new FileInputStream(new File(resolveFile)); properties.load(fis); &#125; catch (IOException e) &#123; throw new IllegalStateException("Unload " + resolveFile + ", cause: " + e.getMessage(), e); &#125; finally &#123; try &#123; if(null != fis) fis.close(); &#125; catch (IOException e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; resolve = properties.getProperty(interfaceName); &#125; &#125; if (resolve != null &amp;&amp; resolve.length() &gt; 0) &#123; url = resolve; if (logger.isWarnEnabled()) &#123; if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) &#123; logger.warn("Using default dubbo resolve file " + resolveFile + " replace " + interfaceName + "" + resolve + " to p2p invoke remote service."); &#125; else &#123; logger.warn("Using -D" + interfaceName + "=" + resolve + " to p2p invoke remote service."); &#125; &#125; &#125; if (consumer != null) &#123; if (application == null) &#123; application = consumer.getApplication(); &#125; if (module == null) &#123; module = consumer.getModule(); &#125; if (registries == null) &#123; registries = consumer.getRegistries(); &#125; if (monitor == null) &#123; monitor = consumer.getMonitor(); &#125; &#125; if (module != null) &#123; if (registries == null) &#123; registries = module.getRegistries(); &#125; if (monitor == null) &#123; monitor = module.getMonitor(); &#125; &#125; if (application != null) &#123; if (registries == null) &#123; registries = application.getRegistries(); &#125; if (monitor == null) &#123; monitor = application.getMonitor(); &#125; &#125; checkApplication(); checkStubAndMock(interfaceClass); Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); Map&lt;Object, Object&gt; attributes = new HashMap&lt;Object, Object&gt;(); map.put(Constants.SIDE_KEY, Constants.CONSUMER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; if (! isGeneric()) &#123; String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put("revision", revision); &#125; String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if(methods.length == 0) &#123; logger.warn("NO method found in service interface " + interfaceClass.getName()); map.put("methods", Constants.ANY_VALUE); &#125; else &#123; map.put("methods", StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), ",")); &#125; &#125; map.put(Constants.INTERFACE_KEY, interfaceName); appendParameters(map, application); appendParameters(map, module); appendParameters(map, consumer, Constants.DEFAULT_KEY); appendParameters(map, this); String prifix = StringUtils.getServiceKey(map); if (methods != null &amp;&amp; methods.size() &gt; 0) &#123; for (MethodConfig method : methods) &#123; appendParameters(map, method, method.getName()); String retryKey = method.getName() + ".retry"; if (map.containsKey(retryKey)) &#123; String retryValue = map.remove(retryKey); if ("false".equals(retryValue)) &#123; map.put(method.getName() + ".retries", "0"); &#125; &#125; appendAttributes(attributes, method, prifix + "." + method.getName()); checkAndConvertImplicitConfig(method, map, attributes); &#125; &#125; //attributes通过系统context进行存储. StaticContext.getSystemContext().putAll(attributes); ref = createProxy(map); &#125; createProxy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个方式是init中的最后一步，创建相应的url 1.先判断是否是本地服务引用injvm 2.判断是否是点对点直连 3.判断是否是通过注册中心连接 4.然后是服务的引用]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo相关问题]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2F2017-12-29%2F</url>
    <content type="text"><![CDATA[The question of dubboQ1防火墙问题:关闭命令： service iptables stop永久关闭防火墙：chkconfig iptables off永久关闭需要两条语句都运行]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[druid分析]]></title>
    <url>%2F2017%2F01%2F02%2Fdruid%2F2017-12-30%2F</url>
    <content type="text"><![CDATA[The analysis of DruidInstancing DruidDataSourceDruidDataSource have two Constructor,and the one without any argument will invoke another by writing a argument, as follows At first, We find it will invoke super(fairLock),its default value is false by instancing the constructor without any argument , it wil call the superclass object and invoke the methods of configFromPropety to Set up relevant property values by getting System property values. Its superclass object constructor is shown below: In superclass object constructor,the instance create Creates an instance of ReentrantLock with the given unfairness policy. after that it will create Condition instance for use with this Lock instance. The returned Condition instance supports the same usages as do the Object monitor methods (wait, notify, and notifyAll) when used with the built-in monitor lock.]]></content>
      <categories>
        <category>druid</category>
      </categories>
      <tags>
        <tag>druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac切换jdk]]></title>
    <url>%2F2017%2F01%2F01%2Fother%2F2018-01-03%2F</url>
    <content type="text"><![CDATA[#切换jdk命令 切换版本： jenv use java 1.8设置缺少版本： jenv default java 1.8]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea上svn相关问题]]></title>
    <url>%2F2017%2F01%2F01%2Fother%2F2018-01-04%2F</url>
    <content type="text"><![CDATA[idea上不显示svn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IntelliJ IDEA打开带SVN信息的项目不显示SVN信息，项目右键SVN以及图标还有Changes都不显示解决方法在VCS菜单中有个开关，叫Enabled Version Control Integration，在打开的窗口的选项中选择Subversion即可 idea忽略某些文件更新]]></content>
      <categories>
        <category>idea</category>
      </categories>
      <tags>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea相关问题]]></title>
    <url>%2F2017%2F01%2F01%2Fother%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[Q1源发行版 1.6 需要目标发行版 1.6 setting-&gt;Compiler-&gt;Java Compiler 设置相应Module的target byte code version的合适版本就行来（搜索首选项）]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven错误记录]]></title>
    <url>%2F2017%2F01%2F01%2Fmaven%2F2018-01-05%2F</url>
    <content type="text"><![CDATA[不能部署1Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.5: deploy (default-deploy) 这是在发布到私服的过程中，可能]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven命令使用指南]]></title>
    <url>%2F2017%2F01%2F01%2Fmaven%2F2018-01-03%2F</url>
    <content type="text"><![CDATA[#基本命令 编译源代码: mvn compile编译测试代码：mvn test-compile运行测试：mvn test产生site：mvn site打包：mvn package -Dmaven.test.skip=true(跳过测试) #编译jar到本地仓库 mvn install:install-file -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4-1.7 -Dpackaging=jar -Dfile=dubbo-2.8.4.jar mvn install:install-file -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4-1.7 -Dpackaging=jar -Dfile=dubbo-2.8.4-sources.jar -Dclassifier=sources mvn install:install-file -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4-1.7 -Dpackaging=jar -Dfile=dubbo-2.8.4-javadoc.jar -Dclassifier=javadoc]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ofbiz模块加载机制即创建独立模块（脱离热部署)]]></title>
    <url>%2F2016%2F07%2F25%2Fofbiz%2Fofbiz13%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 一般我们在ofbiz下的hot-deploy下直接创建模块组件就可以进行访问，但是我觉得文件过多话，就不方便管理，所以我们可以分离出来单独建立一个文件模块，原理大家可以从启动类开始看，在这里我只说明一下操作步骤,因为好多东西我也没看懂呢。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一步：找到framework\base\config\component-load.xml这个文件，内容如下： 1234567891011121314151617&lt;component-loaderxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/component-loader.xsd&quot;&gt; &lt;load-components parent-directory=&quot;framework&quot;/&gt; &lt;load-components parent-directory=&quot;themes&quot;/&gt; &lt;load-components parent-directory=&quot;applications&quot;/&gt; &lt;load-components parent-directory=&quot;specialpurpose&quot;/&gt; &lt;load-components parent-directory=&quot;hot-deploy&quot;/&gt; &lt;load-components parent-directory=&quot;wuliys&quot;/&gt;&lt;/component-loader&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 很显然start类通过该文件属性，找到相应的子目录，如图所示： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当然这里的runtime和tools文件夹并没有加载进来，因为它们一个是运行，一个是工具存放的.而其它模块则加载进来了，文件夹是加载进来了，然后怎么进行具体操作.看第二步. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第二步:因为上面的除了最后一个都是系统存在的，所以我就拿自己创建的一个模块做例子讲述.，文件分级如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 我们先看看component-load.xml文件里面是什么(文件路径已经从同级开始往下哈哈)如下： 1234567891011&lt;?xmlversion=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;component-loaderxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/component-loader.xsd&quot;&gt; &lt;load-componentcomponent-location=&quot;mytest&quot;/&gt; &lt;load-componentcomponent-location=&quot;myparty&quot;/&gt; &lt;/component-loader&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 很显然就是通过load-component这一元素将mytest和myparty这两个文件加给加载进来。至于这两个模块就是我们能够写具体请求应用的模块。至于具体请求可以参考网上的热部署hello,world差不多]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz连接mysql并创建独立数据库]]></title>
    <url>%2F2016%2F07%2F24%2Fofbiz%2F2018-01-16%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ofbiz原生数据库是derby，而作为开发使用，其就不能满足我们需求，ofbiz支持多种数据库，我们就可以将数据移植到mysql. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第一步：找到framework\entity\config\entityengine.xml这个文件，找到之后进行下面相关操作 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1、添加或者修改datasource,因为该文件本身存在这些资料，只是被注释掉了. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171&lt;datasourcename=&quot;localmysql&quot; helper-class=&quot;org.ofbiz.entity.datasource.GenericHelperDAO&quot; field-type-name=&quot;mysql&quot; check-on-start=&quot;true&quot; add-missing-on-start=&quot;true&quot; check-pks-on-start=&quot;false&quot; use-foreign-keys=&quot;true&quot; join-style=&quot;ansi-no-parenthesis&quot; alias-view-columns=&quot;false&quot; drop-fk-use-foreign-key-keyword=&quot;true&quot; table-type=&quot;InnoDB&quot; character-set=&quot;utf8&quot; collate=&quot;utf8_general_ci&quot;&gt; &lt;read-data reader-name=&quot;tenant&quot;/&gt; &lt;read-data reader-name=&quot;seed&quot;/&gt; &lt;read-data reader-name=&quot;seed-initial&quot;/&gt; &lt;read-data reader-name=&quot;demo&quot;/&gt; &lt;read-data reader-name=&quot;ext&quot;/&gt; &lt;inline-jdbc jdbc-driver=&quot;com.mysql.jdbc.Driver&quot; jdbc-uri=&quot;jdbc:mysql://localhost:3306/ofbiz?autoReconnect=true&amp;characterEncoding=UTF-8&quot; jdbc-username=&quot;root&quot; jdbc-password=&quot;&quot; isolation-level=&quot;ReadCommitted&quot; pool-minsize=&quot;2&quot; pool-maxsize=&quot;250&quot; time-between-eviction-runs-millis=&quot;600000&quot;/&gt; &lt;/datasource&gt; &lt;datasource name=&quot;localmysqlolap&quot; helper-class=&quot;org.ofbiz.entity.datasource.GenericHelperDAO&quot; field-type-name=&quot;mysql&quot; check-on-start=&quot;true&quot; add-missing-on-start=&quot;true&quot; check-pks-on-start=&quot;false&quot; use-foreign-keys=&quot;true&quot; join-style=&quot;ansi-no-parenthesis&quot; alias-view-columns=&quot;false&quot; drop-fk-use-foreign-key-keyword=&quot;true&quot; table-type=&quot;InnoDB&quot; character-set=&quot;utf8&quot; collate=&quot;utf8_general_ci &quot;&gt; &lt;read-data reader-name=&quot;tenant&quot;/&gt; &lt;read-data reader-name=&quot;seed&quot;/&gt; &lt;read-data reader-name=&quot;seed-initial&quot;/&gt; &lt;read-data reader-name=&quot;demo&quot;/&gt; &lt;read-data reader-name=&quot;ext&quot;/&gt; &lt;inline-jdbc jdbc-driver=&quot;com.mysql.jdbc.Driver&quot; jdbc-uri=&quot;jdbc:mysql://localhost:3306/ofbizolap?autoReconnect=true&amp;characterEncoding=UTF-8&quot; jdbc-username=&quot;root&quot; jdbc-password=&quot;&quot; isolation-level=&quot;ReadCommitted&quot; pool-minsize=&quot;2&quot; pool-maxsize=&quot;250&quot; time-between-eviction-runs-millis=&quot;600000&quot;/&gt; &lt;/datasource&gt; &lt;datasource name=&quot;localmysqltenant&quot; helper-class=&quot;org.ofbiz.entity.datasource.GenericHelperDAO&quot; field-type-name=&quot;mysql&quot; check-on-start=&quot;true&quot; add-missing-on-start=&quot;true&quot; check-pks-on-start=&quot;false&quot; use-foreign-keys=&quot;true&quot; join-style=&quot;ansi-no-parenthesis&quot; alias-view-columns=&quot;false&quot; drop-fk-use-foreign-key-keyword=&quot;true&quot; table-type=&quot;InnoDB&quot; character-set=&quot;utf8&quot; collate=&quot;utf8_general_ci&quot;&gt; &lt;read-data reader-name=&quot;tenant&quot;/&gt; &lt;read-data reader-name=&quot;seed&quot;/&gt; &lt;read-data reader-name=&quot;seed-initial&quot;/&gt; &lt;read-data reader-name=&quot;demo&quot;/&gt; &lt;read-data reader-name=&quot;ext&quot;/&gt; &lt;inline-jdbc jdbc-driver=&quot;com.mysql.jdbc.Driver&quot; jdbc-uri=&quot;jdbc:mysql://localhost:3306/ofbiztenant?autoReconnect=true&amp;characterEncoding=UTF-8&quot; jdbc-username=&quot;root&quot; jdbc-password=&quot;&quot; isolation-level=&quot;ReadCommitted&quot; pool-minsize=&quot;2&quot; pool-maxsize=&quot;250&quot; time-between-eviction-runs-millis=&quot;600000&quot;/&gt; &lt;/datasource&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.还是在该文件添加一些内容，注意上面的datasource name=””与下面的datasource-name是对应的. 1234567891011121314151617181920212223242526272829303132333435&lt;delegator name=&quot;default&quot;entity-model-reader=&quot;main&quot; entity-group-reader=&quot;main&quot;entity-eca-reader=&quot;main&quot;distributed-cache-clear-enabled=&quot;false&quot;&gt; &lt;group-map group-name=&quot;org.ofbiz&quot;datasource-name=&quot;localmysql&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.olap&quot;datasource-name=&quot;localmysqlolap&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.tenant&quot; datasource-name=&quot;localmysqltenant&quot;/&gt; &lt;/delegator&gt; &lt;delegator name=&quot;default-no-eca&quot;entity-model-reader=&quot;main&quot; entity-group-reader=&quot;main&quot;entity-eca-reader=&quot;main&quot; entity-eca-enabled=&quot;false&quot;distributed-cache-clear-enabled=&quot;false&quot;&gt; &lt;group-mapgroup-name=&quot;org.ofbiz&quot; datasource-name=&quot;localmysql&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.olap&quot;datasource-name=&quot;localmysqlolap&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.tenant&quot;datasource-name=&quot;localmysqltenant&quot;/&gt; &lt;/delegator&gt; &lt;!-- be sure that your default delegator (or the one you use) usesthe same datasource for test. You must run &quot;ant load-demo&quot; beforerunning &quot;ant run-tests&quot; --&gt; &lt;delegator name=&quot;test&quot; entity-model-reader=&quot;main&quot;entity-group-reader=&quot;main&quot; entity-eca-reader=&quot;main&quot;&gt; &lt;group-mapgroup-name=&quot;org.ofbiz&quot; datasource-name=&quot;localmysql&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.olap&quot;datasource-name=&quot;localmysqlolap&quot;/&gt; &lt;group-map group-name=&quot;org.ofbiz.tenant&quot; datasource-name=&quot;localmysqltenant&quot;/&gt;&lt;/delegator&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; datasource-name:就是配置1中对应的数据库名 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; group-name： :是用来进行分组辨识的，即可以将数据资料移植到不同的数据库 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 问题：可以一直为什么要创建三个数据库，一个不行？带着这个问题我们进行下面操作. 12345678910111213141516171819202122232425&lt;span style=&quot;font-size:14px;&quot;&gt;&lt;?xml version=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt;&lt;entitygroup xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/entitygroup.xsd&quot;&gt; &lt;!-- ========================================================= --&gt; &lt;!-- org.ofbiz.entity.tenant --&gt; &lt;!-- ========================================================= --&gt; &lt;entity-group group=&quot;org.ofbiz.tenant&quot;entity=&quot;Tenant&quot;/&gt; &lt;entity-group group=&quot;org.ofbiz.tenant&quot;entity=&quot;TenantDataSource&quot;/&gt; &lt;entity-group group=&quot;org.ofbiz.tenant&quot;entity=&quot;Component&quot;/&gt; &lt;entity-group group=&quot;org.ofbiz.tenant&quot;entity=&quot;TenantComponent&quot;/&gt; &lt;entity-group group=&quot;org.ofbiz.tenant&quot;entity=&quot;TenantDomainName&quot;/&gt;&lt;/entitygroup&gt;&lt;/span&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 就是这个配置将Tenant等一些实体(数据库中的表，至于创建方式我就不在这里讲述了)分到org.ofbiz.tenant这个组名的数据库中即上面中第三个数据库，数据库名叫localmysqltenant.当然若没有这种配置，那么数据资料就会到默认数据库中，但是这里是项目自带，所以我们就需要这样一个数据库，同样的道理还有到另一个数据库中的资料，加上默认的，所以我们需要三个数据库. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 至于这些文件的加载在当前目下ofbiz-component.xml文件下，如下： 123&lt;entity-resource type=&quot;model&quot;reader-name=&quot;main&quot; loader=&quot;main&quot;location=&quot;entitydef/entitymodel.xml&quot;/&gt;&lt;entity-resourcetype=&quot;group&quot; reader-name=&quot;main&quot; loader=&quot;main&quot;location=&quot;entitydef/entitygroup.xml&quot;/&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 注意：framework/base/lib下需要导入mysql的包 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 上面就配置完成，然后我们在数据库创建对应的三个数据库名会跟上文中一一对应（注意编码一致），在启动的时候带参数load-data（如何代参运行，不知道的话，详情百度，嘻嘻） 下面我们独立创建一个数据库，来放我们自己的资料. 相应文件的位置： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第一步：在上文配置文件framework\entity\config\entityengine.xml下加入相应的配置，我的资料如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 &lt;datasourcename=&quot;test&quot; &lt;pre name=&quot;code&quot; class=&quot;html&quot;&gt; helper-class=&quot;org.ofbiz.entity.datasource.GenericHelperDAO&quot; field-type-name=&quot;mysql&quot; check-on-start=&quot;true&quot; add-missing-on-start=&quot;true&quot; check-pks-on-start=&quot;false&quot; use-foreign-keys=&quot;true&quot; join-style=&quot;ansi-no-parenthesis&quot; alias-view-columns=&quot;false&quot; drop-fk-use-foreign-key-keyword=&quot;true&quot; table-type=&quot;InnoDB&quot; character-set=&quot;utf8&quot; collate=&quot;utf8_general_ci&quot;&gt; &lt;read-data reader-name=&quot;tenant&quot;/&gt; &lt;read-data reader-name=&quot;seed&quot;/&gt; &lt;read-data reader-name=&quot;seed-initial&quot;/&gt; &lt;read-data reader-name=&quot;demo&quot;/&gt; &lt;read-data reader-name=&quot;ext&quot;/&gt; &lt;inline-jdbc jdbc-driver=&quot;com.mysql.jdbc.Driver&quot; jdbc-uri=&quot;jdbc:mysql://localhost:3306/wuliys?autoReconnect=true&amp;characterEncoding=UTF-8&quot; jdbc-username=&quot;root&quot; jdbc-password=&quot;&quot; isolation-level=&quot;ReadCommitted&quot; pool-minsize=&quot;2&quot; pool-maxsize=&quot;250&quot; time-between-eviction-runs-millis=&quot;600000&quot;/&gt; &lt;/datasource&gt; 1&lt;group-mapgroup-name=&quot;org.ofbiz.wuliys&quot; datasource-name=&quot;test&quot;/&gt; 至于这些资料所放位置与上文一一对应 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第二步:创建对应的数据库wuliys，并设置其编码为utf-8,字符集utf8_general_ci &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第三步:创建一个实体，文件路径\myparty\entitydef\entitymodel.xml，注意其可以是hot-deploy下的一个模块，也可以是你分离出来的一个模块.内容如下： 123456789101112131415161718192021&lt;entitymodelxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/entitymodel.xsd&quot;&gt; &lt;title&gt;Entity of anApache OFBiz Component&lt;/title&gt; &lt;description&gt;None&lt;/description&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;entityentity-name=&quot;Test&quot; package-name=&quot;wuliys&quot;&gt; &lt;field name=&quot;myId&quot; type=&quot;id-ne&quot;&gt;&lt;/field&gt; &lt;field name=&quot;myName&quot;type=&quot;id-ne&quot;&gt;&lt;/field&gt; &lt;prim-key field=&quot;myId&quot;/&gt; &lt;/entity&gt; &lt;/entitymodel&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第四步:将创建的实体引入到自己所想到的分组,文件路径: \myparty\entitydef\entitygroup.xml,内容如下： 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;entitygroupxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/entitygroup.xsd&quot;&gt;&lt;entity-group entity=&quot;Test&quot;group=&quot;org.ofbiz.wuliys&quot;/&gt;&lt;/entitygroup&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第五步:在该实体下创建一条数据，文件路径\myparty\data\testdata.xml，内容如下： 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;entity-engine-xml&gt; &lt;Test myName=&quot;jack&quot;&gt;&lt;/Test&gt; &lt;Test myName=&quot;zheng&quot;&gt;&lt;/Test&gt; &lt;/entity-engine-xml&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 第六步:将这写配置文件在该模块的ofbiz-component.xml下加载，内容如下 12345678910111213141516171819202122232425&lt;?xmlversion=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;ofbiz-componentname=&quot;myparty&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/ofbiz-component.xsd&quot;&gt; &lt;resource-loader name=&quot;main&quot;type=&quot;component&quot;/&gt; &lt;entity-resource type=&quot;model&quot;reader-name=&quot;main&quot; loader=&quot;main&quot;location=&quot;entitydef/entitymodel.xml&quot;/&gt; &lt;entity-resource type=&quot;group&quot;reader-name=&quot;main&quot; loader=&quot;main&quot;location=&quot;entitydef/entitygroup.xml&quot;/&gt; &lt;entity-resourcetype=&quot;data&quot; reader-name=&quot;seed&quot; loader=&quot;main&quot;location=&quot;data/testdata.xml&quot;/&gt; &lt;webappname=&quot;myparty&quot; server=&quot;default-server&quot; location=&quot;webapp/myparty&quot; mount-point=&quot;/myparty&quot;&gt;&lt;/webapp&gt;&lt;/ofbiz-component&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 而后带参load-data启动一下，就在数据库相应位置创建好了自己的数据资料.]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
</search>
