<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[zookeeper选举机制]]></title>
    <url>%2F2018%2F01%2F18%2Fzookeeper%2F2018-01-11%2F</url>
    <content type="text"><![CDATA[znode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;zookeeper集群自身维护了一套数据结构。这个存储结构是一个树形结构，其上的每一个节点，我们称之为“znode” lookForLeader方法:]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F01%2F16%2Fofbiz%2F2018-01-16%2F</url>
    <content type="text"><![CDATA[#]]></content>
  </entry>
  <entry>
    <title><![CDATA[SQLite源码解析-操作数据库]]></title>
    <url>%2F2018%2F01%2F13%2Fsqlite%2F2018-01-14%2F</url>
    <content type="text"><![CDATA[SQLite基本操作方式 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SQLite的基本操作方式同大多数关系型数据库是一样的执行sqlite3_open打开数据库,若返回结果是SQLITE_OK即0则表示打开成功,利用sqlite3_exec执行相应的sql语句,返回函数同样是执行状态,SQLITE_OK表示执行成功,最终利用sqlite3_close关闭数据库 SQLite打开数据库&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SQLite打开数据库可以通过三种方式sqlite3_open、sqlite3_open_v2、sqlite3_open16他们的具体实现都是调用openDatabase,只有具体的参数有所不同，openDatabase的具体过程中进行了初始化和创建校对规则，以及加载相应的数据驱动。 123456789101112131415SQLITE_API int sqlite3_open(const char *zFilename, sqlite3 **ppDb )&#123; return openDatabase(zFilename, ppDb, SQLITE_OPEN_READWRITE | SQLITE_OPEN_CREATE, 0);&#125;SQLITE_API int sqlite3_open_v2( const char *filename, /* Database filename (UTF-8) */ sqlite3 **ppDb, /* OUT: SQLite db handle 返回一个数据库连接对象*/ int flags, /* Flags */ const char *zVfs /* Name of VFS module to use 数据库连接应该使用的操作系统接口的sqlite3_vfs对象的名称*/)&#123; return openDatabase(filename, ppDb, (unsigned int)flags, zVfs);&#125;SQLITE_API int sqlite3_open16(const void *zFilename, sqlite3 **ppDb) SQLite执行sql语句 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sqlite3exec()函数一次可以执行多条SQL命令。执行完成后返回一个SQLITE success/failure代码，还会将错误信息写到*pzErrMsg中。首先进行安全检查以及检查sql语句是为空，在获取线程锁，调用sqlite3Error将errCode赋值为SQLITE_OK之后调用sqlte3_prepare_v2编译一条语句，通过sqlite3_step进行具体执行，如果SQL是查询，查询结果中的每一行都会调用xCallback()函数。pArg为传递给xCallback()的第一个参数。如果xCallback==NULL，即使对查询命令也没有回叫调用。 sqlte3_prepare_v2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;它调用sqlite3GetToken对SQL语句zSql进行分词，然后调用sqlite3Parser进行语法分析。而sqlite3Parser在语法规则发生规约时调用相应的opcode生成子例程，生成opcode。 SQLite关闭数据库]]></content>
      <categories>
        <category>SQLite</category>
      </categories>
      <tags>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLite网址大全]]></title>
    <url>%2F2018%2F01%2F13%2Fsqlite%2F2018-01-14-1%2F</url>
    <content type="text"><![CDATA[SQLite API手册http://www.yfvb.com/help/sqlite3/ SQLite源码分析http://huili.github.io/sqlite/sqliteintro.html]]></content>
      <categories>
        <category>SQLite</category>
      </categories>
      <tags>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLite简介]]></title>
    <url>%2F2018%2F01%2F13%2Fsqlite%2F2018-01-13%2F</url>
    <content type="text"><![CDATA[SQLite的组成 parser tokenize virtual machine SQLite的数据结构 Connections和Statements&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Connection和statement是执行SQL命令涉及的两个主要数据结构，几乎所有通过API进行的操作都要用到它们。一个连接(Connection)代表在一个独立的事务环境下的一个连接A (connection represents a single connection to a database as well as a single transaction context)。每一个statement都和一个connection关联，它通常表示一个编译过的SQL语句，在内部，它以VDBE字节码表示。Statement包括执行一个命令所需要一切，包括保存VDBE程序执行状态所需的资源，指向硬盘记录的B-树游标，以及参数等等 B-tree和pager&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个connection可以有多个database对象—一个主要的数据库以及附加的数据库，每一个数据库对象有一个B-tree对象，一个B-tree有一个pager对象(这里的对象不是面向对象的“对象”，只是为了说清楚问题)。 Statement最终都是通过connection的B-tree和pager从数据库读或者写数据，通过B-tree的游标(cursor)遍历存储在页面(page)中的记录。游标在访问页面之前要把数所从disk加载到内存，而这就是pager的任务。任何时候，如果B-tree需要页面，它都会请求pager从disk读取数据，然后把页面(page)加载到页面缓冲区(page cache)，之后，B-tree和与之关联的游标就可以访问位于page中的记录了。 如果cursor改变了page，为了防止事务回滚，pager必须采取特殊的方式保存原来的page。总的来说，pager负责读写数据库，管理内存缓存和页面（page），以及管理事务，锁和崩溃恢复(这些在事务一节会详细介绍)。 总之，关于connection和transaction，你必须知道两件事： (1)对数据库的任何操作，一个连接存在于一个事务下。 (2)一个连接决不会同时存在多个事务下。]]></content>
      <categories>
        <category>SQLite</category>
      </categories>
      <tags>
        <tag>SQLite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 源码分析一 zookeeper启动]]></title>
    <url>%2F2018%2F01%2F11%2Fzookeeper%2F2018-01-04%2F</url>
    <content type="text"><![CDATA[zookeeper启动类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; zookeeper的启动方式是调用目录下的zkServer.sh start 由此我们应该到这个文件下找相应的启动入口，最终我找到的org.apache.zookeeper.server.quorum.QuorumPeerMain #z ookeeper的启动流程 zookeeper的启动通过调用zkServer.sh start启动，这个过程实际上是以QuorumPeerMain的main方法为函数入口,具体步骤如下: 1调用初始化方法 1.1初始化过程中实例化QuorumPeerConfig解析配置文件 1.2创建文件清理器DatadirCleanupManager并启动 1.3判断启动方式，验证条件如果是有参数或者解析配置文件过程中给config的Server句柄具有相应的集群服务则通过运行配置文件启动，否则就是一个伪分布式直接通过ZooKeeperServerMain主函数启动服务 2.正常退出程序 runFromConfig利用配置文件启动过程位置: QuorumPeerMain.java runFromConfig &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 运行配置文件的过程中，主要将quorumPeer启动。具体步骤如下:1.注册JMX,作用是可以通过jconsole或者浏览器来管理各个对象2.创建ServerCnxnFactory这个server工厂,默认是NIOServerCnxnFactory,可以在配置文件中进行配置, 属性名是zookeeper.serverCnxnFactory, 在zookeeper中还提供另一种工程NettyServerCnxnFactory3.根据传入的地址通过configure方法打开socket通道，绑定ip地址,并注册相应的选择键4.实例化QuorumPeer并启动-待补录 启动QuorumPeerQuorumPeerMain.java&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.加载基础数据&nbsp;&nbsp; 2.创建相应的服务工厂&nbsp;&nbsp; 3.startLeaderElection开始选举&nbsp;&nbsp; 4.调用start启动当前线程即本实例方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.1 利用JMX注册MbeanServer jmxQuorumBean和LocalPeerBean，RemotePeerBean 这里是根据myId来进行注册，myId是在加载属性实例化QuorumPeer的时候注入。id是QuorumServer的属性，其在解析属性的过程中解析server.0=SY-001:2888:3888 这个0就是解析的id所以如果myid 和这个id相等则采用LocalPeerBean, myid和这个id定义不同则是RemotePeerBean， 可以看出其实定义的主zookeeper节点&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2在循环的过程中有四种 LOOKING, FOLLOWING, LEADING, OBSERVING针对当前状态执行相应的指令 1234LOOKING，竞选状态。这里是进行选举算法，将票投给谁setCurrentVote(makeLEStrategy().lookForLeader());FOLLOWING，随从状态，同步leader状态，参与投票。OBSERVING，观察状态,同步leader状态，不参与投票。LEADING，领导者状态。 quorumPeer.joinQuorumPeerMain.java 主要目的是为了让quorumPeer启动完毕,才继续向下执行。]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成5--搭建maven私服(nexus)]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-4%2F</url>
    <content type="text"><![CDATA[安装nexus]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成4--tomcat部署svnadmin]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-3%2F</url>
    <content type="text"><![CDATA[安装tomcat部署svnadmin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将svnadmin.war包部署到tomcat的服务器上解压,编辑配置文件 vim /usr/local/svn-tomcat/webapps/svnadmin/WEB-INF/jdbc.properties #tail -f -n 500 /usr/local/dubbo-tomcat/logs/catalina.out]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成3--安装jsvnadmin管理平台]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-2%2F</url>
    <content type="text"><![CDATA[安装mysql1yum install mysql-server mysql mysql-devel 启动1service mysqld start 查看1chkconfig --list | grep mysqld 设置开机启动1chkconfig mysqld on 设置mysql密码1mysqladmin -u root password root 进行远程访问赋权1Sql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION; Sql&gt; FLUSH PRIVILEGES;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成2--linux下安装svn]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2F2018-01-04-1%2F</url>
    <content type="text"><![CDATA[下载1yum install mod_dav_svn subversion 重启Apache服务&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里重启的是持续集成1中的httpd服务 123重启命令: service httpd restart查看命令: ls /etc/httpd/modules/ | grep svn查看版本: svn --version 创建svn库创建文件夹命令: 12mkdir /svn/``` 编辑subversion.conf文件 vim /etc/httpd/conf.d/subversion.conf DAV svnSVNListParentPath on SVNParentPath /svnAuthType BasicAuthName “Subversion repositories” AuthUserFile /svn/passwd.http AuthzSVNAccessFile /svn/authz Require valid-userRedirectMatch ^(/svn)$ $1/12# 创建/svn/passwd.http 和 /svn/authz 文件 touch /svn/passwd.httptouch /svn/authzservice httpd restart 重启apache服务```]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 架构介绍]]></title>
    <url>%2F2018%2F01%2F04%2Fzookeeper%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[zookeeper介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。其具体功能如下: 文件系统 通知机制 ZooKeeper典型的应用场景&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zookeeper 从设计模式角度来看，是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper 就将负责通知已经在 Zookeeper 上注册的那些观察者做出相应的反应，从而实现集群中类似 Master/Slave 管理模式 统一命名服务（Name Service）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式应用中，通常需要有一套完整的命名规则，既能够产生唯一的名称又便于人识别和记住,而Name Service已经是 Zookeeper 内置的功能，所以你只要调用Zookeeper的 API就能实现。如调用create接口就可以很容易创建一个目录节点。 配置管理（Configuration Management）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;配置的管理在分布式应用环境中很常见，例如同一个应用系统需要多台 PC Server 运行，但是它们运行的应用系统的某些配置项是相同的，如果要修改这些相同的配置项，那么就必须同时修改每台运行这个应用系统的 PC Server，这样非常麻烦而且容易出错。像这样的配置信息完全可以交给 Zookeeper 来管理，将配置信息保存在 Zookeeper 的某个目录节点中，然后将所有需要修改的应用机器监控配置信息的状态，一旦配置信息发生变化，每台应用机器就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中。 集群管理（Group Membership）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zookeeper 能够很容易的实现集群管理的功能，如有多台 Server 组成一个服务集群，那么必须要一个“总管”知道当前集群中每台机器的服务状态，一旦有机器不能提供服务，集群中其它集群必须知道，从而做出调整重新分配服务策略。同样当增加集群的服务能力时，就会增加一台或多台Server，同样也必须让“总管”知道。Zookeeper 不仅能够帮你维护当前的集群中机器的服务状态，而且能够帮你选出一个“总管”，让这个总管来管理集群，这就是 Zookeeper 的另一个功能 Leader Election &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;它们的实现方式都是在 Zookeeper 上创建一个 EPHEMERAL 类型的目录节点，然后每个 Server 在它们创建目录节点的父目录节点上调用getChildren(String path,boolean watch) 方法并设置 watch 为 true，由于是 EPHEMERAL 目录节点，当创建它的 Server 死去，这个目录节点也随之被删除，所以 Children 将会变化，这时 getChildren上的 Watch 将会被调用，所以其它 Server 就知道已经有某台 Server 死去了。新增 Server 也是同样的原理。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zookeeper 如何实现 Leader Election，也就是选出一个 Master Server。和前面的一样每台 Server 创建一个 EPHEMERAL 目录节点，不同的是它还是一个 SEQUENTIAL 目录节点，所以它是个 EPHEMERAL_SEQUENTIAL 目录节点。之所以它是 EPHEMERAL_SEQUENTIAL 目录节点，是因为我们可以给每台 Server 编号，我们可以选择当前是最小编号的 Server 为 Master，假如这个最小编号的 Server 死去，由于是 EPHEMERAL 节点，死去的 Server 对应的节点也被删除，所以当前的节点列表中又出现一个最小编号的节点，我们就选择这个节点为当前 Master。这样就实现了动态选择 Master，避免了传统意义上单 Master 容易出现单点故障的问题 12345678910111213141516protected InetSocketAddress findLeader() &#123; InetSocketAddress addr = null; // Find the leader by id Vote current = self.getCurrentVote(); for (QuorumServer s : self.getView().values()) &#123; if (s.id == current.getId()) &#123; addr = s.addr; break; &#125; &#125; if (addr == null) &#123; LOG.warn("Couldn't find the leader with id = " + current.getId()); &#125; return addr; &#125; 共享锁（Locks）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;共享锁在同一个进程中很容易实现，但是在跨进程或者在不同 Server 之间就不好实现了。Zookeeper 却很容易实现这个功能，实现方式也是需要获得锁的 Server 创建一个 EPHEMERAL_SEQUENTIAL 目录节点，然后调用 getChildren方法获取当前的目录节点列表中最小的目录节点是不是就是自己创建的目录节点，如果正是自己创建的，那么它就获得了这个锁，如果不是那么它就调用 exists(String path, boolean watch) 方法并监控 Zookeeper 上目录节点列表的变化，一直到自己创建的节点是列表中最小编号的目录节点，从而获得锁，释放锁很简单，只要删除前面它自己所创建的目录节点就行了。 队列管理参考链接: ZooKeeper学习第一期—Zookeeper简单介绍https://www.cnblogs.com/wuxl360/p/5817471.html Zookeeper的功能以及工作原理https://www.cnblogs.com/felixzh/p/5869212.html 分布式服务框架Zookeeper(IBM)https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql一些常用sql语句]]></title>
    <url>%2F2018%2F01%2F03%2Fmysql%2F2018-01-03%2F</url>
    <content type="text"><![CDATA[E1获取当前时间select now&amp;#40; &amp;#4 #E2获取当前时间戳 123SELECT UNIX_TIMESTAMPSELECT UNIX_TIMESTAMP*1000 毫秒级SELECT UNIX_TIMESTAMP*1000*1000 微秒级]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下安装httpd]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-04%2F</url>
    <content type="text"><![CDATA[下载 1yum install httpd httpd-devel 启动 1service httpd start 修改端口： 12vim /etc/httpd/conf/httpd.confServerName localhost:80 然后就可以根据ip进行访问]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机vm-tools安装]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-01-1%2F</url>
    <content type="text"><![CDATA[虚拟机vm-tools安装##centos下 ###点击vm fusion下安装VMware Tools ###解压 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在点击上面安装之后会出现一个CD文件，里面存在VmwareTools-10* 的包 这是一个tar.gz的压缩包，现在我们通过tar -zxvf 文件名tar.gz来进行解压（可以自行存放位置） ###安装 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;转到上面解压文件的目录vmware-tools-distrib 下，运行./vmware-install.pl 在安装的过程中不断点击enter 直到安装完成，之后调用reboot重新启动就完成了]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 环境安装]]></title>
    <url>%2F2018%2F01%2F01%2Fzookeeper%2F2017-12-30%2F</url>
    <content type="text"><![CDATA[解压tar -zvxf zookeeper-3.4.5.tar.gz -C /usr/local #配置环境变量vim /etc/profile 12export ZOOKEEPER_HOME =/usr/local/zookeeper-3.4.5export PATH=$ZOOKEEPER_HOME/bin:$PATH source /etc/profile #修改配置文件 相对路径:/ZOOKEEPER_HOME/conf/zoo.cfg 修改 1.datadir=/ZOOKEEPER_HOME/data 2.server0=ip地址。。。。。。 ZOOKEEPER_HOME下面创建data文件并创建脚本文件myid #启动 1zkServer.sh start]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux修改ip为静态ip]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-01-3%2F</url>
    <content type="text"><![CDATA[#修改网卡信息 vi /etc/sysconfig/network-scripts/ifcfg-eth0 123456BOOTPROTO=&quot;static&quot; #注意：原值为dhcpHWADDR=&quot;00:0c:29:ba:18:25&quot;IPV6INIT=&quot;yes&quot;NM_CONTROLLED=&quot;yes&quot;ONBOOT=&quot;yes&quot;TYPE=&quot;Ethernet&quot; 以下是修改为静态时需要加IPADDR=192.168.1.200GATEWAY=192.168.1.1NETMASK=255.255.255.0 重启网卡service network restart #设置DNS vim /ect/resolv.conf 12nameserver 8.8.8.8nameserver 114.114.114.114]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux卸载openJDK安装sun下jdk]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[卸载openJDK查看相应openJDK的信息rpm -qa | grep java 123tzdata-java-2014g-1.el6.noarchjava-1.6.0-openjdk-1.6.0.0-11.1.13.4.el6.x86_64java-1.7.0-openjdk-1.7.0.65-2.5.1.2.el6_5.x86_64 删除相应的文件123rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-11.1.13.4.el6.x86_64rpm -e --nodeps java-1.7.0-openjdk-1.7.0.65-2.5.1.2.el6_5.x86_64rpm -e --nodeps tzdata-java-2014g-1.el6.noarch 安装JDK找到相应的jdk资源，将其解压到指定目录 配置环境打开环境变量存储文件vi /etc/profile 12345JAVA_HOME=/usr/java/jdk1.7JRE_HOME=/usr/java/jdk1.7/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH CLASSPATH 编译环境变量存储文件source /etc/profile]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware Fusion实现虚拟机拷贝]]></title>
    <url>%2F2018%2F01%2F01%2Flinux%2F2018-01-01-2%2F</url>
    <content type="text"><![CDATA[参考链接:http://www.linuxidc.com/Linux/2017-06/144720.htm #拷贝&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;点击需要拷贝的文件,然后进行复制-粘贴,如下: #打开&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;打开相应的虚拟机&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;点击已拷贝 #修改hostname vi /etc/sysconfig/network 将”HOSTNAME=”后的内容改成机器名，比如centos.04，保存退出 vi /etc/hosts 在最后添加一行 127.0.0.1 centos.04，保存退出 如果要马上生效，可再输入hostname centos.04，否则要重启才能生效 shutdown -h now关机 注意最好执行这个命令，下面生成mac地址需要关机 #给新虚拟机的网卡，生成一个新mac地址在设置里面点击网络适配器生成一个新的mac地址 #修改网卡信息 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vi /etc/udev/rules.d/70-persistent-net.rules&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;编辑这个文件，它记录了当前机器上的所有网卡信息根据刚才新生成的mac地址，找到对应的行，把网卡名称改成 eth0，其它的全删除 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vi /etc/sysconfig/network-scripts/ifcfg-eth0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;把uuid随便改一个数字，保证它跟原来的系统不同即可，然后把HWADDR改成新生成的mac地址，保存退出]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Working principle of the Netty]]></title>
    <url>%2F2017%2F12%2F20%2Fnetty%2Fnetty3%2F</url>
    <content type="text"></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Huffman Coding Greedy Algorithm]]></title>
    <url>%2F2017%2F12%2F17%2Farithmetic%2Fhuffmancoding%2F</url>
    <content type="text"><![CDATA[What is Huffman Coding&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Huffman coding is Data Compression Algorithm,Based on lengths of assigned codes based on frequencies, Variable Length Codes are known as Prefix Codes The GoalTry to reduce the total number of bits used without losing any information The process of Huffman coding Scan text to be compressed and tally occurrence of all characters. Sort or prioritize characters based on number of occurrences in text. Build Huffman code tree based on prioritized list. Perform a traversal of tree to determine all code words. Scan text again and create new file using the Huffman codes. The Schematic diagram Code process #The code of Huffman&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Now, we specific display Huffman code. By code, we analysis of its process step by step. ##The structure of Node&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In its structure, We define the frequency to statistic the number of occurrences of the characters. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Node implements Comparable&lt;Node&gt; &#123; private String chars = ""; private int frequence = 0; private Node parent; private Node leftNode; private Node rightNode; @Override public int compareTo(Node node) &#123; return frequence - node.frequence; &#125; public String getChars() &#123; return chars; &#125; public void setChars(String chars) &#123; this.chars = chars; &#125; public int getFrequence() &#123; return frequence; &#125; public void setFrequence(int frequence) &#123; this.frequence = frequence; &#125; public Node getParent() &#123; return parent; &#125; public void setParent(Node parent) &#123; this.parent = parent; &#125; public Node getLeftNode() &#123; return leftNode; &#125; public void setLeftNode(Node leftNode) &#123; this.leftNode = leftNode; &#125; public Node getRightNode() &#123; return rightNode; &#125; public void setRightNode(Node rightNode) &#123; this.rightNode = rightNode; &#125;&#125; statistic frequency of every character&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this part, Our main purpose is to statistic frequency of every character. so we structure a HashMap to store data, when we get data from the HashMap by key, we add one to the number of it and store into The value of the current mapping as new value 12345678910111213public static Map&lt;Character, Integer&gt; statistics(char[] charArray) &#123; Map&lt;Character, Integer&gt; map = new HashMap&lt;Character, Integer&gt;(); for (char c : charArray) &#123; Character character = new Character(c); if (map.containsKey(character)) &#123; map.put(character, map.get(character) + 1); &#125; else &#123; map.put(character, 1); &#125; &#125; return map; &#125; build a tree&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PriorityQueue will Retrieves and removes the head of this queue, or returns null if this queue is empty. PriorityQueue maintain a heap what you can poll the smallest element every time actually. so we will obtain the two minimum elements and build Node, By this way, we will get a complete binary tree.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The idea of algorithm: transfer statistical information to Node and stored in a priority queue. each time it pop-up two minimum frequency nodes the queue to build a new parent node. The frequency of characters is the sum of two pop-up Node.he first pop-up as the left child node, the back one as the right child node, and the newly built parent node inside the queue. Repeat the above action N-1 times. 1234567891011121314151617181920212223242526272829303132333435private static Tree buildTree(Map&lt;Character, Integer&gt; statistics, List&lt;Node&gt; leafs) &#123; Character[] keys = statistics.keySet().toArray(new Character[0]); PriorityQueue&lt;Node&gt; priorityQueue = new PriorityQueue&lt;Node&gt;(); for (Character character : keys) &#123; Node node = new Node(); node.setChars(character.toString()); node.setFrequence(statistics.get(character)); priorityQueue.add(node); leafs.add(node); &#125; int size = priorityQueue.size(); for (int i = 1; i &lt;= size - 1; i++) &#123; Node node1 = priorityQueue.poll(); Node node2 = priorityQueue.poll(); Node sumNode = new Node(); sumNode.setChars(node1.getChars()+node2.getChars()); sumNode.setFrequence(node1.getFrequence()+node2.getFrequence()); sumNode.setLeftNode(node1); sumNode.setRightNode(node2); node1.setParent(sumNode); node2.setParent(sumNode); priorityQueue.add(sumNode); &#125; Tree tree = new Tree(); tree.setRoot(priorityQueue.poll()); return tree; &#125; encode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this part, we will invoke buildTree to let the Node produce associated. searching up from the leaf node of current character, if the character is the parent node of the left node, add 0 before the coded character , otherwise if it is right node, add 1, until the root node. 12345678910111213141516171819public static String encode(String originalStr, Map&lt;Character, Integer&gt; statistics) &#123; if (originalStr == null || originalStr.equals("")) &#123; return ""; &#125; char[] charArray = originalStr.toCharArray(); List&lt;Node&gt; leafNodes = new ArrayList&lt;Node&gt;(); buildTree(statistics, leafNodes); Map&lt;Character, String&gt; encodInfo = buildEncodingInfo(leafNodes); StringBuffer buffer = new StringBuffer(); for (char c : charArray) &#123; Character character = new Character(c); buffer.append(encodInfo.get(character)); &#125; return buffer.toString(); &#125; decode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Huffman coding algorithm can ensure any binary code is not going to be another code prefix, decoding is simple, each in turn to take out the binary, search down from the root, 1 to the right, 0 to the left, to the leaf node (hit), return a root node continue to repeat the action 12345678910111213141516171819202122232425262728293031323334public static String decode(String binaryStr, Map&lt;Character, Integer&gt; statistics) &#123; if (binaryStr == null || binaryStr.equals("")) &#123; return ""; &#125; char[] binaryCharArray = binaryStr.toCharArray(); LinkedList&lt;Character&gt; binaryList = new LinkedList&lt;Character&gt;(); int size = binaryCharArray.length; for (int i = 0; i &lt; size; i++) &#123; binaryList.addLast(new Character(binaryCharArray[i])); &#125; List&lt;Node&gt; leafNodes = new ArrayList&lt;Node&gt;(); Tree tree = buildTree(statistics, leafNodes); StringBuffer buffer = new StringBuffer(); while (binaryList.size() &gt; 0) &#123; Node node = tree.getRoot(); do &#123; Character c = binaryList.removeFirst(); if (c.charValue() == '0') &#123; node = node.getLeftNode(); &#125; else &#123; node = node.getRightNode(); &#125; &#125; while (!node.isLeaf()); buffer.append(node.getChars()); &#125; return buffer.toString();&#125; The Test Result123456789101112public static void main(String[] args) &#123; String oriStr = "Huffman codes compress data very effectively"; Map&lt;Character, Integer&gt; statistics = statistics(oriStr.toCharArray()); String encodedBinariStr = encode(oriStr, statistics); String decodedStr = decode(encodedBinariStr, statistics); System.out.println("Original sstring: " + oriStr+"\n"); System.out.println("Huffman encoed binary string: " + encodedBinariStr+"\n"); System.out.println("decoded string from binariy string: " + decodedStr); &#125; result: 12345Original sstring: Huffman codes compress data very effectivelyHuffman encoed binary string: 11111011010101001011100100011011001111000010111011011001011110000101110011011100111011001100101111101100000011000011111101010011000001110101001010111000001111111111101011101000000decoded string from binariy string: Huffman codes compress data very effectively]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EightQueen]]></title>
    <url>%2F2017%2F12%2F17%2Farithmetic%2F2017-12-18%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The N queens puzzle is the problem of placing N chess queens on an N×N chessboard so that no two queens threaten each other. Thus, a solution requires that no two queens share the same row, column, or diagonal.For example, below is one of the solution for famous 8 Queen problem. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Backtracking Algorithm for N-Queen is already discussed here. In backtracking solution we backtrack when we hit a dead end. In Branch and Bound solution, after building a partial solution, we figure out that there is no point going any deeper as we are going to hit a dead end. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Let’s begin by describing backtracking solution. “The idea is to place queens one by one in different columns, starting from the leftmost column. When we place a queen in a column, we check for clashes with already placed queens. In the current column, if we find a row for which there is no clash, we mark this row and column as part of the solution. If we do not find such a row due to clashes, then we backtrack and return false.” &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.For the 1st Queen, there are total 8 possibilities as we can place 1st Queen in any row of first column. Let’s place Queen 1 on row 3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.After placing 1st Queen, there are 7 possibilities left for the 2nd Queen. But wait, we don’t really have 7 possibilities. We cannot place Queen 2 on rows 2, 3 or 4 as those cells are under attack from Queen 1. So, Queen 2 has only 8 – 3 = 5 valid positions left.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.After picking a position for Queen 2, Queen 3 has even fewer options as most of the cells in its column are under attack from the first 2 Queens. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We need to figure out an efficient way of keeping track of which cells are under attack. In previous solution we kept an 8­-by­-8 Boolean matrix and update it each time we placed a queen, but that required linear time to update as we need to check for safe cells. Basically, we have to ensure 4 things: No two queens share a column. No two queens share a row. No two queens share a top-right to left-bottom diagonal. No two queens share a top-left to bottom-right diagonal &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Number 1 is automatic because of the way we store the solution. For number 2, 3 and 4, we can perform updates in O(1) time. The idea is to keep three Boolean arrays that tell us which rows and which diagonals are occupied. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Lets do some pre-processing first. Let’s create two N x N matrix one for / diagonal and other one for \ diagonal. Let’s call them slashCode and backslashCode respectively. The trick is to fill them in such a way that two queens sharing a same /­diagonal will have the same value in matrix slashCode, and if they share same \­diagonal, they will have the same value in backslashCode matrix. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; For an N x N matrix, fill slashCode and backslashCode matrix using below formula – cols[N] != cols[N-1] cols[N] != cols[N-1]-1 cols[N]!=cols[N-1]+1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class Queen8 &#123; public static int num = 0; //累计方案总数 public static final int MAXQUEEN = 8;//皇后个数，同时也是棋盘行列总数 public static int[] cols = new int[MAXQUEEN]; //定义cols数组，表示8列棋子摆放情况 public Queen8() &#123; //核心函数 getArrangement(0); System.out.print("/n"); System.out.println(MAXQUEEN+"皇后问题有"+num+"种摆放方法。"); &#125; public void getArrangement(int n)&#123; //遍历该列所有不合法的行，并用rows数组记录，不合法即rows[i]=true boolean[] rows = new boolean[MAXQUEEN]; for(int i=0;i&lt;n;i++)&#123; rows[cols[i]]=true; int d = n-i; if(cols[i]-d &gt;= 0)rows[cols[i]-d]=true; if(cols[i]+d &lt;= MAXQUEEN-1)rows[cols[i]+d]=true; &#125; for(int i=0;i&lt;MAXQUEEN;i++)&#123; //判断该行是否合法 if(rows[i])continue; //设置当前列合法棋子所在行数 cols[n] = i; //当前列不为最后一列时 if(n&lt;MAXQUEEN-1)&#123; getArrangement(n+1); &#125;else&#123; //累计方案个数 num++; //打印棋盘信息 printChessBoard(); &#125; &#125; &#125; public void printChessBoard()&#123; System.out.print("第"+num+"种走法 /n"); for(int i=0;i&lt;MAXQUEEN;i++)&#123; for(int j=0;j&lt;MAXQUEEN;j++)&#123; if(i==cols[j])&#123; System.out.print("0 "); &#125;else System.out.print("+ "); &#125; System.out.print("/n"); &#125; &#125; public static void main(String args[])&#123; Queen8 queen = new Queen8(); &#125; &#125; output: 12345678910111213141516171819第1种走法 0 + + + + + + + + + + + + + 0 + + + + + 0 + + + + + + + + + + 0 + 0 + + + + + + + + + 0 + + + + + + + + + 0 + + + + 0 + + + + + 第2种走法 0 + + + + + + + + + + + + + 0 + + + + 0 + + + + + + + + + 0 + + + + + + + + + 0 + 0 + + + + + + + + + + 0 + + + + + 0 + + + + + .......]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A example of Netty]]></title>
    <url>%2F2017%2F12%2F12%2Fnetty%2Fnetty1%2F</url>
    <content type="text"><![CDATA[The introduce of Netty&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; we often use an HTTP client library to retrieve information from a web server and to invoke a remote procedure call via web services. Netty is an NIO client server framework which enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server development. A example of NettyThe Main class&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this part, we introduce a simple process for a netty service. At first, we create multithreaded event loop that handles I/O operation and add them into corresponding server and add corresponding channel to transmit message. In this channel, we will create corresponding handle to receive the message, In this process, some handle can encode or decode the message. In the end, it will wait the message from client. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class DiscardServer &#123; private int port; public DiscardServer(int port) &#123; this.port = port; &#125; public void run() throws Exception &#123; //bossGroup will accept an incoming connection EventLoopGroup bossGroup = new NioEventLoopGroup(); //workerGroup handles the traffic of the accepted connection once the bossGroup accepts the connection //and registers the accepted the connection to the worker EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; //ServerBootstrap is a helper class that sets up a server. you can set up the server using channel ServerBootstrap serverBootstrap = new ServerBootstrap(); //we specify to use the NioServerSocketChannel class which is used to a new channel to accept incoming connection serverBootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) //the handler specified here will always be evaluated by a newly channel //The ChannelInitializer's purpose is to help user configure a new channel and add some handler which can implement network application .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new DiscardServerHandler()); &#125; &#125;) //you can set some socket option by this way //option() is for the NioServerSocketChannel that accepts incoming connections. //childOption() is for the Channels accepted by the parent ServerChannel, which is NioServerSocketChannel in this case. .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); // Bind and start to accept incoming connections. ChannelFuture f = serverBootstrap.bind(port).sync(); System.out.println("before closeFuture.."); // Wait until the server socket is closed. // In this example, this does not happen, but you can do that to gracefully // shut down your server. f.channel().closeFuture().sync(); System.out.println("after closeFuture.."); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; int port; if (args.length &gt; 0) &#123; port = Integer.parseInt(args[0]); &#125; else &#123; port = 8080; &#125; new DiscardServer(port).run(); &#125;&#125;``` ## The corresponding handle &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; In this handle, we override the channelRead method from the interface of ChannelInboundHandler to receive the message and do some operation. ```java/*** * * ChannelInboundHandlerAdapter is a implementation for ChannelHandlerAdapter (abstract class) and ChannelInboundHandler(interface) * ChannelInboundHandler provides various event handler methods that you can override * For now, it is just enough to extend ChannelInboundHandlerAdapter rather than to implement the handler interface by yourself. * */public class DiscardServerHandler extends ChannelInboundHandlerAdapter &#123; /** * we override the channelRead method from the interface of ChannelInboundHandler * Invoked when the current channel has read a message from the peer. * * @param ctx this variable provide various operations that enable you to trigger various I/O operations and event * @param msg receive the message from channel * */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf in = (ByteBuf) msg; char temp ; try &#123; ctx.write("you message:"); while (in.isReadable()) &#123; temp = (char)in.readByte(); System.out.print(temp); ctx.write(temp); System.out.flush(); &#125; ctx.flush(); &#125; finally &#123; ReferenceCountUtil.release(msg); &#125; &#125; /** * The exceptionCaught() event handler method s called with a Throwable * when an exception was raised by Netty due to an I/O error or by a handler implementation due to the exception thrown while processing events * */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // Close the connection when an exception is raised. System.out.println("channelRead..."); cause.printStackTrace(); ctx.close(); &#125;&#125; ##The result of this example]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PriorityQueue]]></title>
    <url>%2F2017%2F12%2F12%2FJdk%2FPriorityQueue%2F</url>
    <content type="text"><![CDATA[The introduce of PriorityQueue&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; An unbounded priority queue based on a priority heap. The elements of the priority queue are ordered according to their natural ordering, or by a Comparator provided at queue construction time, depending on which constructor is used. A priority queue does not permit null elements. A priority queue relying on natural ordering also does not permit insertion of non-comparable objects #The family of PriorityQueue #The structure of PriorityQueue #The method of PriorityQueue]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QuickSort]]></title>
    <url>%2F2017%2F12%2F11%2Farithmetic%2FquickSort%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Like Merge Sort, QuickSort is a Divide and Conquer algorithm. It picks an element as pivot and partitions the given array around the picked pivot. There are many different versions of quickSort that pick pivot in different ways. 1.Always pick first element as pivot.2.Always pick last element as pivot (implemented below)3.Pick a random element as pivot.4.Pick median as pivot. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The key process in quickSort is partition(). Target of partitions is, given an array and an element x of array as pivot, put x at its correct position in sorted array and put all smaller elements (smaller than x) before x, and put all greater elements (greater than x) after x. All this should be done in linear time. Pseudo Code for recursive QuickSort function :12345678910111213/* low --&gt; Starting index, high --&gt; Ending index */quickSort(arr[], low, high)&#123; if (low &lt; high) &#123; /* pi is partitioning index, arr[p] is now at right place */ pi = partition(arr, low, high); quickSort(arr, low, pi - 1); // Before pi quickSort(arr, pi + 1, high); // After pi &#125;&#125; Partition Algorithm&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There can be many ways to do partition, following pseudo code adopts the method given in CLRS book. The logic is simple, we start from the leftmost element and keep track of index of smaller (or equal to) elements as i. While traversing, if we find a smaller element, we swap current element with arr[i]. Otherwise we ignore current element. 12345678910111213/* low --&gt; Starting index, high --&gt; Ending index */quickSort(arr[], low, high)&#123; if (low &lt; high) &#123; /* pi is partitioning index, arr[p] is now at right place */ pi = partition(arr, low, high); quickSort(arr, low, pi - 1); // Before pi quickSort(arr, pi + 1, high); // After pi &#125;&#125; Pseudo code for partition()12345678910111213141516171819202122232425/* This function takes last element as pivot, places the pivot element at its correct position in sorted array, and places all smaller (smaller than pivot) to left of pivot and all greater elements to right of pivot */partition (arr[], low, high)&#123; // pivot (Element to be placed at right position) pivot = arr[high]; i = (low - 1) // Index of smaller element for (j = low; j &lt;= high- 1; j++) &#123; // If current element is smaller than or // equal to pivot if (arr[j] &lt;= pivot) &#123; i++; // increment index of smaller element swap arr[i] and arr[j] &#125; &#125; swap arr[i + 1] and arr[high]) return (i + 1)&#125; Illustration of partition()12345678910111213141516171819202122232425262728293031323334353637arr[] = &#123;10, 80, 30, 90, 40, 50, 70&#125;Indexes: 0 1 2 3 4 5 6 low = 0, high = 6, pivot = arr[h] = 70Initialize index of smaller element, i = -1Traverse elements from j = low to high-1j = 0 : Since arr[j] &lt;= pivot, do i++ and swap(arr[i], arr[j])i = 0 arr[] = &#123;10, 80, 30, 90, 40, 50, 70&#125; // No change as i and j // are samej = 1 : Since arr[j] &gt; pivot, do nothing// No change in i and arr[]j = 2 : Since arr[j] &lt;= pivot, do i++ and swap(arr[i], arr[j])i = 1arr[] = &#123;10, 30, 80, 90, 40, 50, 70&#125; // We swap 80 and 30 j = 3 : Since arr[j] &gt; pivot, do nothing// No change in i and arr[]j = 4 : Since arr[j] &lt;= pivot, do i++ and swap(arr[i], arr[j])i = 2arr[] = &#123;10, 30, 40, 90, 80, 50, 70&#125; // 80 and 40 Swappedj = 5 : Since arr[j] &lt;= pivot, do i++ and swap arr[i] with arr[j] i = 3 arr[] = &#123;10, 30, 40, 50, 80, 90, 70&#125; // 90 and 50 Swapped We come out of loop because j is now equal to high-1.Finally we place pivot at correct position by swappingarr[i+1] and arr[high] (or pivot) arr[] = &#123;10, 30, 40, 50, 70, 90, 80&#125; // 80 and 70 Swapped Now 70 is at its correct place. All elements smaller than70 are before it and all elements greater than 70 are afterit. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// Java program for implementation of QuickSortclass QuickSort&#123; /* This function takes last element as pivot, places the pivot element at its correct position in sorted array, and places all smaller (smaller than pivot) to left of pivot and all greater elements to right of pivot */ int partition(int arr[], int low, int high) &#123; int pivot = arr[high]; int i = (low-1); // index of smaller element for (int j=low; j&lt;high; j++) &#123; // If current element is smaller than or // equal to pivot if (arr[j] &lt;= pivot) &#123; i++; // swap arr[i] and arr[j] int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; &#125; // swap arr[i+1] and arr[high] (or pivot) int temp = arr[i+1]; arr[i+1] = arr[high]; arr[high] = temp; return i+1; &#125; /* The main function that implements QuickSort() arr[] --&gt; Array to be sorted, low --&gt; Starting index, high --&gt; Ending index */ void sort(int arr[], int low, int high) &#123; if (low &lt; high) &#123; /* pi is partitioning index, arr[pi] is now at right place */ int pi = partition(arr, low, high); // Recursively sort elements before // partition and after partition sort(arr, low, pi-1); sort(arr, pi+1, high); &#125; &#125; /* A utility function to print array of size n */ static void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i]+" "); System.out.println(); &#125; // Driver program public static void main(String args[]) &#123; int arr[] = &#123;10, 7, 8, 9, 1, 5&#125;; int n = arr.length; QuickSort ob = new QuickSort(); ob.sort(arr, 0, n-1); System.out.println("sorted array"); printArray(arr); &#125;&#125; output: 12Sorted array:1 5 7 8 9 10]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java NIO Selector]]></title>
    <url>%2F2017%2F12%2F11%2FNIO%2Fnio4%2F</url>
    <content type="text"><![CDATA[#The Selector, SelectableChannel, and SelectionKey Classes Selector&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The Selector class manages information about a set of registered channel and their readies state. Channels are registered with selectors, and a selector can be asked to update readies state of channels. When doing so, the invoking thread can optionally indicate that it would prefer to be suspended until one of the registered channel is ready. ##]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基本指令]]></title>
    <url>%2F2017%2F12%2F11%2Flinux%2F2018-01-01%2F</url>
    <content type="text"><![CDATA[解压1tar -zxvf 文件名 移动文件移动命令mv 命令格式：mv [-fiv] source destination 参数说明： -f:force，强制直接移动而不询问 -i:若目标文件(destination)已经存在，就会询问是否覆盖 -u:若目标文件已经存在，且源文件比较新，才会更新 如将/test1目录下的file1复制到/test3 目录，并将文件名改为file2,可输入以下命令： mv /test1/file1 /test3/file2 重命名关机poweroff 立刻关机shutdown -h now 立刻关机shutdown -h 10 10分钟后自动关机 关闭防火墙关闭命令： service iptables stop永久关闭防火墙：chkconfig iptables off永久关闭需要两条语句都运行 关闭端口1lsof -i:]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java NIO channel]]></title>
    <url>%2F2017%2F12%2F11%2FNIO%2Fnio3%2F</url>
    <content type="text"><![CDATA[java NIO channel&emsp;&emsp; When it comes to NIO, the first New concept we approach is channel, we operate data by using it instead of stream in traditional IO. The introduce of channelWhat is channel?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Channels is the second invocation of java NIO, they used to transmit data to the corresponding entity in both sides of the channel. Channels are gateways through which the native I/O services of the operating system can be accessed with a minimum of overhead, and buffers are the internal endpoints used by channels to send and receive data. The feature of channel 1.channel both can read data also can write data2.channel can read or write data from asynchronous3.channel must have a buffer to transmit data The family of channeljava.nio.channels.Channel 接口： |--FileChannel |--SocketChannel |--ServerSocketChannel |--DatagramChannel The use of channel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In the above, we know about what is channel roughly. Now, we tell channel by using it. Copy file by channel1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public void copyFile()&#123; FileInputStream fis = null; FileOutputStream fos = null; //Getting channel FileChannel inChannel = null; FileChannel outChannel = null; try &#123; fis = new FileInputStream("1.txt"); fos = new FileOutputStream("2.txt"); inChannel = fis.getChannel(); outChannel = fos.getChannel(); //allocate specified size buffer ByteBuffer buf = ByteBuffer.allocate(1024); //Getting data from channel, and storage it in buffer while(inChannel.read(buf) != -1)&#123; buf.flip(); //Flips this buffer //write the data in the buffer into the channel outChannel.write(buf); //clear buffer, The position is set to zero, the limit is set to the capacity buf.clear(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; //handle corresponding exception &#125; &#125;``` &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; above the code, we get corresponding stream from File stream, then we write data to FileOutputStream. Now, we detail some of these method. `FileChannelImpl.open` will create corresponding instance.# A set of method of channel## getChannel()&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; `getChannel`method will Returns the unique FileChannel object associated with this file input stream.```java /** * * &lt;p&gt; The initial &#123;@link java.nio.channels.FileChannel#position() * position&#125; of the returned channel will be equal to the * number of bytes read from the file so far. Reading bytes from this * stream will increment the channel's position. Changing the channel's * position, either explicitly or by reading, will change this stream's * file position. * * @return the file channel associated with this file input stream * * @since 1.4 * @spec JSR-51 */ public FileChannel getChannel() &#123; synchronized (this) &#123; if (channel == null) &#123; channel = FileChannelImpl.open(fd, path, true, false, this); &#125; return channel; &#125; &#125; read(ByteBuffer dst)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; read is abstract method, it will read a sequence of bytes from this channel into the given buffer. Bytes are read starting at this channel’s current file position, and then file position is updated with the number of bytes actually read. 1234567891011121314151617181920212223public int read(ByteBuffer dst) throws IOException &#123; ensureOpen(); if (!readable) throw new NonReadableChannelException(); synchronized (positionLock) &#123; int n = 0; int ti = -1; try &#123; begin(); ti = threads.add(); if (!isOpen()) return 0; do &#123; n = IOUtil.read(fd, dst, -1, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); end(n &gt; 0); assert IOStatus.check(n); &#125; &#125; &#125; write(ByteBuffer src)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Writes a sequence of bytes to this channel from given buffer. 1234567891011121314151617181920212223public int write(ByteBuffer src) throws IOException &#123; ensureOpen(); if (!writable) throw new NonWritableChannelException(); synchronized (positionLock) &#123; int n = 0; int ti = -1; try &#123; begin(); ti = threads.add(); if (!isOpen()) return 0; do &#123; n = IOUtil.write(fd, src, -1, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); end(n &gt; 0); assert IOStatus.check(n); &#125; &#125; &#125;]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java NIO buffer]]></title>
    <url>%2F2017%2F12%2F10%2FNIO%2Fnio2%2F</url>
    <content type="text"><![CDATA[java NIO buffer&emsp;&emsp; A buffer Object is a container of a fixed amount of data, it acts as a block or staging area, where data can be stored and later retrieved.Buffers work hand in glove with channels, Channels are portals through which i/o transfers take place, and buffers are the sources or targets of those data transfers. The family of buffer in java nio &emsp;&emsp; From the system diagram, we can find each of the basic data types has their own corresponding buffer class. as follows: ByteBuffershortBufferCharBufferIntBufferLongBufferFloatBufferDoubleBufferMappedByteBuffer Attributes&emsp;&emsp; Buffer is mainly has four attributes Capacity: The maximum number of data elements the buffer can hold. The capacity is set when the buffer is created and can never be changed. Limit: The first element of the buffer that should not be read or written. In other words, the count of live elements in the buffer. Position:The index of next element to be read or written. The position is updated automatically by get() and put() methods. Mark: A remembered position,Mark() and reset() are used together. when we use Mark(), we will record the position so that calling reset() sets position = mark The following relationship between these four attributes always holds: 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity Buffer interface The Usage of Buffer&emsp;&emsp; Now, i show how to use it and explain the source code through it’s the implementation class — ByteBuffer The constructor of it12345678910ByteBuffer(int mark, int pos, int lim, int cap, byte[] hb, int offset) &#123; super(mark, pos, lim, cap); this.hb = hb; this.offset = offset; &#125; // Creates a new buffer with the given mark, position, limit, and capacity ByteBuffer(int mark, int pos, int lim, int cap) &#123; this(mark, pos, lim, cap, null, 0); &#125; &emsp;&emsp;&emsp; we can find the core of it invoke the superclass, at first we see the parent class constructor. it easy to find the superclass is Buffer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657Buffer(int mark, int pos, int lim, int cap) &#123; if (cap &lt; 0) throw new IllegalArgumentException("Negative capacity: " + cap); this.capacity = cap; limit(lim); position(pos); if (mark &gt;= 0) &#123; if (mark &gt; pos) throw new IllegalArgumentException("mark &gt; position: (" + mark + " &gt; " + pos + ")"); this.mark = mark; &#125; &#125; /** * Sets this buffer's limit. If the position is larger than the new limit * then it is set to the new limit. If the mark is defined and larger than * the new limit then it is discarded. * * @param newLimit * The new limit value; must be non-negative * and no larger than this buffer's capacity * * @return This buffer * * @throws IllegalArgumentException * If the preconditions on &lt;tt&gt;newLimit&lt;/tt&gt; do not hold */ public final Buffer limit(int newLimit) &#123; if ((newLimit &gt; capacity) || (newLimit &lt; 0)) throw new IllegalArgumentException(); limit = newLimit; if (position &gt; limit) position = limit; if (mark &gt; limit) mark = -1; return this; &#125; /** * Sets this buffer's position. If the mark is defined and larger than the * new position then it is discarded. * * @param newPosition * The new position value; must be non-negative * and no larger than the current limit * * @return This buffer * * @throws IllegalArgumentException * If the preconditions on &lt;tt&gt;newPosition&lt;/tt&gt; do not hold */ public final Buffer position(int newPosition) &#123; if ((newPosition &gt; limit) || (newPosition &lt; 0)) throw new IllegalArgumentException(); position = newPosition; if (mark &gt; position) mark = -1; return this; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this constructor, Main purpose is to give the corresponding handle to set the appropriate attribute values through the way of refs, these attributes was introduced in the above. Each method of them has corresponding judgment whether the property value whether meet the conditions. if not, it will throws corresponding exception. allocate a specify memory space12345//allocate a specify memory spaceByteBuffer buf = ByteBuffer.allocate(1024);System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); 1234result:010241024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In the beginning of allocate a memory space to buffer, we can find the property value of position is 0, property values of limit and capacity is the value of the incoming. Buffer after five put( )s123456String str = "Hello"; //put data in the bufferbuf.put(str.getBytes());System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); 1234result:510241024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Follow the above code, I convert a string into a byte array and store it the buf instance. From the result, we can find the position has some change, limit and capacity don’t have any change. The model is shown. Switch to Read data mode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Continuing to follow the above code, we begin to read the data which we put in the above. At first we switch to read data mode by calling the flip() method. 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; 1234buf.flip();System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); result: 123051024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Flips this buffer. The limit is set to the current position and then the position is set to zero. If the mark is defined then it is discarded.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; After invoking the flip(), we begin to read the data in the buffer. Read data from buffer123456byte[] dst = new byte[buf.limit()];buf.get(dst);System.out.println(new String(dst, 0, dst.length));System.out.println(buf.position());System.out.println(buf.limit());System.out.println(buf.capacity()); result: 1234hello551024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; From the code, we can find we build a byte array to read data from buffer. after reading it, The property value of position changed. The principle of it is after we invoke the get() method It can read the Reads the byte at this buffer’s current position, and then increments the position. The process of get() method is in its implementation class. Rewinds this buffer12345public final Buffer rewind() &#123; position = 0; mark = -1; return this; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The position is set to zero and the mark is discarded. Invoking this method before a sequence of channel-write or get operations, assuming that the limit has already been set appropriately. Clears this buffer&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The position is set to zero, the limit is set to the capacity, and the mark is discarded.This method does not actually erase the data in the buffer, but it is named as if it did because it will most often be used in situations in which that might as well be the case. 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; hasRemaining()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Tells whether there are any elements between the current position and the limit. if true, there is at least one element remaining in this buffer 123public final boolean hasRemaining() &#123; return position &lt; limit; &#125; The Compare BuffersDirect byte buffers&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Direct byte buffers are usually the best choice for I/O operations. By design, they support the most efficient I/O mechanism available to the JVM.Direct buffers are optimal for I/O, but they may be more expensive to create than non direct byte buffers. The memory used by direct buffers is allocated by calling through to native, operating system-specific code, by passing the standard JVM heap. Setting up and tearing down direct buffers could be significantly more expensive than heap-resident buffers, depending on the host operating system and JVM implementation. The memory-storage areas of direct buffers are not subject to garbage collection because they are outside the standard JVM heap. —reference O’reilly java NIO The Method of creationstatic ByteBuffer allocateDirect(int capacity) 12345678910111213141516171819/** * Allocates a new direct byte buffer. * * &lt;p&gt; The new buffer's position will be zero, its limit will be its * capacity, its mark will be undefined, and each of its elements will be * initialized to zero. Whether or not it has a * &#123;@link #hasArray backing array&#125; is unspecified. * * @param capacity * The new buffer's capacity, in bytes * * @return The new byte buffer * * @throws IllegalArgumentException * If the &lt;tt&gt;capacity&lt;/tt&gt; is a negative integer */public static ByteBuffer allocateDirect(int capacity) &#123; return new DirectByteBuffer(capacity);&#125; 12345678910111213141516171819202122232425262728DirectByteBuffer(int cap) &#123; // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; base = unsafe.allocateMemory(size); &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null;&#125; Non direct byte buffers&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Non direct byte buffers can be passed to channels, but doing so may incur a performance penalty. It’s usually not possible for a non direct buffer to be the target of a native I/O operation. If you pass a non direct ByteBuffer object to a channel for write, the channel may implicitly do the following on each call: Create a temporary direct ByteBuffer object. Copy the content of the non direct buffer to the temporary buffer. Perform the low-level I/O operation using the temporary buffer. The temporary buffer object goes out of scope and is eventually garbage collected. —reference O‘reilly java NIO The Method of creation123456789101112131415161718192021/** * Allocates a new byte buffer. * * &lt;p&gt; The new buffer's position will be zero, its limit will be its * capacity, its mark will be undefined, and each of its elements will be * initialized to zero. It will have a &#123;@link #array backing array&#125;, * and its &#123;@link #arrayOffset array offset&#125; will be zero. * * @param capacity * The new buffer's capacity, in bytes * * @return The new byte buffer * * @throws IllegalArgumentException * If the &lt;tt&gt;capacity&lt;/tt&gt; is a negative integer */ public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity); &#125; 12345678910111213141516171819HeapByteBuffer(int cap, int lim) &#123; super(-1, 0, lim, cap, new byte[cap], 0); &#125;HeapByteBuffer(byte[] buf, int off, int len) &#123; super(-1, off, off + len, buf.length, buf, 0);&#125;protected HeapByteBuffer(byte[] buf, int mark, int pos, int lim, int cap, int off) &#123; super(mark, pos, lim, cap, buf, off); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We can see it invoke superclass’s constructor, so its data will store in the Heap.]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The introduce of NIO]]></title>
    <url>%2F2017%2F12%2F09%2FNIO%2Fnio1%2F</url>
    <content type="text"><![CDATA[The introduce of NIOWhat is NIO？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; java.nio (non-blocking I/O) is a collection of Java programming language APIs that offer features for intensive I/O operations. It was introduced with the J2SE 1.4 release of Java by Sun Microsystems to complement an existing standard I/O —reference wiki The compare between NIO and IO IO NIO Stream Oriented Buffer Oriented Blocking IO Non Blocking IO Selectors The function of NIO&emsp;&emsp; When it comes to NIO, we should what is IO. In the traditional IO, we read or store data in the form of stream, so it is easy to cause obstruction that we difficult calls in multiple threads.But in NIO,The problem has a good way to solve it, the way is that we convey information by channel. in the channel, we can construct the corresponding buffer to transfer data. so we can say it is base on Buffer Oriented.]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(九) 多租户]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz9%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819/** * @author 郑小康 * 设置完整的delegator 其可能形式有 default 或者defalut#tenantDelegatorName * 针对于第一种情况 delegatorBaseName =="default" delegatorTenantId=null * 针对第二种情况 delegatorBaseName =="default" delegatorTenantId="tenantDelegatorName" * 为什么存在第二种情况，是因为在多租户中要实现数据独立，所以获取基础delagtor 和租户delegator,注意这时并未创建实例更没有建立数据库连接 * 其再获取了默认的delegator中的信息之后，如果存在delegatorBaseName 则将 uri username password进行覆盖 * */ protected void setDelegatorNames(String delegatorFullName) &#123; this.delegatorFullName = delegatorFullName; int hashSymbolIndex = delegatorFullName.indexOf('#'); if (hashSymbolIndex == -1) &#123; this.delegatorBaseName = delegatorFullName; &#125; else &#123; this.delegatorBaseName = delegatorFullName.substring(0, hashSymbolIndex); this.delegatorTenantId = delegatorFullName.substring(hashSymbolIndex + 1); &#125; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//多租户 根据默认baseDelegator获取域名对应TenantId 拼接DelegatorName获取其实例if (useMultitenant) &#123; // get tenant delegator by domain name，获取服务名 String serverName = httpRequest.getServerName(); try &#123; // if tenant was specified, replace delegator with the new per-tenant delegator and set tenantId to session attribute Delegator delegator = getDelegator(config.getServletContext()); //Use base delegator for fetching data from entity of entityGroup com.hanlin.fadp.tenant Delegator baseDelegator = DelegatorFactory.getDelegator(delegator.getDelegatorBaseName()); GenericValue tenantDomainName = EntityQuery.use(baseDelegator).from("TenantDomainName").where("domainName", serverName).queryOne(); String tenantId = null; if(UtilValidate.isNotEmpty(tenantDomainName)) &#123; tenantId = tenantDomainName.getString("tenantId"); &#125; if(UtilValidate.isEmpty(tenantId)) &#123; tenantId = (String) httpRequest.getAttribute("userTenantId"); &#125; if(UtilValidate.isEmpty(tenantId)) &#123; tenantId = (String) httpRequest.getParameter("userTenantId"); &#125; if (UtilValidate.isNotEmpty(tenantId)) &#123; // if the request path is a root mount then redirect to the initial path if (UtilValidate.isNotEmpty(requestPath) &amp;&amp; requestPath.equals(contextUri)) &#123; GenericValue tenant = EntityQuery.use(baseDelegator).from("Tenant").where("tenantId", tenantId).queryOne(); String initialPath = tenant.getString("initialPath"); if (UtilValidate.isNotEmpty(initialPath) &amp;&amp; !"/".equals(initialPath)) &#123; ((HttpServletResponse)response).sendRedirect(initialPath); return; &#125; &#125; // make that tenant active, setup a new delegator and a new dispatcher String tenantDelegatorName = delegator.getDelegatorBaseName() + "#" + tenantId; httpRequest.getSession().setAttribute("delegatorName", tenantDelegatorName); // after this line the delegator is replaced with the new per-tenant delegator delegator = DelegatorFactory.getDelegator(tenantDelegatorName); config.getServletContext().setAttribute("delegator", delegator); // clear web context objects config.getServletContext().setAttribute("security", null); config.getServletContext().setAttribute("dispatcher", null); /** * 初始化security，根据delegatorName先从缓存中获取，如果缓存中不存在对应的security，则实例化一个 * 由于该过滤器是每次请求都会经过，所以根据域名不同，获取的security就有所不同，这样就可以实现共用一套用户表在不同租户中权限不同 */ Security security = getSecurity(); // initialize the services dispatcher LocalDispatcher dispatcher = getDispatcher(config.getServletContext()); // set web context objects request.setAttribute("dispatcher", dispatcher); request.setAttribute("security", security); request.setAttribute("userTenantId", tenantId); &#125; // NOTE DEJ20101130: do NOT always put the delegator name in the user's session because the user may // have logged in and specified a tenant, and even if no Tenant record with a matching domainName field // is found this will change the user's delegator back to the base one instead of the one for the // tenant specified on login // httpRequest.getSession().setAttribute("delegatorName", delegator.getDelegatorName()); &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, "Unable to get Tenant没有获取这个租户", module); &#125; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(八) 创建表]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz8%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158/** * @author 郑小康 * * 1.检验实体是否为空 * * 2.检验视图实体是否为空 * * 3.获取数据库连接 * * 4.根据对应的ModelEntity来创建表 其中modelEntities是关系表的集合 * * */public String createTable(ModelEntity entity, Map&lt;String, ModelEntity&gt; modelEntities, boolean addFks) &#123; if (entity == null) &#123; return "ModelEntity was null and is required to create a table ModelEntity是空，不能创建表"; &#125; if (entity instanceof ModelViewEntity) &#123; return "ERROR: Cannot create table for a view entity 不能为视图实体创建表"; &#125; Connection connection = null; Statement stmt = null; try &#123; connection = getConnection(); &#125; catch (SQLException e) &#123; String errMsg = "在建表过程中Unable to establish a connection with the database for helperName [" + this.helperInfo.getHelperFullName() + "]... Error was: " + e.toString(); Debug.logError(e, errMsg, module); return errMsg; &#125; catch (GenericEntityException e) &#123; String errMsg = "在建表过程中 Unable to establish a connection with the database for helperName [" + this.helperInfo.getHelperFullName() + "]... Error was: " + e.toString(); Debug.logError(e, errMsg, module); return errMsg; &#125; StringBuilder sqlBuf = new StringBuilder("CREATE TABLE "); sqlBuf.append(entity.getTableName(this.datasourceInfo)); sqlBuf.append(" ("); Iterator&lt;ModelField&gt; fieldIter = entity.getFieldsIterator(); while (fieldIter.hasNext()) &#123; ModelField field = fieldIter.next(); ModelFieldType type = modelFieldTypeReader.getModelFieldType(field.getType()); if (type == null) &#123; return "Field type [" + type + "] not found for field [" + field.getName() + "] of entity [" + entity.getEntityName() + "], not creating table."; &#125; sqlBuf.append(field.getColName()); sqlBuf.append(" "); sqlBuf.append(type.getSqlType()); if ("String".equals(type.getJavaType()) || "java.lang.String".equals(type.getJavaType())) &#123; // if there is a characterSet, add the CHARACTER SET arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCharacterSet())) &#123; sqlBuf.append(" CHARACTER SET "); sqlBuf.append(this.datasourceInfo.getCharacterSet()); &#125; // if there is a collate, add the COLLATE arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCollate())) &#123; sqlBuf.append(" COLLATE "); sqlBuf.append(this.datasourceInfo.getCollate()); &#125; &#125; if (field.getIsNotNull() || field.getIsPk()) &#123; if (this.datasourceInfo.getAlwaysUseConstraintKeyword()) &#123; sqlBuf.append(" CONSTRAINT NOT NULL, "); &#125; else &#123; sqlBuf.append(" NOT NULL, "); &#125; &#125; else &#123; sqlBuf.append(", "); &#125; &#125; String pkName = makePkConstraintName(entity, this.datasourceInfo.getConstraintNameClipLength()); if (this.datasourceInfo.getUsePkConstraintNames()) &#123; sqlBuf.append("CONSTRAINT "); sqlBuf.append(pkName); &#125; sqlBuf.append(" PRIMARY KEY ("); entity.colNameString(entity.getPkFieldsUnmodifiable(), sqlBuf, ""); sqlBuf.append(")"); if (addFks) &#123; // NOTE: This is kind of a bad idea anyway since ordering table creations is crazy, if not impossible // go through the relationships to see if any foreign keys need to be added Iterator&lt;ModelRelation&gt; relationsIter = entity.getRelationsIterator(); while (relationsIter.hasNext()) &#123; ModelRelation modelRelation = relationsIter.next(); if ("one".equals(modelRelation.getType())) &#123; ModelEntity relModelEntity = modelEntities.get(modelRelation.getRelEntityName()); if (relModelEntity == null) &#123; Debug.logError("Error adding foreign key: ModelEntity was null for related entity name " + modelRelation.getRelEntityName(), module); continue; &#125; if (relModelEntity instanceof ModelViewEntity) &#123; Debug.logError("Error adding foreign key: related entity is a view entity for related entity name " + modelRelation.getRelEntityName(), module); continue; &#125; String fkConstraintClause = makeFkConstraintClause(entity, modelRelation, relModelEntity, this.datasourceInfo.getConstraintNameClipLength(), this.datasourceInfo.getFkStyle(), this.datasourceInfo.getUseFkInitiallyDeferred()); if (UtilValidate.isNotEmpty(fkConstraintClause)) &#123; sqlBuf.append(", "); sqlBuf.append(fkConstraintClause); &#125; else &#123; continue; &#125; &#125; &#125; &#125; sqlBuf.append(")"); // if there is a tableType, add the TYPE arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getTableType())) &#123; // jaz:20101229 - This appears to be only used by mysql and now mysql has // deprecated (and in 5.5.x removed) the use of the TYPE keyword. This is // changed to ENGINE which is supported starting at 4.1 sqlBuf.append(" ENGINE "); //sqlBuf.append(" TYPE "); sqlBuf.append(this.datasourceInfo.getTableType()); &#125; // if there is a characterSet, add the CHARACTER SET arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCharacterSet())) &#123; sqlBuf.append(" CHARACTER SET "); sqlBuf.append(this.datasourceInfo.getCharacterSet()); &#125; // if there is a collate, add the COLLATE arg here if (UtilValidate.isNotEmpty(this.datasourceInfo.getCollate())) &#123; sqlBuf.append(" COLLATE "); sqlBuf.append(this.datasourceInfo.getCollate()); &#125; if (Debug.verboseOn()) Debug.logVerbose("[createTable] sql=" + sqlBuf.toString(), module); try &#123; stmt = connection.createStatement(); stmt.executeUpdate(sqlBuf.toString()); &#125; catch (SQLException e) &#123; return "SQL Exception while executing the following:\n" + sqlBuf.toString() + "\nError was: " + e.toString(); &#125; finally &#123; try &#123; if (stmt != null) stmt.close(); &#125; catch (SQLException e) &#123; Debug.logError(e, module); &#125; try &#123; if (connection != null) &#123; connection.close(); &#125; &#125; catch (SQLException e) &#123; Debug.logError(e, module); &#125; &#125; return null;&#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(七) 检查数据源]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz7%2F</url>
    <content type="text"><![CDATA[123456789101112/** * Check the datasource to make sure the entity definitions are correct, optionally adding missing entities or fields on the server *@param modelEntities Map of entityName names and ModelEntity values *@param messages List to put any result messages in *@param addMissing Flag indicating whether or not to add missing entities and fields on the server * * 检查数据源确保实体正确定义,选择性添加没有的实体和字段 */ public void checkDataSource(Map&lt;String, ModelEntity&gt; modelEntities, List&lt;String&gt; messages, boolean addMissing) throws GenericEntityException &#123; genericDAO.checkDb(modelEntities, messages, addMissing); &#125;&#125; 值得一提helper的实例化的是GenericHelperDAO 所以checkDb调用的是GenericHeleper中的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * @author 郑小康 * * 1.从缓存中获取helperFullName的GenericHelper * * 2.如果为空根据helperBaseName(localmysql)获取Datasource标签实例 * * 3.根据Datasource标签的helperClass,创造构造器,构建对应实例 * * 4.以HelperFullName为k 实例为v存入到缓存 * * 5.返回当前实例化的GenericHelper * * */ public static GenericHelper getHelper(GenericHelperInfo helperInfo) &#123; GenericHelper helper = helperCache.get(helperInfo.getHelperFullName()); if (helper == null) &#123; // don't want to block here synchronized (GenericHelperFactory.class) &#123; // must check if null again as one of the blocked threads can still enter helper = helperCache.get(helperInfo.getHelperFullName()); if (helper == null) &#123; try &#123; Datasource datasourceInfo = EntityConfig.getDatasource(helperInfo.getHelperBaseName()); if (datasourceInfo == null) &#123; throw new IllegalStateException("Could not find datasource definition with name " + helperInfo.getHelperBaseName()); &#125; String helperClassName = datasourceInfo.getHelperClass(); Class&lt;?&gt; helperClass = null; if (UtilValidate.isNotEmpty(helperClassName)) &#123; try &#123; ClassLoader loader = Thread.currentThread().getContextClassLoader(); helperClass = loader.loadClass(helperClassName); &#125; catch (ClassNotFoundException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; &#125; Class&lt;?&gt;[] paramTypes = new Class&lt;?&gt;[] &#123;GenericHelperInfo.class&#125;; Object[] params = new Object[] &#123;helperInfo&#125;; java.lang.reflect.Constructor&lt;?&gt; helperConstructor = null; if (helperClass != null) &#123; try &#123; helperConstructor = helperClass.getConstructor(paramTypes); &#125; catch (NoSuchMethodException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; &#125; try &#123; helper = (GenericHelper) helperConstructor.newInstance(params); &#125; catch (IllegalAccessException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; catch (InstantiationException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; catch (java.lang.reflect.InvocationTargetException e) &#123; Debug.logWarning(e, module); throw new IllegalStateException("Error loading GenericHelper class \"" + helperClassName + "\": " + e.getMessage()); &#125; if (helper != null) helperCache.put(helperInfo.getHelperFullName(), helper); &#125; catch (SecurityException e) &#123; Debug.logError(e, module); throw new IllegalStateException("Error loading GenericHelper class: " + e.toString()); &#125; &#125; &#125; &#125; return helper; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(六) GenericHelper的初始化创建]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz6%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * @author 郑小康 * * 1.根据groupName获取GenericHelperInfo * * 2.获取GenericHelperInfo的helperBaseName * * 3.如果HelperFullName不为空,则进行下面的操作 HelperFullName可能是default,也可能是default#tenantId * * 4.根据helperBaseName(localmysql),获取对应的ModelFieldTypeReader 字段类型阅读器,这个是为了在建表的时候的创建对应字段类型 * * 5.根据helperInfo通过GenericHelperFactory工厂获取GenericHelper,实际是GenericHelperDAO * * 6.根据helperBaseName获取对应的Datasource标签实例 * * 7.根据GenericHelper所构建的实例,调用其checkDataSource检查数据源,向其中添加未添加的表和字段 * * */ private void initializeOneGenericHelper(String groupName) &#123; //根据groupName获取GenericHelperInfo GenericHelperInfo helperInfo = this.getGroupHelperInfo(groupName); if (helperInfo == null) &#123; if (Debug.infoOn()) &#123; Debug.logInfo("Delegator \"" + delegatorFullName + "\" NOT initializing helper for entity group \"" + groupName + "\" because the group is not associated to this delegator.", module); &#125; return; &#125; String helperBaseName = helperInfo.getHelperBaseName(); if (Debug.infoOn()) &#123; Debug.logInfo("Delegator \"" + delegatorFullName + "\" initializing helper \"" + helperBaseName + "\" for entity group \"" + groupName + "\".", module); &#125; if (UtilValidate.isNotEmpty(helperInfo.getHelperFullName())) &#123; // pre-load field type defs, the return value is ignored ModelFieldTypeReader.getModelFieldTypeReader(helperBaseName); // get the helper and if configured, do the datasource check GenericHelper helper = GenericHelperFactory.getHelper(helperInfo); try &#123; Datasource datasource = EntityConfig.getDatasource(helperBaseName); if (datasource.getCheckOnStart()) &#123; if (Debug.infoOn()) &#123; Debug.logInfo("Doing database check as requested in entityengine.xml with addMissing=" + datasource.getAddMissingOnStart(), module); &#125; helper.checkDataSource(this.getModelEntityMapByGroup(groupName), null, datasource.getAddMissingOnStart()); &#125; &#125; catch (GenericEntityException e) &#123; Debug.logWarning(e, e.getMessage(), module); &#125; &#125; &#125; protected Callable&lt;Void&gt; createHelperCallable(final String groupName) &#123; return new Callable&lt;Void&gt;() &#123; @Override public Void call() &#123; initializeOneGenericHelper(groupName); return null; &#125; &#125;; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(五) ModelGroupReader]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz5%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246public class ModelGroupReader implements Serializable &#123; public static final String module = ModelGroupReader.class.getName(); //缓存所有ModelGroupReader,其k是entity-group-reader属性值 private static final UtilCache&lt;String, ModelGroupReader&gt; readers = UtilCache.createUtilCache("entity.ModelGroupReader", 0, 0); private Map&lt;String, String&gt; groupCache = null;//以entityName为k groupName为v private Set&lt;String&gt; groupNames = null;//delegator所有的组名 public String modelName;//entity-group-reader属性值 public List&lt;ResourceHandler&gt; entityGroupResourceHandlers = new LinkedList&lt;ResourceHandler&gt;();//存放像entity-resource这样标签实例 /** * @author 郑小康 * 1.获取当前delegatorName的delegator标签的DelegatorElement实例 * * 2.获取delegator的entity-group-reader属性值 * * 3.根据属性值获取ModelGroupReader * * 4.如果没有获取到根据delegatorName和entity-group-reader属性值构造一个ModelGroupReader实例,具体过程就在本类中 * * */ public static ModelGroupReader getModelGroupReader(String delegatorName) throws GenericEntityConfException &#123; DelegatorElement delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorName); if (delegatorInfo == null) &#123; throw new GenericEntityConfException("不能发现叫做" + delegatorName+"的delegator"); &#125; String tempModelName = delegatorInfo.getEntityGroupReader(); ModelGroupReader reader = readers.get(tempModelName); if (reader == null) &#123; reader = readers.putIfAbsentAndGet(tempModelName, new ModelGroupReader(delegatorName, tempModelName)); &#125; return reader; &#125; /** * @author 郑小康 * 1. 赋值entity-group-reader的属性值 * * 2. 根据entity-group-reader的属性值获取其对应的EntityGroupReader实例,如果为空就抛出异常 * 原因:其获取的是EntityConfig实例的中的属性,EntityGroupReader是在EntityConfig实例化是加载的属性标签的对象,所以没有是肯定有问题的 * * 3. 添加entityngine.xml中的句柄属性标签MainResourceHandler实例 * * 4. 获取component.xml文件中entity-resource标签类型为group,根据与entity-group-reader的属性值对应reader-name构建ComponentResourceHandler实例添加到entityGroupResourceHandlers这个集合 * 作用是通过这个属性在对应文件中entityName所在的组,后续将其放入到对应的组中，与具体的数据源关联 * * 5. 获取delegator中与entity-group-reader的属性值对应的entity-resource中reader-name相同的标签实例 * 根据entity-resource的路径获取文件下所有entity-group实例,将其以entityName为k,groupNam为v存入到具体的groupCache中 * */ public ModelGroupReader(String delegatorName, String modelName) throws GenericEntityConfException &#123; this.modelName = modelName; EntityGroupReader entityGroupReaderInfo = EntityConfig.getInstance().getEntityGroupReader(modelName); if (entityGroupReaderInfo == null) &#123; throw new GenericEntityConfException("Cound not find an entity-group-reader with the name " + modelName); &#125; for (Resource resourceElement: entityGroupReaderInfo.getResourceList()) &#123; this.entityGroupResourceHandlers.add(new MainResourceHandler(EntityConfig.ENTITY_ENGINE_XML_FILENAME, resourceElement.getLoader(), resourceElement.getLocation())); &#125; // get all of the component resource group stuff, ie specified in each fadp-component.xml file for (ComponentConfig.EntityResourceInfo componentResourceInfo: ComponentConfig.getAllEntityResourceInfos("group")) &#123; if (modelName.equals(componentResourceInfo.readerName)) &#123; this.entityGroupResourceHandlers.add(componentResourceInfo.createResourceHandler()); &#125; &#125; // preload caches... getGroupCache(delegatorName); &#125; /** * @author 郑小康 * 如果groupCache为空则将当前delegator下,如果不为空才进行下面的操作 * * 1.构建对应的groupCache和groupNames * * 2.加载所有资源句柄文件 * 即根据与当前entity-group-reader的属性值相同的entity-resource中reader-name的entity-resource标签 * 根据entity-resource的路径获取文件下所有entity-group实例,将其以entityName为k,groupNam为v存入到具体的groupCache中 * 以entityName为k groupName为v 这样做的作用就是像getEntityGroupName等方法可以根据实体名获取对应的组名 * */ public Map&lt;String, String&gt; getGroupCache(String delegatorName) &#123; if (this.groupCache == null) &#123; // don't want to block here synchronized (ModelGroupReader.class) &#123; //再次检查groupCache是否为空,避免其它线程创建 if (this.groupCache == null) &#123; //构造groupCache这个hashMap 和groupNames这个TreeSet this.groupCache = new HashMap&lt;String, String&gt;(); this.groupNames = new TreeSet&lt;String&gt;(); //做一些时间的通知 UtilTimer utilTimer = new UtilTimer(); utilTimer.timerString("[ModelGroupReader.getGroupCache] Before getDocument"); int i = 0; //遍历所有entity-resource标签对应ComponentResourceHandler实例 for (ResourceHandler entityGroupResourceHandler: this.entityGroupResourceHandlers) &#123; Document document = null; try &#123; //解析为文档元素 document = entityGroupResourceHandler.getDocument(); &#125; catch (GenericConfigException e) &#123; Debug.logError(e, "Error loading entity group model", module); &#125; //如果document为空,缓存置为空,并且返回 if (document == null) &#123; this.groupCache = null; return null; &#125; // utilTimer.timerString("[ModelGroupReader.getGroupCache] Before getDocumentElement"); Element docElement = document.getDocumentElement(); if (docElement == null) &#123; continue; &#125; //移除空的文本节点 docElement.normalize(); //以获取首个节点,而后进行遍历,处理所有entity-group节点将其组名加到groupNames这个集合,并以entityName为k,groupName为v存到对应groupCache中 //注意有一个检查,检查是否具有entityengine.xml对应的group-map的实例,如果没有加载就没有任何意义 Node curChild = docElement.getFirstChild(); if (curChild != null) &#123; utilTimer.timerString("[ModelGroupReader.getGroupCache] Before start of entity loop"); do &#123; if (curChild.getNodeType() == Node.ELEMENT_NODE &amp;&amp; "entity-group".equals(curChild.getNodeName())) &#123; Element curEntity = (Element) curChild; String entityName = UtilXml.checkEmpty(curEntity.getAttribute("entity")).intern(); String groupName = UtilXml.checkEmpty(curEntity.getAttribute("group")).intern(); if (groupName == null || entityName == null) continue; try &#123; if (null == EntityConfig.getInstance().getDelegator(delegatorName).getGroupDataSource(groupName)) &#123; Debug.logError("The declared group name " + groupName + " has no corresponding group-map in entityengine.xml: ", module); &#125; &#125; catch (GenericEntityConfException e) &#123; Debug.logWarning(e, "Exception thrown while getting group name: ", module); &#125; this.groupNames.add(groupName); this.groupCache.put(entityName, groupName); i++; &#125; &#125; while ((curChild = curChild.getNextSibling()) != null); &#125; else &#123; Debug.logWarning("[ModelGroupReader.getGroupCache] No child nodes found.", module); &#125; &#125; utilTimer.timerString("[ModelGroupReader.getGroupCache] FINISHED - Total Entity-Groups: " + i + " FINISHED"); &#125; &#125; &#125; return this.groupCache; &#125; /** * @author 郑小康 * 方法作用:根据entityName和delegatorBaseName获取其对应的组名 * * 1.根据方法获取groupCache * * 2.根据entityName获取组名 * * 3.如果组名为空,获取delegator标签实体，获取其默认组名 * * 4.返回组名 * */ public String getEntityGroupName(String entityName, String delegatorBaseName) &#123; Map&lt;String, String&gt; gc = getGroupCache(delegatorBaseName); if (gc != null) &#123; String groupName = gc.get(entityName); if (groupName == null) &#123; DelegatorElement delegatorInfo = null; try &#123; delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorBaseName); &#125; catch (GenericEntityConfException e) &#123; Debug.logWarning(e, "Exception thrown while getting delegator config: ", module); &#125; if (delegatorInfo == null) &#123; throw new RuntimeException("Could not find DelegatorInfo for delegatorBaseName [" + delegatorBaseName + "]"); &#125; groupName = delegatorInfo.getDefaultGroupName(); &#125; return groupName; &#125; else &#123; return null; &#125; &#125; /** * @author 郑小康 * * 1.确保delegatorName是默认的delegatorName * * 2.调用getGroupCache方法的作用确保将对应的groupCache给加载到类属性 * * 3.根据delegator的default-group-name获取所有其下面默认group-name标签实例的name,将其添加到一个HashSet集合 * * 4.向该集合中添加已经通过getGroupCache方法加载的存放过entityName的groupNames集合 * */ public Set&lt;String&gt; getGroupNames(String delegatorBaseName) &#123; if (delegatorBaseName.indexOf('#') &gt;= 0) &#123; delegatorBaseName = delegatorBaseName.substring(0, delegatorBaseName.indexOf('#')); &#125; getGroupCache(delegatorBaseName); if (this.groupNames == null) return null; Set&lt;String&gt; newSet = new HashSet&lt;String&gt;(); try &#123; newSet.add(EntityConfig.getInstance().getDelegator(delegatorBaseName).getDefaultGroupName()); &#125; catch (GenericEntityConfException e) &#123; Debug.logWarning(e, "Exception thrown while getting delegator config: ", module); &#125; newSet.addAll(this.groupNames); return newSet; &#125; /** * * @author 郑小康 * * 1.构造一个Set根据delegatorBaseName和groupName,向该set注入该组里面所有的实体名 * * 2.遍历groupCache,将组名相同的entityName添加到enames这个HashSet * * 3.返回对应的enames */ public Set&lt;String&gt; getEntityNamesByGroup(String delegatorBaseName, String groupName) &#123; Map&lt;String, String&gt; gc = getGroupCache(delegatorBaseName); Set&lt;String&gt; enames = new HashSet&lt;String&gt;(); if (groupName == null || groupName.length() &lt;= 0) return enames; if (UtilValidate.isEmpty(gc)) return enames; for (Map.Entry&lt;String, String&gt; entry: gc.entrySet()) &#123; if (groupName.equals(entry.getValue())) enames.add(entry.getKey()); &#125; return enames; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(四) ModelReader的作用]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz4%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668public class ModelReader implements Serializable &#123; public static final String module = ModelReader.class.getName(); private static final UtilCache&lt;String, ModelReader&gt; readers = UtilCache.createUtilCache("entity.ModelReader", 0, 0); protected Map&lt;String, ModelEntity&gt; entityCache = null; protected int numEntities = 0; protected int numViewEntities = 0; protected int numFields = 0; protected int numRelations = 0; protected int numAutoRelations = 0; protected String modelName; /**实体资源句柄文件集合*/ protected Collection&lt;ResourceHandler&gt; entityResourceHandlers; /**实体资源句柄文件为key,其下面entityName的集合为v*/ protected Map&lt;ResourceHandler, Collection&lt;String&gt;&gt; resourceHandlerEntities; /**entityName为k 实体资源句柄文件 为v*/ protected Map&lt;String, ResourceHandler&gt; entityResourceHandlerMap; /** * @author 郑小康 * * 1.根据delegatorName获取对应DelegatorElement标签实例 * * 2.获取Delegator的entity-model-reader属性值 * * 3.根据entity-model-reader属性值获取ModelReader实例 * * 4.如果ModelReader实例为空,则创建其对应的ModelReader,并获取所有实体缓存 * * 5.以entity-model-reader属性值为k ModelReader实例为v存放到readers这个UtilCache中去 * * 6.返回当前ModelReader实例 * */ public static ModelReader getModelReader(String delegatorName) throws GenericEntityException &#123; DelegatorElement delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorName); if (delegatorInfo == null) &#123; throw new GenericEntityConfException("Could not find a delegator with the name " + delegatorName); &#125; String tempModelName = delegatorInfo.getEntityModelReader(); ModelReader reader = readers.get(tempModelName); if (reader == null) &#123; reader = new ModelReader(tempModelName); // preload caches... reader.getEntityCache(); reader = readers.putIfAbsentAndGet(tempModelName, reader); &#125; return reader; &#125; /** * @author 郑小康 * * 1.赋值entity-model-reader的属性 * * 2.根据entity-model-reader的属性值获取其对应的EntityModelReader实例,如果为空就抛出异常 * 原因:其获取的是EntityConfig实例的中的属性,EntityModelReader是在EntityConfig实例化是加载的属性标签的对象,所以没有是肯定有问题的 * * 3.添加entityngine.xml中的句柄属性标签MainResourceHandler实例 * * 4.获取*****-component.xml文件中entity-resource标签类型为model,根据与entity-model-reader的属性值对应reader-name构建ComponentResourceHandler实例添加到entityModelResourceHandlers这个集合 * * 注意:这个构造器主要是给entityResourceHandlers这个集合中添加了当前EntityModelReader 对应entity-resource对应的实例 * 它是一个私有构造器,通过getModelReader方法来创建对应实例,后续操作在getModelReader这个静态方法中 * */ private ModelReader(String modelName) throws GenericEntityException &#123; this.modelName = modelName; entityResourceHandlers = new LinkedList&lt;ResourceHandler&gt;(); resourceHandlerEntities = new HashMap&lt;ResourceHandler, Collection&lt;String&gt;&gt;(); entityResourceHandlerMap = new HashMap&lt;String, ResourceHandler&gt;(); EntityModelReader entityModelReaderInfo = EntityConfig.getInstance().getEntityModelReader(modelName); if (entityModelReaderInfo == null) &#123; throw new GenericEntityConfException("Cound not find an entity-model-reader with the name " + modelName); &#125; // get all of the main resource model stuff, ie specified in the entityengine.xml file for (Resource resourceElement : entityModelReaderInfo.getResourceList()) &#123; ResourceHandler handler = new MainResourceHandler(EntityConfig.ENTITY_ENGINE_XML_FILENAME, resourceElement.getLoader(), resourceElement.getLocation()); entityResourceHandlers.add(handler); &#125; // get all of the component resource model stuff, ie specified in each fadp-component.xml file for (ComponentConfig.EntityResourceInfo componentResourceInfo: ComponentConfig.getAllEntityResourceInfos("model")) &#123; if (modelName.equals(componentResourceInfo.readerName)) &#123; entityResourceHandlers.add(componentResourceInfo.createResourceHandler()); &#125; &#125; &#125; /** * @author 郑小康 * 1.判断节点元素是否是entity * * 2.获取entity-name的值 * * 3.获取entity的redefinition属性,这个属性的作用是说明这个实体不能被覆盖,即entity节点元素不能定义两遍 * 但这仅仅是一个警告,定义了后面的就会覆盖钱买呢 * * 4.获取当前资源句柄文件的实体名集合,为空则实例化一个LinkedList集合 * 将当前实体名添加到集合 * * 5.以entityName为k entityResourceHandler为v存放在entityResourceHandlerMap,这样做的好处是根据entityName获取其资源句柄文件 * * 6.实体不为空,构造对应的modelEntity或者ModelViewEntity * * 7.将实体的资源句柄文件路径添加到当前modelEntity * * 8.返回当前modelEntity * * 注意:这里只是构造modelEntity,并没有在数据库建表 * */ private ModelEntity buildEntity(ResourceHandler entityResourceHandler, Element curEntityElement, int i, ModelInfo def) throws GenericEntityException &#123; boolean isEntity = "entity".equals(curEntityElement.getNodeName()); String entityName = UtilXml.checkEmpty(curEntityElement.getAttribute("entity-name")).intern(); //获取entity的redefinition属性,这个属性的作用是 boolean redefinedEntity = "true".equals(curEntityElement.getAttribute("redefinition")); //获取当前entityResourceHandler的resourceHandlerEntityNames,里面存放的是这个句柄文件中存在entity,在这里获取的目的是将当前构建的entity的entityName添加进去 Collection&lt;String&gt; resourceHandlerEntityNames = resourceHandlerEntities.get(entityResourceHandler); if (resourceHandlerEntityNames == null) &#123; resourceHandlerEntityNames = new LinkedList&lt;String&gt;(); resourceHandlerEntities.put(entityResourceHandler, resourceHandlerEntityNames); &#125; resourceHandlerEntityNames.add(entityName); //检查缓存中是包含 如果缓存中包含,且它不允许重定义(entity属性中默认是false) 这样就会报一些井盖 if (entityCache.containsKey(entityName) &amp;&amp; !redefinedEntity) &#123; Debug.logWarning("实体 " + entityName + " 被再次定义,其将覆盖原有的", module); Debug.logWarning("Entity " + entityName + " 被发现在资源句柄文件 " + entityResourceHandler + ", 但是已经被定义在 " + entityResourceHandlerMap.get(entityName).toString(), module); &#125; //以entityName为k entityResourceHandler为v存放在entityResourceHandlerMap,这样做的好处是根据entityName获取其资源句柄文件 entityResourceHandlerMap.put(entityName, entityResourceHandler); //构造对应的modelEntity或者ModelViewEntity ModelEntity modelEntity = null; if (isEntity) &#123; modelEntity = createModelEntity(curEntityElement, null, def); &#125; else &#123; modelEntity = createModelViewEntity(curEntityElement, null, def); &#125; //获取句柄资源文件的路径 String resourceLocation = entityResourceHandler.getLocation(); try &#123; resourceLocation = entityResourceHandler.getURL().toExternalForm(); &#125; catch (GenericConfigException e) &#123; Debug.logError(e, "Could not get resource URL", module); &#125; //如果modelEntity不为空,将实体的路径注入到modelEntity if (modelEntity != null) &#123; modelEntity.setLocation(resourceLocation); // utilTimer.timerString(" After entityCache.put -- " + i + " --"); if (isEntity) &#123; if (Debug.verboseOn()) Debug.logVerbose("-- [Entity]: #" + i + ": " + entityName, module); &#125; else &#123; if (Debug.verboseOn()) Debug.logVerbose("-- [ViewEntity]: #" + i + ": " + entityName, module); &#125; &#125; else &#123; Debug.logWarning("-- -- ENTITYGEN ERROR:getModelEntity: Could not create " + "entity for entityName: " + entityName, module); &#125; return modelEntity; &#125; /** * @author 郑小康 * 1.检查entityCache是否为空,如果不为空直接返回当前缓存,如果为空才向下执行 * * 2.再次检查,避免其他线程在这个过程创建entityCache * * 3.对类属性进行初始化 numEntities:实体数量 numViewEntities:视图实体数量 numFields:字段数量 * numRelations: numAutoRelations numAutoRelations: * * 4.创建tempViewEntityList&lt;ModelViewEntity&gt;:临时视图模型实体集合 tempExtendEntityElementList&lt;Element&gt; 扩展实体元素 * * 5.遍历所有资源句柄文件,包括entity-model-reader中孩子标签Resource 和对应的组件下entity-resource * * 6.根据entityResourceHandler的路径,获取其对应的文档的Document实例 * * 7.从首个节点开始,首先构造ModelInfo,获取当前entity的属性 * * 8.节点有三种 entity view-entity extend-entity * 如果是实体或者视图实体,调用buildEntity,构造对应的ModelEntity * 视图实体:构造后,添加到tempViewEntityList集合 * 实体:构造后以entityName为k modelEntity为v放入到entityCache * * 如果是extend-entity,直接将节点元素添加到对应的tempExtendEntityElementList集合 * * 9.从缓存中获取extend-entity的name相同的ModelEntity,然后对这个ModelEntity进行扩展字段,并且其会覆盖原有entity的属性 * * 10.将视图实体添加到对应的成员ModelEntity,这样就可以通过ModelEntity获取其下面所有ModelViewEntity * 并将视图以entityName为k ModelViewEntity为v存放到缓存 * * 11.检查出某些视图存在有些成员实体不存在，列举出来,这些ModelViewEntity并没有加到entitycache中 * * 12构建关系,主要是给当前实体添加其存在的关系集合,关系的实体中也添加这个ModelRelation到CopyOnWriteArrayList&lt;ModelRelation&gt; relations * CopyOnWrite容器即写时复制的容器。 * 读取的时候拷贝一个副本,进行读取 * 写入的需要加锁,对副本进行写入之后,再将原容器的引用指向新的容器 * 这样的好处是可以进行并发的读 * * */ public Map&lt;String, ModelEntity&gt; getEntityCache() throws GenericEntityException &#123; if (entityCache == null) &#123; // don't want to block here synchronized (ModelReader.class) &#123; // must check if null again as one of the blocked threads can still enter if (entityCache == null) &#123; // now it's safe numEntities = 0; numViewEntities = 0; numFields = 0; numRelations = 0; numAutoRelations = 0; entityCache = new HashMap&lt;String, ModelEntity&gt;(); List&lt;ModelViewEntity&gt; tempViewEntityList = new LinkedList&lt;ModelViewEntity&gt;(); List&lt;Element&gt; tempExtendEntityElementList = new LinkedList&lt;Element&gt;(); UtilTimer utilTimer = new UtilTimer(); for (ResourceHandler entityResourceHandler: entityResourceHandlers) &#123; // utilTimer.timerString("Before getDocument in file " + entityFileName); Document document = null; try &#123; document = entityResourceHandler.getDocument(); &#125; catch (GenericConfigException e) &#123; throw new GenericEntityConfException("Error getting document from resource handler 获取entitymodel.xml文件失败", e); &#125; if (document == null) &#123; throw new GenericEntityConfException("Could not get document for " + entityResourceHandler.toString()); &#125; // utilTimer.timerString("Before getDocumentElement in " + entityResourceHandler.toString()); Element docElement = document.getDocumentElement(); if (docElement == null) &#123; return null; &#125; docElement.normalize(); Node curChild = docElement.getFirstChild(); ModelInfo def = ModelInfo.createFromElements(ModelInfo.DEFAULT, docElement); int i = 0; if (curChild != null) &#123; utilTimer.timerString("Before start of entity loop in " + entityResourceHandler.toString()); do &#123; boolean isEntity = "entity".equals(curChild.getNodeName()); boolean isViewEntity = "view-entity".equals(curChild.getNodeName()); boolean isExtendEntity = "extend-entity".equals(curChild.getNodeName()); if ((isEntity || isViewEntity) &amp;&amp; curChild.getNodeType() == Node.ELEMENT_NODE) &#123; i++; ModelEntity modelEntity = buildEntity(entityResourceHandler, (Element) curChild, i, def); // put the view entity in a list to get ready for the second pass to populate fields... if (isViewEntity) &#123; tempViewEntityList.add((ModelViewEntity) modelEntity); &#125; else &#123; entityCache.put(modelEntity.getEntityName(), modelEntity); &#125; &#125; else if (isExtendEntity &amp;&amp; curChild.getNodeType() == Node.ELEMENT_NODE) &#123; tempExtendEntityElementList.add((Element) curChild); &#125; &#125; while ((curChild = curChild.getNextSibling()) != null); &#125; else &#123; Debug.logWarning("No child nodes found.", module); &#125; utilTimer.timerString("Finished " + entityResourceHandler.toString() + " - Total Entities: " + i + " FINISHED"); &#125; //从缓存中获取extend-entity的name相同的ModelEntity,然后对这个ModelEntity进行扩展字段,并且其会覆盖原有entity的属性 for (Element extendEntityElement: tempExtendEntityElementList) &#123; String entityName = UtilXml.checkEmpty(extendEntityElement.getAttribute("entity-name")); ModelEntity modelEntity = entityCache.get(entityName); if (modelEntity == null) throw new GenericEntityConfException("Entity to extend does not exist: " + entityName); modelEntity.addExtendEntity(this, extendEntityElement); &#125; //如果视图不为空,获取视图的大小 while (!tempViewEntityList.isEmpty()) &#123; int startSize = tempViewEntityList.size(); //对视图进行迭代 Iterator&lt;ModelViewEntity&gt; mveIt = tempViewEntityList.iterator();TEMP_VIEW_LOOP: while (mveIt.hasNext()) &#123; ModelViewEntity curViewEntity = mveIt.next(); //遍历当前视图的所有ModelMemberEntity(member-entity)成员,如果在缓存中不存在就不执行,存在则继续执行 for (ModelViewEntity.ModelMemberEntity mve: curViewEntity.getAllModelMemberEntities()) &#123; if (!entityCache.containsKey(mve.getEntityName())) &#123; continue TEMP_VIEW_LOOP; &#125; &#125; mveIt.remove(); //注入视图实体所有字段 curViewEntity.populateFields(this); //加视图实体添加到其下面所有成员实体ModelEntity下,以为这可以根据ModelEntity查询其所有视图实体 for (ModelViewEntity.ModelMemberEntity mve: curViewEntity.getAllModelMemberEntities()) &#123; ModelEntity me = entityCache.get(mve.getEntityName()); me.addViewEntity(curViewEntity); &#125; entityCache.put(curViewEntity.getEntityName(), curViewEntity); &#125; //这段代码的作用是标识tempViewEntityList集合中的成员是都存在不包含在entityCache if (tempViewEntityList.size() == startSize) &#123; // Oops, the remaining views reference other entities // that can't be found, or they reference other views // that have some reference problem. break; &#125; &#125; //这段代码的作用是在上面遍历tempViewEntityList,有些MemberEntity在缓存中不存在 //检查不存在的memberEntity添加到perViewMissingEntities这个SET集合,并将其给输出 if (!tempViewEntityList.isEmpty()) &#123; StringBuilder sb = new StringBuilder("View entities reference non-existant members:\n"); Set&lt;String&gt; allViews = new HashSet&lt;String&gt;(); for (ModelViewEntity curViewEntity: tempViewEntityList) &#123; allViews.add(curViewEntity.getEntityName()); &#125; for (ModelViewEntity curViewEntity: tempViewEntityList) &#123; Set&lt;String&gt; perViewMissingEntities = new HashSet&lt;String&gt;(); Iterator&lt;ModelViewEntity.ModelMemberEntity&gt; mmeIt = curViewEntity.getAllModelMemberEntities().iterator(); while (mmeIt.hasNext()) &#123; ModelViewEntity.ModelMemberEntity mme = mmeIt.next(); String memberEntityName = mme.getEntityName(); if (!entityCache.containsKey(memberEntityName)) &#123; // this member is not a real entity // check to see if it is a view if (!allViews.contains(memberEntityName)) &#123; // not a view, it's a real missing entity perViewMissingEntities.add(memberEntityName); &#125; &#125; &#125; for (String perViewMissingEntity: perViewMissingEntities) &#123; sb.append("\t[").append(curViewEntity.getEntityName()).append("] missing member entity [").append(perViewMissingEntity).append("]\n"); &#125; &#125; throw new GenericEntityConfException(sb.toString()); &#125; /** * @author 郑小康 * 1.遍历当前ModelReader下所有实体名 * 2.获取对应ModelEntity * 3.将其关系进行迭代处理 * 4.如果类型是one 或者one-nofk(不是AutoRelation) 获取其关系ModelEntity * 5.将所有key-map的name添加到curEntityKeyFields集合 * 6.实例化ModelRelation * 7.如果是自关联,将ModelRealation添加到当前实体 * 如果不是在相关实体加入ModelRealation * */ TreeSet&lt;String&gt; orderedMessages = new TreeSet&lt;String&gt;(); for (String curEntityName: new TreeSet&lt;String&gt;(this.getEntityNames())) &#123; ModelEntity curModelEntity = this.getModelEntity(curEntityName); if (curModelEntity instanceof ModelViewEntity) &#123; // for view-entities auto-create relationships for all member-entity relationships that have all corresponding fields in the view-entity &#125; else &#123; // for entities auto-create many relationships for all type one relationships // just in case we add a new relation to the same entity, keep in a separate list and add them at the end List&lt;ModelRelation&gt; newSameEntityRelations = new LinkedList&lt;ModelRelation&gt;(); Iterator&lt;ModelRelation&gt; relationsIter = curModelEntity.getRelationsIterator(); while (relationsIter.hasNext()) &#123; ModelRelation modelRelation = relationsIter.next(); if (("one".equals(modelRelation.getType()) || "one-nofk".equals(modelRelation.getType())) &amp;&amp; !modelRelation.isAutoRelation()) &#123; ModelEntity relatedEnt = null; try &#123; /** 得到参考的 RelEntityName. */ relatedEnt = this.getModelEntity(modelRelation.getRelEntityName()); &#125; catch (GenericModelException e) &#123;// com.hanlin.fadp.petrescence.datasource.FindMissedEntity.addMissed(modelRelation.getRelEntityName()); throw new GenericModelException("Error getting related entity [" + modelRelation.getRelEntityName() + "] definition from entity [" + curEntityName + "]", e); &#125; if (relatedEnt != null) &#123; // create the new relationship even if one exists so we can show what we are looking for in the info message // don't do relationship to the same entity, unless title is "Parent", then do a "Child" automatically String title = modelRelation.getTitle(); if (curModelEntity.getEntityName().equals(relatedEnt.getEntityName()) &amp;&amp; "Parent".equals(title)) &#123; title = "Child"; &#125; String description = ""; String type = ""; String relEntityName = curModelEntity.getEntityName(); String fkName = ""; ArrayList&lt;ModelKeyMap&gt; keyMaps = new ArrayList&lt;ModelKeyMap&gt;(); boolean isAutoRelation = true; Set&lt;String&gt; curEntityKeyFields = new HashSet&lt;String&gt;(); for (ModelKeyMap curkm : modelRelation.getKeyMaps()) &#123; keyMaps.add(new ModelKeyMap(curkm.getRelFieldName(), curkm.getFieldName())); curEntityKeyFields.add(curkm.getFieldName()); &#125; keyMaps.trimToSize(); // decide whether it should be one or many by seeing if the key map represents the complete pk of the relEntity if (curModelEntity.containsAllPkFieldNames(curEntityKeyFields)) &#123; // always use one-nofk, we don't want auto-fks getting in for these automatic ones type = "one-nofk"; // to keep it clean, remove any additional keys that aren't part of the PK List&lt;String&gt; curPkFieldNames = curModelEntity.getPkFieldNames(); Iterator&lt;ModelKeyMap&gt; nrkmIter = keyMaps.iterator(); while (nrkmIter.hasNext()) &#123; ModelKeyMap nrkm =nrkmIter.next(); String checkField = nrkm.getRelFieldName(); if (!curPkFieldNames.contains(checkField)) &#123; nrkmIter.remove(); &#125; &#125; &#125; else &#123; type= "many"; &#125; ModelRelation newRel = ModelRelation.create(relatedEnt, description, type, title, relEntityName, fkName, keyMaps, isAutoRelation); ModelRelation existingRelation = relatedEnt.getRelation(title + curModelEntity.getEntityName()); if (existingRelation == null) &#123; numAutoRelations++; if (curModelEntity.getEntityName().equals(relatedEnt.getEntityName())) &#123; newSameEntityRelations.add(newRel); &#125; else &#123; relatedEnt.addRelation(newRel); &#125; &#125; else &#123; if (newRel.equals(existingRelation)) &#123; // don't warn if the target title+entity = current title+entity if (Debug.infoOn() &amp;&amp; !(title + curModelEntity.getEntityName()).equals(modelRelation.getTitle() + modelRelation.getRelEntityName())) &#123; //String errorMsg = "Relation already exists to entity [] with title [" + targetTitle + "],from entity []"; String message = "Entity [" + relatedEnt.getPackageName() + ":" + relatedEnt.getEntityName() + "] already has identical relationship to entity [" + curModelEntity.getEntityName() + "] title [" + title + "]; would auto-create: type [" + newRel.getType() + "] and fields [" + newRel.keyMapString(",", "") + "]"; orderedMessages.add(message); &#125; &#125; else &#123; String message = "Existing relationship with the same name, but different specs found from what would be auto-created for Entity [" + relatedEnt.getEntityName() + "] and relationship to entity [" + curModelEntity.getEntityName() + "] title [" + title + "]; would auto-create: type [" + newRel.getType() + "] and fields [" + newRel.keyMapString(",", "") + "]"; Debug.logVerbose(message, module); &#125; &#125; &#125; else &#123; String errorMsg = "Could not find related entity [" + modelRelation.getRelEntityName() + "], no reverse relation added."; Debug.logWarning(errorMsg, module); &#125; &#125; &#125; if (newSameEntityRelations.size() &gt; 0) &#123; for (ModelRelation newRel: newSameEntityRelations) &#123; curModelEntity.addRelation(newRel); &#125; &#125; &#125; &#125; if (Debug.infoOn()) &#123; for (String message : orderedMessages) &#123; Debug.logInfo(message, module); &#125; Debug.logInfo("Finished loading entities; #Entities=" + numEntities + " #ViewEntities=" + numViewEntities + " #Fields=" + numFields + " #Relationships=" + numRelations + " #AutoRelationships=" + numAutoRelations, module); &#125; &#125; &#125; &#125; return entityCache; &#125; /** * rebuilds the resourceHandlerEntities Map of Collections based on the current * entityResourceHandlerMap Map, must be done whenever a manual change is made to the * entityResourceHandlerMap Map after the initial load to make them consistent again. * * Map&lt;ResourceHandler, Collection&lt;String&gt;&gt; resourceHandlerEntities * Map&lt;String, ResourceHandler&gt; entityResourceHandlerMap * 依据entityResourceHandlerMap来更新resourceHandlerEntities * FIXME:暂时不理解为什么会出现这种情况 */ public void rebuildResourceHandlerEntities() &#123; resourceHandlerEntities = new HashMap&lt;ResourceHandler, Collection&lt;String&gt;&gt;(); Iterator&lt;Map.Entry&lt;String, ResourceHandler&gt;&gt; entityResourceIter = entityResourceHandlerMap.entrySet().iterator(); while (entityResourceIter.hasNext()) &#123; Map.Entry&lt;String, ResourceHandler&gt; entry = entityResourceIter.next(); // add entityName to appropriate resourceHandlerEntities collection Collection&lt;String&gt; resourceHandlerEntityNames = resourceHandlerEntities.get(entry.getValue()); if (resourceHandlerEntityNames == null) &#123; resourceHandlerEntityNames = new LinkedList&lt;String&gt;(); resourceHandlerEntities.put(entry.getValue(), resourceHandlerEntityNames); &#125; resourceHandlerEntityNames.add(entry.getKey()); &#125; &#125; /**获取当前模型阅读器的resourceHandler迭代器*/ public Iterator&lt;ResourceHandler&gt; getResourceHandlerEntitiesKeyIterator() &#123; if (resourceHandlerEntities == null) return null; return resourceHandlerEntities.keySet().iterator(); &#125; public Collection&lt;String&gt; getResourceHandlerEntities(ResourceHandler resourceHandler) &#123; if (resourceHandlerEntities == null) return null; return resourceHandlerEntities.get(resourceHandler); &#125; public void addEntityToResourceHandler(String entityName, String loaderName, String location) &#123; entityResourceHandlerMap.put(entityName, new MainResourceHandler(EntityConfig.ENTITY_ENGINE_XML_FILENAME, loaderName, location)); &#125; public ResourceHandler getEntityResourceHandler(String entityName) &#123; return entityResourceHandlerMap.get(entityName); &#125; /** Gets an Entity object based on a definition from the specified XML Entity descriptor file. * @param entityName The entityName of the Entity definition to use. * @return An Entity object describing the specified entity of the specified descriptor file. */ public ModelEntity getModelEntity(String entityName) throws GenericEntityException &#123; if (entityName == null) &#123; throw new IllegalArgumentException("Tried to find entity definition for a null entityName"); &#125; Map&lt;String, ModelEntity&gt; ec = getEntityCache(); if (ec == null) &#123; throw new GenericEntityConfException("ERROR: Unable to load Entity Cache"); &#125; ModelEntity modelEntity = ec.get(entityName); if (modelEntity == null) &#123; String errMsg = "Could not find definition for entity name " + entityName; // Debug.logError(new Exception("Placeholder"), errMsg, module);// com.hanlin.fadp.petrescence.datasource.FindMissedEntity.addMissed(entityName); throw new GenericModelException(errMsg); &#125; return modelEntity; &#125; public ModelEntity getModelEntityNoCheck(String entityName) &#123; Map&lt;String, ModelEntity&gt; ec = null; try &#123; ec = getEntityCache(); &#125; catch (GenericEntityException e) &#123; Debug.logError(e, "Error getting entity cache", module); &#125; if (ec == null) &#123; return null; &#125; ModelEntity modelEntity = ec.get(entityName); return modelEntity; &#125; /** Creates a Iterator with the entityName of each Entity defined in the specified XML Entity Descriptor file. * @return A Iterator of entityName Strings */ public Iterator&lt;String&gt; getEntityNamesIterator() throws GenericEntityException &#123; Collection&lt;String&gt; collection = getEntityNames(); if (collection != null) &#123; return collection.iterator(); &#125; else &#123; return null; &#125; &#125; /** Creates a Set with the entityName of each Entity defined in the specified XML Entity Descriptor file. * @return A Set of entityName Strings */ public Set&lt;String&gt; getEntityNames() throws GenericEntityException &#123; Map&lt;String, ModelEntity&gt; ec = getEntityCache(); if (ec == null) &#123; throw new GenericEntityConfException("ERROR: Unable to load Entity Cache"); &#125; return ec.keySet(); &#125; /** Get all entities, organized by package */ public Map&lt;String, TreeSet&lt;String&gt;&gt; getEntitiesByPackage(Set&lt;String&gt; packageFilterSet, Set&lt;String&gt; entityFilterSet) throws GenericEntityException &#123; Map&lt;String, TreeSet&lt;String&gt;&gt; entitiesByPackage = new HashMap&lt;String, TreeSet&lt;String&gt;&gt;(); //put the entityNames TreeSets in a HashMap by packageName Iterator&lt;String&gt; ecIter = this.getEntityNames().iterator(); while (ecIter.hasNext()) &#123; String entityName = ecIter.next(); ModelEntity entity = this.getModelEntity(entityName); String packageName = entity.getPackageName(); if (UtilValidate.isNotEmpty(packageFilterSet)) &#123; // does it match any of these? boolean foundMatch = false; for (String packageFilter: packageFilterSet) &#123; if (packageName.contains(packageFilter)) &#123; foundMatch = true; &#125; &#125; if (!foundMatch) &#123; //Debug.logInfo("Not including entity " + entityName + " becuase it is not in the package set: " + packageFilterSet, module); continue; &#125; &#125; if (UtilValidate.isNotEmpty(entityFilterSet) &amp;&amp; !entityFilterSet.contains(entityName)) &#123; //Debug.logInfo("Not including entity " + entityName + " because it is not in the entity set: " + entityFilterSet, module); continue; &#125; TreeSet&lt;String&gt; entities = entitiesByPackage.get(entity.getPackageName()); if (entities == null) &#123; entities = new TreeSet&lt;String&gt;(); entitiesByPackage.put(entity.getPackageName(), entities); &#125; entities.add(entityName); &#125; return entitiesByPackage; &#125; /** Util method to validate an entity name; if no entity is found with the name, * characters are stripped from the beginning of the name until a valid entity name is found. * It is intended to be used to determine the entity name from a relation name. * @return A valid entityName or null */ public String validateEntityName(String entityName) throws GenericEntityException &#123; if (entityName == null) &#123; return null; &#125; Set&lt;String&gt; allEntities = this.getEntityNames(); while (!allEntities.contains(entityName) &amp;&amp; entityName.length() &gt; 0) &#123; entityName = entityName.substring(1); &#125; return (entityName.length() &gt; 0? entityName: null); &#125; ModelEntity createModelEntity(Element entityElement, UtilTimer utilTimer, ModelInfo def) &#123; if (entityElement == null) return null; this.numEntities++; ModelEntity entity = new ModelEntity(this, entityElement, utilTimer, def); return entity; &#125; ModelEntity createModelViewEntity(Element entityElement, UtilTimer utilTimer, ModelInfo def) &#123; if (entityElement == null) return null; this.numViewEntities++; ModelViewEntity entity = new ModelViewEntity(this, entityElement, utilTimer, def); return entity; &#125; public ModelRelation createRelation(ModelEntity entity, Element relationElement) &#123; this.numRelations++; ModelRelation relation = ModelRelation.create(entity, relationElement, false); return relation; &#125; /**增加当前ModelReader字段个数*/ public void incrementFieldCount(int amount) &#123; this.numFields += amount; &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(二) delegator实例化具体方式]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz2%2F</url>
    <content type="text"><![CDATA[123456789101112131415/** * @author 郑小康 * 采用spi创建对应实例DelegatorFactoryImpl * */ public static &lt;A, R&gt; R getObjectFromFactory(Class&lt;? extends Factory&lt;R, A&gt;&gt; factoryInterface, A obj) throws ClassNotFoundException &#123; Iterator&lt;? extends Factory&lt;R, A&gt;&gt; it = ServiceLoader.load(factoryInterface).iterator(); while (it.hasNext()) &#123; Factory&lt;R, A&gt; factory = it.next(); R instance = factory.getInstance(obj); if (instance != null) &#123; return instance; &#125; &#125; throw new ClassNotFoundException(factoryInterface.getClass().getName()); &#125; 注：上下代码不是在一个类 1234567891011121314151617181920 /** * @author 郑小康 * 根据delegatorName创建一个GenericDelegator * 所以实际delegator引用的是一个GenericDelegator实例 * */public class DelegatorFactoryImpl extends DelegatorFactory &#123; public static final String module = DelegatorFactoryImpl.class.getName(); public Delegator getInstance(String delegatorName) &#123; if (Debug.infoOn()) Debug.logInfo("Creating new delegator [" + delegatorName + "] (" + Thread.currentThread().getName() + ")", module); //Debug.logInfo(new Exception(), "Showing stack where new delegator is being created...", module); try &#123; return new GenericDelegator(delegatorName); &#125; catch (GenericEntityException e) &#123; Debug.logError(e, "Error creating delegator", module); return null; &#125; &#125;&#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(三) GenericDelegator实例化的具体过程]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz3%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * @author 郑小康 * 1.设置delegatorFullName 基本delegatorName+"#"+tenantId 如果tenantId为空 则就是默认的delegatorName * * 2.获取EntityConfig实例,并获取基本delegatorBaseName的delegator标签,并解析为对应的DelegatorElement实例 * &lt;delegator name="default" entity-model-reader="main" entity-group-reader="main"&gt;&lt;/delegator&gt; * * 3.判断delegatorTenantId是否为空,这是租户id * 第一种情况租户id不为空:获取默认的Delegator,用delegator查询Tenant表中当前tenantId的对应GenericValue * :获取对应租户的kekText FIXME:暂时未应用 网上搜索说对数据库连接密码进行解密的操作 * 第二种情况租户id为空 :获取delegator标签实例的key-encrypting-key * * 4.获取ModelReader 检查了实体缓存之类的操作,获取所有ModelEntity * * 5.获取所有ModelGroupReader * 该类的主要操作是构造对应groupCache缓存,将entity-name为k,groupName为v这样存放,并提供一些获取方法,如获取所有组名,根据实体名获取组名 * * 6.缓存当前delegatorFullName * * 7.对实体进行检查 有检查组里面是否有对应实体 实体名是否是保留字 建立视图一个字段是否被引用多次 * * 8.获取组名集合 * * 9.遍历delegaot组,通过ThreadPoolExecutor线程池提交Future中任务,对每个组的实体创建到其组对应数据源的数据库 * 调用Future的原因是,是因为建表很耗时间,所以采用异步执行 * * */ protected GenericDelegator(String delegatorFullName) throws GenericEntityException &#123; this.setDelegatorNames(delegatorFullName); //获取基本的delegator中的信息 this.delegatorInfo = EntityConfig.getInstance().getDelegator(delegatorBaseName); String kekText; // before continuing, if there is a tenantId use the base delegator to see if it is valid if (UtilValidate.isNotEmpty(this.delegatorTenantId)) &#123; Delegator baseDelegator = DelegatorFactory.getDelegator(this.delegatorBaseName); GenericValue tenant = EntityQuery.use(baseDelegator).from("Tenant").where("tenantId", this.delegatorTenantId).cache(true).queryOne(); if (tenant == null) &#123; throw new GenericEntityException("No Tenant record found for delegator [" + this.delegatorFullName + "] with tenantId [" + this.delegatorTenantId + "]"); &#125; else if ("Y".equals(tenant.getString("disabled"))) &#123; throw new GenericEntityException("No Tenant record found for delegator [" + this.delegatorFullName + "] with tenantId [" + this.delegatorTenantId + "]"); &#125; GenericValue kekValue = EntityQuery.use(baseDelegator).from("TenantKeyEncryptingKey").where("tenantId", getDelegatorTenantId()).cache(true).queryOne(); if (kekValue != null) &#123; kekText = kekValue.getString("kekText"); &#125; else &#123; kekText = this.delegatorInfo.getKeyEncryptingKey(); &#125; &#125; else &#123; kekText = this.delegatorInfo.getKeyEncryptingKey(); &#125; this.modelReader = ModelReader.getModelReader(delegatorBaseName); this.modelGroupReader = ModelGroupReader.getModelGroupReader(delegatorBaseName); cache = new Cache(delegatorFullName); //对实体进行检查 有检查组里面是否有对应实体 实体名是否是保留字 建立视图一个字段是否被引用多次 List&lt;String&gt; warningList = new LinkedList&lt;String&gt;(); Debug.logInfo("Doing entity definition check...", module); ModelEntityChecker.checkEntities(this, warningList); if (warningList.size() &gt; 0) &#123; Debug.logWarning("=-=-=-=-= Found " + warningList.size() + " warnings when checking the entity definitions:", module); for (String warning: warningList) &#123; Debug.logWarning(warning, module); &#125; &#125; //获取当前delegator中的groupNames集合,遍历创建对应的GenericHelper,同时在数据库中创建未创建的表和字段 Set&lt;String&gt; groupNames = getModelGroupReader().getGroupNames(delegatorBaseName); List&lt;Future&lt;Void&gt;&gt; futures = new LinkedList&lt;Future&lt;Void&gt;&gt;(); for (String groupName: groupNames) &#123; futures.add(ExecutionPool.GLOBAL_BATCH.submit(createHelperCallable(groupName))); &#125; ExecutionPool.getAllFutures(futures); // NOTE: doing some things before the ECAs and such to make sure it is in place just in case it is used in a service engine startup thing or something // setup the crypto class; this also after the delegator is in the cache otherwise we get infinite recursion this.crypto = new EntityCrypto(this, kekText); &#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz实体引擎(一) 获取Delegator]]></title>
    <url>%2F2017%2F07%2F30%2Fofbiz%2Fofbiz1%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public abstract class DelegatorFactory implements Factory&lt;Delegator, String&gt; &#123; public static final String module = DelegatorFactoryImpl.class.getName(); private static final ConcurrentHashMap&lt;String, Future&lt;Delegator&gt;&gt; delegators = new ConcurrentHashMap&lt;String, Future&lt;Delegator&gt;&gt;(); private static final ThreadGroup DELEGATOR_THREAD_GROUP = new ThreadGroup("DelegatorFactory"); private static final ScheduledExecutorService executor = ExecutionPool.getScheduledExecutor(DELEGATOR_THREAD_GROUP, "delegator-startup", Runtime.getRuntime().availableProcessors(), 10, true); /** *@author 郑小康 * * 根据delegatorName调用getDelegatorFuture方法,获取当前delegator的 Future&lt;Delegator&gt; * * 而后调用get方法获取Delegator实例 * * */ public static Delegator getDelegator(String delegatorName) &#123; Future&lt;Delegator&gt; future = getDelegatorFuture(delegatorName); try &#123; return future.get(); &#125; catch (ExecutionException e) &#123; Debug.logError(e, module); return null; &#125; catch (InterruptedException e) &#123; Debug.logError(e, module); return null; &#125; &#125; /** * @author 郑小康 * * 根据delegatorName获取Future&lt;Delegator&gt; 如果为空,新创建一个FutureTask&lt;Delegator&gt;将其加入到缓存中去 * * 将这个futureTask给提交到线程池,futureTask中存放的是DelegatorConfigurable实例对象 * * * */ public static Future&lt;Delegator&gt; getDelegatorFuture(String delegatorName) &#123; if (delegatorName == null) &#123; delegatorName = "default"; //Debug.logWarning(new Exception("Location where getting delegator with null name"), "Got a getGenericDelegator call with a null delegatorName, assuming default for the name.", module); &#125; do &#123; Future&lt;Delegator&gt; future = delegators.get(delegatorName); if (future != null) &#123; //Debug.logInfo("got delegator(future(" + delegatorName + ")) from cache", module); return future; &#125; FutureTask&lt;Delegator&gt; futureTask = new FutureTask&lt;Delegator&gt;(new DelegatorConfigurable(delegatorName)); //Debug.logInfo("putting delegator(future(" + delegatorName + ")) into cache", module); if (delegators.putIfAbsent(delegatorName, futureTask) != null) &#123; continue; &#125; executor.submit(futureTask); &#125; while (true); &#125; public static final class DelegatorConfigurable implements Callable&lt;Delegator&gt; &#123; private final String delegatorName; public DelegatorConfigurable(String delegatorName) &#123; this.delegatorName = delegatorName; &#125; /** * 获取delegator的具体方法 * 并做了分布式缓存和ECA Handler FIXME:未研究 * */ public Delegator call() throws ClassNotFoundException &#123; try &#123; Delegator delegator = UtilObject.getObjectFromFactory(DelegatorFactory.class, delegatorName); // setup the Entity ECA Handler delegator.initEntityEcaHandler(); // setup the distributed CacheClear delegator.initDistributedCacheClear(); return delegator; &#125; catch (ClassNotFoundException e) &#123; Debug.logError(e, module); throw e; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz方法之FreeMarkerWorker的makeConfiguration]]></title>
    <url>%2F2017%2F06%2F26%2Fofbiz%2Fofbiz10%2F</url>
    <content type="text"><![CDATA[代码展示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133public static Configuration makeConfiguration(BeansWrapper wrapper) &#123; /** * freemarker.template.Configuration实例并调整其设置。 * 一个Configuration实例是存储FreeMarker应用程序级别设置的中心。 * 另外，它处理预先解析的模板（即 对象）的创建和 缓存Template * */ Configuration newConfig = new Configuration(version); /** * @author jack * * 对象包装器 * wrapper == &gt;freemarker.ext.beans.BeansWrapper * 这是一个最原始的对象包装器，主要用来映射java * 虽然原始，但是也有使用的时候，比如collection-s和map-s被允许修改模板时执行 * 参考资料 http://freemarker.org/docs/pgui_misc_beanwrapper.html * */ newConfig.setObjectWrapper(wrapper); /** * @author jack * * 从beanswrapper返回TemplateHashModel。 * getstaticmodels()可以用来访问静态方法和任意一类的字段创建哈希模型。 * */ TemplateHashModel staticModels = wrapper.getStaticModels(); /** * @author jack * 将TemplateHashModel通过Static注入 以后就可以直接通过Static进行访问 * Shared variables共享变量是为所有模板定义的变量 * 形式：statics["java.lang.System"].currentTimeMillis() 这是一种调用java方法的处理方式 ftl中的用法 * */ newConfig.setSharedVariable("Static", staticModels); /** * @author jack * * #assign ls = EntityQuery.use(delegator).from("DictType").() ftl中的用法 * 注入后就可以直接使用EntityQuery了 * */ try &#123; newConfig.setSharedVariable("EntityQuery", staticModels.get("com.hanlin.fadp.entity.util.EntityQuery")); &#125; catch (TemplateModelException e) &#123; Debug.logError(e, module); &#125; /** * @author jack * * 当一个模板包含另一个模板时，它试图加载以相同的本地化环境加载模板。 * 假定你的模板以本地化en_US来加载，那就意味着是U.S. English。当你包含另外一个模板：那么引擎实际上就会寻找一些模板，并按照这个顺序： * footer_en_US.ftl * footer_en.ftl * footer.ftl * 设置成为false就不会有这些问题 * */ newConfig.setLocalizedLookup(false); //创建StringUtil这个工具类共享变量 newConfig.setSharedVariable("StringUtil", new BeanModel(StringUtil.INSTANCE, wrapper)); /** * @author jack * * 如果在这些内建的模版加载器中没有一个符合你的要求， * 那么你可以自己定制一个模版加载器，只需要实现freemarker.cache.TemplateLoader 接口就可以了， * 然后通过方法setTemplateLoader(TemplateLoader loader)把其传递给Configuration对象。 * 主要业务处理不是很清楚 * */ newConfig.setTemplateLoader(new FlexibleTemplateLoader()); /** * @author jack * * 导入库也就是说，它创建一个新的空命名空间 然后执行path在该命名空间中使用参数给出的模板 * 导入法则： * #import "/lib/example.ftl" as e * &lt;@e.copyright date="1999-2002"/&gt; * 属性文件中的模板就是通过这种方式加载进去 * 所以在调用的时候需要加入命令空间 * */ newConfig.setAutoImports(UtilProperties.getProperties("freemarkerImports")); /** * @author jack * * 自定义类实现TemplateExceptionHandler * 当ftl渲染出现异常调用这个类的handleTemplateException * */ newConfig.setTemplateExceptionHandler(new FreeMarkerWorker.OFBizTemplateExceptionHandler()); try &#123; newConfig.setSetting("datetime_format", "yyyy-MM-dd HH:mm:ss.SSS"); newConfig.setSetting("number_format", "0.##########"); &#125; catch (TemplateException e) &#123; Debug.logError("Unable to set date/time and number formats in FreeMarker: " + e, module); &#125; // Transforms properties file set up as key=transform name, property=transform class name /** * @author jack * * 获取上下文加载器，当前加载器在webapp,随意加载其中config的freemarkerTransforms.properties所有值 * */ ClassLoader loader = Thread.currentThread().getContextClassLoader(); Enumeration&lt;URL&gt; resources; try &#123; resources = loader.getResources("freemarkerTransforms.properties"); &#125; catch (IOException e) &#123; Debug.logError(e, "Could not load list of freemarkerTransforms.properties", module); throw UtilMisc.initCause(new InternalError(e.getMessage()), e); &#125; /** * @author jack * * 创建其中资源文件值得实例并通过key用setSharedVariable设置进入共享变量 * */ while (resources.hasMoreElements()) &#123; URL propertyURL = resources.nextElement(); Debug.logInfo("loading properties: " + propertyURL, module); Properties props = UtilProperties.getProperties(propertyURL); if (UtilValidate.isEmpty(props)) &#123; Debug.logError("Unable to locate properties file " + propertyURL, module); &#125; else &#123; loadTransforms(loader, props, newConfig); &#125; &#125; return newConfig; &#125; 用例说明1&lt;#assign displayApps = Static[&quot;org.ofbiz.webapp.control.LoginWorker&quot;].getAppBarWebInfos(security, userLogin, ofbizServerName, &quot;main&quot;)&gt; StringUtil1&lt;link rel=&quot;shortcut icon&quot; href=&quot;&lt;@ofbizContentUrl&gt;$&#123;StringUtil.wrapString(shortcutIcon)&#125;&lt;/@ofbizContentUrl&gt;&quot; /&gt;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz方法之条件查询createConditionList]]></title>
    <url>%2F2017%2F06%2F26%2Fofbiz%2Fofbiz11%2F</url>
    <content type="text"><![CDATA[方法代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110/** * Parses input parameters and returns an &lt;code&gt;EntityCondition&lt;/code&gt; list. * * @param parameters * @param fieldList * @param queryStringMap * @param delegator * @param context * @return returns an EntityCondition list * * @author jack * 第一步：获取所有字段信息 存入到Map&lt;String, ModelField&gt; fieldMap * 第二步：将上下文这个map进行遍历,这个map是传进来的参数 * 由于是根据参数，一个字段最多具有三个条件 _op _fld0_op _fld1_op * 第三步: 调用createSingleCondition创造条件，添加到集合 * * @param parameters 获取传入的参数 * @param fieldList 传入当前实体所有字段 * @param queryStringMap * @param delegator 操作数据库的实例 * @param context 获取上下文 */ public static List&lt;EntityCondition&gt; createConditionList(Map&lt;String, ? extends Object&gt; parameters, List&lt;ModelField&gt; fieldList, Map&lt;String, Object&gt; queryStringMap, Delegator delegator, Map&lt;String, ?&gt; context) &#123; Set&lt;String&gt; processed = new LinkedHashSet&lt;String&gt;(); Set&lt;String&gt; keys = new LinkedHashSet&lt;String&gt;(); Map&lt;String, ModelField&gt; fieldMap = new LinkedHashMap&lt;String, ModelField&gt;(); for (ModelField modelField : fieldList) &#123; fieldMap.put(modelField.getName(), modelField); &#125; List&lt;EntityCondition&gt; result = new LinkedList&lt;EntityCondition&gt;(); for (Map.Entry&lt;String, ? extends Object&gt; entry : parameters.entrySet()) &#123; String parameterName = entry.getKey(); //获取上下文中的键值 //如果已经有了这个键值在进程中就不在对它进行处理 if (processed.contains(parameterName)) &#123; continue; &#125; keys.clear(); String fieldName = parameterName; Object fieldValue = null; String operation = null; boolean ignoreCase = false; /** * 将参数名截断对应实体中的字段名，这样做的方式是先获取字段名 * (如果包含fld0 fld1下面则需要再截断）， * 下面进行连接，针对几种不同的情况进行处理 */ if (parameterName.endsWith("_ic") || parameterName.endsWith("_op")) &#123; fieldName = parameterName.substring(0, parameterName.length() - 3); &#125; else if (parameterName.endsWith("_value")) &#123; fieldName = parameterName.substring(0, parameterName.length() - 6); &#125; //_ic连接 是判断条件查找是否忽略大小写 String key = fieldName.concat("_ic"); if (parameters.containsKey(key)) &#123; keys.add(key); ignoreCase = "Y".equals(parameters.get(key)); &#125; //获取字段要进行的操作 key = fieldName.concat("_op"); if (parameters.containsKey(key)) &#123; keys.add(key); operation = (String) parameters.get(key); &#125; //获取字段的值,如果具有_fld0 这些可能获取不到，后面会进一步截断获取 key = fieldName.concat("_value"); if (parameters.containsKey(key)) &#123; keys.add(key); fieldValue = parameters.get(key); &#125; //主要是对时间进行处理，一个条件大于多少 小于多少 if (fieldName.endsWith("_fld0") || fieldName.endsWith("_fld1")) &#123; if (parameters.containsKey(fieldName)) &#123; keys.add(fieldName); &#125; fieldName = fieldName.substring(0, fieldName.length() - 5); &#125; //将字段名，之所以这样不断截断是为了获取对应与实体中的真实字段名 if (parameters.containsKey(fieldName)) &#123; keys.add(fieldName); &#125; processed.addAll(keys); ModelField modelField = fieldMap.get(fieldName); if (modelField == null) &#123; continue; &#125; //获取字段值 if (fieldValue == null) &#123; fieldValue = parameters.get(fieldName); &#125; //如果值为空，则不进行任何操作 if (ObjectType.isEmpty(fieldValue) &amp;&amp; !"empty".equals(operation)) &#123; continue; &#125; //将创建的条件加入list集合 即AND关系 result.add(createSingleCondition(modelField, operation, fieldValue, ignoreCase, delegator, context)); for (String mapKey : keys) &#123; queryStringMap.put(mapKey, parameters.get(mapKey)); &#125; &#125; return result; &#125; 方法使用1234567&lt;select name=&quot;visitId_op&quot; class=&quot;selectBox&quot;&gt; &lt;option value=&quot;equals&quot;&gt;等于&lt;/option&gt; &lt;option value=&quot;like&quot;&gt;开头字符&lt;/option&gt; &lt;option value=&quot;contains&quot; selected=&quot;selected&quot;&gt;包含&lt;/option&gt; &lt;option value=&quot;empty&quot;&gt;为空&lt;/option&gt; &lt;option value=&quot;notEqual&quot;&gt;不等于&lt;/option&gt;&lt;/select&gt;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ofbiz view渲染处理机制]]></title>
    <url>%2F2017%2F06%2F16%2Fofbiz%2Fofbiz12%2F</url>
    <content type="text"><![CDATA[初始化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ControlServlet.java 这是一个servlet,其配置文件在web.xml里 1234567891011&lt;servlet&gt; &lt;servlet-name&gt;ControlServlet&lt;/servlet-name&gt; &lt;display-name&gt;ControlServlet&lt;/display-name&gt; &lt;description&gt;MainControl Servlet&lt;/description&gt; &lt;servlet-class&gt;org.apache.ofbiz.webapp.control.ControlServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;ControlServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/control/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这也是为什么大多数请求都是组件名/control/* 首先在第一次请求时经过Servlet的init方法，该Servlet方法如下： 123456789101112131415public void init(ServletConfig config) throws ServletException &#123; super.init(config); if (Debug.infoOn()) &#123; ServletContext servletContext = config.getServletContext(); String webappName = servletContext.getContextPath().length() != 0 ?servletContext.getContextPath().substring(1) : ""; Debug.logInfo("Loading webapp [" + webappName + "],located at " + servletContext.getRealPath("/"), module);&#125; //配置默认脚本引擎，默认有beanshell和平台自定义的minilang脚本，可扩展其它脚本 configureBsf(); // 初始化request处理句柄，实质就是加载controller.xml中handler节点中class属性值对应类的实例化和初始化 getRequestHandler();&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 该方法中的getRequestHandler就是获取所有的handler节点，加载方式如下 123456789/** * @Title: getRequestHandler * @Description: 获取request的处理句柄，request处理分两类，一类是view， * 另一类是event，对应controller.xml中handler节点的配置信息的获取 * @return: RequestHandler */ protected RequestHandler getRequestHandler() &#123; return RequestHandler.getRequestHandler(getServletContext());&#125; 12345678910111213141516/** * @Title: getRequestHandler * @Description: 在上下文中新建一个requesthandler，命名为_REQUEST_HANDLER_， * 构造方法为private，此方法共外界获取实例，为单例模式使用，requesthandler配置来至 * 处理controller.xml中handler节点的配置数据 * @param servletContext * @return: RequestHandler */ public static RequestHandler getRequestHandler(ServletContextservletContext) &#123; RequestHandler rh = (RequestHandler)servletContext.getAttribute("_REQUEST_HANDLER_"); if (rh == null) &#123; rh = newRequestHandler(servletContext); servletContext.setAttribute("_REQUEST_HANDLER_", rh); &#125; return rh;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 其中的RequestHandler方法如下 12345678910111213141516171819202122232425/** * @author jack * 第一步:将controller.xml的解析信息加入到缓存中 * */ private RequestHandler(ServletContext context) &#123; // init the ControllerConfig, but don't save it anywhere, just load itinto the cache this.controllerConfigURL = ConfigXMLReader.getControllerConfigURL(context); try &#123; //将controller.xml的解析信息加入到缓存中 ConfigXMLReader.getControllerConfig(this.controllerConfigURL); &#125; catch (WebAppConfigurationException e) &#123; // FIXME: controller.xml errors should throw an exception. Debug.logError(e, "Exception thrown while parsing controller.xmlfile: ", module); &#125; //加载ViewHandler实现类的实例，其为controller.xml中handler的类型为view this.viewFactory = new ViewFactory(context,this.controllerConfigURL); //加载EventHandler实现类的实例，其为controller.xml中handler的类型为非view的情况 this.eventFactory = new EventFactory(context, this.controllerConfigURL); this.forceHttpSession ="true".equalsIgnoreCase(context.getInitParameter("forceHttpSession")); this.trackServerHit =!"false".equalsIgnoreCase(context.getInitParameter("track-serverhit")); this.trackVisit =!"false".equalsIgnoreCase(context.getInitParameter("track-visit")); this.cookies = !"false".equalsIgnoreCase(context.getInitParameter("cookies")); this.charset = context.getInitParameter("charset");&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 其具体存储方式如下 12345678910111213141516171819202122232425262728293031/** * @author jack * 构建ViewHandler实现类的map，对handler节点的class属性值对应的类进行实例化和初始化， * 并设置key=default时，其value=com.hanlin.fadp.webapp.view.JspViewHandler的实例 * @param context * @param controllerConfigURL */ public ViewFactory(ServletContext context, URL controllerConfigURL) &#123; // load all the view handlers try &#123; Set&lt;Map.Entry&lt;String,String&gt;&gt; handlerEntries =ConfigXMLReader.getControllerConfig(controllerConfigURL).getViewHandlerMap().entrySet(); if (handlerEntries != null) &#123; for(Map.Entry&lt;String,String&gt; handlerEntry: handlerEntries) &#123; //将对应的handler给实例化 ViewHandlerhandler = (ViewHandler) ObjectType.getInstance(handlerEntry.getValue()); handler.setName(handlerEntry.getKey()); handler.init(context); this.handlers.put(handlerEntry.getKey(),handler); &#125; &#125; // load the "default" type if (!this.handlers.containsKey("default")) &#123; ViewHandler defaultHandler =(ViewHandler) ObjectType.getInstance("com.hanlin.fadp.webapp.view.JspViewHandler"); defaultHandler.init(context); this.handlers.put("default", defaultHandler); &#125; &#125; catch (Exception e) &#123; Debug.logError(e, module); throw new GeneralRuntimeException(e); &#125; &#125; 渲染处理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在经过多contoller文件的request 和response标签处理后，其中的response中对应type=“view”会到对应的view-map标签处理，最终处理如下： 123456789try &#123; if (Debug.verboseOn())Debug.logVerbose("Rendering view [" + nextPage + "] of type[" + viewMap.type + "]", module); ViewHandlervh = viewFactory.getViewHandler(viewMap.type); vh.render(view,nextPage, viewMap.info, contentType, charset, req, resp); &#125; catch (ViewHandlerException e) &#123; Throwable throwable = e.getNested()!= null ? e.getNested() : e; throw newRequestHandlerException(e.getNonNestedMessage(), throwable); &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 标记的第一步是根据key获取上文初始化中的对应ViewHandler实例，这个key来自于view-map中的screen.具体操作如下 1234567891011public ViewHandlergetViewHandler(String type) throws ViewHandlerException &#123; if (UtilValidate.isEmpty(type)) &#123; type = "default"; &#125; // get the view handler by type fromthe contextHandlers ViewHandler handler =handlers.get(type); if (handler == null) &#123; throw newViewHandlerException("No handler found for type: " + type); &#125; return handler; &#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 标记的第二步是进行具体的渲染，针对于不同类型有不同实现类进行处理，在这里只是展示一下它的接口 1234567891011/** * Render the page. * * @param name The name of the view. * @param page The source of the view;could be a page, url, etc depending on the type of handler. * @param info An info string attached tothis view * @param request The HttpServletRequestobject used when requesting this page. * @param response The HttpServletResponseobject to be used to present the page. * @throws ViewHandlerException */ public void render(String name, Stringpage, String info, String contentType, String encoding, HttpServletRequestrequest, HttpServletResponse response) throws ViewHandlerException;]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hashMap]]></title>
    <url>%2F2017%2F01%2F10%2FJdk%2F2018-01-10%2F</url>
    <content type="text"><![CDATA[hashMap的简介1.HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。2.HashMap 继承于AbstractMap，实现了Map、Cloneable、java.io.Serializable接口 hashMap的关系结构图 hashMap的构造器■ HashMap():构建一个初始容量为16,负载因子为0.75的HashMap。■ HashMap(int initialCapacity):构建一个初始容量为 initialCapacity，负栽因子为0.75的 HashMap.■ HashMap(int initialCapacity, float loadFactor):以指定初始容量、指定的负栽因子创建一 个 HashMap. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; init(); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */ public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */ public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR); &#125; /** * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the * specified &lt;tt&gt;Map&lt;/tt&gt;. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); inflateTable(threshold); putAllForCreate(m); &#125; 当创建一个HashMap时，系统会自动创建一个table数组来保存HashMap中的Entry。下 面是HashMap中一个构造器的代码 table = new Entry[capacity]; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; hashMap has four Constructs, at first we must know the public HashMap(int initialCapacity, float loadFactor)]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring doGetBean源码解读]]></title>
    <url>%2F2017%2F01%2F07%2Fspring%2F2018-01-07-2%2F</url>
    <content type="text"><![CDATA[AbstractBeanFactory 123456789101112/** * Return an instance, which may be shared or independent, of the specified bean. * @param name the name of the bean to retrieve * @param requiredType the required type of the bean to retrieve * @param args arguments to use when creating a bean instance using explicit arguments * (only applied when creating a new instance as opposed to retrieving an existing one) * @param typeCheckOnly whether the instance is obtained for a type check, * not for actual use * @return an instance of the bean * @throws BeansException if the bean could not be created */protected &lt;T&gt; T doGetBean(final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) 1.name转化为规范形式beanname2.根据beanname调用getSingleton获取相应的单例3.如果2中没有获取则根据beanname获取RootBeanDefinition而后通过匿名内部类的方式创建其单例]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring ClassPathXmlApplicationContext代码解读]]></title>
    <url>%2F2017%2F01%2F07%2Fspring%2F2018-01-07-1%2F</url>
    <content type="text"><![CDATA[实例化ClassPathXmlApplicationContext12ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext( new String[] &#123; "spring-context.xml" &#125;); 调用父级构造器123this(configLocations, refresh, null);。。。。。。super(parent); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在实例化的过程中不断调用父类构造器直到找到AbstractApplicationContext,调用this方法实例化PathMatchingResourcePatternResolver并注入作为句柄。并且该实例的resourceLoader句柄的值就是当前ClassPathXmlApplicationContext实例。这个时候ClassPathXmlApplicationContext中传入的父级上下文为空，所以父级上下文始终为空。 设置配置文件路径1setConfigLocations(configLocations); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个代码中,主要做的事情是设置配置文件的路径。如上文中的spring-context.xml，最终将其存入configLocations这个String数组中。 refresh方法123if (refresh) &#123; refresh();&#125; 具体代码过程如下: 12/** 这里会重新设置容器启动时间和启动标志字段*/ prepareRefresh(); 1234567891011121314151617181920ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();``` 通知子类刷新beanFactory，具体实现在AbstractRefreshableApplicationContext中， 注这里的默认实例&gt; 1.如果当前Context持有beanFactory，则先destoryBeans，再关闭beanFactory &gt; &gt; 2.createBeanFactory：用父容器创建一个DefaultListableBeanFactory，（这里如果父容器为ConfigurableApplicationContext， 则返回该context持有的beanFacotry，否则直接返回父BeanFactory。ps：这里可能就是context和beanFactory的区分点） &gt; &gt; 3.customizeBeanFactory：根据参数设置是否允许子类定制DefaultListableBeanFactory。 &gt; &gt; 4.loadBeanDefinitions：加载BeanDefinitions，具体实现在AbstractXmlApplicationContext中。（TODO：后面会详细扩展讲解） 并返回子类的beanFactory &gt; &gt; ```javaprepareBeanFactory(beanFactory); 1.设置ClassLoader 2.addPropertyEditorRegistrar，设置用户定义的propertyEditor注册器 3.addBeanPostProcessor，设置ApplicationContextAwareProcessor， 处理ApplicationContextAware实现接口的Bean。 4.ignoreDependencyInterface，设置不解析某些接口的依赖关系 5.registerResolvableDependency,设置特殊接口和bean的绑定关系 /* 提供接口给子类修改beanFactory。 / postProcessBeanFactory(beanFactory); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** 调用注册的BeanFactoryPostProcessor，按照实现的排序接口PriorityOrdered&gt;Ordered&gt;无接口 */ invokeBeanFactoryPostProcessors(beanFactory); /** 按照排序接口，依次注册BeanPostProcessor，后面会按照这个顺序调用 */ registerBeanPostProcessors(beanFactory); /** * 初始化messageSource,（MessageSource接口用于支持国际化）如果context中尤定义id为messageSource * 的MessageSource接口的bean（潜规则），则采用它来解析Message资源，否则采用父容器messageSource，这里会创建一个DelegatingMessageSource， * 避免为空的情况导致调用失败。 */ initMessageSource(); /** * 初始化并注册ApplicationEventMulticaster，容器事情广播器，同样采用MessageSource类似的潜规则， * 如果容器中有名为applicationEventMulticaster且实现了ApplicationEventMulticaster接口的bean，则注册它， * 否则创建SimpleApplicationEventMulticaster，将它当作默认的广播器。 */ initApplicationEventMulticaster(); /** 给子类保留的接口，通知子类刷新 */ onRefresh(); /** 获取容器中定义的所有ApplicationListener，容器事件监听器，并注册 */ registerListeners(); /** * 1.清除用于类型匹配的classLoader * 2.冻结bean definitions中设置，不能再修改bean的配置 * 3.实例化非延迟加载的单例bean，包括由FactoryBean实例化的bean（TODO：需要进一步深挖） */ finishBeanFactoryInitialization(beanFactory); /** 广播ContextRefreshedEvent容器刷新事件。 */ finishRefresh(); ``` # 调用ClassPathXmlApplicationContext的start方法```javapublic void start() &#123; getLifecycleProcessor().start(); publishEvent(new ContextStartedEvent(this));&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面展示它的具体实现方法.getLifecycleProcessor获取的默认的实例是，在其中会调用如下: 1234public void start() &#123; startBeans(false); this.running = true;&#125; 1234567891011121314151617181920212223private void startBeans(boolean autoStartupOnly) &#123; Map&lt;String, Lifecycle&gt; lifecycleBeans = getLifecycleBeans(); Map&lt;Integer, LifecycleGroup&gt; phases = new HashMap&lt;Integer, LifecycleGroup&gt;(); for (Map.Entry&lt;String, ? extends Lifecycle&gt; entry : lifecycleBeans.entrySet()) &#123; Lifecycle bean = entry.getValue(); if (!autoStartupOnly || (bean instanceof SmartLifecycle &amp;&amp; ((SmartLifecycle) bean).isAutoStartup())) &#123; int phase = getPhase(bean); LifecycleGroup group = phases.get(phase); if (group == null) &#123; group = new LifecycleGroup(phase, this.timeoutPerShutdownPhase, lifecycleBeans, autoStartupOnly); phases.put(phase, group); &#125; group.add(entry.getKey(), bean); &#125; &#125; if (phases.size() &gt; 0) &#123; List&lt;Integer&gt; keys = new ArrayList&lt;Integer&gt;(phases.keySet()); Collections.sort(keys); for (Integer key : keys) &#123; phases.get(key).start(); &#125; &#125;&#125; 12345678910public void publishEvent(ApplicationEvent event) &#123; Assert.notNull(event, "Event must not be null"); if (logger.isTraceEnabled()) &#123; logger.trace("Publishing event in " + getDisplayName() + ": " + event); &#125; getApplicationEventMulticaster().multicastEvent(event); if (this.parent != null) &#123; this.parent.publishEvent(event); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以第一句的作用是添加相应监听器，第二句的作用是通知监听器，然后执行相应的时间 loadBeanDefinitions&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个里面有个东西需要单独说明一下，即装载bean。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring IOC源码分析]]></title>
    <url>%2F2017%2F01%2F07%2Fspring%2F2018-01-07%2F</url>
    <content type="text"><![CDATA[What is IOC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ioc—Inversion of Control，即“控制反转”，不是什么技术，而是一种设计思想&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 谁控制谁，控制什么：Ioc容器来控制对象的创建,控制了外部资源获取&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为何是反转，哪些方面反转了：因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转,依赖对象的获取被反转了 传统程序设计: IOC容器模型: IOC的作用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IoC是一个重要的面向对象编程的法则，它能指导我们如何设计出松耦合、更优良的程序。即由IoC容器帮对象找相应的依赖对象并注入，而不是由对象主动去找。 参考链接：http://jinnianshilongnian.iteye.com/category/206533]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo环境搭建]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[#解压dubbo-admin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将dubbo-admin解压到tomcat的webapps下面 解压命令unzip dubbo-admin.war -d dubbp-admin #修改属性文件 1.将用户密码都改成root2.修改相应地址 截图如下: #启动tomcat&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;直接将tomcat启动，启动之后可以查看相应的日志，启动命令：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在相应的bin目录下执行startup.sh日志命令:tail -f -n 500 /usr/local/dubbo-tomcat/logs/catalina.out]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git基本指令]]></title>
    <url>%2F2017%2F01%2F02%2Fgit%2F2017-12-29%2F</url>
    <content type="text"><![CDATA[The knowledge of gitbase codegit init在当前目录生成的一个管理git仓库的文件夹，这里包含所有git操作所需要的东西 1 hooks:这个目录存放一些shell脚本，可以设置特定的git命令后触发相应的脚本；在搭建gitweb系统或其他git托管系统会经常用到hook script。 2 info:包含仓库的一些信息 3 logs:保存所有更新的引用记录 4 objects:该目录存放所有的Git对象，对象的SHA1哈希值的前两位是文件夹名称，后38位作为对象文件名。比如前面log里的HEAD文件里有个哈希值5426426e3ccc9ab4e3330640862a7b96e28828af 5 refs:具体的引用，Reference Specification，这个目录一般包括三个子文件夹，heads、remotes和tags，比如，heads中的master文件标识了项目中的master分支指向的当前commit，其他类似。 6 COMMIT_EDITMSG:保存最新的commit message，Git系统不会用到这个文件，只是给用户一个参考 7 config:这个是GIt仓库的配置文件 8 description:仓库的描述信息，主要给gitweb等git托管系统使用 9 index:这个文件就是我们前面提到的暂存区（stage），是一个二进制文件 10 HEAD:这个文件包含了一个分支（branch）的引用，通过这个文件Git可以得到下一次commit的parent，什么是引用呢，你可以理解为指针，哪儿都可以指，但是不能指向没有的东西哦。详细介绍请看这里： ###git add git add . ：他会监控工作区的状态树，使用它会把工作时的所有变化提交到暂存区，包括文件内容修改(modified)以及新文件(new)，但不包括被删除的文件。 git add -u ：他仅监控已经被add的文件（即tracked file），他会将被修改的文件提交到暂存区。add -u 不会提交新文件（untracked file）。（git add –update的缩写） git add -A ：是上面两个功能的合集（git add –all的缩写） git remotegit remote add:命令用于添加远程主机 1git remote add &lt;主机名&gt; &lt;网址&gt; src refspec master does not match any.]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[druid分析]]></title>
    <url>%2F2017%2F01%2F02%2Fdruid%2F2017-12-30%2F</url>
    <content type="text"><![CDATA[The analysis of DruidInstancing DruidDataSourceDruidDataSource have two Constructor,and the one without any argument will invoke another by writing a argument, as follows At first, We find it will invoke super(fairLock),its default value is false by instancing the constructor without any argument , it wil call the superclass object and invoke the methods of configFromPropety to Set up relevant property values by getting System property values. Its superclass object constructor is shown below: In superclass object constructor,the instance create Creates an instance of ReentrantLock with the given unfairness policy. after that it will create Condition instance for use with this Lock instance. The returned Condition instance supports the same usages as do the Object monitor methods (wait, notify, and notifyAll) when used with the built-in monitor lock.]]></content>
      <categories>
        <category>druid</category>
      </categories>
      <tags>
        <tag>druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo源码分析1-spring方式启动]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2F2018-01-07%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在一下的代码中主要是装载标签元素并进行解析，其中装载是根据namespaceUri找到对应的句柄，然后通过句柄来解析自己定义的元素. 123456789public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; String namespaceUri = getNamespaceURI(ele); NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error("Unable to locate Spring NamespaceHandler for XML schema namespace [" + namespaceUri + "]", ele); return null; &#125; return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));&#125; 装载标签元素Spring为了支持用户自定义类加载到Spring容器，提供了org.springframework.beans.factory.xml.NamespaceHandler接口org.springframework.beans.factory.xml.NamespaceHandlerSupport抽象类，NamespaceHandler#init方法会在对象的构造函数调用之后、属性初始化之前被DefaultNamespaceHandlerResolver调用。dubbo的DubboNamespaceHandler类正是继承了NamespaceHandlerSupport所以在spring加载过程中会执行这个类中的内容 1234567891011121314151617181920public class DubboNamespaceHandler extends NamespaceHandlerSupport &#123; static &#123; Version.checkDuplicate(DubboNamespaceHandler.class); &#125; public void init() &#123; registerBeanDefinitionParser("application", new DubboBeanDefinitionParser(ApplicationConfig.class, true)); registerBeanDefinitionParser("module", new DubboBeanDefinitionParser(ModuleConfig.class, true)); registerBeanDefinitionParser("registry", new DubboBeanDefinitionParser(RegistryConfig.class, true)); registerBeanDefinitionParser("monitor", new DubboBeanDefinitionParser(MonitorConfig.class, true)); registerBeanDefinitionParser("provider", new DubboBeanDefinitionParser(ProviderConfig.class, true)); registerBeanDefinitionParser("consumer", new DubboBeanDefinitionParser(ConsumerConfig.class, true)); registerBeanDefinitionParser("protocol", new DubboBeanDefinitionParser(ProtocolConfig.class, true)); registerBeanDefinitionParser("service", new DubboBeanDefinitionParser(ServiceBean.class, true)); registerBeanDefinitionParser("reference", new DubboBeanDefinitionParser(ReferenceBean.class, false)); registerBeanDefinitionParser("annotation", new DubboBeanDefinitionParser(AnnotationBean.class, true)); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过上面发现所有的标签元素都是通过registerBeanDefinitionParser注册，这个方法主要是将所有的标签对应的解析定义注入一个parsers这个Map 123protected final void registerBeanDefinitionParser(String elementName, BeanDefinitionParser parser) &#123; this.parsers.put(elementName, parser);&#125; #解析标签元素&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将所有dubbo的标签给装载之后，就是对具体的标签进行解析，首先展示一下解析逻辑,从这里可以看出来，它是根据具体的标签元素找到DubboBeanDefinitionParser这个实例,然后开始进行解析。 12345678910111213141516171819202122232425/** * Parse the elements at the root level in the document: * "import", "alias", "bean". * @param root the DOM root element of the document */protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; else &#123; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125;&#125; 123456789public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; String namespaceUri = getNamespaceURI(ele); NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error("Unable to locate Spring NamespaceHandler for XML schema namespace [" + namespaceUri + "]", ele); return null; &#125; return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));&#125; 1234@Overridepublic BeanDefinition parse(Element element, ParserContext parserContext) &#123; return findParserForElement(element, parserContext).parse(element, parserContext);&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意在这里将上面注册的beanClass给传入进去，所以在解析beanDefinition的时候就可以获取到这个标签的具体类实例 123public BeanDefinition parse(Element element, ParserContext parserContext) &#123; return parse(element, parserContext, beanClass, required);&#125;]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo源码分析2-远程接口暴露过程]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2FReferenceConfig%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在提供接口服务的过程，都是围绕着一行代码展开，如下:&lt;dubbo:reference interface=&quot;cfs.com.facade.SysUserFacade&quot; id=&quot;sysUserFacade&quot; /&gt; 获取相应ReferenceBean&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里我们先要获取的是相应的ReferenceFactoryBean具体过程在dubbo源码分析1-spring方式启动中,首先装载所有标签相应的 DubboNamespaceHandler.java 1registerBeanDefinitionParser("reference", new DubboBeanDefinitionParser(ReferenceBean.class, false)); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据DubboBeanDefinitionParser来解析，在loadBeanDefinitions中将所有的BeanDefinition解析出来生成形影的ReferenceBean DubboBeanDefinitionParser.java 1private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) &#123;&#125; 调用ReferenceBean的get方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于ReferenceBean继承ReferenceConfig，且自身没有覆盖get方法所以调用的是ReferenceConfig中. 123456789public synchronized T get() &#123; if (destroyed)&#123; throw new IllegalStateException("Already destroyed!"); &#125; if (ref == null) &#123; init(); &#125; return ref;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由上可以看出其核心方法是调用init 1.验证时候初始化，如果已经初始化直接返回2.保证接口名长度不为空或者03.配置消费者和提供者全局属性4.获取相应的接口全限定类名5.设置基础属性6.将属性添加到context_map这个静态map中去7.创建相应的代理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142 private void init() &#123; if (initialized) &#123; return; &#125; initialized = true; if (interfaceName == null || interfaceName.length() == 0) &#123; throw new IllegalStateException("&lt;dubbo:reference interface=\"\" /&gt; interface not allow null!"); &#125; // 获取消费者全局配置 checkDefault(); appendProperties(this); if (getGeneric() == null &amp;&amp; getConsumer() != null) &#123; setGeneric(getConsumer().getGeneric()); &#125; if (ProtocolUtils.isGeneric(getGeneric())) &#123; interfaceClass = GenericService.class; &#125; else &#123; try &#123; interfaceClass = Class.forName(interfaceName, true, Thread.currentThread() .getContextClassLoader());&#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e);&#125; checkInterfaceAndMethods(interfaceClass, methods); &#125; String resolve = System.getProperty(interfaceName); String resolveFile = null; if (resolve == null || resolve.length() == 0) &#123; resolveFile = System.getProperty("dubbo.resolve.file"); if (resolveFile == null || resolveFile.length() == 0) &#123; File userResolveFile = new File(new File(System.getProperty("user.home")), "dubbo-resolve.properties"); if (userResolveFile.exists()) &#123; resolveFile = userResolveFile.getAbsolutePath(); &#125; &#125; if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) &#123; Properties properties = new Properties(); FileInputStream fis = null; try &#123; fis = new FileInputStream(new File(resolveFile)); properties.load(fis); &#125; catch (IOException e) &#123; throw new IllegalStateException("Unload " + resolveFile + ", cause: " + e.getMessage(), e); &#125; finally &#123; try &#123; if(null != fis) fis.close(); &#125; catch (IOException e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; resolve = properties.getProperty(interfaceName); &#125; &#125; if (resolve != null &amp;&amp; resolve.length() &gt; 0) &#123; url = resolve; if (logger.isWarnEnabled()) &#123; if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) &#123; logger.warn("Using default dubbo resolve file " + resolveFile + " replace " + interfaceName + "" + resolve + " to p2p invoke remote service."); &#125; else &#123; logger.warn("Using -D" + interfaceName + "=" + resolve + " to p2p invoke remote service."); &#125; &#125; &#125; if (consumer != null) &#123; if (application == null) &#123; application = consumer.getApplication(); &#125; if (module == null) &#123; module = consumer.getModule(); &#125; if (registries == null) &#123; registries = consumer.getRegistries(); &#125; if (monitor == null) &#123; monitor = consumer.getMonitor(); &#125; &#125; if (module != null) &#123; if (registries == null) &#123; registries = module.getRegistries(); &#125; if (monitor == null) &#123; monitor = module.getMonitor(); &#125; &#125; if (application != null) &#123; if (registries == null) &#123; registries = application.getRegistries(); &#125; if (monitor == null) &#123; monitor = application.getMonitor(); &#125; &#125; checkApplication(); checkStubAndMock(interfaceClass); Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); Map&lt;Object, Object&gt; attributes = new HashMap&lt;Object, Object&gt;(); map.put(Constants.SIDE_KEY, Constants.CONSUMER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; if (! isGeneric()) &#123; String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put("revision", revision); &#125; String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if(methods.length == 0) &#123; logger.warn("NO method found in service interface " + interfaceClass.getName()); map.put("methods", Constants.ANY_VALUE); &#125; else &#123; map.put("methods", StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), ",")); &#125; &#125; map.put(Constants.INTERFACE_KEY, interfaceName); appendParameters(map, application); appendParameters(map, module); appendParameters(map, consumer, Constants.DEFAULT_KEY); appendParameters(map, this); String prifix = StringUtils.getServiceKey(map); if (methods != null &amp;&amp; methods.size() &gt; 0) &#123; for (MethodConfig method : methods) &#123; appendParameters(map, method, method.getName()); String retryKey = method.getName() + ".retry"; if (map.containsKey(retryKey)) &#123; String retryValue = map.remove(retryKey); if ("false".equals(retryValue)) &#123; map.put(method.getName() + ".retries", "0"); &#125; &#125; appendAttributes(attributes, method, prifix + "." + method.getName()); checkAndConvertImplicitConfig(method, map, attributes); &#125; &#125; //attributes通过系统context进行存储. StaticContext.getSystemContext().putAll(attributes); ref = createProxy(map); &#125; createProxy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个方式是init中的最后一步，创建相应的url 1.先判断是否是本地服务引用injvm 2.判断是否是点对点直连 3.判断是否是通过注册中心连接 4.然后是服务的引用]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo相关问题]]></title>
    <url>%2F2017%2F01%2F02%2Fdubbo%2F2017-12-29%2F</url>
    <content type="text"><![CDATA[The question of dubboQ1防火墙问题:关闭命令： service iptables stop永久关闭防火墙：chkconfig iptables off永久关闭需要两条语句都运行]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac切换jdk]]></title>
    <url>%2F2017%2F01%2F01%2Fother%2F2018-01-03%2F</url>
    <content type="text"><![CDATA[#切换jdk命令 切换版本： jenv use java 1.8设置缺少版本： jenv default java 1.8]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven命令使用指南]]></title>
    <url>%2F2017%2F01%2F01%2Fmaven%2F2018-01-03%2F</url>
    <content type="text"><![CDATA[#基本命令 编译源代码: mvn compile编译测试代码：mvn test-compile运行测试：mvn test产生site：mvn site打包：mvn package -Dmaven.test.skip=true(跳过测试) #编译jar到本地仓库 mvn install:install-file -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4-1.7 -Dpackaging=jar -Dfile=dubbo-2.8.4.jar mvn install:install-file -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4-1.7 -Dpackaging=jar -Dfile=dubbo-2.8.4-sources.jar -Dclassifier=sources mvn install:install-file -DgroupId=com.alibaba -DartifactId=dubbo -Dversion=2.8.4-1.7 -Dpackaging=jar -Dfile=dubbo-2.8.4-javadoc.jar -Dclassifier=javadoc]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea相关问题]]></title>
    <url>%2F2017%2F01%2F01%2Fother%2F2018-01-02%2F</url>
    <content type="text"><![CDATA[Q1源发行版 1.6 需要目标发行版 1.6 setting-&gt;Compiler-&gt;Java Compiler 设置相应Module的target byte code version的合适版本就行来（搜索首选项）]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea上svn相关问题]]></title>
    <url>%2F2017%2F01%2F01%2Fother%2F2018-01-04%2F</url>
    <content type="text"><![CDATA[idea上不显示svn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IntelliJ IDEA打开带SVN信息的项目不显示SVN信息，项目右键SVN以及图标还有Changes都不显示解决方法在VCS菜单中有个开关，叫Enabled Version Control Integration，在打开的窗口的选项中选择Subversion即可 idea忽略某些文件更新]]></content>
      <categories>
        <category>idea</category>
      </categories>
      <tags>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven错误记录]]></title>
    <url>%2F2017%2F01%2F01%2Fmaven%2F2018-01-05%2F</url>
    <content type="text"><![CDATA[不能部署1Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.5: deploy (default-deploy) 这是在发布到私服的过程中，可能]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ofbiz模块加载机制即创建独立模块（脱离热部署)]]></title>
    <url>%2F2016%2F07%2F25%2Fofbiz%2Fofbiz13%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 一般我们在ofbiz下的hot-deploy下直接创建模块组件就可以进行访问，但是我觉得文件过多话，就不方便管理，所以我们可以分离出来单独建立一个文件模块，原理大家可以从启动类开始看，在这里我只说明一下操作步骤,因为好多东西我也没看懂呢。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一步：找到framework\base\config\component-load.xml这个文件，内容如下： 1234567891011121314151617&lt;component-loaderxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/component-loader.xsd&quot;&gt; &lt;load-components parent-directory=&quot;framework&quot;/&gt; &lt;load-components parent-directory=&quot;themes&quot;/&gt; &lt;load-components parent-directory=&quot;applications&quot;/&gt; &lt;load-components parent-directory=&quot;specialpurpose&quot;/&gt; &lt;load-components parent-directory=&quot;hot-deploy&quot;/&gt; &lt;load-components parent-directory=&quot;wuliys&quot;/&gt;&lt;/component-loader&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 很显然start类通过该文件属性，找到相应的子目录，如图所示： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当然这里的runtime和tools文件夹并没有加载进来，因为它们一个是运行，一个是工具存放的.而其它模块则加载进来了，文件夹是加载进来了，然后怎么进行具体操作.看第二步. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第二步:因为上面的除了最后一个都是系统存在的，所以我就拿自己创建的一个模块做例子讲述.，文件分级如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 我们先看看component-load.xml文件里面是什么(文件路径已经从同级开始往下哈哈)如下： 1234567891011&lt;?xmlversion=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;component-loaderxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ofbiz.apache.org/dtds/component-loader.xsd&quot;&gt; &lt;load-componentcomponent-location=&quot;mytest&quot;/&gt; &lt;load-componentcomponent-location=&quot;myparty&quot;/&gt; &lt;/component-loader&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 很显然就是通过load-component这一元素将mytest和myparty这两个文件加给加载进来。至于这两个模块就是我们能够写具体请求应用的模块。至于具体请求可以参考网上的热部署hello,world差不多]]></content>
      <categories>
        <category>OFBiz</category>
      </categories>
      <tags>
        <tag>OFBiz</tag>
      </tags>
  </entry>
</search>
